@incollection{GAUR2026107,
title = {Chapter 7 - Ethical concern of data privacy and patient data ownership},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {107-130},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00014-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044333124400014X},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {AI data breaches, Data ownership, Generative AI, Healthcare AI ethics, HIPAA, Patient data privacy, Transparency in AI},
abstract = {Generative artificial intelligence (AI) in healthcare offers remarkable advancements in patient care, such as personalized treatment plans and predictive diagnostics, but also raises significant ethical concerns surrounding data privacy and patient data ownership. This chapter explores these dual-edged issues, beginning with the promise of AI-driven healthcare and the rising worries about data privacy violations. It delves into the core concepts of data privacy in healthcare, examining how generative AI processes patient data and the risks of breaches and unauthorized access. The chapter also addresses patient data ownership, exploring the ethical tension between the need for vast datasets to train AI models and the right of patients to control their personal health information. It further assesses the effectiveness of privacy laws like HIPAA, identifying gaps and limitations that require reform to protect patient data in AI applications. Through case studies, the chapter illustrates real-world ethical dilemmas, including data breaches and the monetization of patient information by AI companies. Finally, it proposes best practices for developing privacy frameworks and enhancing transparency and accountability to foster trust in AI-driven healthcare.}
}
@article{SPALLEK2023,
title = {Can we use ChatGPT for Mental Health and Substance Use Education? Examining Its Quality and Potential Harms},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/51243},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000831},
author = {Sophia Spallek and Louise Birrell and Stephanie Kershaw and Emma Krogh Devine and Louise Thornton},
keywords = {artificial intelligence, generative artificial intelligence, large language models, ChatGPT, medical education, health education, patient education handout, preventive health services, educational intervention, mental health, substance use},
abstract = {Background
The use of generative artificial intelligence, more specifically large language models (LLMs), is proliferating, and as such, it is vital to consider both the value and potential harms of its use in medical education. Their efficiency in a variety of writing styles makes LLMs, such as ChatGPT, attractive for tailoring educational materials. However, this technology can feature biases and misinformation, which can be particularly harmful in medical education settings, such as mental health and substance use education. This viewpoint investigates if ChatGPT is sufficient for 2 common health education functions in the field of mental health and substance use: (1) answering users’ direct queries and (2) aiding in the development of quality consumer educational health materials.
Objective
This viewpoint includes a case study to provide insight into the accessibility, biases, and quality of ChatGPT’s query responses and educational health materials. We aim to provide guidance for the general public and health educators wishing to utilize LLMs.
Methods
We collected real world queries from 2 large-scale mental health and substance use portals and engineered a variety of prompts to use on GPT-4 Pro with the Bing BETA internet browsing plug-in. The outputs were evaluated with tools from the Sydney Health Literacy Lab to determine the accessibility, the adherence to Mindframe communication guidelines to identify biases, and author assessments on quality, including tailoring to audiences, duty of care disclaimers, and evidence-based internet references.
Results
GPT-4’s outputs had good face validity, but upon detailed analysis were substandard in comparison to expert-developed materials. Without engineered prompting, the reading level, adherence to communication guidelines, and use of evidence-based websites were poor. Therefore, all outputs still required cautious human editing and oversight.
Conclusions
GPT-4 is currently not reliable enough for direct-consumer queries, but educators and researchers can use it for creating educational materials with caution. Materials created with LLMs should disclose the use of generative artificial intelligence and be evaluated on their efficacy with the target audience.}
}
@article{AYYILDIZ2026103058,
title = {The use of ChatGPT in service recovery: Compensating customers},
journal = {Technology in Society},
volume = {84},
pages = {103058},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103058},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002489},
author = {Ahu Yazici Ayyildiz and Tugrul Ayyildiz and Erdogan Koc},
keywords = {Service failure, Service recovery, Compensation, Generative artificial intelligence, ChatGPT, Hospitality},
abstract = {Determining the appropriate compensation for customers is a crucial decision, as it may result in the wasting of resources and further exacerbating customer frustration. Making the right compensation decision requires a great deal of knowledge and expertise about the customers and their service encounters, as well as taking both the customers' and the service business's interests into account. This study investigates the usability of ChatGPT, as a generative AI tool, in identifying the severity of service failures for customers and producing an effective and efficient compensation suggestion accordingly. The two surveys in the study, carried out in two stages with 298 hotel customers and 54 managers from 5-star hotels, established that no single compensation strategy developed by ChatGPT can satisfy most of the customers, and a combination of compensation strategies needs to be used. The study has important theoretical and practical implications both regarding the field of generative AI, in terms of developing business solutions, and for the service recovery and compensation literature.}
}
@article{BARAKCORREN2024128,
title = {Harnessing the Power of Generative AI for Clinical Summaries: Perspectives From Emergency Physicians},
journal = {Annals of Emergency Medicine},
volume = {84},
number = {2},
pages = {128-138},
year = {2024},
issn = {0196-0644},
doi = {https://doi.org/10.1016/j.annemergmed.2024.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S0196064424000787},
author = {Yuval Barak-Corren and Rebecca Wolf and Ronen Rozenblum and Jessica K. Creedon and Susan C. Lipsett and Todd W. Lyons and Kenneth A. Michelson and Kelsey A. Miller and Daniel J. Shapiro and Ben Y. Reis and Andrew M. Fine},
abstract = {Study objective
The workload of clinical documentation contributes to health care costs and professional burnout. The advent of generative artificial intelligence language models presents a promising solution. The perspective of clinicians may contribute to effective and responsible implementation of such tools. This study sought to evaluate 3 uses for generative artificial intelligence for clinical documentation in pediatric emergency medicine, measuring time savings, effort reduction, and physician attitudes and identifying potential risks and barriers.
Methods
This mixed-methods study was performed with 10 pediatric emergency medicine attending physicians from a single pediatric emergency department. Participants were asked to write a supervisory note for 4 clinical scenarios, with varying levels of complexity, twice without any assistance and twice with the assistance of ChatGPT Version 4.0. Participants evaluated 2 additional ChatGPT-generated clinical summaries: a structured handoff and a visit summary for a family written at an 8th grade reading level. Finally, a semistructured interview was performed to assess physicians’ perspective on the use of ChatGPT in pediatric emergency medicine. Main outcomes and measures included between subjects’ comparisons of the effort and time taken to complete the supervisory note with and without ChatGPT assistance. Effort was measured using a self-reported Likert scale of 0 to 10. Physicians’ scoring of and attitude toward the ChatGPT-generated summaries were measured using a 0 to 10 Likert scale and open-ended questions. Summaries were scored for completeness, accuracy, efficiency, readability, and overall satisfaction. A thematic analysis was performed to analyze the content of the open-ended questions and to identify key themes.
Results
ChatGPT yielded a 40% reduction in time and a 33% decrease in effort for supervisory notes in intricate cases, with no discernible effect on simpler notes. ChatGPT-generated summaries for structured handoffs and family letters were highly rated, ranging from 7.0 to 9.0 out of 10, and most participants favored their inclusion in clinical practice. However, there were several critical reservations, out of which a set of general recommendations for applying ChatGPT to clinical summaries was formulated.
Conclusion
Pediatric emergency medicine attendings in our study perceived that ChatGPT can deliver high-quality summaries while saving time and effort in many scenarios, but not all.}
}
@article{POZDNIAKOV2024100289,
title = {Large language models meet user interfaces: The case of provisioning feedback},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100289},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100289},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000924},
author = {Stanislav Pozdniakov and Jonathan Brazil and Solmaz Abdi and Aneesha Bakharia and Shazia Sadiq and Dragan Gašević and Paul Denny and Hassan Khosravi},
keywords = {Artificial intelligence, Large language models, Generative artificial intelligence, Interfaces, Feedback, Learning analytics},
abstract = {Incorporating Generative Artificial Intelligence (GenAI), especially Large Language Models (LLMs), into educational settings presents valuable opportunities to boost the efficiency of educators and enrich the learning experiences of students. A significant portion of the current use of LLMs by educators has involved using conversational user interfaces (CUIs), such as chat windows, for functions like generating educational materials or offering feedback to learners. The ability to engage in real-time conversations with LLMs, which can enhance educators' domain knowledge across various subjects, has been of high value. However, it also presents challenges to LLMs' widespread, ethical, and effective adoption. Firstly, educators must have a degree of expertise, including tool familiarity, AI literacy and prompting to effectively use CUIs, which can be a barrier to adoption. Secondly, the open-ended design of CUIs makes them exceptionally powerful, which raises ethical concerns, particularly when used for high-stakes decisions like grading. Additionally, there are risks related to privacy and intellectual property, stemming from the potential unauthorised sharing of sensitive information. Finally, CUIs are designed for short, synchronous interactions and often struggle and hallucinate when given complex, multi-step tasks (e.g., providing individual feedback based on a rubric on a large scale). To address these challenges, we explored the benefits of transitioning away from employing LLMs via CUIs to the creation of applications with user-friendly interfaces that leverage LLMs through API calls. We first propose a framework for pedagogically sound and ethically responsible incorporation of GenAI into educational tools, emphasizing a human-centred design. We then illustrate the application of our framework to the design and implementation of a novel tool called Feedback Copilot, which enables instructors to provide students with personalized qualitative feedback on their assignments in classes of any size. An evaluation involving the generation of feedback from two distinct variations of the Feedback Copilot tool, using numerically graded assignments from 338 students, demonstrates the viability and effectiveness of our approach. Our findings have significant implications for GenAI application researchers, educators seeking to leverage accessible GenAI tools, and educational technologists aiming to transcend the limitations of conversational AI interfaces, thereby charting a course for the future of GenAI in education.}
}
@article{ZHENG20255635,
title = {Leveraging ChatGPT for Enhancing Learning in Radiology Resident Education},
journal = {Academic Radiology},
volume = {32},
number = {9},
pages = {5635-5642},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2025.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1076633225005677},
author = {Aaron Zheng and Cole J. Barker and Sergio S. Ferrante and Judy H. Squires and Barton F. {Branstetter IV} and Marion A. Hughes},
keywords = {ChatGPT, Artificial intelligence, Education, Resident, Multiple-choice question},
abstract = {Rationale and Objectives
Chat generative pre-trained transformer (ChatGPT) is a generative artificial intelligence chatbot based on a LLM at the forefront of technological development with promising applications in medical education. This study aims to evaluate the use of ChatGPT in generating board-style practice questions for radiology resident education.
Materials and Methods
Multiple-choice questions (MCQs) were generated by ChatGPT from resident lecture transcripts using a custom prompt. 17 of the ChatGPT-generated MCQs were selected for inclusion in the study and randomly combined with 11 attending radiologist-written MCQs. For each MCQ, the 21 participating radiology residents answered the MCQ, rated the MCQ from 1–10 on effectiveness in reinforcing lecture material, and responded whether they thought an attending radiologist at their institution wrote the MCQ versus an alternative source.
Results
Perceived MCQ quality was not significantly different between ChatGPT-generated (M=6.93, SD=0.29) and attending radiologist-written MCQs (M=7.08, SD=0.51) (p=0.15). MCQ correct answer percentages did not significantly differ between ChatGPT-generated (M=57%, SD=20%) and attending radiologist-written MCQs (M=59%, SD=25%) (p=0.78). The percentage of MCQs thought to be written by an attending radiologist was significantly different between ChatGPT-generated (M=57%, SD=13%) and attending radiologist-written MCQs (M=71%, SD=20%) (p=0.04).
Conclusion
LLMs such as ChatGPT demonstrate potential in generating and presenting educational material for radiology education, and their use should be explored further on a larger scale.}
}
@article{BAUCON2024112027,
title = {Life in an Artinskian (Cisuralian) Permian megacaldera: Benthic palaeoecology in the shadow of the Bolzano Supervolcano (Athesian Volcanic District, Italy)},
journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
volume = {638},
pages = {112027},
year = {2024},
issn = {0031-0182},
doi = {https://doi.org/10.1016/j.palaeo.2024.112027},
url = {https://www.sciencedirect.com/science/article/pii/S0031018224000166},
author = {Andrea Baucon and Corrado Morelli and Carlos {Neto de Carvalho} and Evelyn Kustascher},
keywords = {Supervolcano, Freshwater, Trace fossils, Caldera, Planolites, Artificial intelligence},
abstract = {Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment.}
}
@article{CHEN2023100496,
title = {Generative design of therapeutics that bind and modulate protein states},
journal = {Current Opinion in Biomedical Engineering},
volume = {28},
pages = {100496},
year = {2023},
issn = {2468-4511},
doi = {https://doi.org/10.1016/j.cobme.2023.100496},
url = {https://www.sciencedirect.com/science/article/pii/S2468451123000521},
author = {Tianlai Chen and Lauren Hong and Vivian Yudistyra and Sophia Vincoff and Pranam Chatterjee},
keywords = {Post-translational modifications, Generative AI, Binder design},
abstract = {Numerous therapeutic approaches have been developed to enable interrogation and modulation of protein isoforms, but often require laborious experimental development or screening of binders to targets of interest. In this article, we focus on efficient, state-of-the-art computational methods to design both small molecule and protein-based binders to target proteins, and highlight recent generative artificial intelligence approaches to binder design, which represents the most promising direction to enable targeting and modulation of any protein state. Integrated with advances in protein-modifying architectures, the strategies described here may serve as the foundation for therapeutic development in the near future.}
}
@article{OBREJA2025100576,
title = {Mapping the multidimensional trend of generative AI: A bibliometric analysis and qualitative thematic review},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100576},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100576},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824002094},
author = {Dragoș M. Obreja and Răzvan Rughiniș and Daniel Rosner},
keywords = {Generative AI, Bibliometrics, ChatGPT, Ethical implications, Knowledge dimensions, Copyright, Thematic review},
abstract = {Generative artificial intelligence (AI) represents an increasingly popular topic that is visible even in most research areas within the social sciences and humanities fields. However, little attention has been paid to the knowledge dimensions reflecting the potential macro-social implications of generative technologies. This study utilizes a two-fold methodology, consisting of a bibliometric analysis of articles published in the last decade (N = 484) and a subsequent qualitative thematic review of the most influential articles in each research area (N = 246). The objective is to investigate the main conceptual dimensions associated with generative AI in the social sciences. Applying a thematic analysis framework, we notice that the most popular dimensions are technological, ethical, and social. These dimensions primarily focus on investigating the implications of the generative use of AI on employees in professional sectors as well as on students and teachers in the educational environment. Moreover, the political dimension reflects macro-social consequences on governance and legal components related to ensuring social protection for professions that risk becoming obsolete due to the widespread adoption of ChatGPT-type technologies. Overall, our research emphasizes concrete scholarly tensions through which generative AI-based technologies are predominantly encouraged in the educational and organizational sectors, but the potential risks associated with copyright infringement and job loss might constitute important drivers of social change. We also notice that a Foucauldian power/knowledge framework would prove useful in understanding the underdiscussed effects of generative AI on the societal/macro level.}
}
@article{AGNIHOTRI2025100681,
title = {Large Language Models in Ophthalmology: A Review of Publications from Top Ophthalmology Journals},
journal = {Ophthalmology Science},
volume = {5},
number = {3},
pages = {100681},
year = {2025},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100681},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524002173},
author = {Akshay Prashant Agnihotri and Ines Doris Nagel and Jose Carlo M. Artiaga and Ma. Carmela B. Guevarra and George Michael N. Sosuan and Fritz Gerald P. Kalaw},
keywords = {Large language models, Generative artificial intelligence, Chatbots, ChatGPT},
abstract = {Purpose
To review and evaluate the current literature on the application and impact of large language models (LLMs) in the field of ophthalmology, focusing on studies published in high-ranking ophthalmology journals.
Design
This is a retrospective review of published articles.
Participants
This study did not involve human participation.
Methods
Articles published in the first quartile (Q1) of ophthalmology journals on Scimago Journal & Country Rank discussing different LLMs up to June 7, 2024, were reviewed, parsed, and analyzed.
Main Outcome Measures
All available articles were parsed and analyzed, which included the article and author characteristics and data regarding the LLM used and its applications, focusing on its use in medical education, clinical assistance, research, and patient education.
Results
There were 35 Q1-ranked journals identified, 19 of which contained articles discussing LLMs, with 101 articles eligible for review. One-third were original investigations (32%; 32/101), with an average of 5.3 authors per article. The United States (50.4%; 51/101) was the most represented country, followed by the United Kingdom (25.7%; 26/101) and Canada (16.8%; 17/101). ChatGPT was the most used LLM among the studies, with different versions discussed and compared. Large language model applications were discussed relevant to their implications in medical education, clinical assistance, research, and patient education.
Conclusions
The numerous publications on the use of LLM in ophthalmology can provide valuable insights for stakeholders and consumers of these applications. Large language models present significant opportunities for advancement in ophthalmology, particularly in team science, education, clinical assistance, and research. Although LLMs show promise, they also show challenges such as performance inconsistencies, bias, and ethical concerns. The study emphasizes the need for ongoing artificial intelligence improvement, ethical guidelines, and multidisciplinary collaboration.
Financial Disclosure(s)
The author(s) have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{ZHANG2025,
title = {Generative Video Communications: Concepts, Key Technologies, and Future Research Trends},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925003157},
author = {Wenjun Zhang and Guo Lu and Zhiyong Chen and Geoffrey Ye Li},
keywords = {Video communications, Video compression, Video transmission, Video Evaluation},
abstract = {With the rapid growth of video traffic and the evolution of video formats, traditional video communication systems are encountering many challenges, such as limited data compression capacity, high energy consumption, and a narrow range of services. These challenges stem from the constraints of current systems, which rely heavily on discriminative methods for visual content reconstruction and achieve communication gains only in the information and physical domains. To address these issues, this paper introduces generative video communication, a novel paradigm that leverages generative artificial intelligence technologies to enhance video content expression. The core objective is to improve the expressive capabilities of video communication by enabling new gains in the cognitive domain (i.e., content dimension) while complementing existing frameworks. This paper presents key technical pathways for the proposed paradigm, including elastic encoding, collaborative transmission, and trustworthy evaluation, and explores its potential applications in task-oriented and immersive communication. Through this generative approach, we aim to overcome the limitations of traditional video communication systems, offering more efficient, adaptable, and immersive video services.}
}
@article{PANTPAI2025e522,
title = {The future of HIV diagnostics: an exemplar in infectious diseases},
journal = {The Lancet HIV},
volume = {12},
number = {7},
pages = {e522-e531},
year = {2025},
issn = {2352-3018},
doi = {https://doi.org/10.1016/S2352-3018(25)00078-5},
url = {https://www.sciencedirect.com/science/article/pii/S2352301825000785},
author = {Nitika {Pant Pai} and Rigveda Kadam and Ilesh Jani and George Alemnji and Ruslan Malyuta and Trevor Peter},
abstract = {Summary
Over the past 40 years, diagnostics have become the backbone of HIV prevention, treatment, and retention in care, and are central to the achievement of UNAIDS 95-95-95 targets. Over the next decade, the global HIV response will face difficult challenges. In addition to sustaining gains achieved in prevention and treatment, substantial gaps in care need to be addressed for underserved populations. Diagnostics will play an important role in control and prevention of HIV infection through novel technologies, digital solutions, and integrated service delivery innovations. The integration of diagnostics with digital health, machine learning, and generative artificial intelligence provides opportunities for more effective individual and public health disease control. These diagnostics and other futuristic innovations such as wearable technologies, omics, metaverse-based solutions, and quantum diagnostics could enable the achievement of the UNAIDS 95-95-95 targets; however, their use will face barriers related to health-care system financing, infrastructure, technological readiness and skills, and long-term sustainability. This Review highlights diagnostic strategies and innovations that could catalyse a new era in the management of the HIV pandemic.}
}
@article{HOCUTT2024102829,
title = {Composing with generative AI on digital advertising platforms},
journal = {Computers and Composition},
volume = {71},
pages = {102829},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102829},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000057},
author = {Daniel L. Hocutt},
keywords = {Generative artificial intelligence, Composition, Persuasion, Digital advertising, Search engine, Online marketing, Positionality, Privilege, Power},
abstract = {This study introduces online advertising platforms as digital composing tools where persuasive rhetoric encourages users to follow links and take action on landing pages. It frames these platforms as digital spaces where human actors work alongside non-human AI agents (Duin & Pedersen, 2021 & 2023) and where rhetorical agency emerges through the activity of machine learning and artificial intelligence. It theorizes a (human) user-centered approach to composing digital ads in digital advertising platforms built around Walton, Moore & Jones’ (2019) framework of positionality, position, and power. It provides guidance for technical and professional writers in placing human users at the center of an abstracted, algorithm-driven partnership where generative AI appears poised to wrest power from both composers and users.}
}
@article{LI2025101003,
title = {Exploring human and AI collaboration in inclusive STEM teacher training: A synergistic approach based on self-determination theory},
journal = {The Internet and Higher Education},
volume = {65},
pages = {101003},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101003},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000120},
author = {Tingting Li and Zehui Zhan and Yu Ji and Tongde Li},
keywords = {STEM education, Teacher professional learning, Collaborative learning, ChatGPT, AI-assisted learning},
abstract = {Inclusive STEM teacher training plays a critical role in shaping the future of STEM teaching practices and improving educational outcomes for all students, particularly those from marginalized and underrepresented backgrounds. This study investigates the inclusive collaborative learning framework for enhancing STEM teaching among student teachers, focusing on interpersonal and human-machine (generative artificial intelligence) collaboration. Employing a Self-Determination Theory guided approach, two rounds of exploratory studies were conducted. Study 1 compared the effects of interpersonal collaboration (TSPL: in-Service Teacher-Student Teacher Pair Learning) and human-machine collaboration (CSPL: ChatGPT-Student Teacher Pair Learning). Building on Study 1, Study 2 employed a hybrid inclusive collaborative learning model (iHMCL: integrated Human-Machine Collaborative Learning) with expanded participant demographics, blended course formats, and integrated peer, expert, and AI feedback mechanisms. The two-year iterative empirical research revealed differences in the impact of the three collaborative learning approaches on student teachers' learning. CSPL and iHMCL groups outperformed TSPL in STEM teaching knowledge and cognitive load, while TSPL and iHMCL excelled in STEM teaching ability compared to CSPL. The SDT-based inclusive collaborative learning framework for STEM teacher training proved effective, with noted implications. In the future, the integration of generative artificial intelligence and cross boundary learning in inclusive STEM teacher education will require educators to redefine their roles, emphasizing emotional support, critical thinking, and creativity, ensuring that AI complements rather than replaces hands-on, reality-based learning.}
}
@article{LASAROV2026105309,
title = {How practitioners can leverage GenAI to bridge the research-practice gap},
journal = {Tourism Management},
volume = {113},
pages = {105309},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105309},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001797},
author = {Wassili Lasarov and Melanie Trabandt and Stefan Hoffmann and Giampaolo Viglia},
keywords = {Research-practice gap, GenAI, Knowledge translation process, Toolkit, Literature review},
abstract = {Despite the practical relevance of many tourism research studies, organizations and policymakers often struggle to integrate them due to time constraints, language barriers, limited resources, and interaction challenges. Generative artificial intelligence (GenAI) offers new capabilities to overcome these barriers. We propose a GenAI-enabled knowledge translation process with three stages: (i) research curation to identify and translate relevant literature; (ii) content creation to produce materials; and (iii) market research using synthetic guests to pre-test their effectiveness. We examine the capabilities, limitations, and ethical implications of GenAI at each stage, drawing on a systematic review of GenAI and tourism literature. To equip managers with the knowledge and tools needed to harness research-based insights effectively, we offer a toolkit comprising a handbook, a promptbook, and tailored GPT models. The toolkit enables tourism and hospitality practitioners to apply research findings in their decision-making and content strategies without direct stakeholder interaction.}
}
@article{ZHANG2025125059,
title = {Deep generative models in energy system applications: Review, challenges, and future directions},
journal = {Applied Energy},
volume = {380},
pages = {125059},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.125059},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924024437},
author = {Xiangyu Zhang and Andrew Glaws and Alexandre Cortiella and Patrick Emami and Ryan N. King},
keywords = {Generative artificial intelligence, Deep generative models, Energy systems, Smart grid},
abstract = {In recent years, with the advent of mature machine learning products like ChatGPT, Stable Diffusion, and Sora, the world has witnessed tremendous changes driven by the rapid development of generative artificial intelligence (GAI). Beyond applications in text, speech, image, and video creation, deep generative models (DGMs) underpinning these cutting-edge technologies have also been employed by domain researchers to address scientific and engineering challenges. This paper aims to fill a gap in the research community by providing a comprehensive review of how DGMs have been utilized in energy system applications. Based on five of the most popular DGMs, we review and categorize 228 research articles into five focus areas: data generation, forecasting, situational awareness, modeling, and optimal decision-making. Through this classification, we uncover trends in how DGMs are employed for each type of problem, highlighting GAI techniques that contribute to breakthroughs over traditional methods. We discuss limitations in existing literature, engineering challenges, and propose future directions, all tailored to the unique nature of problems in energy system engineering. Our goal is to offer insights for energy system domain researchers, providing a comprehensive view of existing studies and potential future opportunities.}
}
@article{LLEDO2025105275,
title = {Assessing the performance of generative AI chatbots in preimplantation genetic testing: a comparative study of expert evaluations},
journal = {Reproductive BioMedicine Online},
pages = {105275},
year = {2025},
issn = {1472-6483},
doi = {https://doi.org/10.1016/j.rbmo.2025.105275},
url = {https://www.sciencedirect.com/science/article/pii/S1472648325004821},
author = {Belén Lledo and Paola Carbone and Jose A. Ortiz and Ruth Morales and Adoración Rodríguez-Arnedo and Leyre Herrero and Elisa Alvarez and Jorge Ten and Lydia Luque and Juan C. Castillo and Jordi Suñol and Annalisa Racca and Andrea Bernabeu},
keywords = {Generative AI, chatbots, PGT and embryo mosaicism},
abstract = {Research Question
How reliable are generative artificial intelligence (AI) chatbots in responding to patient-relevant questions about preimplantation genetic testing (PGT), as evaluated by reproductive medicine specialists?
Design
A prospective evaluation was conducted comparing three publicly available generative AI models—ChatGPT-3.5, Gemini-1.5, and Llama-2. Twelve reproductive medicine specialists from different clinics assessed chatbot-generated responses to 13 PGT-related questions, divided into simple and controversial categories. Each response was scored from 0 to 5 using predefined criteria. Assuming all answers were excellent, the maximum score was 25 points for simple questions and 40 points for controversial ones.
Results
A total of 156 evaluations were completed. Among simple questions, the lowest-rated response was to “What are the types and techniques used for PGT?” (mean score: 2.83±0.94). For controversial questions, “What is the percentage of aneuploidy that allows an embryo to be defined as mosaic?” scored lowest (2.67±1.22). ChatGPT performed best across both categories (simple: 16.83±1.80; controversial: 27.75±4.49), followed by Gemini (14.92±2.02; 26.08±3.99) and Llama (13.58±3.60; 16.92±4.96). Statistically significant differences were observed, particularly between ChatGPT and Llama (p=0.027 for simple, p<0.001 for controversial), and between Gemini and Llama for controversial questions (p<0.001). No significant performance differences were noted across participating specialists.
Conclusions
Generative AI shows moderate reliability in addressing PGT-related inquiries, with ChatGPT and Gemini outperforming Llama. While performance was higher for simple than for controversial questions, the variability underscores the need for clinical oversight. Further refinement and validation are essential before widespread integration of AI tools in reproductive medicine.}
}
@article{ZHAI2025132773,
title = {Data-driven machine learning improves prediction of sulfonamide antibiotic adsorption by biochar in aqueous phase},
journal = {Bioresource Technology},
volume = {434},
pages = {132773},
year = {2025},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2025.132773},
url = {https://www.sciencedirect.com/science/article/pii/S0960852425007394},
author = {Mudi Zhai and Bomin Fu and Zhaozhong Wu and Junsen Wang and Weijie Wang and Hongtao Wang},
keywords = {Wastewater, Data augmentation, Wasserstein generative adversarial network, Generative artificial intelligence},
abstract = {Sulfonamide antibiotics (SAs) have attracted much attention due to their environmental risks to aquatic ecosystems. Biochars (BCs), as excellent adsorbent materials, have been used to remove SAs from aqueous phases. To achieve effective evaluation of adsorption, machine learning (ML) strategies are increasingly being developed. However, no applicable data-driven ML models have been studied to predict the adsorption of SAs by BCs in water. Therefore, this study employed an ML approach based on Wasserstein generative adversarial network (WGAN) data augmentation to predict the adsorption of SAs on BCs in the aqueous phase. The results indicated that the WGAN could generate virtual data highly similar to the original adsorption dataset. By expanding the original data using WGAN, the performance of the extreme gradient boosting model in predicting the adsorption amount improved. This study provides new insights into predicting the adsorption behavior of waste-based BCs for SAs in water environments.}
}
@article{DANIEL2024100168,
title = {Responsible use of Generative AI in chemical engineering},
journal = {Digital Chemical Engineering},
volume = {12},
pages = {100168},
year = {2024},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2024.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2772508124000309},
author = {Thorin Daniel and Jin Xuan},
keywords = {Responsible technology, Ethics, Generative AI},
abstract = {Generative Artificial Intelligence is a rapidly developing area being used to create powerful tools which have the potential to change a wide range of professional practices in chemical engineering. As this area develops, new principles on responsible use of Generative AI in chemical engineering are required to ensure that traditional engineering ethics are able to accommodate the new landscape. In this perspective, we assess the current state of engineering ethics, responsible AI principles and suggest how they can combine to ensure that Generative AI can be used responsibly within the chemical engineering sector. Whilst there are many aspect to engineering ethics and responsible AI use, the core principles which include transparency, integrity, and accountability are omnipresent and provide a shared foundation of good practice on which new regulations may be built as the need arises. Future breakthrough will require development on the AI technology itself, the people-centre approach and regulation changes.}
}
@article{TANI202520,
title = {Prompt Engineering P2X Business Ecosystem with Generative AI},
journal = {Procedia Computer Science},
volume = {256},
pages = {20-27},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.091},
url = {https://www.sciencedirect.com/science/article/pii/S187705092500448X},
author = {Toni Tani and Antti Yläkujala and Lasse Metso and Tiina Sinkkonen and Timo Kärri},
keywords = {Generative AI, Prompt Engineering, Power-to-X, Business Ecosystem, GPT-4, AI Data Visualization, Sustainability},
abstract = {This study examines the potential of generative Artificial Intelligence (AI) in visualizing and sketching Power-to-X (P2X) business ecosystems via the Business Ecosystem Prompt2X Method (BEP2X). Utilizing advancements in GPT technology, this approach offers a dynamic alternative to traditional static visualization methods. Guided by the research questions, this study investigates the role of generative AI in ecosystem categorization, led by prompt engineering for detailed visualization, and culminates in the creation of a tangible artifact through this process. Using the DSR framework, BEP2X is introduced as a new method for applying generative AI to draw complex business ecosystems. The synthetic methanol plant project in Finland serves as a case study in its development, illustrating BEP2X’s practical utility.}
}
@article{AKHTAR2024109283,
title = {Smart product platforming powered by AI and generative AI: Personalization for the circular economy},
journal = {International Journal of Production Economics},
volume = {273},
pages = {109283},
year = {2024},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2024.109283},
url = {https://www.sciencedirect.com/science/article/pii/S0925527324001403},
author = {Pervaiz Akhtar and Arsalan Mujahid Ghouri and Aniqa Ashraf and Jia Jia Lim and Naveed R Khan and Shuang Ma},
keywords = {Smart product platforms and flexibility, Personalized product design and manufacturing, Environmentally friendly products and circular economy, Generative artificial intelligence and large language models, Big data analytics and machine learning},
abstract = {The interlocks between smart product platforming (SPP) powered by Artificial Intelligence (AI) and Generative AI, big data analytics, and machine learning are still in their infancy. Modern technology-driven SPP promotes personalized product design and manufacturing suited to support environmentally friendly products for the circular economy. In this study, we develop a framework pertaining to the interlinks between SPP, big data analytics, machine learning, and the circular economy. To test our framework, we apply structure equation modeling based on data collected from more than 200 automotive industry professionals operating in China. Our results demonstrate that SPP and big data analytics are the central determinants for manufacturing environmentally friendly products, ultimately promoting circular economy applications. SPP plays a pivotal role in innovative product design and in facilitating the relevant manufacturing procedures. Big data analytics significantly feed into SPP applications. Machine learning and flexibility in SPP perform moderating roles in strengthening environmentally friendly outcomes. The mediating role played by SPP between big data analytics and environmentally friendly products for the circular economy is partially encouraging. As SPP powered by AI and Generative AI is an emerging phenomenon, our study contributes to this new knowledge dimension. We conclude this paper by discussing the theoretical and practical implications of our study, its limitations, and directions for future research.}
}
@article{KRISHNAN2025,
title = {A generative deep learning approach to de novo antibiotic design},
journal = {Cell},
year = {2025},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2025.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0092867425008554},
author = {Aarti Krishnan and Melis N. Anahtar and Jacqueline A. Valeri and Wengong Jin and Nina M. Donghia and Leif Sieben and Andreas Luttens and Yu Zhang and Seyed Majed Modaresi and Andrew Hennes and Jenna Fromer and Parijat Bandyopadhyay and Jonathan C. Chen and Danyal Rehman and Ronak Desai and Paige Edwards and Ryan S. Lach and Marie-Stéphanie Aschtgen and Margaux Gaborieau and Massimiliano Gaetani and Samantha G. Palace and Satotaka Omori and Lutete Khonde and Yurii S. Moroz and Bruce Blough and Chunyang Jin and Edmund Loh and Yonatan H. Grad and Amir Ata Saei and Connor W. Coley and Felix Wong and James J. Collins},
keywords = {antibiotics, drug discovery, generative artificial intelligence, machine learning, fragments,  design, graph neural networks, , , bacterial infection},
abstract = {Summary
The antimicrobial resistance crisis necessitates structurally distinct antibiotics. While deep learning approaches can identify antibacterial compounds from existing libraries, structural novelty remains limited. Here, we developed a generative artificial intelligence framework for designing de novo antibiotics through two approaches: a fragment-based method to comprehensively screen >107 chemical fragments in silico against Neisseria gonorrhoeae or Staphylococcus aureus, subsequently expanding promising fragments, and an unconstrained de novo compound generation, each using genetic algorithms and variational autoencoders. Of 24 synthesized compounds, seven demonstrated selective antibacterial activity. Two lead compounds exhibited bactericidal efficacy against multidrug-resistant isolates with distinct mechanisms of action and reduced bacterial burden in vivo in mouse models of N. gonorrhoeae vaginal infection and methicillin-resistant S. aureus skin infection. We further validated structural analogs for both compound classes as antibacterial. Our approach enables the generative deep-learning-guided design of de novo antibiotics, providing a platform for mapping uncharted regions of chemical space.}
}
@article{JAYARAMAN20253203,
title = {Llama3 with Parameter Efficient Fine-Tuning Approach for 5G Cellular Network Security Text Classification},
journal = {Procedia Computer Science},
volume = {258},
pages = {3203-3210},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.578},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016825},
author = {Ashok Kumar Jayaraman and Magudeeswaran Muthappagounder and Vinoth Kannan Ranganathan},
keywords = {Security text classification, 5G Technology, Generative AI, large language models, multiclass classification},
abstract = {Third generation partnership project (3GPP) provides unified telecom standards in terms of numerous technical documents related to 5G cellular networks. Understanding these technical documents becomes a time-consuming task. Therefore, researchers use generative artificial intelligence based LLM models to create and understand the 3GPP knowledge base. This helps to improve network securities in terms of threats, incidents, vulnerability, policy compliance, and security intelligence. In this paper, a Llama3 model with parameter efficient fine-tuning (PEFT) approach is presented with the task of 3GPP 5G cellular network security text classification. This approach is compared with multiple transformer models. The 3GPP-based SPEC5G dataset is used for the task of security-related text classification. Our results indicate that the proposed Llama3 with PEFT approach significantly outperforms.}
}
@article{SCHMITT2024389,
title = {Measurability of quality characteristics identified in latent spaces of Generative AI Models},
journal = {CIRP Annals},
volume = {73},
number = {1},
pages = {389-392},
year = {2024},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2024.04.073},
url = {https://www.sciencedirect.com/science/article/pii/S0007850624000866},
author = {Robert H. Schmitt and Dominik Wolfschläger and Jan-Henrik Woltersmann and Lennart Stohrer},
keywords = {Metrology, Artificial intelligence, Generative artificial intelligence},
abstract = {Deep Learning can learn complex properties from image datasets, which are difficult to model with traditional machine vision algorithms, inherently in the form of disentangled latent spaces. With latent spaces of Generative AI models, a feature extraction method to access these properties can be implemented. This work evaluates whether the learned properties can be measured in the latent space. Quantity and quantity-value scale properties and the measurability of the dimensional quality characteristic ‘filling degree’ using a linear calibration function are demonstrated for an industrial machine vision application. An uncertainty indicator between 0.4–0.9 mm is estimated for the latent space measurements.}
}
@article{LIN2024110682,
title = {Circular supply chain for smart production in Industry 4.0},
journal = {Computers & Industrial Engineering},
volume = {198},
pages = {110682},
year = {2024},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2024.110682},
url = {https://www.sciencedirect.com/science/article/pii/S0360835224008040},
author = {Kuo-Yi Lin},
keywords = {Circular Supply Chain, Industry 4.0, Smart Production, Generative AI, Industry, Innovation and Infrastructure},
abstract = {Sustainable practices in industrial engineering are not just ideal but necessary. The push for Circular Supply Chain (CSC) in Industry 4.0 has become increasingly vital. Motivated by this, this study proposed the UNISONE framework, integrated with advanced smart production technologies grounded in CSC principles. The proposed framework resulted in enhanced operational efficiency and a sustainable production system that significantly minimizes waste. The research was validated through an empirical study within a bearing factory, successfully demonstrating the framework’s efficacy and creating value within the CSC paradigm. Key findings include the impact of different signal-to-noise ratios on model performance, with peak test accuracy at a noise ratio of 0.6, and the best results of 85.32 % accuracy achieved by combining sparse and noise reduction autoencoder techniques in generative artificial intelligence. This study underscores the framework’s potential to address industrial engineering challenges and promote scalable, efficient, and eco-conscious manufacturing, benefiting both the environment and the economy.}
}
@article{CARNAT2024106067,
title = {Addressing the risks of generative AI for the judiciary: The accountability framework(s) under the EU AI Act},
journal = {Computer Law & Security Review},
volume = {55},
pages = {106067},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.106067},
url = {https://www.sciencedirect.com/science/article/pii/S026736492400133X},
author = {Irina Carnat},
keywords = {Large Language Models, Generative Artificial Intelligence, Accountability, Automation bias, Judicial decision-making},
abstract = {The rapid advancements in natural language processing, particularly the development of generative large language models (LLMs), have renewed interest in using artificial intelligence (AI) for judicial decision-making. While these technological breakthroughs present new possibilities for legal automation, they also raise concerns about over-reliance and automation bias. Drawing insights from the COMPAS case, this paper examines the implications of deploying generative LLMs in the judicial domain. It identifies the persistent factors that contributed to an accountability gap when AI systems were previously used for judicial decision-making. To address these risks, the paper analyses the relevant provisions of the EU Artificial Intelligence Act, outlining a comprehensive accountability framework based on the regulation's risk-based approach. The paper concludes that the successful integration of generative LLMs in judicial decision-making requires a holistic approach addressing cognitive biases. By emphasising shared responsibility and the imperative of AI literacy across the AI value chain, the regulatory framework can help mitigate the risks of automation bias and preserve the rule of law.}
}
@article{ILAGAN20241124,
title = {A prototype of a conversational virtual university support agent powered by a large language model that addresses inquiries about policies in the student handbook},
journal = {Procedia Computer Science},
volume = {239},
pages = {1124-1131},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.278},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015217},
author = {Joseph Benjamin Ilagan and Jose Ramon Ilagan},
keywords = {Conversational User Experience, Conversational agents, Natural language processing, Large language model, Chatbot},
abstract = {Universities gain a competitive advantage by deliberately improving overall service, student, faculty, and staff experience, leading to attractiveness, retention, and improved outcomes. Quality services are achieved partly by addressing employee satisfaction, specifically in the work environment. This paper presents a prototype study of a virtual university support agent, a system grounded in a Large Language Model (LLM) engineered to address inquiries from university students, faculty and staff related to the student handbook. The study investigates the integration of generative artificial intelligence and natural conversation properties inherent in LLMs to overcome customer service shortcomings identified in previous chatbot applications. The LLMs’ susceptibility to ‘hallucination’ is mitigated through a combined approach of few-shot learning and chain of thought libraries in the training phase. The information core of this system comprises student handbook PDF files, from which an algorithm extracts and structures data to be utilized by the LLM. As a result, the university support agent facilitates a viable Q&A interface for students, faculty, and administrators to inquire about university guidelines and policies.}
}
@article{DANG2024101157,
title = {Ethical use of generative AI for writing practices: Addressing linguistically diverse students in U.S. Universities' AI statements},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101157},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101157},
url = {https://www.sciencedirect.com/science/article/pii/S106037432400064X},
author = {Anh Dang and Hui Wang},
keywords = {Generative AI, ChatGPT, L2 Writing and Generative AI, GenAI Statements, University, Policies, Critical AI Literacy},
abstract = {Given the rapid development in Generative Artificial Intelligence (GenAI) technologies, conversations regarding how these tools will shape the teaching and learning of writing can be difficult to unpack. Thus, higher-ed institutions across the U.S. are paying more attention to the discussion of GenAI in their own contexts and also establishing guidelines to support instructors and students in this GenAI era. To understand more about the direction of these universities, this research brief examines publicly available statements and resources from 100 U.S. universities on the teaching of writing and GenAI usage, and from there, guide institutions in developing effective strategies for the responsible implementation of these tools. This report also highlights the importance of including L2 students as a focus in the process of crafting these statements, especially when viewing GenAI through the lens of critical pedagogy, social justice and inequalities.}
}
@article{GROVES2025101103,
title = {Cultivating the experience of dignity at work during digital transformation: Protective & proactive strategies for leaders and organizations},
journal = {Organizational Dynamics},
volume = {54},
number = {3, Part 2},
pages = {101103},
year = {2025},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101103},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000767},
author = {Kevin S. Groves and Jaclyn Margolis and Cristina Gibson},
keywords = {Dignity, Leadership development, Meaningful work, Digital transformation, Employee engagement},
abstract = {Ubiquitous digital transformation technologies such as robotics, generative artificial intelligence (AI) tools, large language models (LLMs), and other digital applications automate both mechanistic and creative work processes, which represent potential advancements never imagined a decade ago. Yet many view digital transformation as not only redefining the experience of work, but also undermining the humanity of organizations. Employees across the spectrum of skill-levels, job classes, and wages also face unprecedented and existential threats to their sense of self-worth, value, and esteem, which collectively embody dignity. Given the onslaught of these technological advances and digital transformation initiatives across industries and sectors, leaders need a set of practical strategies that both protect employees from threats to their dignity as well as proactively cultivate the experience of dignity in their organizations. To meet this growing need, this article presents executives, management teams, HR professionals, and other leaders with evidence-based approaches for protecting and promoting the experience of dignity at work. Grounded in the latest thinking and research on dignity in the workplace, this article offers practical strategies for investing in protective mechanisms (policies and processes) that insulate employees from aspects of work that erode the experience of dignity, as well as proactive mechanisms (practices and behaviors) that cultivate meaningful opportunities to experience dignity at work.}
}
@article{LIU2025108569,
title = {Enhancing student GAI literacy in digital multimodal composing through development and validation of a scale},
journal = {Computers in Human Behavior},
volume = {166},
pages = {108569},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108569},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000160},
author = {Meilu Liu and Lawrence Jun Zhang and Donglan Zhang},
keywords = {Generative artificial intelligence, Digital multimodal composing, Literacy},
abstract = {It is widely acknowledged that Generative Artificial Intelligence (GAI) has exerted a greater influence on EFL learners' digital multimodal composing (DMC) process. GAI focuses on creating new textual and multimodal content using large language models (LLMs), and it puts different demands on EFL learners. Although much research has been conducted on EFL learners' AI literacy in various socio-cultural contexts, more attention should now be paid to EFL learners' GAI literacy in the DMC context, a new autonomous model of literacy. It should be noted that even though some studies may concentrate on users' perceptions and experiences with GAI, which may be closely tied to GAI literacy, there lacks the development of a scale for assessing GAI literacy in DMC. Thus, this study attempted to fill these research gaps by developing and validating an applicable and generalizable instrument to measure Chinese EFL learners' multimodal GAI literacy in their DMC process. Two subsamples (n1 = 296, n2 = 294) were randomly invited to respond to the GAIDMCS, and the data were subjected to exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) to test the validity and reliability of the instrument. The findings suggested that a four-factor solution with 17 items can help explain Chinese EFL learners’ GAI literacy in DMC in terms of affective learning, behavior learning, cognitive learning, and ethical learning. Our GAI literacy in DMC scale may help improve GAI education for researchers and practitioners by providing a comprehensive and plausible framework that can serve as an outline for further syllabus design.}
}
@article{SURI2025818,
title = {An artificial intelligence-generated interactive carbon footprint calculator for anaesthesia},
journal = {British Journal of Anaesthesia},
volume = {135},
number = {3},
pages = {818-820},
year = {2025},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2025.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S0007091225003848},
author = {Aditi Suri and Gaurav Sindwani},
keywords = {anaesthesia, artificial intelligence, carbon footprint, climate change, generative artificial intelligence, global warming potential, sustainability}
}
@article{SINGH2025112220,
title = {Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112220},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112220},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625022286},
author = {Prithvipal Singh and Sandeep Singh and Gurupdesh Singh and Amritpal Singh},
keywords = {Conditional generative adversarial network, Conditional hybrid network, Cybersecurity enhancement, Generative artificial intelligence, Spatial-temporal attention mechanism, Transformer-based conditional variational AutoEncoder},
abstract = {Since, Artificial Intelligence is highly developing and concatenating into several domains, cybersecurity is an important field of delivering both the advantages and disadvantages. In addition to this, Artificial Intelligence is applied in a wide variety of applications like healthcare sector, content creation and entertainment and financial industries. Therefore, this work finds the efficiency of Artificial Intelligence -oriented cybersecurity metrics in succeeding the digital environment over elevating cyber threats. Here, the developed models consist of two different stages while implementing the model. In the first stage, the essential dataset is assembled from the benchmark data source. These datasets are assembled by using Generative Artificial Intelligence (Gen Artificial Intelligence networks). Consequently, the raw data is given as an input to Conditional Hybrid Network for cybersecurity enhancement. Further, the Transformer-based Conditional Variational Autoencoders with Spatial-temporal Attention are designed for feature extraction that is subjected to the Conditional Generative Adversarial Network for classifying the cyber attacks. Henceforth, the developed network is evaluated and designed with multiple measures. Comparing baseline models, the suggested network obtains higher performance for developing security over cyber networks.}
}
@article{JIA2025,
title = {Dependability of Large Language Models in Cardiovascular Medicine: A Scoping Review},
journal = {Journal of Cardiothoracic and Vascular Anesthesia},
year = {2025},
issn = {1053-0770},
doi = {https://doi.org/10.1053/j.jvca.2025.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S1053077025006214},
author = {Ying Ying Jia and Lin Yan Pang and Ming Ming Bi and Xiang Lu Yang and Jian Ping Song},
keywords = {cardiovascular, large language models, generative artificial intelligence, ChatGPT, trustworthiness, reliability},
abstract = {Background
The adoption of large language models (LLMs) in both clinical and consumer healthcare settings has surged exponentially. However, there remains limited evidence on their reliability and impact in cardiovascular practice.
Objectives
This scoping review was designed to consolidate the existing biomedical literature on applicability, reliability, and quality improvement strategies for the integration of LLMs into the cardiovascular domain. Following Cochrane methodology and Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, three electronic databases (PubMed, Web of Science, and Embase) were systematically searched to identify pertinent studies published between August 2020 and February 2025. Articles addressing the development, implementation, and assessment of LLMs in cardiovascular medicine were selected for comprehensive analysis.
Results
Twenty-five eligible publications evaluated the performance of LLMs in responding to cardiology-related questions, encompassing parameters such as accuracy, response latency, indirectness, completeness, and so on. The assessment methodology varied considerably across studies. LLMs demonstrated potential utility in cardiovascular decision-making, myocarditis management, cardiac arrest diagnosis and treatment, and image differentiation.
Conclusions
Although some LLM-generated responses to cardiovascular-related questions exhibit acceptable levels of quality, significant drawbacks persist. These include verbosity, inaccuracies, occasional misinformation, inconsistent outputs to identical questions, bias, and poor reproducibility. Overall, this work highlights the urgent need for continued refinement and validation.}
}
@article{YANG2024100309,
title = {Enhancing python learning with PyTutor: Efficacy of a ChatGPT-Based intelligent tutoring system in programming education},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100309},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100309},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001127},
author = {Albert C.M. Yang and Ji-Yang Lin and Cheng-Yan Lin and Hiroaki Ogata},
keywords = {Generative artificial intelligence, Intelligent tutoring system, Automatic hint generation, Programming education},
abstract = {Programming is regarded as a focal point in the current rapidly evolving educational landscape. To aid learning in this domain, we developed PyTutor, an innovative intelligent tutoring system (ITS) that is designed to assist beginners in Python programming. PyTutor utilizes the ChatGPT model to offer continuous guidance, problem-solving hints, and detailed code explanations. It features a structured hint system for each question, covering pseudocode, cloze, basic, and advanced coding solutions. In our 11-week experiment, we compared 35 students who used PyTutor with 36 students who did not. The results indicated the effectiveness of PyTutor, particularly for students with weak foundations in programming. Those with lower initial knowledge exhibited higher engagement, completion rates, and success rates in in-class and after-class programming exercises. Nevertheless, we observed a potential risk of overreliance on PyTutor among students, which may impede the development of independent problem-solving skills. Thus, we recommend the balanced usage of PyTutor. In conclusion, PyTutor is a valuable ITS in programming education that considerably improves the learning outcomes of beginners. Its tailored approach renders it a promising tool for bridging knowledge gaps and enhancing overall educational experiences in the field of programming.}
}
@article{DAGA2025100846,
title = {Process Knowledge Graphs (PKG): Towards unpacking and repacking AI applications},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100846},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100846},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000325},
author = {Enrico Daga},
keywords = {Knowledge graphs, Prompt engineering, Data science pipelines, Data pipelines documentation, Data pipelines design},
abstract = {In the past years, a new generation of systems has emerged, which apply recent advances in generative Artificial Intelligence (AI) in combination with traditional technologies. Specifically, generative AI is being delegated tasks in natural language or vision understanding within complex hybrid architectures that also include databases, procedural code, and interfaces. Process Knowledge Graphs (PKG) have a long-standing tradition within symbolic AI research. On the one hand, PKGs can play an important role in describing complex, hybrid applications, thus opening the way for addressing fundamental challenges such as explaining and documenting such systems (unpacking). On the other hand, by organising complex processes in simpler building blocks, PKGs can potentially increase accuracy and control over such systems (repacking). In this position paper, we discuss opportunities and challenges of PGRs and their potential role towards a more robust and principled design of AI applications.}
}
@article{HOLTZ20251888,
title = {Bridging Risk and Innovation: Generative AI in Scenario Creation},
journal = {Procedia Computer Science},
volume = {256},
pages = {1888-1895},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.330},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006982},
author = {Niklas Holtz and Sven Wittfoth and Jorge Marx Gómez},
keywords = {Natural Language Processing, Generative Artificial Intelligence, Information Retrieval, Risk Scenarios},
abstract = {Risk management is essential in decision-making, yet traditional methods for creating risk scenarios face challenges in modern, complex business environments. Despite various techniques available, these conventional approaches struggle with managing vast amounts of information. The rapid advancement of Generative AI offers a promising yet underexplored opportunity to transform this process. This paper explores integrating Generative AI to enhance and automate risk scenario generation, bridging the gap between traditional methods and cutting-edge AI. Our approach is twofold: first, we introduce a method to retrieve and structure relevant real-time data related to a risk topic using a combination of sentence embeddings and a Multi-Agent system; second, we derive risk scenarios from this data. By utilizing real-time data, this approach enhances the accuracy and relevance of risk scenarios compared to traditional methods. Furthermore, the automated nature of the process allows scenarios to be continuously monitored and updated over time, ensuring long-term applicability and adaptability for decision-makers.}
}
@article{SAFARI2026103086,
title = {Grid-to-Robot: Deep Wasserstein generative modeling of robot/power grid interaction using hybrid adversarial Residual Networks},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {97},
pages = {103086},
year = {2026},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2025.103086},
url = {https://www.sciencedirect.com/science/article/pii/S0736584525001401},
author = {Ashkan Safari and Hamed Kharrati and Afshin Rahimi and M. Ali Tavallaei},
keywords = {Generative Artificial Intelligence, Deep learning, Robotic manipulator, Renewable energy, Power grid},
abstract = {Smart Manufacturing (SM) is an important factor for driving innovation, enhancing operational efficiency, and increasing sustainable industrial growth in an increasingly competitive and resource-constrained world. However, it faces several challenges related to increasing energy consumption and climate change. The high energy demands of connected devices and robotic manipulators increase the carbon footprint. To resolve this issue, most enterprises are now transitioning to use Renewable Energy Sources (RES), and optimizing their power and energy usage, while holding the process efficient. To fully achieve this transition, a detailed power modeling of the robotic manufacturing system is crucial and, therefore, it is important to investigate this power modeling of the robotic manipulators’ consumption in a Smart Sustainable Manufacturing (SSM) to achieve the best power modeling results and better integrability analytics in optimal power planning of the robotic systems power supply. To this end, this paper presents a deep Generative Artificial Intelligence (GAI)-based modeling of robotic manipulators’ power supply interaction with the power grid, and RES. In the proposed system, which is powered by solar energy and the power grid, a SSM equipped with ten 6-Degrees of Freedom (DoF) robotic manipulators is considered in the presence of Battery Energy Storage Systems (BESSs). Subsequently, a Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) is employed to generate synthetic data for the system alongside the real data, thereby expanding the analytical horizons across varying operational characteristics of the system. Following this, a Residual Networks (ResNet) is developed to comprehensively analyze and predictively model the power consumption of the manipulators and their interactions with the power supply resources. Finally, the proposed hybrid GAI modeling strategy is numerically evaluated across a broad spectrum of Key Performance Indicators (KPIs) (MSE= 10−4, MAE= 3.6×10−3, R2= 99.98%, MARE= 1.97×10−2, RMSPE= 8.83×10−2%, MSRE= 7.8×10−3, RMSRE= 8.84×10−2, MAPE= 1.97×10−2%, and Max Error= 2.04×10−2), where these metrics demonstrate superior performance in power modeling. As a result, the concept of Grid-to-Robot (G2R) is introduced for the first time as a foundation for further advancements in SSM, enhancing sustainability and mitigating negative impacts on climate change while contributing to the development of an advanced manufacturing system.}
}
@article{EBIHARA2025,
title = {Development of a Clinical Clerkship Mentor Using Generative AI and Evaluation of Its Effectiveness in a Medical Student Trial Compared to Student Mentors: 2-Part Comparative Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/76702},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001138},
author = {Hayato Ebihara and Hajime Kasai and Ikuo Shimizu and Kiyoshi Shikino and Hiroshi Tajima and Yasuhiko Kimura and Shoichi Ito},
keywords = {artificial intelligence, AI, mentoring, clinical clerkship, medical students, social support},
abstract = {Background
At the beginning of their clinical clerkships (CCs), medical students face multiple challenges related to acquiring clinical and communication skills, building professional relationships, and managing psychological stress. While mentoring and structured feedback are known to provide critical support, existing systems may not offer sufficient and timely guidance owing to the faculty’s limited availability. Generative artificial intelligence, particularly large language models, offers new opportunities to support medical education by providing context-sensitive responses.
Objective
This study aimed to develop a generative artificial intelligence CC mentor (AI-CCM) based on ChatGPT and evaluate its effectiveness in supporting medical students’ clinical learning, addressing their concerns, and supplementing human mentoring. The secondary objective was to compare AI-CCM’s educational value with responses from senior student mentors.
Methods
We conducted 2 studies. In study 1, we created 5 scenarios based on challenges that students commonly encountered during CCs. For each scenario, 5 senior student mentors and AI-CCM generated written advice. Five medical education experts evaluated these responses using a rubric to assess accuracy, practical utility, educational appropriateness (5-point Likert scale), and safety (binary scale). In study 2, a total of 17 fourth-year medical students used AI-CCM for 1 week during their CCs and completed a questionnaire evaluating its usefulness, clarity, emotional support, and impact on communication and learning (5-point Likert scale) informed by the technology acceptance model.
Results
All results indicated that AI-CCM achieved higher mean scores than senior student mentors. AI-CCM responses were rated higher in educational appropriateness (4.2, SD 0.7 vs 3.8, SD 1.0; P=.001). No significant differences with senior student mentors were observed in accuracy (4.4, SD 0.7 vs 4.2, SD 0.9; P=.11) or practical utility (4.1, SD 0.7 vs 4.0, SD 0.9; P=.35). No safety concerns were identified in AI-CCM responses, whereas 2 concerns were noted in student mentors’ responses. Scenario-specific analysis revealed that AI-CCM performed substantially better in emotional and psychological stress scenarios. In the student trial, AI-CCM was rated as moderately useful (mean usefulness score 3.9, SD 1.1), with positive evaluations for clarity (4.0, SD 0.9) and emotional support (3.8, SD 1.1). However, aspects related to feedback guidance (2.9, SD 0.9) and anxiety reduction (3.2, SD 1.0) received more neutral ratings. Students primarily consulted AI-CCM regarding learning workload and communication difficulties; few students used it to address emotional stress–related issues.
Conclusions
AI-CCM has the potential to serve as a supplementary educational partner during CCs, offering comparable support to that of senior student mentors in structured scenarios. Despite challenges of response latency and limited depth in clinical content, AI-CCM was received well by and accessible to students who used ChatGPT’s free version. With further refinements, including specialty-specific content and improved responsiveness, AI-CCM may serve as a scalable, context-sensitive support system in clinical medical education.}
}
@article{SUN2026105271,
title = {When cutting edge meets silver tongue: Understanding the word-of-machine effect on travel decisions},
journal = {Tourism Management},
volume = {112},
pages = {105271},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105271},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001414},
author = {Danni Sun and IpKin Anthony Wong and Xiling Xiong and Shina Li},
keywords = {Artificial intelligence, Word-of-machine, Persuasion strategy, Travel recommendation},
abstract = {The rapid development of generative artificial intelligence (GenAI) has fostered scholarly discussions on its persuasive capabilities when compared to traditional word-of-mouth recommendations. This study explores the “word-of-machine” effect by comparing AI-based recommendations with human-generated ones to assess their impact on user perceptions. Drawing from dual-system theory and the persuasion knowledge model, this research examines the interplay among persuasion strategies (informational vs. narrative) and three persuasion boundary conditions: recommender types (AI vs. human), AI attributes (functional vs. social), AI hallucination reminder (present vs. absent), and large language model (LLM) type (tourism-specific vs. generic). Seven studies indicate that AI recommenders, especially those perceived as functional and employing informational strategies, enhance the perceived usefulness of recommendations. Furthermore, the inclusion of an AI hallucination reminder or tourism-specific LLM acts as boundary conditions, moderating the persuasiveness of informational AI recommendations. Taken together, this research offers novel insights into AI-driven persuasion, contributing to the understanding of user responses to AI-generated content.}
}
@article{FENG2025104499,
title = {Integrating generative AI with neurophysiological methods in psychiatric practice},
journal = {Asian Journal of Psychiatry},
volume = {108},
pages = {104499},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104499},
url = {https://www.sciencedirect.com/science/article/pii/S187620182500142X},
author = {Yi Feng and Yuan Zhou and Jian Xu and Xinquan Lu and Ruolei Gu and Zhihong Qiao},
keywords = {Generative artificial intelligence, Large language models, Psychiatry, Neuroscience, Physiology, Biomarkers},
abstract = {This paper explores the potential integration of generative AI (e.g., large language models) with neuroscientific and physiological approaches in psychiatric practice. Renowned for its advanced natural language processing capabilities, generative AI has shown promise in psychological counseling, emotional support, and clinical interventions. However, its application alongside neuroscience and physiology in psychiatry remains underexplored. We propose that generative AI can facilitate translations and adaptive explanations, streamline experimental preparation, enhance multi-modal data analysis, and improve clinical applications through real-time communication, content generation, and data synthesis. Furthermore, we examine how generative AI, as a specialized application of deep learning, can identify new biomarkers and construct neurophysiological models of psychiatric symptoms. We also discuss the synergistic relationship between neuroscience and AI development, particularly in improving AI's emotional recognition and learning mechanisms. While acknowledging the potential benefits, we address the challenges and risks associated with generative AI in psychiatry, including data reliability, privacy concerns, and resource constraints. This perspective advocates for a balanced approach to leveraging AI's capabilities while safeguarding mental health.}
}
@article{HERNANDEZRAMIREZ2024414,
title = {The Future End of Design Work: A Critical Overview of Managerialism, Generative AI, and the Nature of Knowledge Work, and Why Craft Remains Relevant},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {414-440},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000960},
author = {Rodrigo Hernández-Ramírez and João Batalheiro Ferreira},
keywords = {creativity, design work, generative artificial intelligence (GenAI), knowledge work, managerialism},
abstract = {This article examines the transformation of design work under the influence of managerialism and the rise of Generative Artificial Intelligence (GenAI). Drawing on John Maynard Keynes’s projections of technological unemployment and the evolving nature of work, it argues that despite advancements in automation, work has not diminished but rather devalued. Design, understood as a type of knowledge work, faces an apparent existential crisis. GenAI grows adept at mimicking the output of creative processes. The article explores how the fear of the end of design work fueled by the rise of GenAI is rooted in a misunderstanding of design work. This misunderstanding is driven by managerialism—an ideology that prioritizes efficiency and quantifiable outcomes over the intrinsic value of work. Managerialism seeks to instrumentalize and automate design, turning it into a controllable procedure to generate quantifiable creative outputs. The article argues why design work cannot be turned into a procedure and automated using GenAI. Advocates of these systems claim they enhance productivity and open new opportunities. However, evidence so far shows that flawed GenAI models produce disappointing outcomes while operating at a significant environmental cost. The article concludes by arguing for a robust theory of design—one that acknowledges the unique ontological and epistemic boundaries of design work and underscores why design cannot be reduced to a procedural output.}
}
@article{CHEN2024519,
title = {Exploration of Brand Visual Communication Innovation Design Method Based on AIGC Technology},
journal = {Procedia Computer Science},
volume = {247},
pages = {519-528},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.062},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402862X},
author = {Tiantian Chen and Bingnan Pang and Chuhua Ma and Wenwen Shao},
keywords = {AIGC Technology, Branding, Visual Communication, Creative Design, Innovative Design},
abstract = {This paper discusses the innovative application and challenges of generative artificial intelligence technology (AIGC) in brand visual communication and creative design of advertisements. AIGC has subverted the traditional communication method by virtue of its high efficiency and intelligence, realizing personalized customization and precise push ads, effectively improving the conversion effect and saving costs, and enhancing the brand's rapid response to the market and the efficiency of creative output. At the same time, this technology can promote the digitalization and intelligence of the advertising industry by tapping into big data resources. Accompanied by issues such as data security, privacy protection, talent shortage, creative quality control, brand image maintenance and regulatory adaptability, the industry needs to strengthen data security protection, cultivate cross-discipline AIGC technology and design talents, and establish a rigorous content audit system, so as to inject a strong impetus for brand visual innovation and design, and lead the brand visual communication and advertising creative design into a new stage of AI empowerment.}
}
@article{GUDEPU2025111237,
title = {GEN-DRIFT: Generative AI-driven drift handling for beyond 5G networks},
journal = {Computer Networks},
volume = {263},
pages = {111237},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111237},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625002051},
author = {Venkateswarlu Gudepu and Bhargav Chirumamilla and Venkatarami Reddy Chintapalli and Piero Castoldi and Luca Valcarenghi and Bheemarjuna Reddy Tamma and Koteswararao Kondepu},
keywords = {Beyond fifth-generation (B5G) networks, Generative Artificial Intelligence (Gen-AI), Artificial Intelligence and Machine Learning (AI/ML), Drift detection and adaptation, Service Level Agreements (SLAs)},
abstract = {Beyond fifth-generation (B5G) networks enable high data rates, low latency, and massive machine communications, driving digital transformation across sectors. The integration of Artificial Intelligence and Machine Learning (AI/ML) technologies plays a vital role in enhancing the performance and efficiency of B5G networks. However, the dynamic and ever-evolving service demands associated with B5G use cases lead to the occurrence of drift, which can significantly degrade the performance of AI/ML models. Drift occurrence often results in violations of Service Level Agreements (SLAs) and over- or under-provisioning of resources, ultimately impacting user experience and network reliability. Drift detection and adaptation are essential for addressing the dynamic service demands of B5G networks. Existing threshold approach and various other frameworks, have significant limitations, — SLA violations from delayed drift detection and inefficient resource management due to frequent retraining. This paper proposes a drift handling framework that determines drift promptly after its occurrence using Generative Artificial Intelligence (Gen-AI). The proposed Gen-AI framework is evaluated for a Quality of Service Prediction use case on the Open Radio Access Network (O-RAN) Software Community (OSC) platform and compared to the existing threshold and other frameworks. Also, a real-time dataset from the Colosseum testbed is considered to evaluate the Network Slicing (NS) use case with the proposed Gen-AI framework for drift handling. The results demonstrate that the proposed Gen-AI framework leverages both Generative Adversarial Network (GAN) and Variational AutoEncoder (VAE), significantly enhances drift detection and adaptation time in B5G networks. Specifically, in the QoS prediction use case, GAN achieves 98% drift detection accuracy, while the VAE achieves 95% , compared to 85% for the classifier framework, 25% for the threshold-based approach. In addition, a similar kind of results is observed in case of the network slicing use case. These results highlight the effectiveness of the proposed Gen-AI framework in proactively handling drift with reduced detection and adaptation time, making it a promising solution for B5G networks.}
}
@article{FLORIDOBENITEZ2025106311,
title = {Towards a new generation of smart tourism cities–GenAI-enabled aerotainment},
journal = {Cities},
volume = {167},
pages = {106311},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106311},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125006122},
author = {Lázaro Florido-Benítez and J. Andres Coca-Stefaniak},
keywords = {Artificial intelligence, Smart city marketing, Airports, Smart tourism, Digital twins},
abstract = {This article adopts a futures-based approach to explore the marketing of smart cities as tourism destinations with a specific focus on the role generative artificial intelligence (GenAI) can play in this process. Building on the novel concept of aerotainment, which advocates a holistic approach to urban destination management merging airports, theme parks, regional visitor attractions and tourism cities, the future impacts of GenAI on the planning and management of visitor experiences are discussed critically. A novel framework for the development of GenAI-enabled smart tourism cities - the urban tourism destination pyramid - is posited and discussed, including the use of tools such as digital twins and GenAI to monitor and predict future customer behaviour.}
}
@article{NGUYEN2025105463,
title = {How does GenAI reinforce higher education students' digital entrepreneurship? The curvilinear roles of perceived digital entrepreneurial desirability and feasibility},
journal = {Acta Psychologica},
volume = {259},
pages = {105463},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105463},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825007760},
author = {Thi Thu Thuy Nguyen and Cong Doanh Duong and Ngoc Huyen Nguyen and Huong Thao Pham and Thi Phuong Thu Nguyen and Van Tuan Le and Ngoc Duong Nguyen},
keywords = {Incorporation of GenAI, Infusion of GenAI, Digital entrepreneurial intentions, Entrepreneurial event model, Polynomial regression, Response surface analysis},
abstract = {Generative Artificial Intelligence (GenAI) is reshaping digital entrepreneurship by altering how individuals perceive and pursue new ventures. This study integrates GenAI adoption into the Entrepreneurial Event Model to examine its influence on perceived desirability, feasibility, and entrepreneurial intention. Using stratified random sampling, data from 1061 Vietnamese university students were analyzed via polynomial regression and response surface analysis. The findings confirm that both the incorporation and infusion of GenAI enhance entrepreneurial intentions, primarily by increasing desirability and feasibility. Cognitive alignment between desirability and feasibility emerged as critical: intentions peak when both are high and congruent, while misalignment dampens commitment. This study contributes to entrepreneurial intention theory by introducing GenAI as a cognitive trigger and uncovering curvilinear effects in cognitive evaluations. Practical implications underscore the need for AI literacy, the structured integration of AI into entrepreneurship education, and supportive ecosystems for AI-driven startups.}
}
@article{PRESCOTT2024,
title = {Comparing the Efficacy and Efficiency of Human and Generative AI: Qualitative Thematic Analyses},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/54482},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000425},
author = {Maximo R Prescott and Samantha Yeager and Lillian Ham and Carlos D {Rivera Saldana} and Vanessa Serrano and Joey Narez and Dafna Paltin and Jorge Delgado and David J Moore and Jessica Montoya},
keywords = {GenAI, generative artificial intelligence, ChatGPT, Bard, qualitative research, thematic analysis, digital health},
abstract = {Background
Qualitative methods are incredibly beneficial to the dissemination and implementation of new digital health interventions; however, these methods can be time intensive and slow down dissemination when timely knowledge from the data sources is needed in ever-changing health systems. Recent advancements in generative artificial intelligence (GenAI) and their underlying large language models (LLMs) may provide a promising opportunity to expedite the qualitative analysis of textual data, but their efficacy and reliability remain unknown.
Objective
The primary objectives of our study were to evaluate the consistency in themes, reliability of coding, and time needed for inductive and deductive thematic analyses between GenAI (ie, ChatGPT and Bard) and human coders.
Methods
The qualitative data for this study consisted of 40 brief SMS text message reminder prompts used in a digital health intervention for promoting antiretroviral medication adherence among people with HIV who use methamphetamine. Inductive and deductive thematic analyses of these SMS text messages were conducted by 2 independent teams of human coders. An independent human analyst conducted analyses following both approaches using ChatGPT and Bard. The consistency in themes (or the extent to which the themes were the same) and reliability (or agreement in coding of themes) between methods were compared.
Results
The themes generated by GenAI (both ChatGPT and Bard) were consistent with 71% (5/7) of the themes identified by human analysts following inductive thematic analysis. The consistency in themes was lower between humans and GenAI following a deductive thematic analysis procedure (ChatGPT: 6/12, 50%; Bard: 7/12, 58%). The percentage agreement (or intercoder reliability) for these congruent themes between human coders and GenAI ranged from fair to moderate (ChatGPT, inductive: 31/66, 47%; ChatGPT, deductive: 22/59, 37%; Bard, inductive: 20/54, 37%; Bard, deductive: 21/58, 36%). In general, ChatGPT and Bard performed similarly to each other across both types of qualitative analyses in terms of consistency of themes (inductive: 6/6, 100%; deductive: 5/6, 83%) and reliability of coding (inductive: 23/62, 37%; deductive: 22/47, 47%). On average, GenAI required significantly less overall time than human coders when conducting qualitative analysis (20, SD 3.5 min vs 567, SD 106.5 min).
Conclusions
The promising consistency in the themes generated by human coders and GenAI suggests that these technologies hold promise in reducing the resource intensiveness of qualitative thematic analysis; however, the relatively lower reliability in coding between them suggests that hybrid approaches are necessary. Human coders appeared to be better than GenAI at identifying nuanced and interpretative themes. Future studies should consider how these powerful technologies can be best used in collaboration with human coders to improve the efficiency of qualitative research in hybrid approaches while also mitigating potential ethical risks that they may pose.}
}
@article{FELICETTI2024100545,
title = {Artificial intelligence and project management: An empirical investigation on the appropriation of generative Chatbots by project managers},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100545},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000842},
author = {Alberto Michele Felicetti and Antonio Cimino and Alberto Mazzoleni and Salvatore Ammirato},
keywords = {Project managers, Generative artificial intelligence, Chatgpt, Appropriation Theory, Structural Equation Modeling},
abstract = {The integration of generative AI tools, such as chatbots, into project management is revolutionizing the field. This paper explores how project managers are adopting and adapting these tools, specifically focusing on ChatGPT, for enhanced project management. Using Adaptive Structuration Theory, the study examines project managers' appropriation of generative AI. It considers factors like Innovation Attitude, Peer Influence, and Task-Technology Fit, employing a survey of Italian project managers. The approach adopted to analyze data is based on Partial Least Square - Structural Equation Modeling. The research confirms the significance of the hypothesized antecedents in AI tool appropriation. Innovation Attitude and Peer Influence are shown to positively impact the creative and 'unfaithful' use of AI in project management. Task-Technology Fit is crucial for effective AI integration, impacting both creative behaviour and unfaithful appropriation. The study highlights the role of an innovative mindset, peer dynamics, and task compatibility in the effective use of AI tools in project management. It suggests potential areas for future research, including exploring cultural and organizational contexts and the rapid evolution of AI technologies.}
}
@article{CAMPBELL2025,
title = {The AI intelligence playbook: Decoding GenAI capabilities for strategic advantage},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001405},
author = {Colin Campbell and Sean Sands and Lucas Whittaker and Alexis Mavrommatis},
keywords = {Generative AI, Creative intelligence, Human-AI collaboration, Intelligence management},
abstract = {The rapid adoption of Generative Artificial Intelligence (GenAI) across industries has created new opportunities for efficiency, creativity, and innovation. At the same time, it has introduced confusion about what GenAI is capable of, how it should be used, and where it fits within existing business structures. While GenAI is often treated as a singular capability, we argue that it is better understood as a collection of distinct intelligences that vary in maturity and application. Drawing from Gardner’s Multiple Intelligences theory, this paper introduces a taxonomy of GenAI intelligences and maps how they relate to current and emerging use cases. Leveraging this taxonomy, we then offer practical guidance to help businesses identify where GenAI can provide value today and where it remains limited. We propose that companies adopt an intelligence management approach that treats GenAI not as a generic tool but as a dynamic and evolving collaborator. By understanding the specific capabilities of different AI intelligences, business leaders can align GenAI adoption with strategic goals, communicate its role more clearly, and build long-term competitive advantage.}
}
@article{ACOSTAENRIQUEZ2024100320,
title = {Exploring attitudes toward ChatGPT among college students: An empirical analysis of cognitive, affective, and behavioral components using path analysis},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100320},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100320},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001231},
author = {Benicio Gonzalo Acosta-Enriquez and Carmen Graciela {Arbulú Pérez Vargas} and Olger {Huamaní Jordan} and Marco Agustín {Arbulú Ballesteros} and Ana Elizabeth {Paredes Morales}},
keywords = {ChatGPT, University students, Attitudes, Cognitive component, Affective component, Behavioral component, Artificial intelligence, Higher education},
abstract = {The advent of generative artificial intelligence (AI) applications, such as ChatGPT, has significantly impacted various aspects of human life, including higher education. This study explores university students' attitudes toward ChatGPT, focusing on the cognitive, affective, and behavioral components of attitudes, on the basis of Mitcham's philosophical framework of attitudes toward technology. A total of 595 university students from six public and private universities in northern Peru participated in an online survey. The results of the structural equation modeling (SEM) analysis revealed that the affective component (β = 0.672∗∗∗) and the cognitive component (β = 0.260∗∗) positively influence the behavioral component of students' attitudes when ChatGPT is used. Moreover, the cognitive component (β = 0.931∗∗∗) positively influences the affective component of students' attitudes. However, gender and age did not have significant moderating effects on the relationships between the cognitive and affective components and the behavioral component. The discussion highlights that these findings contribute to understanding the psychological mechanisms underlying the adoption of ChatGPT in educational settings and offer valuable guidance for implementing this technology in teaching and learning processes. In conclusion, this study represents a significant advancement in comprehending attitudes toward generative AI technologies in higher education and opens new avenues for future research in this field.}
}
@article{HUANG2025100424,
title = {Academic cheating with generative AI: Exploring a moral extension of the theory of planned behavior},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100424},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100424},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000645},
author = {Dongpeng Huang and Nicole Hash and James J. Cummings and Kelsey Prena},
keywords = {Academic cheating, Generative AI, College students, Modified theory of planned behavior},
abstract = {As generative artificial intelligence (GenAI) tools become increasingly integrated into educational environments, concerns have emerged about their potential to facilitate academic dishonesty. Drawing on the modified theory of planned behavior, this study aimed to understand undergraduate students’ academic cheating behaviors using GenAI. The study conducted a mixed-method approach, utilizing focus groups and polls to gather insights from 25 undergraduate students enrolled in a course that incorporated GenAI into its pedagogical design in the United States. The results revealed that the integration of GenAI into higher education is perceived as inevitable. While students clearly recognized overt cheating, opinions varied regarding subtle forms of dishonesty and the effectiveness of formal deterrents. Peer influence and personal ethics were found to strongly shape cheating behaviors, with class policies enforced by instructors exerting a greater influence on student cheating behavior with GenAI than broader institutional policies. These insights can assist educators and policymakers in managing the challenges and opportunities presented by the integration of GenAI technologies into education.}
}
@article{ZHANG2025105449,
title = {Enhancing responsive teaching through in-the-moment interpretations of student resources: A study in AI-supported virtual simulation},
journal = {Computers & Education},
volume = {239},
pages = {105449},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105449},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002179},
author = {Nuodi Zhang and Fengfeng Ke and Chih-Pu Dai and Alex Barrett and Saptarshi Bhowmik and Sherry A. Southerland and Luke A. West and Xin Yuan},
keywords = {AI-Supported teaching simulation, Simulation-based learning, Preservice teachers, Science and mathematics, Responsive teaching},
abstract = {Responsive teaching, a pedagogical approach that foregrounds and builds instruction on student ideas, requires teachers to attend to and build on student resources. However, teachers' interpretations of student resources, especially during live teaching, remain understudied. In this study, we examined in-the-moment interpretations, teachers' real-time sense-making of and reflection on students' epistemic and emotional resources, and explored how teachers' in-the-moment interpretations can support their responsive teaching talk moves and knowledge. Employing a convergent mixed-methods research design, we designed and implemented a generative artificial intelligence (AI)-supported virtual simulation as a pedagogical sandbox for 40 preservice teachers (PSTs) to practice teaching with virtual students, interpret student resources, and act on these interpretations in real time. Linear regression analysis was conducted and found that PSTs’ in-the-moment interpretations are significant predictors of their responsive teaching talk moves and knowledge. Qualitative thematic analysis identified themes that corroborated and extended the findings of the quantitative component. Implications for teacher education and simulation design are discussed.}
}
@article{ZHANG2025102020,
title = {Factors influencing attitudes and behavioral intentions toward GenAI in creative collaboration: A cross-cultural comparison via a hybrid multistage approach},
journal = {Thinking Skills and Creativity},
pages = {102020},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.102020},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002688},
author = {Longyu Zhang and Cong Fang and Huan Lin and Guanbo Liang and Shijian Luo},
keywords = {Creative collaboration, Generative Artificial Intelligence (GenAI), Technology acceptance behavior, Creative thinking, Cross-cultural comparison, Hybrid multistage approach},
abstract = {ABSTRACT
The integration of Generative Artificial Intelligence (GenAI) into creative tasks offers strong potential to enhance team creativity and collaborative competence. However, the factors shaping attitudes and behavioral intentions toward GenAI in creative collaboration have received limited attention, particularly in cross-cultural contexts. To address these gaps, this study has developed and validated an integrated theoretical framework via a hybrid multistage approach. First, focus group interviews (N = 15) informed the extension of the TAM-TPB model by incorporating perceived risk, openness to experience, and AI literacy. Then, cross-cultural survey data from China (N = 529) and the USA (N = 544) were analyzed using structural equation modeling (SEM), multi-group analysis (MGA), and artificial neural networks (ANN). Results showed that subjective norm influenced user attitudes in both countries. In China, perceived usefulness and risk were key predictors, whereas in the USA, ease of use and openness to experience were more influential. Attitude, subjective norm, and perceived behavioral control were found to be critical determinants of behavioral intentions across both groups. By integrating perspectives from creativity research, this study provides theoretical and practical implications for the adoption of GenAI in creative domains, informing educators, industry practitioners, and technology developers.}
}
@article{RAUSCH202513,
title = {Towards effective continued pre-training of EU institutional LLMs on EuroHPC supercomputers},
journal = {Procedia Computer Science},
volume = {255},
pages = {13-22},
year = {2025},
note = {Proceedings of the Second EuroHPC user day},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.256},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006179},
author = {Ilja Rausch and Bhavani Bhaskar and Anna Safont-Andreu and Hans Ewetz and David Kolovratnik and Csaba Oravecz and Markus Runonen},
keywords = {generative artificial intelligence, large language models, distributed computing},
abstract = {Large Language Models (LLMs) are a significant advancement in artificial intelligence (AI), capable of learning from vast textual datasets and excelling in tasks such as text generation and translation. However, the current general LLMs often do not meet the specific requirements of the public sector and other entities in Europe due to various limitations, including in particular language coverage gaps. In response, the European Commission's Directorate-General for Translation (DGT), in the context of its partnership with the Directorate-General for Communications Networks, Content and Technology (DG CONNECT) under the Digital Europe programme, aims to leverage its high-quality multilingual data coming from all the European Union (EU) institutions to contribute to the European ecosystem of LLMs through continued pre-training of open-source models. This paper presents these ongoing efforts on the supercomputers provided by the European High Performance Computing Joint Undertaking (EuroHPC JU), with a focus on adapting Meta ’s open-weight LLMs to European linguistic diversity. To this end we leverage the datasets of the European Advanced Multilingual Information System (EURAMIS), a unique and voluminous corpus of multilingual text from all EU institutions. Our approach utilizes state-of-the-art AI tools, including Hugging Face libraries and DeepSpeed ’s ZeRO-3 data parallelism. We report on the results of our experiments, including the human evaluation of our models and various automated benchmarks such as ARC and HellaSwag, and machine translation tasks. Our findings demonstrate the potential of continued pre-training for enhancing the multilingual capabilities of open source LLMs for Europe.}
}
@article{RAHIM2025101206,
title = {Harnessing generative AI: Reviewing applications, challenges, and solutions for out-of-school children in developing regions},
journal = {Sustainable Futures},
volume = {10},
pages = {101206},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101206},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825007683},
author = {Sabit Rahim and Gul Sahar and Gul Jabeen and Sabila Khatoon and Dil Angaiz},
keywords = {AI, Generative AI, Out of school children, ChatGPT, AI integration},
abstract = {Out of school children in Gilgit-Baltistan (GB) face significant challenges due to geographical isolation, inadequate infrastructure, harsh weather, lack of schools, cultural barriers, and socio-economic constraints, especially for girls. Generative AI(GAI) has potential to bridge these gaps with adaptive, engaging and aligned curriculum content to support learning specially for out-of-school children. It enables adaptable access to education through visual, text and audio format in remote and underserved mountainous areas. This analysis includes key applications, challenges and solutions of GAI in education for out of school from an initial pool of 90 studies sourced from scholarly databases such as IEEE Xplore, Science Direct, and Google Scholar (different published included). After exhaustive screening, 30 major papers were reviewed to evaluate the potential of GAI in out-of-school children’s education. The findings highlight the significant role of Generative Artificial Intelligence (GAI) in enabling inclusive education by offering tailored content through Learning Management Systems (LMS). A theoretical model is proposed integrating GAI, LMS, adaptive and data-driven methodologies (A&DM), operational and ethical safety framework, implementation strategy, team structure, and financial considerations. Besides offering content, LMS gathers information to analyze individual needs and create appropriate instructional material. Local community facilitators are essential in reinforcing learning, bridging digital divides, and ensuring a supportive education atmosphere. The study addresses strengths, limitations, and suitability associated with GAI integration, such as integrity in assessment, critical thinking, potential disruptions, data reliability, and human interaction. This study shows GAI's potential in access, inclusivity, and engagement through strategic partnerships, adaptive approaches, and targeted efforts.}
}
@article{XU2024703,
title = {LLM enabled generative collaborative design in a mixed reality environment},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {703-715},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524000967},
author = {Shengyang Xu and Yao Wei and Pai Zheng and Jia Zhang and Chunyang Yu},
keywords = {Large language model, Generative artificial intelligence, Mixed reality, Collaborative design},
abstract = {In the collaborative design process, diverse stakeholder backgrounds often introduce inefficiencies in collaboration, such as delays in design delivery and decreased creativity, primarily due to misunderstandings and communication barriers caused by this diversity. To respond, this study proposes an AI-augmented Multimodal Collaborative Design (AI-MCD) framework. This framework utilizes Large Language Models (LLM) to establish an iterative prompting mechanism that provides professional design prompts for Generative AI (GAI) to generate precise visual schemes. On this basis, the GAI cooperates with Mixed Reality (MR) technology to form an interactive and immersive environment for enabling full participation in the design process. By integrating these technologies, the study aims to help stakeholders form a unified cognition and optimize the traditional collaborative design process. Through a case study involving the development of heart education products for children, the effectiveness of the framework is emphasized, and the practical application and effectiveness of the proposed method innovation are demonstrated.}
}
@article{FAHRNI2025105150,
title = {Teachers' practices in the use of digital technology to promote students’ self-regulated learning and metacognition: A systematic review},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105150},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105150},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002276},
author = {Désirée Delia Diana Fahrni and Glena Iten and Doreen Prasse and Tina Hascher},
keywords = {Self-regulated learning, Metacognition, Digital technology, Teachers},
abstract = {This systematic review examined 45 studies published between January 1986 and January 2025 on how K-12 school teachers promote self-regulated learning (SRL) and metacognition using digital technology. We classified these instructional practices according to instruction, coaching, scaffolding, and feedback. Digital tools such as feedback systems, dashboards, or generative artificial intelligence (GenAI) were found to enhance SRL and metacognition, complementing traditional analog strategies. The findings suggest that an appropriate combination of digital and analog promotion increases the effectiveness of SRL and metacognitive development. Future research should explore the dynamic interplay among teachers, learners, and technology to further optimize SRL promotion.}
}
@article{HUANG2025100977,
title = {Predicting post-VR game experiences with wearable physiological sensors},
journal = {Entertainment Computing},
volume = {55},
pages = {100977},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2025.100977},
url = {https://www.sciencedirect.com/science/article/pii/S1875952125000576},
author = {Wen Huang and Jiayi Gao and Xinyuan Chen},
keywords = {Virtual reality, Post-game experience, Electrodermal activity, Depersonalization, Derealization, Game Experience Questionnaire},
abstract = {Players’ post-game experiences determine their loyalty to a virtual reality (VR) game. However, methods for identifying players’ post-game experiences in the early stages have received far less attention than those for in-game experiences. In this study, we explored the potential of using measurements from wearable physiological sensors to predict players’ post–VR game experiences. The methods employed were correlation analyses and machine learning techniques. The results showed that electrodermal activity (EDA) measurements, particularly the mean EDA and mean EDA peak, are associated with players’ post-VR game experiences after accounting for noise. By utilizing machine learning technology, physiological metrics can forecast players’ diverse reactions after playing VR games with high accuracy. The symptoms of depersonalization/derealization experienced after VR gaming are attributed to being induced by actions within the virtual environment. This research makes significant contributions to the field of user experience recognition and the progression of VR gaming by demonstrating the potential for future VR game centers to analyze player emotions remotely and cost-effectively. This achievement provides the prerequisite for these centers to create tailored new 3D game scenarios to enhance players’ post-game experiences with the support of future advanced generative artificial intelligence technologies.}
}
@article{BAI2025105242,
title = {Ethical perceptions of generative AI use and employee work outcomes: Role of moral rumination and AI-supported autonomy},
journal = {Tourism Management},
volume = {111},
pages = {105242},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105242},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001128},
author = {Jing Yi Bai and IpKin Anthony Wong and Tzung Cheng T.C. Huan and Fevzi Okumus and Aliana Man Wai Leong},
keywords = {Ethical perceptions, Generative AI use, Moral rumination, AI-Supported autonomy, Ethical voice behavior, Service innovative behavior},
abstract = {Despite the numerous ethical challenges in relation to the use of generative artificial intelligence (GAI), our understanding of whether ethical perceptions of using GAI influence employees' work-related outcomes remains limited. Drawing on cognitive rumination theory, we claim that moral rumination mediates the relationship between ethical perceptions of GAI use and employee work-related outcomes. AI-supported autonomy (AI-SA) moderates this relationship. We use two independent studies to test the proposed model: an experiment (Study 1) and a field survey study (Study 2). The research findings suggest that employees’ ethical perceptions of GAI use lead to moral rumination, which impairs their service innovative behavior and ethical voice behavior. Moreover, the negative mediating effects of moral rumination can be strengthened when employees have lower levels of AI-SA. Our research advances the understanding of whether and how GAI use generates unintended consequences through an ethical pathway.}
}
@article{QIU2025,
title = {Physician Use of Large Language Models: A Quantitative Study Based on Large-Scale Query-Level Data},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/76941},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011537},
author = {Lin Qiu and Chuang Tang and Xuan Bi and Gordon Burtch and Yanmin Chen and Heping Zhang},
keywords = {generative AI, large language models, health care, generative AI usage, privacy, artificial intelligence, generative artificial intelligence},
abstract = {Background
Generative artificial intelligence (GenAI) has rapidly emerged as a promising tool in health care. Despite its growing adoption, how physicians make use of it in medical practice has not been qualitatively studied. Existing literature has largely focused on theoretical applications or experimental validations, with limited insight into real-world physician engagement with GenAI technologies.
Objective
The aim of this study was to leverage a fine-grained dataset at the query level to quantitatively examine how physicians incorporate GenAI into their clinical and research workflows. The primary objective was to analyze usage patterns over time and across physician demographics. A secondary goal was to assess potential risks to patient privacy arising from physicians’ interactions with GenAI platforms.
Methods
This study collected 106,942 query-and-answer pairs by 989 physicians between August 29, 2023, and April 16, 2024. We performed topic classification to identify the most prevalent use cases, examining how these use cases evolved over time and across demographics. We also developed sensitivity classifiers to detect personally identifiable information in physicians’ queries to explore the potential privacy breach risks around physicians’ use of GenAI.
Results
Approximately 40% (396/989) of the enrolled physicians were female, 45.9% (454/989) were younger than 25 years, and 54.1% (535/989) were between 25 and 56 years of age. The majority of them worked in clinical departments (680/989, 68.8%) or medical technology departments (127/989, 12.8%). Our classification-based quantitative analyses suggest the following. First, physicians use GenAI predominantly for medical research (64,379/106,942, 60.2%) rather than clinical practice (13,100/106,942, 12.25%). Second, physicians focus more on health care–related questions (rising from 64,165/106,942, 60% to 83,415/106,942, 78%) within the first 15% (16,041/106,942) of their query sequence. Third, the use of GenAI differed across physician demographics and features. Specifically, female physicians asked a larger proportion of clinical questions (female: 0.154 vs male: 0.108; P<.001) and administration questions (female: 0.027 vs male: 0.018; P<.001) than male physicians; younger physicians posed more clinical questions (age ≤25: 0.146 vs age ∈ (25, 40]: 0.115 vs age >40: 0.103; P<.001) but fewer research questions (age ≤25: 0.580 vs age ∈ (25, 40]: 0.607 vs age >40: 0.664; P<.001) than senior physicians; and physicians accessing GenAI via computers asked more research questions (computer: 0.637 vs mobile: 0.296; P<.001), whereas physicians using mobile devices asked more clinical questions (computer: 0.107 vs mobile: 0.264; P<.001). Fourth, only 2.68% (2866/106,942) of physician queries contained sensitive information, the majority of which were primarily derived from writing and editing.
Conclusions
Physicians are actively integrating GenAI into their professional routines, primarily leveraging it for research but also increasingly for clinical support. Usage patterns vary significantly across demographic lines, including gender, age, and device preference. Despite the presence of sensitive information in some queries, the risk of privacy breaches appears to be low.}
}
@article{CUSSENOT2025871,
title = {Eliciting the Impact of Metformin and Statins on Prostate Cancer Outcomes from a Real-life National Database Analysis},
journal = {European Urology Oncology},
volume = {8},
number = {4},
pages = {871-874},
year = {2025},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2025.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S258893112500121X},
author = {Olivier Cussenot and Yoann Taille and Jean-Jacques Portal and Géraldine Cancel-Tassin and Morgan Rouprêt and Alexandre {de la Taille} and Guillaume Ploussard and Romain Mathieu and Eric Vicaut},
keywords = {Prostate cancer, Statins, Metformin, Management, Mortality, Castration, Prostatectomy, Real-life data, Causal analysis, Bayesian network},
abstract = {Several large analyses have revealed contradictory results regarding the association between prostate cancer (PC) survival and the use of statins prescribed for prevention of dyslipidaemia or atherosclerosis complications, or of metformin prescribed for type 2 diabetes (T2D). Using data collected between 2006 and 2018 in French national health databases for 521 052 men with PC and 1 827 345 men without PC, we evaluated current evidence regarding overall survival for men with PC according to statin and/or metformin use. The highest mortality was observed in PC patients exposed to both statins and metformin (hazard ratio [HR] 2.29, 95% confidence interval [CI] 2.25–2.33). However, for patients whose first PC treatment was androgen deprivation therapy, a protective effect was observed for statin alone exposure (HR 0.91, 95% CI 0.88–0.93) and combined statin and metformin exposure (HR 0.86, 95% CI 0.85–0.87), whereas men with metformin exposure alone had higher mortality (HR 1.07, 95% CI 1.03–1.11) in comparison to non-users. This protective effect of statins was not observed for PC patients treated with radical prostatectomy. The result was confirmed using causal analysis in a Bayesian network, followed by semantic elicitation using generative artificial intelligence that compiles web-based human knowledge and dedicated literature.}
}
@article{JI2025105313,
title = {Stop-and-go wave super-resolution reconstruction via iterative refinement},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {180},
pages = {105313},
year = {2025},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2025.105313},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X25003171},
author = {Junyi Ji and Alex Richardson and Derek Gloudemans and Gergely Zachár and Matthew Nice and William Barbour and Jonathan Sprinkle and Benedetto Piccoli and Daniel B. Work},
keywords = {Stop-and-go waves, Super resolution, Generative artificial intelligence, Diffusion model},
abstract = {Stop-and-go waves are a fundamental phenomenon in freeway traffic flow, contributing to inefficiencies, crashes, and emissions. Recent advancements in high-fidelity sensor technologies have improved the ability to capture detailed traffic dynamics, yet such systems remain scarce and costly. In contrast, conventional traffic sensors are widely deployed but suffer from relatively coarse-grain data resolution, potentially impeding accurate analysis of stop-and-go waves. This article explores whether generative AI models can enhance the resolution of conventional traffic sensor to approximate the quality of high-fidelity observations. We present a novel approach using a conditional diffusion denoising model, designed to reconstruct fine-grained traffic speed field from radar-based conventional sensors via iterative refinement. We introduce a new dataset, WaveX (Ji et al., 2025a), comprising 132 hours of data from both low and high-fidelity sensor systems, totaling over 2 million vehicle miles traveled. Our approach leverages this dataset to formulate the traffic state refinement problem as a spatio-temporal super-resolution task. We demonstrate that our model can effectively reproduce the patterns of stop-and-go waves, achieving high accuracy in capturing these critical traffic dynamics. Our results show promising advancements in traffic state refinement, offering a cost-effective way to leverage existing low spatio-temporal resolution sensor networks for improved traffic analysis and management. We also open-source our dataset, trained model and code to enable further research and applications.}
}
@article{DODSON2025390,
title = {Nursing students' AI literacy and ethical understanding of AI in nursing education},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {390-394},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002033},
author = {Tracy M. Dodson and Kimberley Thompson-Hairston and Janet M. Reed},
keywords = {AI literacy, Generative AI, Nursing education, Higher academia},
abstract = {Background
Generative artificial intelligence (GAI) offers opportunities to enhance learning in nursing education yet raises concerns about academic integrity and critical thinking. Limited research exists on nursing students' ethical understanding and prior GAI exposure.
Aim
To explore freshman nursing students’ understanding of ethical versus unethical uses of GAI, their foundational AI literacy, and prior exposure to AI training.
Methods
A cross-sectional descriptive study was conducted using a researcher-developed survey administered to 119 freshman BSN students at a large Midwestern university. The survey assessed knowledge of GAI ethics, GAI use, and perceptions of university-led GAI training.
Results
Students demonstrated a strong ability to differentiate between ethical and unethical uses of GAI (93 % accuracy). However, gaps were noted in understanding when AI-generated content crosses into academic dishonesty. Many students reported limited AI training and expressed strong interest in AI learning modules.
Conclusions
Freshman nursing students are eager to use GAI responsibly but lack foundational training. AI literacy education is essential to support ethical decision-making, preserve academic integrity, and prepare students for responsible AI use in nursing practice.}
}
@article{TAN2025102918,
title = {Voice in AI-assisted multimodal texts: What do readers pay attention to?},
journal = {Computers and Composition},
volume = {75},
pages = {102918},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2025.102918},
url = {https://www.sciencedirect.com/science/article/pii/S8755461525000052},
author = {Xiao Tan and Wei Xu and Chaoran Wang},
keywords = {Voice, Multimodal writing, Photo essay, GenAI-assisted writing, dialogic perspective},
abstract = {Despite the extensive research on voice in traditional text-based writing, there is a notable lack of empirical studies examining this concept within multimodal writing contexts. The shift towards multimodality in writing research, coupled with the rise of Generative Artificial Intelligence (GenAI) in content creation, calls for a deeper understanding of how voice is perceived by readers beyond traditional writing contexts. This mixed-method study addresses this gap by exploring voice construction in GenAI-assisted photo essays from a dialogic perspective. In this study, we invited writing teachers to rank five student-produced photo essays according to their perceived voice strengths and analyzed the rankings using Kendall's Coefficient Concordance. The statistical analysis shows a weak agreement (W = 0.27) among raters, suggesting that voice is perceived quite diversely. The follow-up interviews with six focal raters reveal that they could agree on the importance of having unique ideas and angles in writing, keeping writing coherent and focused, using appropriate quotations, and incorporating images to enhance storytelling. However, opinions diverge regarding using primary and secondary texts, adopting academic discourse features, and including AI-generated images. The study adds to scholarly conversation of voice in composition studies and suggests that divergence in perceiving voice could be leveraged to fuel the discussion about voice in writing pedagogy.}
}
@article{GENES2025100031,
title = {Addressing Note Bloat: Solutions for Effective Clinical Documentation},
journal = {JACEP Open},
volume = {6},
number = {1},
pages = {100031},
year = {2025},
issn = {2688-1152},
doi = {https://doi.org/10.1016/j.acepjo.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2688115224013456},
author = {Nicholas Genes and Joseph Sills and Heather A. Heaton and Bradley D. Shy and Jean Scofi},
keywords = {clinical informatics, documentation, electronic medical records, reimbursement},
abstract = {Clinical documentation in the United States has grown longer and more difficult to read, a phenomenon described as “note bloat.” This issue is especially pronounced in emergency medicine, where high diagnostic uncertainty and brief evaluations demand focused, efficient chart review to inform decision-making. Note bloat arises from multiple factors: efforts to enhance billing, mitigate malpractice risk, and leverage electronic health record tools that improve speed and completeness. We discuss best practices based on available evidence and expert opinion to improve note clarity and concision. Recent E/M coding reforms aim to streamline documentation by prioritizing medical decision-making over details of historical and physical examination, though implementation varies. New technologies such as generative artificial intelligence present opportunities and challenges for documentation practices. Addressing note bloat will require ongoing effort from clinical leadership, electronic health record vendors, and professional organizations.}
}
@article{REN2025,
title = {Generative Semantic Communication: Architectures, Technologies, and Applications},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004291},
author = {Jinke Ren and Yaping Sun and Hongyang Du and Weiwen Yuan and Chongjie Wang and Xianda Wang and Yingbin Zhou and Ziwei Zhu and Fangxin Wang and Shuguang Cui},
keywords = {Semantic communication, Generative artificial intelligence, Large language model, Variational autoencoder, Generative adversarial network, Diffusion model},
abstract = {Semantic communication (SemCom) has emerged as a transformative paradigm for future wireless networks, aiming to improve communication efficiency by transmitting only the semantic meaning (or its encoded version) of the source data rather than the complete set of bits (symbols). However, traditional deep learning-based SemCom systems present challenges such as limited generalization, low robustness, and inadequate reasoning capabilities, primarily due to the inherently discriminative nature of deep neural networks. To address these limitations, generative artificial intelligence (GAI) is seen as a promising solution, offering notable advantages in learning complex data distributions, transforming data between high- and low-dimensional spaces, and generating high-quality content. This paper explores the applications of GAI in SemCom and presents a comprehensive study. It begins by introducing three widely used SemCom systems enabled by classical GAI models: variational autoencoders, generative adversarial networks, and diffusion models. For each system, the fundamental concept of the GAI model, the corresponding SemCom architecture, and a literature review of recent developments are provided. Subsequently, a novel generative SemCom system is proposed, incorporating cutting-edge GAI technology—large language models (LLMs). This system features LLM-based artificial intelligence (AI) agents at both the transmitter and receiver, which act as “brains” to enable advanced information understanding and content regeneration capabilities, respectively. Unlike traditional systems that focus on bitstream recovery, this design allows the receiver to directly generate the desired content from the coded semantic information sent by the transmitter. As a result, the communication paradigm shifts from “information recovery” to “information regeneration,” marking a new era in generative SemCom. A case study on point-to-point video retrieval is presented to demonstrate the effectiveness of the proposed system, showing a 99.98% reduction in communication overhead and a 53% improvement in average retrieval accuracy compared to traditional communication systems. Furthermore, four typical application scenarios for generative SemCom are described, followed by a discussion of three open issues for future research. In summary, this paper provides a comprehensive set of guidelines for applying GAI in SemCom, laying the groundwork for the efficient deployment of generative SemCom in future wireless networks.}
}
@article{BORROMEO2025e1002,
title = {Harnessing generative AI in nursing education: A bibliometric review},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {e1002-e1011},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001349},
author = {Alex S. Borromeo and Allan M. Manaloto and Mark Jerome M. Delos Santos and Ronilo P. Antonio and Magdalena D. Soyosa and Walton Wider},
keywords = {AI for inclusive healthcare education, Generative AI, Healthcare innovation, Nursing education, Education quality},
abstract = {Background
The integration of generative artificial intelligence (AI) in nursing education offers opportunities for personalized learning, clinical decision-making support, and simulation- based training. However, concerns remain about pedagogical, ethical, and practical implications.
Aim
This study aimed to map the existing literature and identify key trends, gaps, and emerging themes in the use of generative AI in nursing education.
Methods
A bibliometric review was conducted using Scopus-indexed publications. Co-citation and co- word analyses were performed to examine the intellectual structure and conceptual development of the field.
Results
Co-citation analysis revealed five thematic clusters, including ChatGPT integration, clinical competence development, and ethical concerns. Co-word analysis identified four clusters focusing on innovation, curriculum reform, and psychological aspects. A rise in publications was observed after 2020, with focal areas including adaptive learning and AI literacy. Barriers include lack of standard implementation frameworks and concerns over overreliance.
Conclusions
This review proposes a framework for ethical and effective AI integration in nursing education and outlines future research directions related to clinical impact, faculty readiness, and regulation.}
}
@article{DOSAJH2025102990,
title = {Modern machine learning methods for protein property prediction},
journal = {Current Opinion in Structural Biology},
volume = {90},
pages = {102990},
year = {2025},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2025.102990},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X25000089},
author = {Arjun Dosajh and Prakul Agrawal and Prathit Chatterjee and U. Deva Priyakumar},
abstract = {Recent progress and development of artificial intelligence and machine learning (AI/ML) techniques have enabled addressing complex biomolecular problems. AI/ML models learn the underlying distribution of data they are trained on and when exposed to new inputs, they make predictions based on patterns and relationships previously observed in the training set. Further, generative artificial intelligence (GenAI) can be used to accurately generate protein structure or sequence from specific selected properties. This review specifically focuses on the applications of AI/ML in predicting important functional properties of proteins, and the potential prospects of reverse-engineering in depicting the sequence and structure, from available protein-property information.}
}
@incollection{NNADILI20243037,
title = {Combining Predictive Models and Reinforcement Learning for Tailored Molecule Generation},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {3037-3042},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50507-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328824150507X},
author = {Miriam Nnadili and Andrew N. Okafor and David Akinpelu and Teslim Olayiwola and Jose Romagnoli},
keywords = {Molecular design, Predictive modelling, Reinforcement learning},
abstract = {This study introduces a three-fold methodology that harnesses the capabilities of generative artificial intelligence (AI), predictive modelling, and reinforcement learning to craft customized molecules with desired properties. The model seamlessly integrates deep learning techniques with Self-Referencing Embedded Strings (SELFIES) molecular representation, constructing a generative model for producing valid molecules. In the framework, a graph neural network model was used to predict molecular properties and a combined Variational Autoencoder and reinforcement learning model to generate new molecules with specific attributes. Experimental data from a surfactant study validates the effectiveness of the framework. This innovative approach not only streamlines molecular design for surfactant systems but also anticipates transformative advancements in diverse scientific and industrial domains.}
}
@article{MOHAWESH2025100580,
title = {A data-driven risk assessment of cybersecurity challenges posed by generative AI},
journal = {Decision Analytics Journal},
volume = {15},
pages = {100580},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100580},
url = {https://www.sciencedirect.com/science/article/pii/S2772662225000360},
author = {Rami Mohawesh and Mohammad Ashraf Ottom and Haythem Bany Salameh},
keywords = {Generative AI, Cybersecurity, Risk mitigation, Data poisoning, Privacy concerns, Bias},
abstract = {Generative artificial intelligence (GenAI) refers to machines that can create new ideas and generate outputs similar to human cognition. This technology has ushered in a new era, offering remarkable learning capabilities and producing unique results. In this paper, we explore the role of GenAI in cybersecurity, highlighting potential risks such as data poisoning attacks, privacy concerns, and bias in decision-making. The study aims to examine how GenAI can enhance cybersecurity by improving AI algorithms and propose strategies for mitigating associated risks. As GenAI continues to gain significance across industries, especially healthcare, it is crucial to understand its potential benefits and the risks it may pose to ensure safe and responsible deployment.}
}
@article{BALLARD20253039,
title = {Impact of ChatGPT and Large Language Models on Radiology Education: Association of Academic Radiology—Radiology Research Alliance Task Force White Paper},
journal = {Academic Radiology},
volume = {32},
number = {5},
pages = {3039-3049},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2024.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S1076633224007840},
author = {David H. Ballard and Alexander Antigua-Made and Emily Barre and Elizabeth Edney and Emile B. Gordon and Linda Kelahan and Taha Lodhi and Jonathan G. Martin and Melis Ozkan and Kevin Serdynski and Bradley Spieler and Daphne Zhu and Scott J. Adams},
keywords = {Large language models, Artificial intelligence, Curriculum, Teaching and learning, Assessment},
abstract = {Generative artificial intelligence, including large language models (LLMs), holds immense potential to enhance healthcare, medical education, and health research. Recognizing the transformative opportunities and potential risks afforded by LLMs, the Association of Academic Radiology—Radiology Research Alliance convened a task force to explore the promise and pitfalls of using LLMs such as ChatGPT in radiology. This white paper explores the impact of LLMs on radiology education, highlighting their potential to enrich curriculum development, teaching and learning, and learner assessment. Despite these advantages, the implementation of LLMs presents challenges, including limits on accuracy and transparency, the risk of misinformation, data privacy issues, and potential biases, which must be carefully considered. We provide recommendations for the successful integration of LLMs and LLM-based educational tools into radiology education programs, emphasizing assessment of the technological readiness of LLMs for specific use cases, structured planning, regular evaluation, faculty development, increased training opportunities, academic-industry collaboration, and research on best practices for employing LLMs in education.}
}
@article{FOUNG2025100248,
title = {Generating synthetic data for CALL research with GenAI: A proof-of-concept study},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100248},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100248},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000692},
author = {Dennis Foung and Lucas Kohnke},
keywords = {GenAI, CALL, Artificial intelligence, Synthetic data},
abstract = {Popular tools like ChatGPT have placed generative artificial intelligence (GenAI) in the spotlight in recent years. One use of GenAI tools is to generate simulated data—or synthetic data—when the full scope of the required microdata is unavailable. Despite suggestions for educational researchers to use synthetic data, little (if any) computer-assisted language learning (CALL) research has used synthetic data thus far. This study addresses this research gap by exploring the possibility of using synthetic datasets in CALL. The publicly available dataset resembles a typical study with a small sample size (n = 55) performed using a CALL platform. Two synthetic datasets are generated from the original datasets using the synthpop package and generative adversarial networks (GAN) in R (via the RGAN package), which are both common synthetic data generation methods. This study evaluates the synthetic datasets by (a) comparing the distribution between the synthetic and original datasets, (b) examining the model parameters of the rebuilt linear models using the synthetic and original datasets, and (c) examining the privacy disclosure metrics. The results suggest that synthpop better represents the original data and preserves privacy. Notably, the GAN-generated dataset does not produce satisfactory results. This demonstrates GAN’s key challenges alongside the potential benefits of generating synthetic data with synthpop.}
}
@article{GUAN2024100323,
title = {AI in informal digital English learning: A meta-analysis of its effectiveness on proficiency, motivation, and self-regulation},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100323},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100323},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001267},
author = {Lihang Guan and Shaofeng Li and Mingyue Michelle Gu},
keywords = {Generative artificial intelligence, Informal digital learning of English, English proficiency, Learning motivation, Self-regulation},
abstract = {This meta-analysis examines the efficacy of generative artificial intelligence (GenAI) in second language acquisition within self-directed, out-of-classroom informal contexts. A total of 15 studies meeting the inclusion criteria were identified that examined the impact of GenAI on second-language proficiency, motivation, and self-regulation. GenAI was shown to have significant effects on English proficiency and self-regulation, demonstrating its versatility in enhancing language learning outcomes. However, GenAI failed to show significant effects on learning motivation, and based on this finding we highlight the need to develop measures of motivation that are suitable for GenAI in education. Possible ways to apply GenAI in the informal language learning environment are also discussed based on the included literature.}
}
@article{KHAN2024e24890,
title = {ChatGPT in finance: Applications, challenges, and solutions},
journal = {Heliyon},
volume = {10},
number = {2},
pages = {e24890},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24890},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024009216},
author = {Muhammad Salar Khan and Hamza Umer},
keywords = {ChatGPT, Finance, Ethical challenges, Policies, Applications, Artificial intelligence},
abstract = {The emergence of ChatGPT, a generative artificial intelligence tool, has sparked a revolution in the finance industry, enabling individuals to interact with technology in natural language. However, the use of ChatGPT in finance presents a profound array of ethical considerations that demand careful scrutiny to ensure its responsible and ethical use. After a concise exploration of ChatGPT's applications in finance, this policy article delves into the ethical challenges arising from the use of ChatGPT in finance, including outcomes contaminated with biases, incorporation of fake information in the financial decisions, concerns surrounding privacy and security, lack of transparency and accountability in the decision-making processes and financial services, human job displacement, and the intricate web of legal complexities. Our article asserts that financial institutions employing ChatGPT must proactively devise strategies to confront these burgeoning challenges, mitigating their adverse effects on both individuals and society as a whole. Additionally, we propose relevant policies to tackle these ethical quandaries head-on. In essence, this article illuminates the imperative need for a meticulous ethical framework, facilitating an informed and responsible use of ChatGPT in the realm of finance, safeguarding the welfare of individuals and society. While our work significantly contributes to the research and practice of finance, we also identify future research avenues.}
}
@article{HUANG2025100526,
title = {Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin},
journal = {Environmental Science and Ecotechnology},
volume = {24},
pages = {100526},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000043},
author = {Jeffrey Huang and Simon Elias Bibri and Paul Keel},
keywords = {Sustainable smart cities, Generative artificial intelligence, Generative spatial artificial intelligence, Foundation models, Large flow model, Urban digital twin, Urban planning and design},
abstract = {Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.}
}
@article{ANDERSON2025296,
title = {Generative AI-driven personalization of the Community of Inquiry model: enhancing individualized learning experiences in digital classrooms},
journal = {International Journal of Information and Learning Technology},
volume = {42},
number = {3},
pages = {296-310},
year = {2025},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-10-2024-0240},
url = {https://www.sciencedirect.com/science/article/pii/S2056488025000034},
author = {Jeffrey E. Anderson and Carlin A. Nguyen and Gerardo Moreira},
keywords = {Social presence, Teaching presence, Personalized learning, Generative artificial intelligence (GenAI), Cognitive presence, Community of Inquiry (CoI)},
abstract = {Purpose
This paper explores the integration of generative artificial intelligence (GenAI) into the Community of Inquiry (CoI) framework, focusing on how GenAI can dynamically personalize online learning environments. The study aims to examine how GenAI can enhance social, cognitive and teaching presence, thus meeting the diverse needs of individual learners and improving engagement in digital classrooms.
Design/methodology/approach
The paper employs a conceptual approach, building on existing literature about the CoI framework and GenAI. It proposes a theoretical model that illustrates how GenAI can personalize social, cognitive and teaching presence in real-time, using engagement patterns, performance data and feedback mechanisms to adapt learning pathways for individual students.
Findings
The study finds that GenAI can significantly enhance personalized learning by dynamically adjusting the CoI framework’s elements. GenAI-driven interactions improve student engagement through personalized prompts and adaptive content delivery, while AI-generated feedback provides timely and individualized support, fostering a more responsive and student-centered learning experience.
Practical implications
For educators, the integration of GenAI into the CoI framework offers scalable solutions for personalized instruction and feedback. Institutions can leverage AI-driven insights to create more adaptive, learner-centered environments that improve learning outcomes, satisfaction and engagement, especially in large-scale online courses.
Social implications
The paper highlights the potential for AI-driven education to bridge gaps in personalized learning, promoting equity and inclusivity. However, it also addresses ethical concerns such as data privacy, algorithmic bias and the digital divide, urging careful implementation to ensure that AI enhances rather than undermines educational fairness.
Originality/value
This paper provides a novel perspective on the intersection of GenAI and the CoI framework, proposing a unique conceptual model for AI-enhanced online education. It offers valuable insights for educators, researchers and institutions aiming to create more personalized, effective and inclusive digital learning environments.}
}
@article{ARAMALI2025100191,
title = {Generative AI in project management: Impacts on corporate values, employee perceptions, and organizational practices},
journal = {Project Leadership and Society},
volume = {6},
pages = {100191},
year = {2025},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2025.100191},
url = {https://www.sciencedirect.com/science/article/pii/S266672152500016X},
author = {Vartenie Aramali and Namho Cho and Falguni Pande and M.K.S. Al-Mhdawi and Udechukwu Ojiako and Abroon Qazi},
keywords = {Generative artificial intelligence, GenAI, ChatGPT, Project management, Organizational adoption, Employee perceptions},
abstract = {This study examines the evolving role of generative AI tools, particularly ChatGPT, in project management, focusing on their impact on corporate values, employee perceptions, and practical application across project phases and roles. Using a mixed methods design comprising a literature review, two industry workshops, and a survey of 52 professionals from diverse sectors, the research integrates thematic qualitative analysis with exploratory quantitative assessment. The most prominent finding is that 74 % of participants expressed mixed or negative sentiments towards AI adoption, citing concerns about job security and data privacy, despite recognizing productivity and automation benefits. In addition, 42 % observed positive shifts in corporate values linked to AI adoption, and strong consensus emerged regarding AI's usefulness in Planning (86 %), Monitoring and Controlling (75 %), and Integration (83 %) project management process groups. While some statistically significant associations were identified, such as employer type (consultant vs. non-consultant) influencing AI use during the project execution phase, these findings are preliminary due to the small sample size. The results highlight the importance of balancing AI-driven efficiencies with ethical safeguards, human oversight, and targeted training. This study contributes to the digital transformation discourse by providing early empirical insights into how generative AI is reshaping project management practices and organisational culture.}
}
@article{BOONE2025104135,
title = {Generative AI: Opportunities, challenges, and research directions for supply chain resilience},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {199},
pages = {104135},
year = {2025},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2025.104135},
url = {https://www.sciencedirect.com/science/article/pii/S1366554525001760},
author = {Tonya Boone and Behnam Fahimnia and Ram Ganeshan and David M. Herold and Nada R. Sanders},
abstract = {Generative Artificial Intelligence (GenAI) is emerging as a transformative force in supply chain resilience, offering new ways to enhance decision-making, automate operations, and improve adaptability to disruptions. Unlike traditional AI, which relies on historical data for prediction and optimization, GenAI can generate novel solutions and simulate alternative scenarios in real time. Despite its potential, research on GenAI’s role in supply chain resilience remains limited. This paper explores GenAI applications and possible research questions across key supply chain areas while also addressing challenges such as misinformation, security risks, and governance. As GenAI integrates with existing technologies, its adoption raises critical questions about accountability and systemic dependencies. To ensure responsible implementation, further research is needed to refine oversight mechanisms, establish benchmarks, and develop hybrid decision-making models where AI enhances, rather than replaces, human expertise. These insights provide guidance to managers and policymakers to help make informed decisions about the strategic deployment of GenAI in resilience-oriented supply chains.}
}
@article{XU2025100205,
title = {Digital twins in ophthalmology: Concepts, applications, and challenges},
journal = {Asia-Pacific Journal of Ophthalmology},
pages = {100205},
year = {2025},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2025.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2162098925000726},
author = {Kezheng Xu and Xiaolan Chen and Bowen Liu and Kai Jin and Mingguang He and Danli Shi},
keywords = {Digital twin, Computational modeling, Digital medicine, Generative artificial intelligence}
}
@article{NG2025100373,
title = {Opportunities, challenges and school strategies for integrating generative AI in education},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100373},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100373},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2500013X},
author = {Davy Tsz Kit Ng and Eagle Kai Chi Chan and Chung Kwan Lo},
keywords = {Artificial intelligence, Generative AI, Teacher education, Learning/teaching, School improvement, School policy, School management},
abstract = {The increasing accessibility of Generative Artificial Intelligence (GenAI) tools has led to their exploration and adoption in education. This qualitative study investigates the opportunities and challenges associated with integrating GenAI in education, and the strategies that encourage teachers and students to embrace GenAI in school settings. We recruited 76 educators in Canada to participate in a professional training seminar about GenAI and expressed their views through online surveys. Through written reflections, an optimistic outlook on GenAI's role in education was identified among the teachers, and some discipline-specific ideas were proposed. Thematic analysis reveals three key practices of AI implementation: teaching/learning, administration and assessments. However, three major challenges are also identified: school's readiness, teachers' AI competencies, and students' AI literacy and ethics. Teachers suggest several strategies to motivate GenAI integration, including professional development, clear guidelines, and access to AI software and technical support. Finally, Singh's Teach AI Global Initiative Guidance and Socio-ecological Model are adapted and proposed to support schools in becoming AI-ready by addressing teachers' and students' needs, facilitating organizational learning, and promoting improvement and transformation to foster their literacy development. Recommendations were provided for developing effective strategies to embrace GenAI in education.}
}
@article{SQUALLIHOUSSAINI2024101491,
title = {Development of a design course for medical curriculum: Using design thinking as an instructional design method empowered by constructive alignment and generative AI},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101491},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101491},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000294},
author = {Mouna {Squalli Houssaini} and Ahmed Aboutajeddine and Imane Toughrai and Adil Ibrahimi},
keywords = {Design thinking, Medical education, Constructive alignment, Generative AI, ChatGPT},
abstract = {Doctors are nowadays experiencing many struggles in their daily practice, mainly due to new intricate challenges of the twenty-first century. However, despite the efforts of traditional medical education, it falls short in providing them with the required tools to effectively overcome these difficulties. In light of these shortcomings, this paper suggests the development of a new educational framework designed to guide medical educators in creating student-centered learning experiences. Which may be ensured by using Design Thinking (DT) as an instructional design method, merged with constructive alignment principles, and generative artificial intelligence. To demonstrate the effectiveness of this new educational approach, a case study is showcased wherein the framework was applied to design a new medical curriculum. The case study specifically focuses on first-year students in a Moroccan medical faculty and was developed based on DT principles, allowing students to engage in a transformative learning process that encourages innovation and creativity. The new curriculum includes lecture sessions, hands-on workshops, and project coaching where teams of medical students learn the design process and are given the opportunity to prototype and test their proposed solutions at local university hospital units. Overall, the showcased case study provides evidence of the framework's effectiveness in designing a new medical curriculum, illustrating its potential for enhancing medical education and engaging future doctors in impact-focused projects with long-term benefits for their career development.}
}
@article{ZHOU2025100982,
title = {Exploring the impact of generative AI on student learning in accounting},
journal = {Journal of Accounting Education},
volume = {72},
pages = {100982},
year = {2025},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2025.100982},
url = {https://www.sciencedirect.com/science/article/pii/S0748575125000338},
author = {Aner Zhou and Yan Luo},
keywords = {AI, ChatGPT, Accounting education, Student engagement with AI, Learning experience, AI in higher education},
abstract = {The rapid development of generative artificial intelligence (AI) is transforming accounting practices and education. This study provides descriptive evidence regarding how accounting students currently engage with AI tools in their learning experience. Survey data from 259 accounting students and 126 non-accounting students at a four-year public university in the U.S. reveals that 80 % of students use AI at least about once a week or more, primarily for help with difficult concepts. Students introduced to AI from their peers and friends feel more encouraged to use it than the rest of the students. While accounting and non-accounting students share many similar usage patterns, accounting students are less likely to use AI for creativity tasks or to accept AI-generated outputs without questioning their accuracy, bias, or currency, especially when it comes to decision making. Among the accounting disciplines, students are more likely to use AI for AIS. Both accounting and non-accounting students believe AI is able to reduce repetitive tasks and perceive AI with a positive impact on their learning experience, including improving GPA, helping with knowledge acquisition, making learning more enjoyable, and saving learning time. Such perceived benefits do vary by usage frequency and student GPA. This study highlights the importance of incorporating AI into accounting education to enhance student learning experience. It complements prior research focusing on educators and professionals, offering insights from students’ perspectives.}
}
@article{URBAN2025102156,
title = {Prompting for creative problem-solving: A process-mining study},
journal = {Learning and Instruction},
volume = {99},
pages = {102156},
year = {2025},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2025.102156},
url = {https://www.sciencedirect.com/science/article/pii/S0959475225000805},
author = {Marek Urban and Jiří Lukavský and Cyril Brom and Veronika Hein and Filip Svacha and Filip Děchtěrenko and Kamila Urban},
keywords = {Generative artificial intelligence, Prompt engineering, Metacognitive skills, Hybrid human-AI regulation, Creative problem-solving},
abstract = {Background
Although generative-AI systems are increasingly used to solve non-routine problems, effective prompting strategies remain largely underexplored.
Aims
The present study investigates how university students prompt ChatGPT to solve complex ill-defined problems, specifically examining which prompts are associated with higher or lower problem-solving performance.
Sample
Seventy-seven university students (53 women; Mage = 22.4 years) participated in the study.
Methods
To identify various prompt types employed by students, the study utilized qualitative analysis of interactions with ChatGPT 3.5 during the resolution of the creative problem-solving task. Participants’ performance was measured by the quality, elaboration, and originality of their ideas. Subsequently, two-step clustering was employed to identify groups of low- and high-performing students. Finally, process-mining techniques (heuristics miner) were used to analyze the interactions of low- and high-performing students.
Results
The findings suggest that including clear evaluation criteria when prompting ChatGPT to generate ideas (rs = .38), providing ChatGPT with an elaborated context for idea generation (rs = .47), and offering specific feedback (rs = .45), enhances the quality, elaboration, and originality of the solutions. Successful problem-solving involves iterative human-AI regulation, with high performers using an overall larger number of prompts (d = .82). High performers interacted with ChatGPT through dialogue, where they monitored and regulated the generation of ideas, while low performers used ChatGPT as an information resource.
Conclusions
These results emphasize the importance of active and iterative engagement for creative problem-solving and suggest that educational practices should foster metacognitive monitoring and regulation to maximize the benefits of human-AI collaboration.}
}
@article{LIM2023100790,
title = {Generative AI and the future of education: Ragnarök or reformation? A paradoxical perspective from management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {2},
pages = {100790},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100790},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000289},
author = {Weng Marc Lim and Asanka Gunasekara and Jessica Leigh Pallant and Jason Ian Pallant and Ekaterina Pechenkina},
keywords = {Academic integrity, Bard, ChatGPT, Critical analysis, DALL-E, Ethics, Future of education, Generative AI, Generative artificial intelligence, Google, Education, Educator, Management education, Management educator, OpenAI, Paradox, Paradox theory, Ragnarök, Reformation, Transformation, Transformative education},
abstract = {Generative artificial intelligence (AI) has taken the world by storm, with notable tension transpiring in the field of education. Given that Generative AI is rapidly emerging as a transformative innovation, this article endeavors to offer a seminal rejoinder that aims to (i) reconcile the great debate on Generative AI in order to (ii) lay the foundation for Generative AI to co-exist as a transformative resource in the future of education. Using critical analysis as a method and paradox theory as a theoretical lens (i.e., the “how”), this article (i) defines Generative AI and transformative education (i.e., the “ideas”), (ii) establishes the paradoxes of Generative AI (i.e., the “what”), and (iii) provides implications for the future of education from the perspective of management educators (i.e., the “so what”). Noteworthily, the paradoxes of Generative AI are four-fold: (Paradox #1) Generative AI is a ‘friend’ yet a ‘foe’, (Paradox #2) Generative AI is ‘capable’ yet ‘dependent’, (Paradox #3) Generative AI is ‘accessible’ yet ‘restrictive’, and (Paradox #4) Generative AI gets even ‘popular’ when ‘banned’ (i.e., the “what”). Through a position that seeks to embrace rather than reject Generative AI, the lessons and implications that emerge from the discussion herein represent a seminal contribution from management educators on this trending topic and should be useful for approaching Generative AI as a game-changer for education reformation in management and the field of education at large, and by extension, mitigating a situation where Generative AI develops into a Ragnarök that dooms the future of education of which management education is a part of (i.e., the “so what”).}
}
@article{SOLODUCHOPELC20244461,
title = {Role of Business Intelligent Systems in Sustainable Strategic Management for Green Jobs Creation},
journal = {Procedia Computer Science},
volume = {246},
pages = {4461-4469},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.296},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023159},
author = {Letycja Sołoducho-Pelc and Adam Sulich},
keywords = {Artificial Intelligence, business development, competitive advantage, green labor market, Scopus AI, sustainable development},
abstract = {Contemporary generative AI tools are becoming integral to business development strategies. Organizations are seeking applications for innovative technologies in science and various areas of operations. Intelligent systems bridge the gap between the scientific world and business practice. This is significant in using generative artificial intelligence in Sustainable Strategic Management (SSM) to create Green Jobs (GJs). Despite the popularity of topics like sustainable strategic management and creating GJs, science rarely combines these into interdisciplinary research. This article stands out from other review articles by using the innovative Scopus AI tool to explore a significant construct from theoretical and practical perspectives. The aim of this article is to highlight the potential for collaboration between science and business in creating GJs using Business Intelligent Systems (BIS) in SSM. The methodology of exploratory scientific inquiry supports this goal. This article employs a new research method, the Scopus AI tool. The results undergo critical analysis and interpretation, presenting conclusions and recommendations for using intelligent systems to create GJs in sustainable strategic management.}
}
@article{BANDEIRA2025,
title = {Viewpoint on the Intersection Among Health Information, Misinformation, and Generative AI Technologies},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/69474},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000556},
author = {António Bandeira and Luis Henrique Gonçalves and Felix Holl and Juliet Ugbedeojo Shaibu and Mariana Laranjo Gonçalves and Ronan Payinda and Sagun Paudel and Alessandro Berionni and Tina D Purnat and Tim Mackey},
keywords = {generative artificial intelligence, infodemics, public health, Health Information, Misinformation},
abstract = {In recent years, artificial intelligence (AI) has seen rapid advancements, with innovations such as large language models and generative AI evolving at a rapid pace. While this progress offers tremendous opportunities, it also presents risks, particularly in the creation, consumption, and amplification of information and its impact on population health and health program delivery. Thoughtful approaches are necessary to navigate the consequences of advances in AI for different health care professionals and patient populations and from a policy and governance perspective. Through a collaboration between the World Federation of Public Health Associations working groups, this Viewpoint article brings together perspectives, concerns, and aspirations from young adult professionals across 5 continents and from diverse backgrounds to explore the future of public health and AI in the context of the changing health information environment. Our discussion is divided into 2 parts, specifically examining aspects of disinformation and AI, and also the role of public health and medical professionals in a growing AI-driven health information ecosystem. This Viewpoint concludes with 5 key recommendations on how to potentially address issues such as information and disinformation overload; misinformation propagation; and resultant changes in health practices, research, ethics, and the need for robust policies that can dynamically address current and future challenges.}
}
@article{LEMPE2025,
title = {Health Care Social Robots in the Age of Generative AI: Protocol for a Scoping Review},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/63017},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825002033},
author = {Paul Notger Lempe and Camille Guinemer and Daniel Fürstenau and Corinna Dressler and Felix Balzer and Thorsten Schaaf},
keywords = {robotics, social robots, artificial intelligence, generative AI, human-robot interaction, health care sector, PRISMA},
abstract = {Background
Social robots (SR), sensorimotor machines designed to interact with humans, can help to respond to the increasing demands in the health care sector. To ensure the successful use of this technology, acceptance is paramount. Generative artificial intelligence (AI) is an emerging technology with the potential to enhance the functionality of SR and promote user acceptance by further improving human-robot interaction.
Objective
We present a protocol for a scoping review of the literature on the implementation of generative AI in SR in the health care sector. The aim of this scoping review is to map out the intersection of SR and generative AI in the health care sector; to explore if generative AI is applied in SR in the health care sector; to outline which models of generative AI and SR are used for these implementations; and to explore whether user acceptance is reported as an outcome following these implementations. This scoping review supports future research by providing an overview of the state of connectedness of 2 emerging technologies and by mapping out research gaps.
Methods
We follow the methodological framework developed by Arksey and O'Malley and the recommendations by the Joanna Briggs Institute. Our protocol was drafted using the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-analyses extension for Scoping Reviews). We will conduct a systematic literature search of the online databases MEDLINE, Embase, CINAHL (Cumulative Index to Nursing and Allied Health Literature), Web of Science, and IEEE Xplore, aiming to retrieve relevant data items via tabular data charting from references meeting specific inclusion criteria which are studies published from 2010 onwards, set in the health care sector, focusing on SR with physical bodies and implemented generative AI. There are no restrictions on study types. Results will be categorized, clustered, and summarized using tables, graphs, visual representations, and narratives.
Results
After conducting a preliminary search and deduplication in the second quarter of 2024, we retrieved 3176 preliminary results. This scoping review will be supplemented with the next methodological steps, including retrieving the results in a reference management tool as well as screening titles, abstracts, and full text regarding specific inclusion criteria. The completion of these steps is scheduled for the second quarter of 2025. Limitations based on the heterogeneity of the included studies and the general breadth of a scoping review compared to a systematic review are to be expected. To reduce bias, we adopted a system of dual reviews and thorough documentation of the study selection.
Conclusions
The conducted preliminary search implies that there are a sufficient number of heterogeneous references to complete this scoping review. To our knowledge, this is the first scoping review on generative AI in health care SR.
International Registered Report Identifier (IRRID)
PRR1-10.2196/63017}
}
@incollection{ZHOU2026109,
title = {Chapter 7 - Generative models for drug design},
editor = {Qifeng Bai and Tingyang Xu and Junzhou Huang},
booktitle = {Deep Learning in Drug Design},
publisher = {Academic Press},
pages = {109-132},
year = {2026},
isbn = {978-0-443-32908-1},
doi = {https://doi.org/10.1016/B978-0-44-332908-1.00015-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443329081000155},
author = {Yijin Zhou and Yu Guang Wang},
keywords = {Generative models, Drug design, Molecule design, Protein generation},
abstract = {This chapter provides an overview of the role of generative artificial intelligence (GAI) in the innovative process of drug discovery and design. Traditional drug design is a lengthy, complex, and expensive process, often taking 3–6 years and costing hundreds of millions of dollars to bring a new drug to market. With advances in deep-generative models, mainly including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Flow-Based Models, and Diffusion Models, researchers have shown promise in generating new drugs digitally. The chapter introduces progress in the design of novel molecules and proteins, respectively. The first section discusses the task classification, strategies, and evaluation metrics used in small molecule design. For protein generation, the chapter outlines various tasks, including sequence-to-structure, properties-to-sequence/structure, backbone design, and so on. Despite progress, challenges remain, such as the lack of standardized benchmarking methods and difficulties with tasks like fold classification and antibody CDR H3 generation. Therefore the chapter summarizes and emphasizes the vital problems and future trends in generative drug design in the last section.}
}
@article{COGNETTARIEKE2025102519,
title = {Embracing innovation and GenAI in nursing: Early lessons from the field},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102519},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102519},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001721},
author = {Cheristi Cognetta-Rieke and Betty Jo Rocchio and Jill D. Seys and Tracy L. Breece and Cheryl L. Denison and Emily Barey},
keywords = {Healthcare transformation, Nursing, Innovation, Artificial intelligence, GenAI, Electronic health record},
abstract = {ABSTRACT
Innovation and the integration of Artificial Intelligence (AI) are essential in addressing the evolving challenges in healthcare, enhancing patient care, and supporting nursing practice. This article explores the opportunities associated with Generative Artificial Intelligence (GenAI) in nursing, considerations for how to leverage it to augment the work of nursing, and strategies to accelerate its adoption. By engaging in interprofessional collaboration, leveraging technology, and fostering a culture of continuous improvement, nurses can lead transformative changes in healthcare delivery. The article also highlights case studies from Mercy and Mayo Clinic, demonstrating the practical implications and successful implementation of AI in nursing practice. These examples emphasize the importance of strategic planning, ethical considerations, and active involvement of frontline nurses in the design and adoption of AI technologies.}
}
@article{WANG2025,
title = {The Application and Ethical Implication of Generative AI in Mental Health: Systematic Review},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/70610},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925000629},
author = {Xi Wang and Yujia Zhou and Guangyu Zhou},
keywords = {generative AI, mental health, large language models, mental health detection and diagnosis, therapeutic chatbots},
abstract = {Background
Mental health disorders affect an estimated 1 in 8 individuals globally, yet traditional interventions often face barriers, such as limited accessibility, high costs, and persistent stigma. Recent advancements in generative artificial intelligence (GenAI) have introduced AI systems capable of understanding and producing humanlike language in real time. These developments present new opportunities to enhance mental health care.
Objective
We aimed to systematically examine the current applications of GenAI in mental health, focusing on 3 core domains: diagnosis and assessment, therapeutic tools, and clinician support. In addition, we identified and synthesized key ethical issues reported in the literature.
Methods
We conducted a comprehensive literature search, following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines, in PubMed, ACM Digital Library, Scopus, Embase, PsycInfo, and Google Scholar databases to identify peer-reviewed studies published from October 1, 2019, to September 30, 2024. After screening 783 records, 79 (10.1%) studies met the inclusion criteria.
Results
The number of studies on GenAI applications in mental health has grown substantially since 2023. Studies on diagnosis and assessment (37/79, 47%) primarily used GenAI models to detect depression and suicidality through text data. Studies on therapeutic applications (20/79, 25%) investigated GenAI-based chatbots and adaptive systems for emotional and behavioral support, reporting promising outcomes but revealing limited real-world deployment and safety assurance. Clinician support studies (24/79, 30%) explored GenAI’s role in clinical decision-making, documentation and summarization, therapy support, training and simulation, and psychoeducation. Ethical concerns were consistently reported across the domains. On the basis of these findings, we proposed an integrative ethical framework, GenAI4MH, comprising 4 core dimensions—data privacy and security, information integrity and fairness, user safety, and ethical governance and oversight—to guide the responsible use of GenAI in mental health contexts.
Conclusions
GenAI shows promise in addressing the escalating global demand for mental health services. They may augment traditional approaches by enhancing diagnostic accuracy, offering more accessible support, and reducing clinicians’ administrative burden. However, to ensure ethical and effective implementation, comprehensive safeguards—particularly around privacy, algorithmic bias, and responsible user engagement—must be established.}
}
@article{YAVUZ2025106108,
title = {Adverse human rights impacts of dissemination of nonconsensual sexual deepfakes in the framework of European Convention on Human Rights: A victim-centered perspective},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106108},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106108},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000032},
author = {Can Yavuz},
keywords = {Deepfake, Generative artificial intelligence, Image-based sexual abuse, Deepfake pornography, Technology-facilitated violence, Gender-based violence, Sexual violence, European Convention on Human Rights, Right to respect for private and family life, Freedom of expression, Protection of property},
abstract = {Generative artificial intelligence systems have advanced significantly over the past decade and can now generate synthetic but highly realistic audio, photo, and video, commonly referred to as deepfake. Image-based sexual abuse was the first widespread (mis)use of deepfake technology and continues to be the most common form of its misuse. However, further (empirical) research is needed to examine this phenomenon's adverse human rights implications. This paper analyses the potential adverse human rights impacts of the dissemination of nonconsensual sexual deepfakes in the framework of the European Convention on Human Rights and argues that the dissemination of such deepfakes can hinder the rights protected by the Convention. These include the right to respect for private and family life, as nonconsensual sexual deepfakes can undermine data protection, harm one's image and reputation, and compromise psychological integrity and personal autonomy. Additionally, such deepfakes can threaten freedom of expression by creating a silencing effect on public watchdogs, politicians, and private individuals. Finally, nonconsensual sexual deepfakes can impair the economic and moral rights of pornography performers by abusing their work and bodies to abuse others without authorization and compensation. These findings highlight that the Council of Europe member states must fulfil their obligations to provide effective protection against this technology-facilitated, gender-based, and sexual violence.}
}
@article{BAZZANO2025,
title = {AI Can Be a Powerful Social Innovation for Public Health if Community Engagement Is at the Core},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/68198},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125000974},
author = {Alessandra N Bazzano and Andrea Mantsios and Nicholas Mattei and Michael R Kosorok and Aron Culotta},
keywords = {Artificial Intelligence, Generative Artificial Intelligence, Citizen Science, Community Participation, Innovation Diffusion},
abstract = {There is a critical need for community engagement in the process of adopting artificial intelligence (AI) technologies in public health. Public health practitioners and researchers have historically innovated in areas like vaccination and sanitation but have been slower in adopting emerging technologies such as generative AI. However, with increasingly complex funding, programming, and research requirements, the field now faces a pivotal moment to enhance its agility and responsiveness to evolving health challenges. Participatory methods and community engagement are key components of many current public health programs and research. The field of public health is well positioned to ensure community engagement is part of AI technologies applied to population health issues. Without such engagement, the adoption of these technologies in public health may exclude significant portions of the population, particularly those with the fewest resources, with the potential to exacerbate health inequities. Risks to privacy and perpetuation of bias are more likely to be avoided if AI technologies in public health are designed with knowledge of community engagement, existing health disparities, and strategies for improving equity. This viewpoint proposes a multifaceted approach to ensure safer and more effective integration of AI in public health with the following call to action: (1) include the basics of AI technology in public health training and professional development; (2) use a community engagement approach to co-design AI technologies in public health; and (3) introduce governance and best practice mechanisms that can guide the use of AI in public health to prevent or mitigate potential harms. These actions will support the application of AI to varied public health domains through a framework for more transparent, responsive, and equitable use of this evolving technology, augmenting the work of public health practitioners and researchers to improve health outcomes while minimizing risks and unintended consequences.}
}
@article{CHENG2025101821,
title = {Does generative AI facilitate investor Trading? Early evidence from ChatGPT outages},
journal = {Journal of Accounting and Economics},
pages = {101821},
year = {2025},
issn = {0165-4101},
doi = {https://doi.org/10.1016/j.jacceco.2025.101821},
url = {https://www.sciencedirect.com/science/article/pii/S0165410125000576},
author = {Qiang Cheng and Pengkai Lin and Yue Zhao},
keywords = {Generative AI, ChatGPT, Trading volume, Information asymmetry, Price informativeness},
abstract = {In this paper, we use ChatGPT outages to provide early evidence on whether investors rely on generative artificial intelligence (GenAI) to perform professional tasks and the associated impact on stock price informativeness. We document a significant decline in stock trading volume during ChatGPT outages. The effect is stronger for firms with corporate news released immediately before or during the outages and for firms with higher ownership held by transient institutional investors. We then document declines in short-run price impact and return variance during the outage periods, consistent with reduced informed trading. Lastly, we document a positive effect of GenAI-assisted trading on long-run stock price informativeness. Overall, our findings indicate that a significant number of investors use ChatGPT in ways that influence their trading decisions and market outcomes. Future research can investigate the mechanisms underlying these GenAI effects and the potential risks of using GenAI for trading.}
}
@article{OTTO2025105444,
title = {Human-GenAI interaction for active learning in STEM education: State-of-the-art and future directions},
journal = {Computers & Education},
volume = {239},
pages = {105444},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105444},
url = {https://www.sciencedirect.com/science/article/pii/S036013152500212X},
author = {Sofie Otto and Rea Lavi and Lykke {Brogaard Bertel}},
keywords = {Generative artificial intelligence, Active learning, Higher-order thinking skills, Problem-solving, Collaborative learning, STEM education, Literature review},
abstract = {This systematic state-of-the-art review synthesizes findings from 50 studies examining the integration of GenAI into active learning models (such as problem-based learning, collaborative learning, and inquiry-based learning) within STEM education from high school to graduate levels. The analysis identifies five overarching categories of human–GenAI interaction: Tutoring, Co-creating, Processing, Coaching, and Simulating, primarily leveraged to support individual learners in developing problem-solving, critical thinking, and computational thinking skills. While the findings highlight GenAI's potential to support constructivist active learning, its application remains largely individual in scope. Moreover, challenges related to algorithmic bias, information reliability, privacy, and limited domain specificity constrain the orchestration of synergistic human-GenAI interaction, placing significant pedagogical demands on both educators and learners when interacting with GenAI-powered applications. Future research should explore how human-GenAI interactions can be orchestrated to support more active, collaborative, and context-sensitive learning environments. This includes supporting students in developing the competencies necessary to engage, individually and collaboratively, with GenAI tools reflectively, purposefully, and meaningfully in ways that enhance active learning.}
}
@article{MA2025100336,
title = {Systematically visualizing ChatGPT used in higher education: Publication trend, disciplinary domains, research themes, adoption and acceptance},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100336},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100336},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001395},
author = {Ting Ma},
keywords = {Systematic review, Bibliometric analysis, ChatGPT, Generative artificial intelligence, Higher education},
abstract = {Since it was released in November 2022, ChatGPT has been exerting revolutionary influence on the realm of higher education. In order to obtain a comprehensive understanding of the research landscape, we conduct a systematic literature review on the studies of ChatGPT used in higher education. Both quantitative and qualitative methods were adopted to bibliometrically examine the included literature selected from Web of Science and Scopus through the PRISMA protocol. Tools of VOSviewer and CitNetExplorer were employed to visualize the citation information. Our findings showed that the recent two years witnessed an ever-growing popularity of this research theme. Citation information analysis reveals the most influential authors, countries, sources, organizations and four focused topics. The disciplinary distribution of related research indicates a wide range of categories. More importantly, ChatGPT was found to be versatile in assisting teachers, students and researchers with a variety of tasks, and the factors influencing the acceptance of this technology among college students could be investigated through models like TAM, UTAUT and their extensions. We suggest future studies to focus on the ways to address the limitations and ethical issues of ChatGPT through AI literacy cultivation and joint efforts of all stakeholders.}
}
@article{HIROSAWA2024,
title = {Comparative Study to Evaluate the Accuracy of Differential Diagnosis Lists Generated by Gemini Advanced, Gemini, and Bard for a Case Report Series Analysis: Cross-Sectional Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/63010},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001352},
author = {Takanobu Hirosawa and Yukinori Harada and Kazuki Tokumasu and Takahiro Ito and Tomoharu Suzuki and Taro Shimizu},
keywords = {artificial intelligence, clinical decision support, diagnostic excellence, generative artificial intelligence, large language models, natural language processing},
abstract = {Background
Generative artificial intelligence (GAI) systems by Google have recently been updated from Bard to Gemini and Gemini Advanced as of December 2023. Gemini is a basic, free-to-use model after a user’s login, while Gemini Advanced operates on a more advanced model requiring a fee-based subscription. These systems have the potential to enhance medical diagnostics. However, the impact of these updates on comprehensive diagnostic accuracy remains unknown.
Objective
This study aimed to compare the accuracy of the differential diagnosis lists generated by Gemini Advanced, Gemini, and Bard across comprehensive medical fields using case report series.
Methods
We identified a case report series with relevant final diagnoses published in the American Journal Case Reports from January 2022 to March 2023. After excluding nondiagnostic cases and patients aged 10 years and younger, we included the remaining case reports. After refining the case parts as case descriptions, we input the same case descriptions into Gemini Advanced, Gemini, and Bard to generate the top 10 differential diagnosis lists. In total, 2 expert physicians independently evaluated whether the final diagnosis was included in the lists and its ranking. Any discrepancies were resolved by another expert physician. Bonferroni correction was applied to adjust the P values for the number of comparisons among 3 GAI systems, setting the corrected significance level at P value <.02.
Results
In total, 392 case reports were included. The inclusion rates of the final diagnosis within the top 10 differential diagnosis lists were 73% (286/392) for Gemini Advanced, 76.5% (300/392) for Gemini, and 68.6% (269/392) for Bard. The top diagnoses matched the final diagnoses in 31.6% (124/392) for Gemini Advanced, 42.6% (167/392) for Gemini, and 31.4% (123/392) for Bard. Gemini demonstrated higher diagnostic accuracy than Bard both within the top 10 differential diagnosis lists (P=.02) and as the top diagnosis (P=.001). In addition, Gemini Advanced achieved significantly lower accuracy than Gemini in identifying the most probable diagnosis (P=.002).
Conclusions
The results of this study suggest that Gemini outperformed Bard in diagnostic accuracy following the model update. However, Gemini Advanced requires further refinement to optimize its performance for future artificial intelligence–enhanced diagnostics. These findings should be interpreted cautiously and considered primarily for research purposes, as these GAI systems have not been adjusted for medical diagnostics nor approved for clinical use.}
}
@article{LEE2024100221,
title = {The impact of generative AI on higher education learning and teaching: A study of educators’ perspectives},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100221},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100221},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000225},
author = {Daniel Lee and Matthew Arnold and Amit Srivastava and Katrina Plastow and Peter Strelan and Florian Ploeckl and Dimitra Lekkas and Edward Palmer},
keywords = {Artificial intelligence, Generative artificial intelligence, Higher education, ChatGPT, Learning and teaching},
abstract = {In recent months, Artificial Intelligence (AI) has had, and will continue to have, a dramatic impact on Higher Education (HE). A study conducted by researchers at a leading university in Australia surveyed 30 of their teaching staff, drawn predominantly from their teaching academy, and interviewed eight of them regarding the impact of AI on HE. Data were analyzed using the procedures of Inductive Thematic Analysis and revealed a lack of any homogenous sentiment around AI in HE and much ambiguity regarding best practice regarding recent technological developments. The results indicate concerns exist around concepts relating to academic integrity, however, these concerns may be exaggerated. Almost half of the participants indicated they were using AI within their teaching roles with the most common design change being modifications to assessments. Less than a quarter of staff agreed the university has adequately equipped them for AI, and more than three quarters indicated they would like support. They unanimously assumed the technology will improve. Keeping in mind universities’ obligation to serve students by preparing them for industry, it is vitally important that the HE sector stays informed of developments in AI and commit to ongoing research and discussions regarding best practice in response to AI. However, anything regarding AI and future developments will be extremely difficult to predict.}
}
@article{HAMED2024108782,
title = {Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI},
journal = {iScience},
volume = {27},
number = {2},
pages = {108782},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.108782},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224000038},
author = {Ahmed Abdeen Hamed and Malgorzata Zachara-Szymanska and Xindong Wu},
keywords = {Biocomputational method, Bioinformatics, Biological sciences, Computational bioinformatics, Natural sciences, Neural networks, Artificial intelligence, Artificial intelligence applications},
abstract = {Summary
As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society.}
}
@article{YANG2025100599,
title = {Research on the precise design of lung cancer-specific receptors and intelligent optimization strategies for sensing interfaces based on the fusion technology of chemical sensors and generative AI},
journal = {Chinese Journal of Analytical Chemistry},
pages = {100599},
year = {2025},
issn = {1872-2040},
doi = {https://doi.org/10.1016/j.cjac.2025.100599},
url = {https://www.sciencedirect.com/science/article/pii/S1872204025001082},
author = {Yu Yang and Li Dingqi and Song Guilin and Gao Yan and Wang Dong and Xi Chongcheng and Feng Quansheng},
keywords = {chemical sensors, generative AI, lung cancer-specific receptors, intelligent optimization of sensing interfaces},
abstract = {Lung cancer is one of the deadliest malignant tumors globally, and innovative early diagnostic technologies are crucial for improving patient prognosis. This study innovatively integrates chemical sensors with generative artificial intelligence (AI) technologies to construct a research paradigm for the intelligent design of lung cancer-specific receptors and the optimization of sensor interfaces. In terms of technological innovation, on one hand, an electrochemical sensing system based on nano-composite materials and an optical enhancement detection platform are built to achieve ultra-trace detection of lung cancer markers, aiming to break through the sensitivity bottleneck of traditional methods; on the other hand, multi-modal generative models are utilized to deeply mine multi-omics data, designing intelligent receptors with topological adaptability, significantly improving the accuracy and binding efficiency of biomolecule recognition. Clinical validation results show that this technology greatly enhances diagnostic efficacy in early lung cancer screening, and personalized treatment strategies based on AI effectively extend patient survival. In terms of technical translation and application, the developed portable detection devices and wearable monitoring technologies can reduce detection costs, providing a widely applicable screening solution for areas with limited medical resources. The study also reveals core challenges such as the explainability of generative AI and the environmental stability of sensors, proposing forward-looking directions such as quantum-biological interface integration and biomimetic adaptive sensing. This research establishes a new paradigm of "intelligent perception - dynamic optimization - precise intervention" for early lung cancer diagnosis, with significant clinical translational value.}
}
@article{SHIMIZU2023,
title = {Developing Medical Education Curriculum Reform Strategies to Address the Impact of Generative AI: Qualitative Study},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/53466},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000818},
author = {Ikuo Shimizu and Hajime Kasai and Kiyoshi Shikino and Nobuyuki Araki and Zaiya Takahashi and Misaki Onodera and Yasuhiko Kimura and Tomoko Tsukamoto and Kazuyo Yamauchi and Mayumi Asahina and Shoichi Ito and Eiryo Kawakami},
keywords = {artificial intelligence, curriculum reform, generative artificial intelligence, large language models, medical education, qualitative analysis, strengths-weaknesses-opportunities-threats (SWOT) framework},
abstract = {Background
Generative artificial intelligence (GAI), represented by large language models, have the potential to transform health care and medical education. In particular, GAI’s impact on higher education has the potential to change students’ learning experience as well as faculty’s teaching. However, concerns have been raised about ethical consideration and decreased reliability of the existing examinations. Furthermore, in medical education, curriculum reform is required to adapt to the revolutionary changes brought about by the integration of GAI into medical practice and research.
Objective
This study analyzes the impact of GAI on medical education curricula and explores strategies for adaptation.
Methods
The study was conducted in the context of faculty development at a medical school in Japan. A workshop involving faculty and students was organized, and participants were divided into groups to address two research questions: (1) How does GAI affect undergraduate medical education curricula? and (2) How should medical school curricula be reformed to address the impact of GAI? The strength, weakness, opportunity, and threat (SWOT) framework was used, and cross-SWOT matrix analysis was used to devise strategies. Further, 4 researchers conducted content analysis on the data generated during the workshop discussions.
Results
The data were collected from 8 groups comprising 55 participants. Further, 5 themes about the impact of GAI on medical education curricula emerged: improvement of teaching and learning, improved access to information, inhibition of existing learning processes, problems in GAI, and changes in physicians’ professionality. Positive impacts included enhanced teaching and learning efficiency and improved access to information, whereas negative impacts included concerns about reduced independent thinking and the adaptability of existing assessment methods. Further, GAI was perceived to change the nature of physicians’ expertise. Three themes emerged from the cross-SWOT analysis for curriculum reform: (1) learning about GAI, (2) learning with GAI, and (3) learning aside from GAI. Participants recommended incorporating GAI literacy, ethical considerations, and compliance into the curriculum. Learning with GAI involved improving learning efficiency, supporting information gathering and dissemination, and facilitating patient involvement. Learning aside from GAI emphasized maintaining GAI-free learning processes, fostering higher cognitive domains of learning, and introducing more communication exercises.
Conclusions
This study highlights the profound impact of GAI on medical education curricula and provides insights into curriculum reform strategies. Participants recognized the need for GAI literacy, ethical education, and adaptive learning. Further, GAI was recognized as a tool that can enhance efficiency and involve patients in education. The study also suggests that medical education should focus on competencies that GAI hardly replaces, such as clinical experience and communication. Notably, involving both faculty and students in curriculum reform discussions fosters a sense of ownership and ensures broader perspectives are encompassed.}
}
@article{NENSA2025100001,
title = {Embracing generative AI: A necessary evolution in professional writing},
journal = {European Journal of Radiology Artificial Intelligence},
volume = {1},
pages = {100001},
year = {2025},
issn = {3050-5771},
doi = {https://doi.org/10.1016/j.ejrai.2024.100001},
url = {https://www.sciencedirect.com/science/article/pii/S305057712400001X},
author = {Felix Nensa},
keywords = {GenAI, LLM, ChatGPT, AI, Writing},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has become an integral part of our professional lives. Despite their transformative potential, many professionals remain cautious about using these tools for drafting and editing manuscripts. While it is reasonable for academic journals to request transparency regarding AI usage, fundamental reservations against employing generative AI (GenAI) are outdated. A useful analogy can be drawn from the film Hidden Figures, which depicts the arrival of IBM computers at NASA, eventually replacing human “computers” for manual calculations. Dorothy Vaughan, the supervisor of these human experts, anticipated the change and adapted proactively by teaching her team programming skills. Today, it is unthinkable for scientific calculations to be done without software, just as it will soon be unthinkable to draft professional texts without AI assistance. GenAI should be seen as a tool that enhances human creativity rather than replacing it. By handling mundane aspects of writing, it allows authors to focus on critical thinking and idea generation. Transparency in AI use fosters trust and maintains ethical standards. Authors are encouraged to use GenAI under supervision and disclose its use openly. This will not only improve manuscript quality but also help authors allocate more time to innovation and creative thinking. Embracing GenAI is not merely an option; it represents an essential evolution in the way we approach writing.}
}