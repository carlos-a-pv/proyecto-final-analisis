@article{SANATIZADEH2025104178,
title = {Engagement or entanglement? The dual impact of generative artificial intelligence in online knowledge exchange platforms},
journal = {Information & Management},
volume = {62},
number = {6},
pages = {104178},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104178},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000813},
author = {Aida Sanatizadeh and Yingda Lu and Keran Zhao and Yuheng Hu},
keywords = {Generative AI, ChatGPT, Online knowledge exchange platforms, User engagement},
abstract = {Generative artificial intelligence (AI) tools, such as ChatGPT and Gemini, have the potential to substantially transform various domains, particularly platforms centered on information exchange. This study investigates the impact of generative AI on content contribution and knowledge-seeking behavior within online knowledge exchange platforms by leveraging a comprehensive dataset from a leading Q&A community. The results indicate a decrease in engagement levels, as evidenced by fewer posts and users, especially within the technology sector. However, this decline is accompanied by a notable benefit: an enhancement in the quality and complexity of questions, leading to an increased number of visits to these types of posts. Furthermore, our findings show a reduction in the number of questions and answers contributed by users with lower expertise, making communities more efficient. Our research highlights the importance of generative AI tools in the dynamics of knowledge exchange and offers suggestions for platform designers to revitalize their ecosystems to enhance user engagement.}
}
@article{SUCHANEK2025100781,
title = {Generative artificial intelligence expectations and experiences in management education: ChatGPT use and student satisfaction},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100781},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100781},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X2500126X},
author = {Petr Suchanek and Maria Kralova},
keywords = {Generative artificial intelligence (AI), ChatGPT, Management studies, Student satisfaction, AI student satisfaction with studies model},
abstract = {Generative artificial intelligence (AI) has witnessed a major boom in recent years and is increasingly penetrating the higher education sector. This study focused on the use of ChatGPT by undergraduate management students. We developed a model called the “AI Student Satisfaction with Studies model” (AI 3S-model) to investigate how generative AI, specifically ChatGPT, affects student satisfaction with their management studies. Factors used in the model included AI-related student expectations, AI-related student job expectations, perceived quality of AI among students, and AI-related overall student satisfaction. An online questionnaire was administered to students from economics faculties at various universities in the Czech Republic. We deliberately focused on one specialized economics college and several large economics faculties. The sample comprised 231 respondents. To analyze the data, we applied covariance-based structural equation modelling using maximum likelihood estimation. Our findings indicate that two factors directly and positively affect overall student satisfaction with AI use: their perceived quality of studies and their expectations. Additionally, perceived quality acts as a significant mediator between student expectations and overall satisfaction, as well as between job expectations and overall satisfaction. Students believe that ChatGPT enhances their quality of education, which boosts their overall satisfaction. For management education programs, this means that finding ways to effectively integrate generative AI into students’ learning and establishing reasonable limits is highly beneficial, whereas prohibiting the use of generative AI tools would likely decrease student satisfaction and diminish the perceived quality of their studies.}
}
@article{HABER2024,
title = {The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/54781},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000544},
author = {Yuval Haber and Inbar Levkovich and Dorit Hadar-Shoval and Zohar Elyoseph},
keywords = {psychoanalysis, generative artificial intelligence, psychotherapy, large language models, narcissism, narcissist, narcissistic, perception, perceptions, critical thinking, transparency, autonomy, mental health, interpersonal, LLM, LLMs, language model, language models, artificial intelligence, generative, AI, ethic, ethics, ethical},
abstract = {This paper explores a significant shift in the field of mental health in general and psychotherapy in particular following generative artificial intelligence’s new capabilities in processing and generating humanlike language. Following Freud, this lingo-technological development is conceptualized as the “fourth narcissistic blow” that science inflicts on humanity. We argue that this narcissistic blow has a potentially dramatic influence on perceptions of human society, interrelationships, and the self. We should, accordingly, expect dramatic changes in perceptions of the therapeutic act following the emergence of what we term the artificial third in the field of psychotherapy. The introduction of an artificial third marks a critical juncture, prompting us to ask the following important core questions that address two basic elements of critical thinking, namely, transparency and autonomy: (1) What is this new artificial presence in therapy relationships? (2) How does it reshape our perception of ourselves and our interpersonal dynamics? and (3) What remains of the irreplaceable human elements at the core of therapy? Given the ethical implications that arise from these questions, this paper proposes that the artificial third can be a valuable asset when applied with insight and ethical consideration, enhancing but not replacing the human touch in therapy.}
}
@article{PUGLIESE2025667,
title = {Generative Artificial Intelligence in Nutrition: A Revolution in Accessibility and Personalization},
journal = {The Journal of Nutrition},
volume = {155},
number = {3},
pages = {667-668},
year = {2025},
issn = {0022-3166},
doi = {https://doi.org/10.1016/j.tjnut.2025.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S002231662500032X},
author = {Nicola Pugliese and Federico Ravaioli}
}
@article{JUSOH2025117825,
title = {How generative Artificial Intelligence can transform drug discovery?},
journal = {European Journal of Medicinal Chemistry},
volume = {295},
pages = {117825},
year = {2025},
issn = {0223-5234},
doi = {https://doi.org/10.1016/j.ejmech.2025.117825},
url = {https://www.sciencedirect.com/science/article/pii/S0223523425005902},
author = {Ainin Sofia Jusoh and Muhammad Akmal Remli and Mohd Saberi Mohamad and Tristan Cazenave and Chin Siok Fong},
keywords = {Generative artificial Intelligence, Drug discovery, Protein-protein interactions, Drug-target interactions, Database, Performance metrics, Molecules representations},
abstract = {Generative Artificial Intelligence (Generative AI) is transforming drug discovery by enabling advanced analysis of complex biological and chemical data. This review explores key Generative AI models, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), flow-based models and Transformer-based models, with Transformers gaining prominence due to the abundance of text-based biological data and the success of language models like ChatGPT. The paper discusses molecular representations, performance evaluation metrics, and current trends in Generative AI-driven drug discovery, such as protein-protein interactions (PPIs), drug-target interactions (DTIs) and de-novo drug design. However, these approaches face significant challenges, including applicability domain issues, lack of interpretability, data scarcity, novelty, scalability, computational resource limitations, and the absence of standardized evaluation metrics. These challenges hinder model performance, complicate decision-making, and limit the generation of novel and viable drug candidates. To address these issues, strategies such as hybrid models, integration of multiomics datasets, explainable AI (XAI) techniques, data augmentation, transfer learning, and cloud-based solutions are proposed. Additionally, a curated list of databases supporting drug discovery research is provided. The review concludes by emphasizing the need for optimized AI models, robust validation methods, interdisciplinary collaboration, and future academic efforts to fully realize the potential of Generative AI in advancing drug discovery.}
}
@article{FLEURENCE2025,
title = {A Taxonomy of Generative Artificial Intelligence in Health Economics and Outcomes Research: An ISPOR Working Group Report},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.2167},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525023356},
author = {Rachael L. Fleurence and Xiaoyan Wang and Jiang Bian and Mitchell K. Higashi and Turgay Ayer and Hua Xu and Dalia Dawoud and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic models, generative AI, large language models, systematic reviews},
abstract = {Objectives
This article presents a taxonomy of generative artificial intelligence (AI) for health economics and outcomes research (HEOR), explores emerging applications, outlines methods to improve the accuracy and reliability of AI-generated outputs, and describes current limitations.
Methods
Foundational generative AI concepts are defined, and current HEOR applications are highlighted, including for systematic literature reviews, health economic modeling, real-world evidence generation, and dossier development. Techniques such as prompt engineering (eg, zero-shot, few-shot, chain-of-thought, and persona pattern prompting), retrieval-augmented generation, model fine-tuning, domain-specific models, and the use of agents are introduced to enhance AI performance. Limitations associated with the use of generative AI foundation models are described.
Results
Generative AI demonstrates significant potential in HEOR, offering enhanced efficiency, productivity, and innovative solutions to complex challenges. Although foundation models show promise in automating complex tasks, challenges persist in scientific accuracy and reproducibility, bias and fairness, and operational deployment. Strategies to address these issues and improve AI accuracy are discussed.
Conclusions
Generative AI has the potential to transform HEOR by improving efficiency and accuracy across diverse applications. However, realizing this potential requires building HEOR expertise and addressing the limitations of current AI technologies. Ongoing research and innovation will be key to shaping AI’s future role in our field.}
}
@article{WHITE2025452,
title = {Generative artificial intelligence tools in journal article preparation: A preliminary catalog of ethical considerations, opportunities, and pitfalls*},
journal = {JDS Communications},
volume = {6},
number = {3},
pages = {452-457},
year = {2025},
issn = {2666-9102},
doi = {https://doi.org/10.3168/jdsc.2024-0707},
url = {https://www.sciencedirect.com/science/article/pii/S2666910224002011},
author = {Robin R. White},
abstract = {The launch of generative artificial intelligence (GenAI) tools has catalyzed considerable discussion about the potential impacts of these systems within the scientific article preparation process. This symposium paper seeks to summarize current recommendations on the use of GenAI tools in scientific article preparation, and to provide speculations about the future challenges and opportunities of GenAI use in scientific publishing. Due to the dynamic nature of these tools and the rapid advancement of their sophistication, the most important recommendation is that ongoing engagement and discussion within the scientific community about these issues is critical. When using GenAI tools in scientific article preparation, humans are ultimately accountable and responsible for products produced. Given that accountability, an expert panel convened by the National Academies of Science, Engineering, and Medicine recently proposed principles of GenAI use in science communication, including (1) transparent disclosure and attribution; (2) verification of AI-generated content and analyses; (3) documentation of artificial intelligence (AI)-generated data; (4) a focus on ethics and equity; and (5) continuous monitoring, oversight, and public engagement. In addition to the importance of human accountability, many publishers have established consistent policies suggesting that GenAI tools should not be used for peer reviewing, figure generation or manipulation, or assigned authorship on scientific articles. Along with the potential ethical challenges associated with GenAI use in scientific publishing, there are numerous potential benefits. Herein we summarize example conversations demonstrating the capacity of GenAI tools to support the article preparation process, and an example standard operating procedure for human-AI interaction in article preparation. Finally, diverse broader questions about the impact of GenAI tools on communication, knowledge, and advancement of science are raised for rumination.}
}
@article{ZAMORA2025103161,
title = {Generative artificial intelligence, large language models and ChatGPT in musculoskeletal Oncology: Current applications and future potential},
journal = {Journal of Clinical Orthopaedics and Trauma},
volume = {69},
pages = {103161},
year = {2025},
issn = {0976-5662},
doi = {https://doi.org/10.1016/j.jcot.2025.103161},
url = {https://www.sciencedirect.com/science/article/pii/S0976566225002590},
author = {Tomas Zamora and Paulina Salas and Sebastian Zuñiga and Eduardo Botello and Marcelo E. Andia},
keywords = {Musculoskeletal neoplasms, Artificial intelligence, Natural language processing, Machine learning, Decision support systems, Clinical, Medical informatics},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has emerged as a transformative technology across all medical specialties, including musculoskeletal (MSK) oncology. These models, such as ChatGPT and others, can process natural language, synthesize vast amounts of information, and generate contextually relevant outputs that resemble human communication. In orthopedic oncology, LLMs show promise in facilitating literature reviews, enhancing patient education, and supporting clinical decision-making by analyzing multidimensional data while providing improved logic-based reasoning. Additionally, they can assist in radiological and pathological workflows by interpreting imaging reports and drafting diagnostic summaries, thereby increasing efficiency and accuracy. In the near future, they are expected to aid in real-time patient follow-up and counseling, information transfer, efficient diagnostics, and even continuous surgical education and assistance. Despite their potential, challenges such as the risk of inaccuracies and biases, as well as the necessity for continuous supervision, warrant a cautious and responsible integration into clinical practice. This narrative review examines the current applications of LLMs in MSK oncology, their limitations, and their future potential in shaping precision medicine and equitable healthcare delivery.}
}
@article{GOFMAN2025S260,
title = {HTA74 Transforming Global Value Dossier (GVD) Drafting: Creation with a Generative Artificial Intelligence (Gen AI)-Driven Coauthoring Accelerator},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S260},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012100},
author = {Larisa Gofman and Jevin G. Meyerink and Sheetal Sharma}
}
@article{BARCAUI2023100101,
title = {Who is better in project planning?Generative artificial intelligence or project managers?},
journal = {Project Leadership and Society},
volume = {4},
pages = {100101},
year = {2023},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2023.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2666721523000224},
author = {André Barcaui and André Monat},
keywords = {Generative, Artificial intelligence, Project management},
abstract = {This paper presents a comparative study of generative artificial intelligence (AI), specifically the GPT-4 model, and a human project manager in the context of a project plan development. The study's objective was to analyze the content and structure of a project plan prepared by this disruptive new technology and its human counterpart, focusing on the digital technology sector. Through a primarily qualitative methodology, the study scrutinizes critical aspects of each part of the project plan, including scope preparation, schedule development, cost estimation, resources evaluation, quality planning, stakeholder mapping, communication planning, and risk analysis. The results indicate unique strengths and weaknesses for both AI-generated and human-generated project plans, revealing them as complementary in the project planning process. It also emphasizes the continued importance of human expertise in refining AI outputs and harnessing the full potential of AI through the process known as prompt engineering. In conclusion, this study illustrates the potential synergy between human experience and AI in project planning, suggesting the careful integration of human and AI capabilities is key to developing robust and trustworthy project plans.}
}
@article{SIMMS2025106544,
title = {Generative artificial intelligence (AI) literacy in nursing education: A crucial call to action},
journal = {Nurse Education Today},
volume = {146},
pages = {106544},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2024.106544},
url = {https://www.sciencedirect.com/science/article/pii/S0260691724004544},
author = {Rachel C. Simms},
keywords = {Artificial intelligence, Nursing education, Educational technology, Ethics, Nursing},
abstract = {Introduction
Generative artificial intelligence (AI) is revolutionizing healthcare, necessitating corresponding advancements in nursing education to ensure that future nurses are equipped for a technologically driven environment. This article explores the imperative integration of generative AI literacy in nursing education.
Implications for nurse educators
The article delves into the practical challenges and opportunities presented by generative AI in nursing. It underscores the need for educators to adapt curricula and teaching methods to effectively incorporate generative AI learning, ensuring students are proficient in generative AI technologies and aware of their ethical implications.
Generative AI literacy
Defined as a core educational requirement, this section highlights the skills and knowledge that nurse educators must impart. It encompasses the ability to critically assess AI-generated content, understand the underlying technologies, and responsibly apply this knowledge in clinical settings.
Conclusion
The article concludes by emphasizing the urgency of integrating generative AI literacy into nursing education. It advocates for a proactive approach to curriculum development and calls for global collaboration and standardization in AI education to address the diverse and evolving needs of healthcare.}
}
@article{LUO2025,
title = {Generative Artificial Intelligence Tools in Medical Research (GAMER): Protocol for a Scoping Review and Development of Reporting Guidelines},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/64640},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825005001},
author = {Xufei Luo and Yih Chung Tham and Mohammad Daher and Zhaoxiang Bian and Yaolong Chen and Janne Estill},
keywords = {generative AI, chatbots, reporting guidelines, transparency, Delphi method, large language models, ChatGPT},
abstract = {Background
The integration of artificial intelligence (AI) has revolutionized medical research, offering innovative solutions for data collection, patient engagement, and information dissemination. Powerful generative AI (GenAI) tools and other similar chatbots have emerged, facilitating user interactions with virtual conversational agents. However, the increasing use of GenAI tools in medical research presents challenges, including ethical concerns, data privacy issues, and the potential for generating false content. These issues necessitate standardization of reporting to ensure transparency and scientific rigor.
Objective
The development of the Generative Artificial Intelligence Tools in Medical Research (GAMER) reporting guidelines aims to establish comprehensive, standardized guidelines for reporting the use of GenAI tools in medical research.
Methods
The GAMER guidelines are being developed following the methodology recommended by the Enhancing the Quality and Transparency of Health Research (EQUATOR) Network, involving a scoping review and expert Delphi consensus. The scoping review searched PubMed, Web of Science, Embase, CINAHL, PsycINFO, and Google Scholar (for the first 200 results) using keywords like “generative AI” and “medical research” to identify reporting elements in GenAI-related studies. The Delphi process involves 30-50 experts with ≥3 years of experience in AI applications or medical research, selected based on publication records and expertise across disciplines (eg, clinicians and data scientists) and regions (eg, Asia and Europe). A 7-point-scale survey will establish consensus on checklist items. The testing phase invites authors to apply the GAMER checklist to GenAI-related manuscripts and provide feedback via a questionnaire, while experts assess reliability (κ statistic) and usability (time taken, 7-point Likert scale). The study has been approved by the Ethics Committee of the Institute of Health Data Science at Lanzhou University (HDS-202406-01).
Results
The GAMER project was launched in July 2023 by the Evidence-Based Medicine Center of Lanzhou University and the WHO Collaborating Centre for Guideline Implementation and Knowledge Translation, and it concluded in July 2024. The scoping review was completed in November 2023. The Delphi process was conducted from October 2023 to April 2024. The testing phase began in March 2025 and is ongoing. The expected outcome of the GAMER project is a reporting checklist accompanied by relevant terminology, examples, and explanations to guide stakeholders in better reporting the use of GenAI tools.
Conclusions
GAMER aims to guide researchers, reviewers, and editors in the transparent and scientific application of GenAI tools in medical research. By providing a standardized reporting checklist, GAMER seeks to enhance the clarity, completeness, and integrity of research involving GenAI tools, thereby promoting collaboration, comparability, and cumulative knowledge generation in AI-driven health care technologies.
International Registered Report Identifier (IRRID)
DERR1-10.2196/64640}
}
@article{LUO2025111903,
title = {Lack of methodological rigor and limited coverage of generative artificial intelligence in existing artificial intelligence reporting guidelines: a scoping review},
journal = {Journal of Clinical Epidemiology},
volume = {186},
pages = {111903},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2025.111903},
url = {https://www.sciencedirect.com/science/article/pii/S0895435625002367},
author = {Xufei Luo and Bingyi Wang and Qianling Shi and Zijun Wang and Honghao Lai and Hui Liu and Yishan Qin and Fengxian Chen and Xuping Song and Long Ge and Lu Zhang and Zhaoxiang Bian and Yaolong Chen and Hongfeng He and Ye Wang and Haodong Li and Huayu Zhang and Di Zhu and Yuanyuan Yao and Dongrui Peng and Zhewei Li and Jie Zhang and Yishan Qin and Fan Wang and Zhenyu Tang and Yueyan Li and Hanxiang Liu and Jungang Zhao},
keywords = {Reporting guidelines, Artificial intelligence, Scoping review, Generative artificial intelligence, Large language models, Methodological quality},
abstract = {Objectives
This study aimed to systematically map the development methods, scope, and limitations of existing artificial intelligence (AI) reporting guidelines in medicine and to explore their applicability to generative AI (GAI) tools, such as large language models (LLMs).
Study Design and Setting
We reported a scoping review adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. Five information sources were searched, including MEDLINE (via PubMed), Enhancing the QUAlity and Transparency Of health Research (EQUATOR) Network, China National Knowledge Infrastructure, FAIRsharing, and Google Scholar, from inception to December 31, 2024. Two reviewers independently screened records and extracted data using a predefined Excel template. Data included guideline characteristics (eg, development methods, target audience, AI domain), adherence to EQUATOR Network recommendations, and consensus methodologies. Discrepancies were resolved by a third reviewer.
Results
Sixty-eight AI reporting guidelines were included; 48.5% focused on general AI, whereas only 7.4% addressed GAI/LLMs. Methodological rigor was limited; 39.7% described development processes, 42.6% involved multidisciplinary experts, and 33.8% followed EQUATOR recommendations. Significant overlap existed, particularly in medical imaging (20.6% of guidelines). GAI-specific guidelines (14.7%) lacked comprehensive coverage and methodological transparency.
Conclusion
Existing AI reporting guidelines in medicine have suboptimal methodological rigor, redundancy, and insufficient coverage of GAI applications. Future and updated guidelines should prioritize standardized development processes, multidisciplinary collaboration, and expanded focus on emerging AI technologies like LLMs.}
}
@article{KUMAR2025115160,
title = {Generative artificial intelligence (GenAI) revolution: A deep dive into GenAI adoption},
journal = {Journal of Business Research},
volume = {189},
pages = {115160},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.115160},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324006647},
author = {Aman Kumar and Amit Shankar and Linda D. Hollebeek and Abhishek Behl and Weng Marc Lim},
keywords = {Artificial intelligence, Generative artificial intelligence, Generative AI, GenAI, Adoption, Behavioral reasoning theory, Mixed methods},
abstract = {This study examines key reasons (for and against) that influence business-to-business (B2B) managers’ intention to adopt generative artificial intelligence (GenAI). We also investigate how GenAI adoption influences firm performance, along with the moderating effect of ethical leadership. Study 1 undertakes a series of in-depth interviews, yielding a set of hypotheses that are tested in Study 2. A total of 277 responses was collected from respondents in the USA, the UK, Canada, India, Australia, Malaysia, and Japan to test the proposed model using structural equation modeling. The findings highlight that need for uniqueness, information completeness, convenience, and deceptiveness significantly impact GenAI adoption. The results also highlight that GenAI adoption boosts firm performance. Finally, ethical leadership was found to moderate the effect of GenAI adoption on firm performance. This study enriches the GenAI, technology adoption, and behavioral reasoning theory literatures while also providing pertinent insights for firms intending to adopt GenAI.}
}
@article{MOULAEI2024105474,
title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105474},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105474},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001370},
author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammad {Reza Afrash}},
keywords = {Generative artificial intelligence, Health, Artificial intelligence},
abstract = {Background
Generative artificial intelligence (GAI) is revolutionizing healthcare with solutions for complex challenges, enhancing diagnosis, treatment, and care through new data and insights. However, its integration raises questions about applications, benefits, and challenges. Our study explores these aspects, offering an overview of GAI's applications and future prospects in healthcare.
Methods
This scoping review searched Web of Science, PubMed, and Scopus . The selection of studies involved screening titles, reviewing abstracts, and examining full texts, adhering to the PRISMA-ScR guidelines throughout the process.
Results
From 1406 articles across three databases, 109 met inclusion criteria after screening and deduplication. Nine GAI models were utilized in healthcare, with ChatGPT (n = 102, 74 %), Google Bard (Gemini) (n = 16, 11 %), and Microsoft Bing AI (n = 10, 7 %) being the most frequently employed. A total of 24 different applications of GAI in healthcare were identified, with the most common being “offering insights and information on health conditions through answering questions” (n = 41) and “diagnosis and prediction of diseases” (n = 17). In total, 606 benefits and challenges were identified, which were condensed to 48 benefits and 61 challenges after consolidation. The predominant benefits included “Providing rapid access to information and valuable insights” and “Improving prediction and diagnosis accuracy”, while the primary challenges comprised “generating inaccurate or fictional content”, “unknown source of information and fake references for texts”, and “lower accuracy in answering questions”.
Conclusion
This scoping review identified the applications, benefits, and challenges of GAI in healthcare. This synthesis offers a crucial overview of GAI's potential to revolutionize healthcare, emphasizing the imperative to address its limitations.}
}
@article{HAASE2023100066,
title = {Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100066},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000250},
author = {Jennifer Haase and Paul H.P. Hanel},
keywords = {Creativity, Originality, AI, Generative artificial intelligence},
abstract = {A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 % of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being “truly” creative.}
}
@article{YIN2025100227,
title = {A systematic examination of generative artificial intelligence (GenAI) use guidelines in applied linguistics journals},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100227},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100227},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000485},
author = {Shuhui Yin and Carol A. Chapelle},
keywords = {GenAI literacy for research, GenAI use guidelines, Applied linguistics journals, Scholarly publishing},
abstract = {The unannounced appearance of GenAI in 2022 and the speed of its adoption by researchers have left many questions unanswered about its accepted ethical use, with no apparent consensus among applied linguists. In this context, it’s essential for researchers to develop their GenAI literacy for research to engage with GenAI effectively and responsibly. This study contributes to identifying key components of this literacy through examining accepted GenAI uses in research practices. Based on a systematically sampled collection of 170 high-impact journals in applied linguistics, we investigated the scope and nature of GenAI use guidelines provided by 76 journals intended to guide authors. A checklist including four items regarding general statements and 17 items regarding three categories of specific aspects that GenAI guidelines target (authorship, uses, and human responsibility) was identified. Our findings reveal that (1) less than half of the journals provided GenAI use guidelines to guide authors, (2) the number of specific aspects varied across journals, with most falling short of comprehensive coverage, and (3) disagreements were observed about whether AI can be cited and used for manuscript drafting, idea generating, image generating, data generation, data collection, and data analysis and interpretation. Additionally, journals varied in their guidance on how to disclose GenAI uses. We propose recommendations for journals in improving their AI guidelines. Importantly, we introduce and conceptualize the new construct GenAI literacy for research article writing (GenAI-LR) that is important for authors to develop. We provide actionable recommendations accordingly based on our findings.}
}
@article{ASSAD2024677,
title = {Enhancing sustainability in manufacturing through cognitive digital twins powered by generative artificial intelligence},
journal = {Procedia CIRP},
volume = {130},
pages = {677-682},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.147},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013040},
author = {Fadi Assad and John Patsavellas and Konstantinos Salonitis},
keywords = {ChatGPT, Cognitive manufacturing, digital twin, generative artificial intelligence, Internet of Things, sustainable manufacturing},
abstract = {The rise of Industry 4.0 has brought new advancements in manufacturing, with a focus on integrating digital technologies to optimise processes and increase sustainability. Cognitive Digital Twins (CDTs) are emerging as a powerful paradigm in this area. They leverage advanced analytics, artificial intelligence (AI), and machine learning to create dynamic, real-time representations of physical manufacturing systems. This paper explores how CDTs can improve sustainability within the manufacturing sector. It proposes integrating generative artificial intelligence (GenAI) into the platforms that operate these digital twins to grant them cognitive capabilities. The work introduces a method for mapping and integrating energy consumption data to an Internet of Things (IoT) platform that includes the digital twin and a generative AI language model, such as ChatGPT. This proposed approach serves as a stepping stone towards unlocking the full potential of CDTs. It empowers manufacturers to achieve higher levels of sustainability and environmental responsibility.}
}
@article{MESSNER2025101622,
title = {Quantification of cultural practices and diversity: An empirical experiment with generative artificial intelligence},
journal = {Journal of World Business},
volume = {60},
number = {3},
pages = {101622},
year = {2025},
issn = {1090-9516},
doi = {https://doi.org/10.1016/j.jwb.2025.101622},
url = {https://www.sciencedirect.com/science/article/pii/S1090951625000112},
author = {Wolfgang Messner},
keywords = {Artificial intelligence, Cultural dimensions, Cultural diversity, Culture, Evolution, Generative artificial intelligence (genAI), GLOBE, Hofstede, Large language model (LLM)},
abstract = {Culture is often viewed as a value system that shapes cultural practices. Frameworks like Hofstede, GLOBE, and Schwartz identify and quantify various cultural dimensions; however, these rely on surveys that are criticized for limited country coverage, lack of psychometric robustness, small sample sizes, and cultural biases. This article presents an empirical experiment designed to quantify cultural practices and diversity across 216 countries and territories by prompting large language models using a zero-shot learning strategy. This approach enables subnational and segment-specific analyses, equipping researchers with powerful tools for deeper cultural insights.}
}
@article{MAYOL2025109496,
title = {Generative artificial intelligence and scientific publishing: Turning noise into trust},
journal = {Surgery},
volume = {183},
pages = {109496},
year = {2025},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2025.109496},
url = {https://www.sciencedirect.com/science/article/pii/S0039606025003484},
author = {Julio Mayol and Caitlin W. Hicks and Steven D. Wexner}
}
@article{HUANG2025445,
title = {Ophthalmology Journals’ Guidelines on Generative Artificial Intelligence: A Comprehensive Analysis},
journal = {American Journal of Ophthalmology},
volume = {271},
pages = {445-454},
year = {2025},
issn = {0002-9394},
doi = {https://doi.org/10.1016/j.ajo.2024.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002939424005889},
author = {Wenqiao Huang and Yating Liang and Xianghui Wei and Yi Du},
abstract = {Purpose
The integration of generative artificial intelligence (GAI) into scientific research and academic writing has generated considerable controversy. Currently, standards for using GAI in academic medicine remain undefined. This study aims to conduct a comprehensive analysis of the guidance provided for authors regarding the use of GAI in ophthalmology scientific journals.
Design
Cross-sectional bibliometric analysis.
Participants
A total of 140 ophthalmology journals listed in the Scimago Journal and Country Rankings, regardless of language or origin.
Methods
We systematically searched and screened the 140 ophthalmology journals’ websites on October 19 and 20, 2024, and conducted updates on November 19 and 20, 2024.
Main Outcome Measures
The content of GAI guidelines from the websites of the 140 ophthalmology journals.
Results
Of 140 journals reviewed, 96 (69%) provide explicit guidelines for authors regarding the use of GAI. Among these, nearly all journals agree on 3 key points: (1) 94 journals (98%) have established specific guidelines prohibiting GAI from being listed as an author; (2) 94 journals (98%) emphasize that human authors are responsible for the outputs generated by GAI tools; and (3) all 96 journals require authors to disclose any use of GAI. In addition, 20 journals (21%) specify that their guidelines pertain solely to the writing process with GAI. Furthermore, 92 journals (66%) have developed guidelines concerning GAI-generated images, with 63 journals (68%) permitting their use and 29 (32%) prohibiting them. Among those that prohibit GAI images, 27 journals (93%) allow their use under specific conditions.
Conclusion
Although there is considerable ethical consensus among ophthalmology journals regarding the use of GAI, notable variations exist in terms of permissible use and disclosure practices. Establishing standardized guidelines is essential to safeguard the originality and integrity of scientific research. Researchers must uphold high standards of academic ethics and integrity when using GAI.}
}
@article{RESELFOLKERSMA2025S1749,
title = {A0902 – Evaluation of the quality of the responses regarding Lower Urinary Tract Symptoms (LUTS) of different generative Artificial Intelligence (AI) App in comparison with UrologuIA (generative AI App developed by urologists and urogynecologists)},
journal = {European Urology},
volume = {87},
pages = {S1749},
year = {2025},
note = {Abstracts EAU25 - 40th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/j.eururo.2025.09.4082},
url = {https://www.sciencedirect.com/science/article/pii/S0302283825045919},
author = {L. {Resel Folkersma} and B. {Padilla Fernández} and C. {González Enguita} and J.L. Gago and M. {García Sanz} and P. {Blasco Hernández} and R. Vozmediano and S. Arlandis and S. Zubillaga and J. {Medina Polo}}
}
@article{METZGER2025103313,
title = {Generative artificial intelligence augmenting SME financial management},
journal = {Technovation},
volume = {147},
pages = {103313},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103313},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225001452},
author = {Michael Metzger and Seán O'Reilly and Ciarán {Mac an Bhaird}},
keywords = {Financial management, SMEs, Artificial intelligence, Digital technologies, Predictive modelling, Going concern},
abstract = {This study investigates the potential for entrepreneurs to leverage advances in technological innovation, specifically generative Artificial Intelligence (AI), to build management capability to mitigate business and financial risks. Drawing on theories of Technology Affordances and Constraints and the Resource-Based View (RBV) of the firm, recognising that small and medium-sized enterprises (SMEs) are inherently resource-constrained. We examine how AI-generated financial diagnostics can empower SMEs by generating accessible, real-time analysis and insights, thus bolstering the management function and increasing chances of survival and growth. Using a dataset of 1,150 UK SMEs spanning eight years of financial statements, we test a large language model (LLM) prediction assessment and analyse the potential for SMEs to utilise the technology, notwithstanding enterprise-specific constraints. We conclude that AI may be a very effective tool for smaller enterprises to augment the financial management function, although its efficacy hinges on organisational readiness, competence in interpreting data, and the will to act on automated red-flag alerts. These findings offer practical guidance for SMEs seeking to enhance their financial management processes in today's digital era.}
}
@article{HOURI2025102040,
title = {Evaluating Knowledge Gaps in Cardio-Obstetrics: A Comparative Analysis of Cardiologists, Obstetricians, and Generative Artificial Intelligence},
journal = {JACC: Advances},
volume = {4},
number = {8},
pages = {102040},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.102040},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25004648},
author = {Ohad Houri and Nili {Schamroth Pravda}}
}
@article{CHONG2025103583,
title = {1345 A Generative Artificial Intelligence Framework for Automated Pathologic Diagnosis of Gastric Endoscopic Biopsy Samples},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103583},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103583},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032616},
author = {Yosep Chong and Anh Nguyen and Jin Sol Song and Kwangil Yim and Jumi Park and Jin Tae Kwak}
}
@article{TAIWO2025672,
title = {Generative artificial intelligence in construction: A Delphi approach, framework, and case study},
journal = {Alexandria Engineering Journal},
volume = {116},
pages = {672-698},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.12.079},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824016776},
author = {Ridwan Taiwo and Idris Temitope Bello and Sulemana Fatoama Abdulai and Abdul-Mugis Yussif and Babatunde Abiodun Salami and Abdullahi Saka and Mohamed El Amine {Ben Seghier} and Tarek Zayed},
keywords = {Generative artificial intelligence, Generative pre-trained transformer, Large language model, Multimodal AI, Retrieval augmented generation, Construction industry, GenAI, RAG, LLM, GPT, ChatGPT},
abstract = {The construction industry plays a crucial role in the global economy, contributing approximately $10 trillion and employing over 220 million workers worldwide, but encounters numerous productivity challenges with only 1 % annual growth compared to 2.8 % for the global economy. These challenges span various processes, including design, planning, procurement, inspection, and maintenance. Generative artificial intelligence (GenAI), capable of producing new and realistic data or content such as text, images, videos, or code from given inputs or existing knowledge, presents innovative solutions to these challenges. While there is an increasing interest in the applications of GenAI in construction, a detailed analysis of its practical uses, advantages, and areas ripe for development is still evolving. This study contributes to this emerging area by offering an insightful analysis of the current state of generative AI in construction. It has three objectives: (1) to identify and categorize the existing and emerging generative AI opportunities and challenges in the construction industry via a Delphi study; (2) to propose a framework enabling construction firms to build customized GenAI solutions; and (3) to illustrate this framework through a case study that employs GenAI model for querying contract documents. Through systematic review and expert consultation, the study identified 76 potential GenAI applications across construction phases and 18 key challenges distributed across domain-specific, technological, adoption, and ethical categories. The case study's findings show that retrieval augmented generation (RAG) improves the baseline large language model (LLM), GPT-4, by 5.2, 9.4, and 4.8 % in terms of quality, relevance, and reproducibility. The study recommends a structured approach to GenAI implementation, emphasizing the need for domain-specific customization, robust validation protocols, and careful consideration of ethical implications. This study equips academics and construction professionals with a comprehensive analysis and practical framework, facilitating the integration of GenAI techniques to enhance productivity, quality, safety, and sustainability across the construction industry.}
}
@article{TAIWO2025100316,
title = {Making waves: Generative artificial intelligence in water distribution networks: Opportunities and challenges},
journal = {Water Research X},
volume = {28},
pages = {100316},
year = {2025},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2025.100316},
url = {https://www.sciencedirect.com/science/article/pii/S2589914725000155},
author = {Ridwan Taiwo and Abdul-Mugis Yussif and Tarek Zayed},
keywords = {Digital water systems, Generative artificial intelligence, Smart water distribution networks, Retrieval-augmented generation, ChatGPT, Reclaimed WDNs, RAG, Multimodal AI},
abstract = {Water distribution networks (WDNs) face increasing challenges from aging infrastructure, population growth, and climate change, necessitating innovative technological solutions. This study examines the integration of Generative Artificial Intelligence (GenAI) in WDNs, including both conventional and reclaimed water systems. Through a comprehensive analysis of current literature and emerging applications, the study identifies key opportunities in near-future applications focusing on enhancing information retrieval through advanced document processing, improving water quality management via real-time monitoring and visualization, implementing predictive maintenance strategies through pattern recognition, and optimizing real-time operational control through adaptive algorithms. Results also demonstrate that GenAI can transform WDN operations through advanced visualization, scenario generation, and adaptive optimization capabilities, particularly in far-future applications such as demand forecasting, emergency response, and network design optimization. The analysis reveals significant challenges, including data quality and availability issues, particularly in non-English speaking regions, scalability constraints in large-scale networks, the critical need for water professionals with hybrid expertise in both traditional engineering and AI systems, and complex regulatory requirements that vary significantly across the globe. The study also explores unique applications in reclaimed WDNs, particularly in quality control, treatment optimization, and stakeholder engagement. These findings provide water utilities, policymakers, and researchers with valuable insights for implementing GenAI technologies while balancing technological advancement with human expertise and social responsibility.}
}
@article{LUSETTI2025S250,
title = {T.06.3 APPLICATIONS OF GENERATIVE ARTIFICIAL INTELLIGENCE IN INFLAMMATORY BOWEL DISEASE: A SYSTEMATIC REVIEW},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S250-S251},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00603-6},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825006036},
author = {F. Lusetti and S. Maimaris and G.P. {La Rosa} and D. Scalvini and A. Schiepatti and F. Biagi and G. Manes and S. Saibeni}
}
@incollection{FU2024,
title = {Generative artificial intelligence in operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00057-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000573},
author = {Yingxuan Fu and Hing Kai Chan and Zhao Cai},
keywords = {Generative AI, , Generative adversarial network, Large language model, Transformer, Variational autoencoder},
abstract = {The rise of generative artificial intelligence (AI) may present a significant opportunity for a profound revolution in operations and supply chain management. However, such technological advancement is accompanied by a scholarly discourse that navigates the balance between its promising abilities and challenges. This chapter provides an overview of generative AI in operations and supply chain management. It begins by expositing its fundamental technical concepts and role alongside existing AI technologies. Subsequently, it delves into potential applications and challenges in implementing generative AI in operations. A future research agenda and takeaways for practitioners and Operations Management (OM) researchers are proposed at the end.}
}
@article{COHEN2025100405,
title = {A comparative analysis of generative artificial intelligence responses from leading chatbots to questions about endometriosis},
journal = {AJOG Global Reports},
volume = {5},
number = {1},
pages = {100405},
year = {2025},
issn = {2666-5778},
doi = {https://doi.org/10.1016/j.xagr.2024.100405},
url = {https://www.sciencedirect.com/science/article/pii/S2666577824000996},
author = {Natalie D. Cohen and Milan Ho and Donald McIntire and Katherine Smith and Kimberly A. Kho},
keywords = {chatbots, endometriosis education, health information technology, large language models, patient education, patient information},
abstract = {Introduction
The use of generative artificial intelligence (AI) has begun to permeate most industries, including medicine, and patients will inevitably start using these large language model (LLM) chatbots as a modality for education. As healthcare information technology evolves, it is imperative to evaluate chatbots and the accuracy of the information they provide to patients and to determine if there is variability between them.
Objective
This study aimed to evaluate the accuracy and comprehensiveness of three chatbots in addressing questions related to endometriosis and determine the level of variability between them.
Study Design
Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic), and Bard (Google) were asked to generate answers to 10 commonly asked questions about endometriosis. The responses were qualitatively compared to current guidelines and expert opinion on endometriosis and rated on a scale by nine gynecologists. The grading scale included the following: (1) Completely incorrect, (2) mostly incorrect and some correct, (3) mostly correct and some incorrect, (4) correct but inadequate, (5) correct and comprehensive. Final scores were averaged between the nine reviewers. Kendall's W and the related chi-square test were used to evaluate the reviewers’ strength of agreement in ranking the LLMs’ responses for each item.
Results
Average scores for the 10 answers amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7, respectively. Two questions showed significant disagreement between the nine reviewers. There were no questions the models could answer comprehensively or correctly across the reviewers. The model most associated with comprehensive and correct responses was ChatGPT. Chatbots showed an improved ability to accurately answer questions about symptoms and pathophysiology over treatment and risk of recurrence.
Conclusion
The analysis of LLMs revealed that, on average, they mainly provided correct but inadequate responses to commonly asked patient questions about endometriosis. While chatbot responses can serve as valuable supplements to information provided by licensed medical professionals, it is crucial to maintain a thorough ongoing evaluation process for outputs to provide the most comprehensive and accurate information to patients. Further research into this technology and its role in patient education and treatment is crucial as generative AI becomes more embedded in the medical field.}
}
@article{ZHANG2025S-318,
title = {1299: GENERATIVE ARTIFICIAL INTELLIGENCE FOR DYNAMIC RISK ASSESSMENT TO PREDICT TRAJECTORIES IN PATIENTS WITH ACUTE GASTROINTESTINAL BLEEDING IN THE INTENSIVE CARE UNIT},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01677-4},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016774},
author = {Xi Zhang and Jun Yup Kim and Yuan Pu and Andrew J. Loza and Alexander Tong and Dennis Shung}
}
@article{MENG2025,
title = {A generative artificial intelligence approach to modular skeletal framework modeling: Bamboo stilt houses as a case study},
journal = {Frontiers of Architectural Research},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2025.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095263525000846},
author = {Xianchuan Meng and Jiadong Liang and Ximing Zhong},
keywords = {Graph neural networks, Modular components, Bamboo architecture, Computational design, Generative artificial intelligence method},
abstract = {This paper presents a new generative artificial intelligence (AI) approach for creating modular skeletal frameworks, using vernacular bamboo stilt houses as examples to investigate an innovative methodological perspective. By transforming building skeletons to connected graphs, our method uses Variational Graph Autoencoders (VGAE) and Graph Sample and Aggregate (GraphSAGE) to generate 3D modular components based on spatial constraints set by users, such as axis grids and chosen room areas. The graph representation encodes structural elements as edges and their connections as nodes, maintaining critical dimensional constraints and spatial relationships. Using data from bamboo stilt houses built without architects, we make a specialized dataset of geometric skeletons for model training. Experimental results demonstrate the effectiveness of our approach in capturing the distribution of featured elements in building frameworks and in generating structurally sound designs, with GraphSAGE showing better performance compared to alternative methods. The probabilistic edge prediction approach allows for a collaborative human-AI design process, empowering designers while utilizing computational capabilities. The inherent flexibility of the graph-based representation makes it adaptable to a wide range of materials and scales.}
}
@article{KANAKALA2024103175,
title = {Generative artificial intelligence for small molecule drug design},
journal = {Current Opinion in Biotechnology},
volume = {89},
pages = {103175},
year = {2024},
issn = {0958-1669},
doi = {https://doi.org/10.1016/j.copbio.2024.103175},
url = {https://www.sciencedirect.com/science/article/pii/S0958166924001113},
author = {Ganesh Chandan Kanakala and Sriram Devata and Prathit Chatterjee and Udaykumar Deva Priyakumar},
abstract = {In recent years, the rapid advancement of generative artificial intelligence (GenAI) has revolutionized the landscape of drug design, offering innovative solutions to potentially expedite the discovery of novel therapeutics. GenAI encompasses algorithms and models that autonomously create new data, including text, images, and molecules, often mirroring characteristics of existing datasets. This comprehensive review delves into the realm of GenAI for drug design, emphasizing recent advancements and methodologies that have propelled the field forward. Specifically, we focus on three prominent paradigms: transformers, diffusion models, and reinforcement learning algorithms, which have been exceptionally impactful in the last few years. By synthesizing insights from a myriad of studies and developments, we elucidate the potential of these approaches in accelerating the drug discovery process. Through a detailed analysis, we explore the current state and future directions of GenAI in the context of drug design, highlighting its transformative impact on pharmaceutical research and development.}
}
@article{RAJARAM2024629,
title = {Generative artificial intelligence in small and medium enterprises: Navigating its promises and challenges},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {629-648},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000685},
author = {Kumaran Rajaram and Patrick Nicolas Tinguely},
keywords = {Generative artificial intelligence, Small and medium enterprises, AI management, Competitiveness, Digital innovation},
abstract = {The latest technological developments in generative artificial intelligence (GenAI) offer powerful capabilities to small and medium enterprises (SMEs) as they facilitate the democratization of scalability and creativity. With little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, improving their product offerings and long-term competitiveness. In this article, we discuss how SMEs can navigate both the promises and challenges of GenAI and offer a roadmap for deploying the technology. We then introduce a sailing metaphor that reveals key strategic dimensions for GenAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We conclude with practical recommendations for successfully deploying GenAI in SMEs.}
}
@article{FENG2024100090,
title = {Latest developments of generative artificial intelligence and applications in ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100090},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100090},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000914},
author = {Xiaoru Feng and Kezheng Xu and Ming-Jie Luo and Haichao Chen and Yangfan Yang and Qi He and Chenxin Song and Ruiyao Li and You Wu and Haibo Wang and Yih Chung Tham and Daniel Shu Wei Ting and Haotian Lin and Tien Yin Wong and Dennis Shun-chiu Lam},
keywords = {Generative artificial intelligence, Ophthalmology, Risk management, Clinical workflow, AI in medical research},
abstract = {The emergence of generative artificial intelligence (AI) has revolutionized various fields. In ophthalmology, generative AI has the potential to enhance efficiency, accuracy, personalization and innovation in clinical practice and medical research, through processing data, streamlining medical documentation, facilitating patient-doctor communication, aiding in clinical decision-making, and simulating clinical trials. This review focuses on the development and integration of generative AI models into clinical workflows and scientific research of ophthalmology. It outlines the need for development of a standard framework for comprehensive assessments, robust evidence, and exploration of the potential of multimodal capabilities and intelligent agents. Additionally, the review addresses the risks in AI model development and application in clinical service and research of ophthalmology, including data privacy, data bias, adaptation friction, over interdependence, and job replacement, based on which we summarized a risk management framework to mitigate these concerns. This review highlights the transformative potential of generative AI in enhancing patient care, improving operational efficiency in the clinical service and research in ophthalmology. It also advocates for a balanced approach to its adoption.}
}
@article{ECKHARDT2025100987,
title = {Livestock behaviour forecasting via generative artificial intelligence},
journal = {Smart Agricultural Technology},
volume = {11},
pages = {100987},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525002205},
author = {Regina Eckhardt and Reza Arablouei and Aaron Ingham and Kieren McCosker and Heinz Bernhardt},
keywords = {Accelerometer data, Cattle behaviour, Data imputation, Generative AI, Precision agriculture},
abstract = {Recent advancements in sensor technology and generative artificial intelligence (AI) are transforming precision livestock farming by enhancing behaviour monitoring and predictive analytics. This study examines the effectiveness of Transformer-type generative AI models in predicting cattle behaviour profiles and imputing missing data from collar accelerometer readings collected during two trials in Queensland, Australia, in 2022 and 2023, alongside climatic data. Each trial involved 60 cattle equipped with collars that classified six core behaviours: grazing, ruminating, walking, resting, drinking, and other over five-second time windows. Hourly behaviour profiles were constructed for each animal and experiment day by aggregating the behaviour predictions over every calendar hour, representing the time spent on each behaviour within each hour. Subsequently, four Transformer-type models (i.e., standard Transformer, Informer, Reformer, and Autoformer) were trained on the hourly behaviour profile data to predict behaviour profiles of the next 24 hours for each animal. Among the considered models, Autoformer showed the highest predictive accuracy when including climate data, achieving a mean absolute error (MAE) of <5.5 min, while the next best model had an MAE of approximately 6 min. For imputing missing data, the standard Transformer outperformed traditional imputation methods, with an MAE of <30 min over 24 hours, compared to 40 to 70 min for traditional methods (mean, median, and linear interpolation). These results highlight the potential of generative AI, particularly Autoformer and Transformer, to enhance predictive accuracy and data imputation in livestock management, thereby supporting regulatory guidance for data-driven decision-making and improved farming practices.}
}
@article{JIANG2024102883,
title = {When generative artificial intelligence meets multimodal composition: Rethinking the composition process through an AI-assisted design project},
journal = {Computers and Composition},
volume = {74},
pages = {102883},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102883},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000598},
author = {Jialei Jiang},
keywords = {Generative artificial intelligence, Multimodal composition process, Adobe Firefly, DALL·E, Wicked problems, Design, Writing studies},
abstract = {This study explores the integration of generative artificial intelligence (GenAI) design technologies, including Adobe Firefly and DALL·E, into the teaching and learning of multimodal composition. Through focus group discussions and case studies, this paper demonstrates the potential of GenAI in reshaping the various stages of the composition process, including invention, designing, and revising. The findings reveal that GenAI technologies have the potential to enhance students’ multimodal composition practices and offer alternative solutions to the wicked problems encountered during the design process. Specifically, GenAI facilitates invention by offering design inspirations and enriches designing by expanding, removing, and editing the student-produced design contents. The students in this study also shared their critical stance on the revision process by modifying and iterating their designs after their uses of GenAI. Through showcasing both the opportunities and challenges of GenAI technologies, this paper contributes to the ongoing scholarly conversations on multimodal composition and pedagogy. Moreover, the paper offers implications for the future research and teaching of GenAI-assisted multimodal composition projects, with the aim of encouraging thoughtful integration of GenAI technologies to foster critical AI literacy among college composition students.}
}
@article{ALLEN2025S64,
title = {OS03-09 Surveying the Landscape: A Modular Generative Artificial Intelligence Workflow to Identify NAMs for Systemic Toxicity},
journal = {Toxicology Letters},
volume = {411},
pages = {S64},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.180},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425017631},
author = {D. Allen and E. Martin and J. Hamm and J. Wignall and K. To and T. Feiler and C. Lemeris and P. Kukic},
abstract = {To identify the areas of systemic toxicity with the greatest need, and which present the best opportunities for human-relevant model (i.e., new approach methodologies [NAMs]) development, standardization, and implementation, we conducted a landscape analysis to collect information on ongoing efforts in the NAMs space. This type of analysis traditionally requires the collection, manual review, summary, and synthesis of an extensive literature base that requires hundreds of hours to complete. To increase both speed and efficiency, we utilized a reproducible workflow that incorporates multiple computational tools including generative artificial intelligence (GenAI) to quickly summarize a large literature database. Our integrated approach coupled subject matter expertise with sorting and extraction algorithms to provide a comprehensive overview of the state of the science for NAMs used for, or potentially useful for, the assessment of systemic toxicity of cosmetics. To identify potentially relevant studies, we conducted a literature search with keywords related to NAMs across three major topic areas: in silico, in chemico, and in vitro. We prioritized studies by coupling supervised clustering, topic extraction and keyword analysis algorithms. These methods led to the prioritization of 8,418 studies. To identify relevant studies, subject matter experts were employed in conjunction with active machine learning to identify relevant studies that were then summarized via GenAI. Given the objective was to provide sufficient coverage of the landscape to both address pragmatic, near-term needs, as well as shaping the future of how safety assessments are performed, we designed prompts to characterize the current and past systematic efforts directed towards developing and refining NAMs, including both success stories, scientific and technical challenges, and roadblocks to wider adoption. Our analysis identified 3,010 peer-reviewed publications and 38 consortium websites cataloguing NAMs that were applicable to the cosmetics regulatory process, from hazard-focused endpoints to exposure-based waiving of studies altogether. Additionally, they covered the full spectrum of maturity, from those approaches that show promise at the research and development phase to fully validated approaches ready for immediate regulatory use. To the extent available, we identified the molecular/cellular endpoints associated with each NAM and the reference dataset that was used to develop and/or evaluate usefulness and limitations across a total of 60,960 endpoints. The landscape also captured opportunities to validate mature NAMs to support their regulatory use and market adoption. These results will support the development and identification of NAMs to be included in frameworks for assessing systemic toxicity potential.}
}
@article{BONNET2025,
title = {Unfolding the Potential of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2025},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.368223},
url = {https://www.sciencedirect.com/science/article/pii/S154806662500013X},
author = {Severin Bonnet and Frank Teuteberg},
keywords = {Generative AI Chatbots, Artificial Intelligence, AI Based Chatbots, Academic Research, ChatGPT},
abstract = {ABSTRACT
Scholars are increasingly using generative artificial intelligence (AI) chatbots, like ChatGPT, in research, though concerns remain about ethics, data privacy, bias, and intellectual property. This study adopts a design science research approach to explore how generative AI chatbots can support academic teaching and research, bridging theory and practice. A literature review and expert interviews identified key requirements and design principles that support virtues such as uniqueness, generalizability, and reproducibility. We also introduce a prototype, “AcademiaBot,” to demonstrate these principles in action. Our findings suggest that AI chatbots can significantly aid scholarly work if users are informed and ethical concerns are addressed. Responsible usage can help AI augment human research efforts without compromising integrity. This study provides valuable design knowledge, ensuring AI-based chatbots remain a beneficial tool for scholars.}
}
@article{RONKSLEYPAVIA2025100437,
title = {A scoping literature review of generative artificial intelligence for supporting neurodivergent school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100437},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100437},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000773},
author = {Michelle Ronksley-Pavia and Lan Nguyen and Elizabeth Wheeley and Judy Rose and Michelle M. Neumann and Chris Bigum and David L. Neumann},
keywords = {Artificial intelligence, Generative AI, GenAI, Neurodiversity, School, Personalized learning, Teachers},
abstract = {While Generative Artificial Intelligence (GenAI) platforms like ChatGPT have gained significant traction in education, their specific applications for neurodivergent learners remain largely unmapped. Through systematic searching of academic databases and grey literature between 2020 and 2024, this scoping literature review examined the emerging landscape of GenAI applications in supporting neurodivergent students (e.g., those with ADHD, autism, dyslexia, gifted, twice-exceptional) within K-12 educational contexts. Twenty-one relevant sources were identified, discussing GenAI usage with neurodivergent students, the analysis revealed discussion of several predominant applications, including personalized learning, administrative assistance for educators, and development of individualized education plans. The review identified both promising approaches and significant concerns. Benefits included GenAI's potential to provide real-time, personalized support for students as well as reducing administrative burdens for educators. However, notable concerns emerged regarding information accuracy, over-reliance on AI, privacy considerations, and the need for human oversight. The limited empirical evidence base was particularly striking, with only nine studies providing original research data. The review identified critical gaps in current understanding, particularly regarding GenAI's effectiveness across different neurodivergent conditions and curriculum areas, and little evidence of approaches detailed in ways that educators could use. This scoping review demonstrates the need for robust empirical research examining GenAI usage in learning for neurodivergent students. These insights are timely and crucial for educators, researchers, and policymakers working to harness GenAI's potential in supporting neurodivergent learners within inclusive educational environments.}
}
@article{RASHID2025S268,
title = {MT14 Role of Generative Artificial Intelligence in Assisting Systematic Review Process in Health Research: A Systematic Review},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S268},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1124},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012495},
author = {Muhammed Rashid and Cheng Su Yi and Suwapat Lawin and Pongsapat Limhensin and Suppachai Insuk and Sajesh K. Veettil and Nai Ming Lai and Xiangyang Ye and Nathorn Chaiyakunapruk and Teerapon Dhippayom}
}
@article{KENOPURUM2025S301,
title = {MSR139 Application of Generative Artificial Intelligence for Extracting Structured Data from Unstructured Bladder Cancer Pathology Reports},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S301},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1290},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525014159},
author = {Jennifer Ken-Opurum and Sidharth Singh and P. Pranav and Rahul Bhonsle and Shekhar Thumake and Heather Marino and Luke Dunlap}
}
@article{YANG2025104877,
title = {The impact of TPACK on teachers’ willingness to integrate generative artificial intelligence (GenAI): The moderating role of negative emotions and the buffering effects of need satisfaction},
journal = {Teaching and Teacher Education},
volume = {154},
pages = {104877},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104877},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004104},
author = {Yiming Yang and Qi Xia and Chuanbin Liu and Thomas K.F. Chiu},
keywords = {TPACK, Negative emotions, Self-determination theory (SDT), Generative artificial intelligence (GenAI), Teachers' willingness},
abstract = {Understanding teachers' willingness to integrate generative AI (WIAI) is essential in the current dilemma where students' adoption rate is faster than teachers'. Therefore, this study aims to identify factors affecting teachers' WIAI and their interactions from the perspectives of needs satisfaction and emotion. We used regression analyses to analyze data collected from 1348 teachers online. The results supported that TPACK positively influences teachers' WIAI, but this effect is weakened by negative emotions, while needs satisfaction for competence and relatedness buffers the negative effect more effectively than autonomy. These highlight the role of emotional and psychological support in fostering teachers’ adoptions.}
}
@article{KARELL2025101966,
title = {Synthetic duality: A framework for analyzing generative artificial intelligence's representation of social reality},
journal = {Poetics},
volume = {108},
pages = {101966},
year = {2025},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101966},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24001049},
author = {Daniel Karell and Jeffrey Sachs and Ryan Barrett},
keywords = {Duality, Mondo-Breiger, Socio-semantic networks, Large language models, Generative artificial intelligence},
abstract = {The development of generative artificial intelligence (genAI) has caused concern about its potential risks, including how its ability to generate human-like texts could affect our shared perception of the social world. Yet, it remains unclear how best to assess and understand genAI's influence on our understanding of social reality. Building on insights into the representation of social worlds within texts, we introduce a framework for analyzing genAI's content and its consequences for perceptions of social reality. We demonstrate this “synthetic duality” framework in two parts. First, we show that genAI can create, with minimal guidance, reasonable portrayals of actors and ascribe relational meaning to those actors – virtual social worlds within texts, or “Mondo-Breigers”. Second, we examine how these synthetic documents with interior social worlds affect readers’ view of social reality. We find that they change individuals’ perceptions of actors depicted in the documents, likely by updating individuals’ expectations about the actors and their meanings. However, additional exploratory analyses suggest it is texts’ style, not their construction of “Mondo-Breigers”, that might be influencing people's perceptions. We end with a discussion of theoretical and methodological implications, including how genAI may unsettle structural notions of individuality. Namely, reimagining the duality of individuals and groups could help theorize growing homogeneity in an increasingly genAI-informed world.}
}
@article{GANJOO2024,
title = {Beyond boundaries: exploring a generative artificial intelligence assignment in graduate, online science courses},
journal = {Journal of Microbiology & Biology Education},
volume = {25},
number = {3},
year = {2024},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00127-24},
url = {https://www.sciencedirect.com/science/article/pii/S1935787724000893},
author = {Rohini Ganjoo and James Rankin and Benjamin Lee and Lisa Schwartz},
keywords = {generative artificial intelligence, graduate courses, assignment, online education, health professional education},
abstract = {ABSTRACT

Generative artificial intelligence (GAI) offers increased accessibility and personalized learning, though the potential for inaccuracies, biases, and unethical use is concerning. We present a newly developed research paper assignment that required students to utilize GAI. The assignment was implemented within three online, asynchronous graduate courses for medical laboratory sciences. Student learning was assessed using a rubric, which rated students’ effective integration and evaluation of GAI-generated content against peer-reviewed research articles, thus demonstrating their critical thinking and synthesis skills, among other metrics. Overall rubric scores were high, suggesting that learning outcomes were met. After field testing, we administered a 16-item survey about GAI utilization, contribution to learning, and ethical concerns. Data (n = 32) were analyzed, and free-response answers were thematically coded. While 93.8% of respondents found the GAI-generated content to be “very good” or “excellent,” 28.1% found inaccuracies, and 68.8% “strongly agreed” or “agreed” that GAI should be allowed to be used as a tool to complete academic assignments. Interestingly, however, only 28.1% “strongly agreed” or “agreed” that GAI may be used for assignments if not explicitly authorized by the instructor. Though GAI allowed for more efficient completion of the project and better understanding of the topic, students noted concerns about academic integrity and the lack of citations in GAI responses. The assignment can easily be modified for different learning preferences and course environments. Raising awareness among students and faculty about the ethical use and limitations of GAI is crucial in today’s evolving pedagogical landscape.}
}
@article{BARROSO2025501667,
title = {Application of generative artificial intelligence chatbots in the field of anesthesia},
journal = {Revista Española de Anestesiología y Reanimación (English Edition)},
volume = {72},
number = {6},
pages = {501667},
year = {2025},
issn = {2341-1929},
doi = {https://doi.org/10.1016/j.redare.2025.501667},
url = {https://www.sciencedirect.com/science/article/pii/S2341192925001179},
author = {A. Barroso and R. Casans}
}
@article{PELLEGRINO2025S126,
title = {OC.02.7 CONVERSATIONAL LARGE LANGUAGE MODEL GENERATIVE ARTIFICIAL INTELLIGENCE CHATBOT CHATGPT-4 FOR COLONOSCOPY BOSTON BOWEL PREPARATION SCORING: AN AI-TO-HEAD HUMAN-BLINDED CONCORDANCE ANALYSIS ON A LARGE VOLUME OF ENDOSCOPIC FRAMES},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S126-S127},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00382-2},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825003822},
author = {R. Pellegrino and G. Palladino and G. Imperio and A. Federico and A.G. Gravina}
}
@article{LI2025S280,
title = {MSR33 Automated Extraction of Kaplan-Meier Survival Curves Using Generative Artificial Intelligence and Computer Vision},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S280},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1185},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525013105},
author = {Ying Li and Augustine Annan and Majid R. Mojarad and Jingcheng Du and Yingxin Xu}
}
@article{MCDONALD2025100121,
title = {Generative artificial intelligence in higher education: Evidence from an analysis of institutional policies and guidelines},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100121},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000052},
author = {Nora McDonald and Aditya Johri and Areej Ali and Aayushi Hingle Collier},
abstract = {The release of ChatGPT in November 2022 prompted a massive uptake of generative artificial intelligence (GenAI) across higher education institutions (HEIs). In response, HEIs focused on regulating its use, particularly among students, before shifting towards advocating for its productive integration within teaching and learning. Since then, many HEIs have increasingly provided policies and guidelines to direct GenAI. This paper presents an analysis of documents produced by 116 US universities classified as as high research activity or R1 institutions providing a comprehensive examination of the advice and guidance offered by institutional stakeholders about GenAI. Through an extensive analysis, we found a majority of universities (N = 73, 63%) encourage the use of GenAI, with many offering detailed guidance for its use in the classroom (N = 48, 41%). Over half the institutions provided sample syllabi (N = 65, 56%) and half (N = 58, 50%) provided sample GenAI curriculum and activities that would help instructors integrate and leverage GenAI in their teaching. Notably, the majority of guidance focused on writing activities focused on writing, whereas references to code and STEM-related activities were infrequent, and often vague, even when mentioned (N = 58, 50%). Finally, more than half of institutions talked about the ethics of GenAI on a broad range of topics, including Diversity, Equity and Inclusion (DEI) (N = 60, 52%). Based on our findings we caution that guidance for faculty can become burdensome as policies suggest or imply substantial revisions to existing pedagogical practices.}
}
@article{MUKHERJEE2026104506,
title = {How lack of choice to opt-out of generative artificial intelligence in traditional search engines drives consumer switching intentions: The mechanism of empowerment},
journal = {Journal of Retailing and Consumer Services},
volume = {88},
pages = {104506},
year = {2026},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104506},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002851},
author = {Pubali Mukherjee and Varsha Jain},
keywords = {Generative artificial intelligence, GenAI, Generative search experience, Search engine behavior, Consumer empowerment, Switching intentions},
abstract = {The growing integration of generative artificial intelligence (AI) in traditional search interfaces is transforming how consumers search for information online. When AI-generated summaries are at the forefront without allowing users to opt out, their search experience becomes less user-driven and more system-controlled. Yet, its impact on consumer switching intentions is underexplored. Grounded in consumer empowerment and psychological reactance theories, this mixed-method research investigates how the lack of a choice feature to opt out of AI integration drives consumer switching intentions. Analyzing real-world discussions on Reddit, followed by an experiment, our findings reveal that when users lack the choice to disable AI-generated content, they feel less empowered, more intrusive, and irritated, increasing their likelihood of switching. Our findings extend interface design literature by identifying “choice to opt out of AI feature” as a critical design element for GenAI interfaces. While previous research has primarily theorized consumer empowerment in AI-enabled interfaces by focusing on autonomy, power, and control, our findings advance this literature by empirically demonstrating consumer choice as a novel and critical antecedent of empowerment. Further, we contribute to psychological reactance theory by extending it to a permanent, system-level disruption and demonstrate that the scale and permanence of reactance drive switching intentions. We provide actionable recommendations for interface designers to incorporate a toggle switch into GenAI interfaces, enabling users to choose to disable AI features. It suggests that managers may use empowerment as a strategic differentiator of interfaces to prevent consumers from migrating to alternative interfaces.}
}
@article{ERIKSEN2024100016,
title = {Generative artificial intelligence for increasing accessibility of patient information videos in ophthalmology},
journal = {AJO International},
volume = {1},
number = {1},
pages = {100016},
year = {2024},
issn = {2950-2535},
doi = {https://doi.org/10.1016/j.ajoint.2024.100016},
url = {https://www.sciencedirect.com/science/article/pii/S2950253524000169},
author = {Nathalie S. Eriksen and Moug Al-Bakri and Kirstine B. Boysen and Oliver N. Klefter and Diana C. Schmidt and Kirsten Reinwaldt and Jakob Grauslund and Lars M. Holm and Yousif Subhi},
keywords = {Artificial intelligence, Accessibility, Patient information videos},
abstract = {Purpose
Patient information videos are excellent for conveying information on eye health. Language barriers lead to inaccessibility for ethnic minorities. So far, overcoming language barriers have been very expensive, but in this short communications paper, we share our experiences with an inexpensive generative artificial intelligence-based translation system for videos.
Design
Explorative study.
Methods
We developed a patient information video on a very common and broadly relevant issue: how to use eye drops. The original video was made in Danish. We used HeyGen (HeyGen, Los Angeles, California, USA) to translate the video into three categories according to distance from Danish according to comparative linguistics: highly related (English and German), remotely related (French and Polish), and no recognizable relationship (Arabic and Turkish). Ophthalmologists with high proficiency in Danish and each of these languages evaluated and commented on the accuracy of the translations.
Results
All translations resulted in a recognizable clone of the original individual with synchronized lip movements and understandable language. We observed certain inaccuracies in the translation, however, these differed across languages without a specific pattern. Inconsistencies in formal/informal pronouns were observed across languages. But overall, the general information was conveyed across all languages.
Conclusion
Modern generative artificial intelligence-based translation tools can help tearing down language barriers and improve accessibility of patient information videos in ophthalmology.}
}
@article{CHENG2025104194,
title = {From emotion to reflection: leveraging EmotionPrompt strategy to empower self-determination in decision-making with generative artificial intelligence},
journal = {Information & Management},
volume = {62},
number = {7},
pages = {104194},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104194},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000977},
author = {Xusen Cheng and Lu Gao and Xin (Robert) Luo},
keywords = {Human–AI interaction, EmotionPrompt, Regulatory focus theory, Cognitive reappraisal, Psychological empowerment},
abstract = {Communication and reflection abilities are critical in managing strategic cooperation between humans and Generative Artificial Intelligence (GAI), especially when facing conflict in decision-making. This study introduces two variations of EmotionPrompt strategies, drawing on regulatory focus theory, to explore both individuals' perceptions of GAI ability and their empowerment in self-competence when handling disagreements. An experiment between humans and GAI chatbots in determining product promotion strategy showed that emotional prompts impact individuals' reappraisals of both chatbots and their own performance profoundly, cultivating self-determination in the final decision. Importantly, EmotionPrompt with promotion orientation can increase the perceived flexibility of chatbot decision-makers, facilitating individual self-enhancement and trust in GAI competence. In contrast, the prevention-oriented EmotionPrompt appears to constrain individuals' judgments and decision-making processes, as evidenced by the increased occurrence of inhibit words and anxiety emotions in their reflections. These findings provide novel perspectives on implementing specific regulatory-oriented EmotionPrompt strategies in GAI to address opinion conflicts in decision-making with humans.}
}
@article{YOGARATNAM2025100226,
title = {What Becomes of the Human Touch in the Age of Generative Artificial Intelligence?},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {2},
pages = {100226},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000331},
author = {Kishwen Kanna {Yoga Ratnam}}
}
@article{ABDALLAH2025,
title = {Generative Artificial Intelligence Models for Developing Neuroimaging Markers of Psychiatric Disorders},
journal = {Biological Psychiatry},
year = {2025},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0006322325011849},
author = {Chadi G. Abdallah and David {van Dijk}}
}
@article{ALEXANDER2025101416,
title = {Exploring Generative Artificial Intelligence to Enhance Reflective Writing in Pharmacy Education},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {6},
pages = {101416},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101416},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925000610},
author = {Kaitlin M. Alexander and Margeaux Johnson and Michelle Z. Farland and Amy Blue and Emily K. Bald},
keywords = {Artificial intelligence, Reflective writing, Reflection techniques, Self-assessment, Pharmacy education},
abstract = {The integration of generative artificial intelligence (AI) holds the potential to impact teaching and learning. In this commentary, we explore the opportunity for AI to enhance reflective writing (RW) among student pharmacists. AI-guided RW has the potential to strengthen students’ reflective capacity, deepen their autobiographical memory, and develop their self-confidence. This commentary presents examples of how AI can be utilized to enrich RW and includes a sample prompt aimed at facilitating student self-reflection. We explore how integrating AI-facilitated RW assignments into the pharmacy curriculum can help students develop detailed examples for self-reflection and gain exposure to the potential uses of AI in their professional development and career advancement.}
}
@article{LEE2025,
title = {Use of a Medical Communication Framework to Assess the Quality of Generative Artificial Intelligence Replies to Primary Care Patient Portal Messages: Content Analysis},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/71966},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005220},
author = {Natalie S Lee and Nathan Richards and Jodi Grandominico and Robert M Cronin and Amanda K Hendricks and Ravi S Tripathi and Daniel E Jonas},
keywords = {communication, artificial intelligence, primary care, electronic health record, patient portal, health communication},
abstract = {Background
There is growing interest in applying generative artificial intelligence (GenAI) to respond to electronic patient portal messages, particularly in primary care where message volumes are highest. However, evaluations of GenAI as an inbox communication tool are limited. Qualitative analysis of when and how often GenAI responses achieve communication goals can inform estimates of impact and guide continuous improvement.
Objective
This study aims to evaluate GenAI responses to primary care messages using a medical communication framework.
Methods
This was a descriptive quality improvement study of 201 GenAI replies to a purposively sampled, diverse pool of real primary care patient messages in a large midwestern academic medical center. Two physician reviewers (NSL and NR) used a hybrid deductive-inductive approach to qualitatively identify and define themes, guided by constructs from the “best practice” medical communication framework. After achieving thematic saturation, the reviewers assessed the presence or absence of identified communication themes, both independently and collaboratively. Discrepant observations were reconciled via discussion. Frequencies of identified themes were tallied.
Results
Themes in strengths and limitations emerged across 5 communication domains. In the domain of rapport building, expressing respect and restating key phrases were strengths, while inappropriate or inadequate rapport building statements were limitations. For information gathering, questions that built toward a plan or elicited patient needs were strengths, while questions that were out of place or redundant were limitations. For information delivery, accurate content delivered clearly and professionally was a strength, but delivery of inaccurate content was an observed limitation. GenAI responses could facilitate next steps by outlining choices or providing instruction, but sometimes those next steps were inappropriate or premature. Finally, in responding to emotion, strengths were that emotions were named and validated, while inadequate or absent acknowledgment of emotion was a limitation. Overall, 26.4% (53/201) of all messages displayed communication strengths without limitations, 27.4% (55/201) had limitations without strengths, and the remaining 46.3% (93/201) had both. Strengths outnumbered limitations in rapport building (87/201, 43.3% vs 35/201, 17.4%) and facilitating next steps (73/201, 36.3% vs 39/201, 19.4%). Limitations outnumbered strengths in the remaining domains of information delivery (89/201, 44.3% vs 43/201, 21.4%), information gathering (60/201, 29.9% vs 43/201, 21.4%), and responding to emotion (7/201, 8.5% vs 9/201, 4.5%).
Conclusions
GenAI response quality on behalf of primary care physicians and advanced practice providers may vary by communication function. Expressions of respect or descriptions of common next steps may be appropriate, but gathering and delivering appropriate information, or responding to emotion, may be limited. While communication standards were often met, they were also often compromised. Understanding these strengths and limitations can inform decisions about whether, when, and how to apply GenAI as a tool for primary care inbox communication.}
}
@article{CHENG2025100374,
title = {Asking generative artificial intelligence the right questions improves writing performance},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100374},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100374},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000141},
author = {Yixin Cheng and Yizhou Fan and Xinyu Li and Guanliang Chen and Dragan Gašević and Zachari Swiecki},
keywords = {Generative AI, ChatGPT, Question asking, Help seeking, Epistemic network analysis, Mediation analysis},
abstract = {Generative Artificial Intelligence (GenAI) tools are widely used by learners and this trend is poised to continue. However, little is known about whether and how GenAI use impacts learning and performance. This study aimed to investigate the effect of GenAI on performance by examining a key affordance of GenAI—seeking help via question asking. We compared the questions that learners asked GenAI versus a human tutor online during a writing task. Using quantitative ethnographic methods, we found that: (a) participants in the GenAI condition asked significantly more questions compared to those in the Tutor condition; (b) GenAI participants tended to ask one-off questions, while Tutor participants tended to have longer conversational exchanges; (c) GenAI participants tended to question pragmatically, asking direct questions about conceptual and procedural knowledge, while Tutor participants tended to make indirect request for feedback; (d) question asking, as measured by epistemic network analysis, mediated the relationship between experimental condition and performance—the more pragmatic the questions, and thus the more like questions in the GenAI condition, the better the performance; and (e) questions in the GenAI condition were driven by social coordination and knowledge deficits, while questions in the Tutor condition were driven by social coordination and establishing common ground. These findings suggest learners may be less hesitant to admit knowledge deficits and more willing to repair them when interacting with GenAI compared to human tutors. Thus, GenAI can be a useful educational tool when improved performance is the goal and human tutoring may benefit from creating a space where learners are more comfortable revealing a lack of knowledge.}
}
@article{DERAKHSHAN2025102114,
title = {EFL students’ perceptions about the role of generative artificial intelligence (GAI)-mediated instruction in their emotional engagement and goal orientation: A motivational climate theory (MCT) perspective in focus},
journal = {Learning and Motivation},
volume = {90},
pages = {102114},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102114},
url = {https://www.sciencedirect.com/science/article/pii/S0023969025000219},
author = {Ali Derakhshan},
keywords = {Achievement goal theory, Emotional engagement, Generative artificial intelligence (GAI), Goal orientation, L2 education, Motivational climate theory (MCT), Self-determination theory (SDT)},
abstract = {Research on the contributions of generative artificial intelligence (GAI) technologies to second language (L2) education has soared in the past couple of years. However, there is limited evidence pertaining to the impact of AI-mediated instruction on postgraduate students’ psycho-affective factors and the overall learning climate in English as a foreign language (EFL) context. To address this gap, the present study drew on motivational climate theory (MCT) to explore postgraduate EFL students’ perceptions of the role of GAI technologies in their emotional engagement and goal orientation. To do so, an interview was conducted with 30 postgraduate students using maximum variation sampling. The results of the inductive thematic analysis revealed that AI-mediated instruction had affected both the emotional engagement and goal orientation of the students. In particular, it was found that GAI tools fostered emotional engagement by ‘enlightening teacher-student classroom relationships’, ‘making the overall classroom culture/climate engaging, motivating, and updated’, ‘improving teachers’ action, instruction, and feedback quality’, ‘providing a personalized, interactive, and autonomy supporting education’, and ‘taping into learner-specific idiosyncrasies and individual differences’. Furthermore, GAI tools affected the students’ goal orientation by ‘facilitating the mastery of course content’, ‘setting personalized and achievable goals’, ‘fostering students’ performance comparison in the classroom’, and ‘providing a reflective and adaptive learning environment’. The findings are discussed and implications are provided for EFL teachers, students, teacher educators, and policymakers concerning the interplay of GAI, emotions, goal orientation, and motivational climate.}
}
@article{YE2024102851,
title = {Privacy and personal data risk governance for generative artificial intelligence: A Chinese perspective},
journal = {Telecommunications Policy},
volume = {48},
number = {10},
pages = {102851},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102851},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124001484},
author = {Xiongbiao Ye and Yuhong Yan and Jia Li and Bo Jiang},
keywords = {Generative AI, Privacy and personal data protection, Risk governance, Chinese law},
abstract = {The rapid development of generative artificial intelligence (AI) has attracted global attention and posed challenges to existing data governance frameworks. The increased technical complexity and expanded scale of data usage not only make it more difficult to regulate AI but also present challenges for the current legal system. This article, which takes ChatGPT's training data and working principles as a starting point, examines specific privacy risks, data leakage risks, and personal data risks posed by generative AI. It also analyzes the latest practices in privacy and personal data protection in China. This article finds that while China's governance on privacy and personal data protection takes a macro-micro integration approach and a private-and-public law integration approach, there are shortcomings in the legal system. Given that the current personal data protection system centered on individual control is unsuitable for the modes of data processing by generative AI, and that private law is insufficient in safeguarding data privacy, urgent institutional innovation is needed to achieve the objective of “trustworthy AI.”}
}
@article{CALLARI2025266,
title = {Can generative artificial intelligence productivity tools support workplace learning? A qualitative study on employee perceptions in a multinational corporation},
journal = {Journal of Workplace Learning},
volume = {37},
number = {3},
pages = {266-283},
year = {2025},
issn = {1366-5626},
doi = {https://doi.org/10.1108/JWL-11-2024-0258},
url = {https://www.sciencedirect.com/science/article/pii/S1366562625000026},
author = {Tiziana C. Callari and Lucia Puppione},
keywords = {Organisational socialisation, Meaningful work, Formal and informal learning, Incidental learning, Sociotechnical capital},
abstract = {Purpose
The purpose of this study was to explore employees’ perceptions and firsthand experiences of the impact of generative artificial intelligence (AI) productivity tools, specifically Microsoft 365 Copilot, on individual and collective learning processes within a multinational corporation. In doing so, the study provides insights into how these tools can shape workplace learning dynamics, fostering both individual skill development and collaborative knowledge-sharing practices.
Design/methodology/approach
The authors collected responses from 357 participants through a survey that included both multiple-choice and open-ended questions. This study focuses exclusively on the qualitative responses. The reflexive thematic analysis method was used to capture and interpret employees’ perceptions of the role of Microsoft 365 Copilot – a generative AI-powered assistant integrated into the Microsoft 365 suite of applications (e.g., Word, Excel, PowerPoint, Outlook, Teams) – in enhancing their work and learning opportunities in the workplace.
Findings
The results highlight four key themes contributing to workplace learning. At the individual level, Task Support illustrates the extent to which generative AI productivity tools transform work practices and facilitate both formal and informal learning pathways, while Meaningful Work underscores the tools’ role in enhancing employees’ foundational knowledge through enriched information. At the organisational level, organisational culture suggests the importance of fostering a supportive environment for AI integration, while organisational socialisation highlights its influence on team cohesion and the informal knowledge-sharing processes essential for effective collaboration within and among team members.
Practical implications
The results of this study offer actionable insights for organisations integrating generative AI productivity tools in the workplace. Understanding employees’ perceptions of the role of AI in workplace learning can inform the design of targeted training programmes that promote individual skill development and foster collaborative knowledge sharing. Furthermore, a supportive organisational culture that positions AI as a complementary resource can improve employee engagement, reduce resistance to new technologies and encourage a growth-oriented mindset, ultimately driving both personal and organisational development.
Originality/value
This study shifts the narrative around the role of AI in the workplace by examining how generative AI productivity tools can enhance workplace learning at both individual and organisational levels, rather than focusing solely on their potential to disrupt work through displacement and automation. By positioning AI-based applications as complementary to human work, this approach highlights their potential as enablers of skill development, knowledge sharing and job enrichment, fostering a more adaptive and learning-oriented work environment.}
}
@article{M2025530,
title = {Debunking myths about Enhanced Recovery After Surgery (ERAS) using Generative Artificial Intelligence},
journal = {Clinical Nutrition ESPEN},
volume = {65},
pages = {530-531},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2024.10.104},
url = {https://www.sciencedirect.com/science/article/pii/S2405457724014414},
author = {Aravind M}
}
@article{NING2024e848,
title = {Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist},
journal = {The Lancet Digital Health},
volume = {6},
number = {11},
pages = {e848-e856},
year = {2024},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(24)00143-2},
url = {https://www.sciencedirect.com/science/article/pii/S2589750024001432},
author = {Yilin Ning and Salinelat Teixayavong and Yuqing Shang and Julian Savulescu and Vaishaanth Nagaraj and Di Miao and Mayli Mertens and Daniel Shu Wei Ting and Jasmine Chiat Ling Ong and Mingxuan Liu and Jiuwen Cao and Michael Dunn and Roger Vaughan and Marcus Eng Hock Ong and Joseph Jao-Yiu Sung and Eric J Topol and Nan Liu},
abstract = {Summary
The widespread use of Chat Generative Pre-trained Transformer (known as ChatGPT) and other emerging technology that is powered by generative artificial intelligence (GenAI) has drawn attention to the potential ethical issues they can cause, especially in high-stakes applications such as health care, but ethical discussions have not yet been translated into operationalisable solutions. Furthermore, ongoing ethical discussions often neglect other types of GenAI that have been used to synthesise data (eg, images) for research and practical purposes, which resolve some ethical issues and expose others. We did a scoping review of the ethical discussions on GenAI in health care to comprehensively analyse gaps in the research. To reduce the gaps, we have developed a checklist for comprehensive assessment and evaluation of ethical discussions in GenAI research. The checklist can be integrated into peer review and publication systems to enhance GenAI research and might be useful for ethics-related disclosures for GenAI-powered products and health-care applications of such products and beyond.}
}
@article{CONTE2024110893,
title = {Statistical analysis and generative Artificial Intelligence (AI) for assessing pain experience, pain-induced disability, and quality of life in Parkinson's disease patients},
journal = {Brain Research Bulletin},
volume = {208},
pages = {110893},
year = {2024},
issn = {0361-9230},
doi = {https://doi.org/10.1016/j.brainresbull.2024.110893},
url = {https://www.sciencedirect.com/science/article/pii/S0361923024000261},
author = {Luana Conte and Roberto Lupo and Pierluigi Lezzi and Alessio Pedone and Ivan Rubbi and Alessia Lezzi and Elsa Vitale and Antonio Fasano and Giorgio {De Nunzio}},
keywords = {Parkinson's disease, Pain, King's Parkinson's Disease Pain Questionnaire (KPPQ), Parkinson's Disease Questionnaire (PDQ), Generative Artificial Intelligence (AI)},
abstract = {The Parkinson's Disease (PD) is a chronic neurodegenerative condition characterized by motor symptoms such as tremors, rigidity, and bradykinesia, which can significantly impact various aspects of daily life. Among these aspects, pain is a prominent element. Despite the widespread use of therapies aimed at improving symptoms and quality of life, effective pain management is essential to enhance the quality of life of individuals affected by this disease. However, a detailed understanding of the factors associated with pain in PD is still evolving. In this study, we examined the disability caused by pain and the pain experienced by PD patients using two validated questionnaires, namely the Parkinson's Disease Questionnaire (PDQ) and the King's Parkinson's Disease Pain Questionnaire (KPPQ). Customized questions were also included to further explore the pain experience and management strategies adopted by PD patients. Through statistical analysis, we explored the relationships between questionnaire scores, socio-demographic data, and other relevant variables. Additionally, generative Artificial Intelligence (AI) was employed to gain a deeper understanding of patient responses. The results indicate the extent and impact of pain in PD and provide valuable insights for more targeted and personalized management. This study lays the foundation for future research and the development of interventions aimed at improving the quality of life for individuals affected by this condition.}
}
@article{KOOLI2025104476,
title = {Generative artificial intelligence addiction syndrome: A new behavioral disorder?},
journal = {Asian Journal of Psychiatry},
volume = {107},
pages = {104476},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104476},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825001194},
author = {Chokri Kooli and Youssef Kooli and Eya Kooli},
keywords = {Generative AI Addiction, Behavioral Addiction, Artificial Intelligence Dependency, Digital Addiction, Cognitive and Emotional Well-being, AI and Mental Health, Human-AI Interaction}
}
@article{FOSSOWAMBA2025103235,
title = {Generative artificial intelligence and the challenges to adding value ethically},
journal = {Technovation},
volume = {144},
pages = {103235},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103235},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000677},
author = {Samuel {Fosso Wamba} and Maciel M. Queiroz and Krithika Randhawa and Gaurav Gupta},
keywords = {Generative AI, Gen-AI, LLMs, Ethical tensions, Business value, Innovation},
abstract = {Generative Artificial Intelligence (Gen-AI) is reshaping business models, innovation processes, and organizational strategies across industries. This editorial highlights its transformative potential through multiple lenses, including business model adaptation, strategic agility, social impact, creative industries, and ethical governance. The special issue “Generative artificial intelligence and the challenges to adding value ethically” presents diverse perspectives on how firms leverage Gen-AI to gain competitive advantage, drive value creation, and enhance resilience while addressing regulatory, ethical, and operational challenges. The accepted papers examine Gen-AI-driven shifts in entrepreneurship, decision-making, and digital ecosystems using quantitative, qualitative, and mixed-method approaches. Their findings point out both the opportunities and tensions of Gen-AI adoption, highlighting the need for responsible governance, strategic alignment, and human-AI collaboration. By integrating multidisciplinary perspectives, this collection offers a rigorous foundation for scholars, practitioners, and policymakers to understand how Gen-AI can be harnessed to drive sustainable and strategic innovation in an evolving and challenging digital landscape.}
}
@article{SUPPAN2025,
title = {Performance of 3 Conversational Generative Artificial Intelligence Models for Computing Maximum Safe Doses of Local Anesthetics: Comparative Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66796},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000419},
author = {Mélanie Suppan and Pietro Elias Fubini and Alexandra Stefani and Mia Gisselbaek and Caroline Flora Samer and Georges Louis Savoldelli},
keywords = {local anesthetic, dose calculation, toxicity, performance, conversational generative artificial intelligence, artificial intelligence, anesthesiology, comparative analysis, anesthetics, LA, generative artificial intelligence, ChatGPT, Copilot, Gemini, artificial intelligence models, machine learning, neural network, LLM, NLP, natural language processing, large language model, AI, ML},
abstract = {Background
Generative artificial intelligence (AI) is showing great promise as a tool to optimize decision-making across various fields, including medicine. In anesthesiology, accurately calculating maximum safe doses of local anesthetics (LAs) is crucial to prevent complications such as local anesthetic systemic toxicity (LAST). Current methods for determining LA dosage are largely based on empirical guidelines and clinician experience, which can result in significant variability and dosing errors. AI models may offer a solution, by processing multiple parameters simultaneously to suggest adequate LA doses.
Objective
This study aimed to evaluate the efficacy and safety of 3 generative AI models, ChatGPT (OpenAI), Copilot (Microsoft Corporation), and Gemini (Google LLC), in calculating maximum safe LA doses, with the goal of determining their potential use in clinical practice.
Methods
A comparative analysis was conducted using a 51-item questionnaire designed to assess LA dose calculation across 10 simulated clinical vignettes. The responses generated by ChatGPT, Copilot, and Gemini were compared with reference doses calculated using a scientifically validated set of rules. Quantitative evaluations involved comparing AI-generated doses to these reference doses, while qualitative assessments were conducted by independent reviewers using a 5-point Likert scale.
Results
All 3 AI models (Gemini, ChatGPT, and Copilot) completed the questionnaire and generated responses aligned with LA dose calculation principles, but their performance in providing safe doses varied significantly. Gemini frequently avoided proposing any specific dose, instead recommending consultation with a specialist. When it did provide dose ranges, they often exceeded safe limits by 140% (SD 103%) in cases involving mixtures. ChatGPT provided unsafe doses in 90% (9/10) of cases, exceeding safe limits by 198% (SD 196%). Copilot’s recommendations were unsafe in 67% (6/9) of cases, exceeding limits by 217% (SD 239%). Qualitative assessments rated Gemini as “fair” and both ChatGPT and Copilot as “poor.”
Conclusions
Generative AI models like Gemini, ChatGPT, and Copilot currently lack the accuracy and reliability needed for safe LA dose calculation. Their poor performance suggests that they should not be used as decision-making tools for this purpose. Until more reliable AI-driven solutions are developed and validated, clinicians should rely on their expertise, experience, and a careful assessment of individual patient factors to guide LA dosing and ensure patient safety.}
}
@article{SILALAHI2025102995,
title = {Can generative artificial intelligence drive sustainable behavior? A consumer-adoption model for AI-driven sustainability recommendations},
journal = {Technology in Society},
volume = {83},
pages = {102995},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102995},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2500185X},
author = {Andri Dayarana K. Silalahi},
keywords = {Generative AI, Sustainable behavior, User trust, Elaboration likelihood model, Cognitive engagement, Pro-environmental adoption},
abstract = {Generative AI (GAI) has the potential to promote sustainable behavior through personalized recommendations; yet its effectiveness hinges on user trust—an issue that remains under-explored in the literature. Existing studies often focus on specific domains without addressing broader trust-building mechanisms or the cognitive and motivational factors needed for sustained engagement. This study investigates how trust shapes the adoption of GAI-driven sustainability recommendations by integrating the Elaboration Likelihood Model (ELM) and Expectancy-Value Theory (EVT) into a single framework. Using data from sustainability-oriented users, we examine how central route constructs-perceived information quality and utility-peripheral route constructs-anthropomorphism and interaction quality-enhance trust, while perceived information complexity and perceived risk moderate these relationships. Our findings indicate that high-quality, useful information enhances trust through cognitive engagement, whereas anthropomorphic design and interaction quality reinforce trust via the heuristic route. However, excessive complexity and privacy concerns undermine trust, highlighting the need for clearer communication and data transparency. This study broadens theoretical understanding by extending ELM and EVT to the context of GAI-driven sustainability efforts, providing an integrated framework that encompasses cognitive and motivational trust drivers. These insights fill gaps in technology adoption research and offer practical guidance for developing GAI platforms that effectively support pro-environmental behavior change.}
}
@article{ALKHATIB2024102676,
title = {How can generative artificial intelligence improve digital supply chain performance in manufacturing firms? Analyzing the mediating role of innovation ambidexterity using hybrid analysis through CB-SEM and PLS-SEM},
journal = {Technology in Society},
volume = {78},
pages = {102676},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002240},
author = {Ayman wael Al-khatib and Moh'd Anwer AL-Shboul and Mais Khattab},
keywords = {Generative artificial intelligence, Innovation ambidexterity, Digital supply chain, Manufacturing firms, Performance, Hybrid analysis, Jordan},
abstract = {Artificial intelligence capabilities (AIC) can influence supply chain management (SCM) in multiple ways. This study explores how generative artificial intelligence capabilities (GAIC) could affect digital supply chain performance (DSCP) through ambidexterity innovation (AMI), which includes both elements, exploratory and exploitative innovations in the manufacturing firms (MFs) in Jordan as a developing and emerging economy. This study adopted a quantitative methodology for the data collection process applying a cross-sectional approach through testing deductive-hypotheses techniques. 263 valid surveys were used for analysis using hybrid analysis measurements (i.e., PLS-SEM, and CB-SEM). Further, it was applied data reliability, convergent validity, and discriminant validity tests. Additionally, examined the mediating effect of exploratory innovation (EXPI), and exploitative innovation (EXTI) on DSCP. The study findings assured that the proposed direct and indirect causal associations illustrated in the study model were accepted due to that all associations between the dimensions s were statistically significant. The findings of the GAIC supported a positive relationship between GAIC and the DSCP, GAIC on EXPI and EXTI, and EXPI and EXTI on DSCP respectively. Furthermore, the mediating effect of EXPI and EXTI is statistically significant, which was confirmed. This study developed a conceptual model to merge GAIC, AMI, and DSCP. This study provides new outcomes that bridge the existing research gap in the literature by testing the mediation model with a focus on the MF benefits of GAIC to improve levels of EXPI, EXTI, and DSCP in Jordan as a developing and emerging economy. Furthermore, this study is considered unique, as it was the first study in Jordan, and through applying hybrid analysis measurements using both PLS-SEM and CB-SEM methods.}
}
@article{LIU2025105479,
title = {Generative artificial intelligence perspectives on typical landscape types: Can ChatGPT compete with human insight?},
journal = {Landscape and Urban Planning},
volume = {264},
pages = {105479},
year = {2025},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2025.105479},
url = {https://www.sciencedirect.com/science/article/pii/S0169204625001860},
author = {Jinxuan Liu and Tianci Zhang and Yongcan Ma and Tianxu Hu and Feng Lin and Huiyi Liang and Danchen Yang and Yinan Pan and Dongyang Gao and Ling Qiu and Tian Gao},
keywords = {ChatGPT, Large language model, Machine perception, Landscape preference, Preference matrix},
abstract = {The emergence of ChatGPT, a prominent generative artificial intelligence (GAI), has raised concerns due to its increasing capability to rival or even surpass human performance across various tasks and domains. However, its alignment with human perception, particularly in emotional and aesthetic dimensions such as landscape preferences, remains uncertain. This study investigated the discrepancies between human and GPT-4 performance in landscape perception and preference, using the Kaplans’ preference matrix as a benchmark. Survey data were collected from 1,333 participants in China, and five typical landscapes i.e. gray, open green, partly open/closed green, closed green, and blue spaces were evaluated. To simulate human-like responses, artificial intelligence (AI) agents using ChatGPT were created with personal attributes mirroring those of the human sample. Results indicated that GPT-4 demonstrated significant divergences from human perception and preference in assessing landscape coherence, complexity, mystery, legibility, and overall preference. While GPT-4 performed comparably well in simpler environments, such as pure single-layer broadleaf forests on flat terrain, it struggled to capture key elements and emotions in more complex or nuanced urban landscapes. Notably, only 2.4 % of ChatGPT’s responses aligned with human perceptions and preferences. These findings highlighted the limitations of current AI in fully replicating human intelligence in landscape perception, emphasizing the continued necessity of human involvement in human-centered landscape design. This study offers insights into the current limitations of ChatGPT and suggests directions for enhancing its application in landscape design.}
}
@article{MARIANI2024114542,
title = {Generative artificial intelligence in innovation management: A preview of future research developments},
journal = {Journal of Business Research},
volume = {175},
pages = {114542},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114542},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000468},
author = {Marcello Mariani and Yogesh K. Dwivedi},
keywords = {Generative artificial intelligence, Delphi study, Management, Innovation},
abstract = {This study outlines the future research opportunities related to Generative Artificial Intelligence (GenAI) in innovation management. To this end, it combines a review of the academic literature with the results of a Delphi study involving leading innovation management scholars. Ten major research themes emerged that can guide future research developments at the intersection of GenAI and innovation management: 1) Gen AI and innovation types; 2) GenAI, dominant designs and technology evolution; 3) Scientific and artistic creativity and GenAI-enabled innovations; 4) GenAI-enabled innovations and intellectual property; 5) GenAI and new product development; 6) Multimodal/unimodal GenAI and innovation outcomes; 7) GenAI, agency and ecosystems; 8) Policymakers, lawmakers and anti-trust authorities in the regulation of GenAI-enabled innovation; 9) Misuse and unethical use of GenAI leading to biased innovation; and 10) Organizational design and boundaries for GenAI-enabled innovation. The paper concludes by discussing how these themes can inform theoretical development in innovation management studies.}
}
@article{MARTIKAINEN2025,
title = {Evaluation of Generative Artificial Intelligence Implementation Impacts in Social and Health Care Language Translation: Mixed Methods Case Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/73658},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25006420},
author = {Miia Martikainen and Kari Smolander and Johan Sanmark and Enni Sanmark},
keywords = {generative artificial intelligence, large language model, ChatGPT, pretrained language model, language translation, machine translation evaluation, public social and health care},
abstract = {Background
Generative artificial intelligence (GAI) is expected to enhance the productivity of the public social and health care sector while maintaining, at minimum, current standards of quality and user experience. However, empirical evidence on GAI impacts in practical, real-life settings remains limited.
Objective
This study investigates productivity, machine translation quality, and user experience impacts of the GPT-4 language model in an in-house language translation services team of a large well-being services county in Finland.
Methods
A mixed methods study was conducted with 4 in-house translators between March and June 2024. Quantitative data of 908 translation segments were collected in real-life conditions using the computer-assisted language translation software Trados (RWS) to assess productivity differences between machine and human translation. Quality was measured using 4 automatic metrics (human-targeted translation edit rate, Bilingual Evaluation Understudy, Metric for Evaluation of Translation With Explicit Ordering, and Character n-gram F-score) applied to 1373 GAI-human segment pairs. User experience was investigated through 5 semistructured interviews, including the team supervisor.
Results
The findings indicate that, on average, postediting machine translation is 14% faster than translating texts from scratch (2.75 vs 2.40 characters per second, P=.03), and up to 37% faster when the number of segments is equalized across translators. However, productivity varied notably between individuals, with improvements ranging from −2% to 102%. Regarding translation quality, 11% (141/1261) of Finnish-Swedish and 16% (18/112) of Finnish-English GAI outputs were accepted without edits. Average human-targeted translation edit rate scores were 55 (Swedish) and 46 (English), indicating that approximately half of the words required editing. Bilingual Evaluation Understudy scores averaged 43 for Swedish and 38 for English, suggesting good translation quality. Metric for Evaluation of Translation With Explicit Ordering and Character n-gram F-scores reached 63 and 68 for Swedish and 59 and 57 for English, respectively. All metrics have been converted to an equivalent scale from 0 to 100, with 100 reflecting a perfect match. Interviewed translators expressed mixed reviews on productivity gains but generally perceived value in using GAI, especially for repetitive, generic content. Identified challenges included inconsistent or incorrect terminology, lack of document-level context, and limited system customization.
Conclusions
Based on this case study, GPT-4–based GAI shows measurable potential to enhance translation productivity and quality within an in-house translation team in the public social and health care sector. However, its effectiveness appears to be influenced by factors, such as translator postediting skills, workflow design, and organizational readiness. These findings suggest that, in similar contexts, public social and health care organizations could benefit from investing in translator training, optimizing technical integration, redesigning workflows, and implementing effective change management. Future research should examine larger translator teams to assess the generalizability of these results and further explore how translation quality and user experience can be improved through domain-specific customization.}
}
@article{LUO2025e117,
title = {Transparent reporting of generative artificial intelligence use in systematic reviews},
journal = {Journal of the American Academy of Dermatology},
volume = {93},
number = {3},
pages = {e117-e118},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.03.101},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225022078},
author = {Xufei Luo and Yaolong Chen},
keywords = {cutaneous squamous cell carcinoma, generative AI, reporting guideline, systematic review}
}
@article{KOHNKE2025108600,
title = {Enhancing the emotional aspects of language education through generative artificial intelligence (GenAI): A qualitative investigation},
journal = {Computers in Human Behavior},
volume = {167},
pages = {108600},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108600},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000470},
author = {Lucas Kohnke and Benjamin Luke Moorhouse},
keywords = {GenAI, Motivation, Emotions, Positive psychology},
abstract = {This qualitative study investigates the impact of generative artificial intelligence (GenAI) on the emotional engagement, motivation and well-being of first-year university students in Hong Kong. We conducted semi-structured interviews with 21 students and three instructors to explore their perceptions of how GenAI influences the affective dimensions of language learning. The data were analyzed using manual coding and inductive thematic analysis to identify key themes. The findings revealed that GenAI generally enhances students’ motivation, reduces anxiety and stress, and fosters an emotionally supportive learning environment. However, challenges related to cultural context and technical issues were also identified. The study highlights the pivotal role of instructors in shaping students’ experiences with GenAI and underscores the need for ongoing support and professional development. It also demonstrates the importance of cultural sensitivity, technological infrastructure and balance. The study is valuable for those who aim to harness GenAI while preserving the irreplaceable human elements of teaching. It contributes to the growing body of knowledge on integrating AI in language learning.}
}
@article{ROBINSON2025390,
title = {Response Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {390-391},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001337},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines}
}
@article{CHEAH2025100363,
title = {Integrating generative artificial intelligence in K-12 education: Examining teachers’ preparedness, practices, and barriers},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100363},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100363},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000037},
author = {Yin Hong Cheah and Jingru Lu and Juhee Kim},
keywords = {Generative artificial intelligence, In-service teachers, Preparedness, Practices, Barriers, K-12 education},
abstract = {Despite the growing body of research on developing K-12 teachers' generative AI (GenAI) knowledge and skills, its integration into daily teaching practices remains underexplored. Using a snowball sampling method, this study examined the preparedness, practices, and barriers encountered by 89 U.S. teachers in the state of Idaho. Participants were predominantly White, female teachers serving in rural schools. A mixed-methods analysis of survey responses revealed that teachers were generally underprepared for integrating GenAI, with fewer than half incorporating it into their educational practices. Unlike the widespread classroom integration patterns observed with general educational technologies, teachers in this study tended to use GenAI for out-of-classroom duties (i.e., lesson preparation, assessment, and administrative tasks) rather than for real-time teaching and learning. These preferences could be attributed to key barriers teachers faced, including doubts about GenAI's ability to manage risks (i.e., technology value beliefs), reduced human interaction in instruction (i.e., pedagogical beliefs), ethical considerations, and the absence of policies and guidance. This study highlights the need to develop support systems and targeted policies to facilitate teachers' GenAI integration, offering implications for Idaho's education system and the broader U.S. context.}
}
@article{HAQUE2026108611,
title = {Generative artificial intelligence and large language models in smart healthcare applications: Current status and future perspectives},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108611},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108611},
url = {https://www.sciencedirect.com/science/article/pii/S1476927125002725},
author = {Md. Asraful Haque and Hifzur R. Siddique},
keywords = {Generative AI, LLM, Healthcare applications, Ethical concern, Bias in AI models},
abstract = {With climate change, habitat destruction, and increased population ages, the incidence of both communicable and non-communicable diseases is rising, and managing these has become a growing concern. In recent years, generative artificial intelligence (AI) and large language models (LLMs) have ushered in a transformative era for smart healthcare applications. These models, built on advanced ML architectures like Generative Pre-trained Transformers (GPT) and Bidirectional Encoder Representations from Transformers (BERT), have demonstrated significant capabilities in various medical tasks. This review aims to provide an overview of the potential benefits of generative AI and LLMs in smart healthcare applications, as well as challenges and ethical considerations. A systematic literature review was conducted to identify relevant research papers published in peer-reviewed journals. Databases such as PubMed, PMC, Cochrane Library, Google Scholar, and Web of Science were searched using keywords related to generative AI, LLMs, and healthcare applications. The relevant papers were analyzed to extract key findings and contributions. Generative AI and LLMs are powerful tools that can process and analyze massive amounts of data. Researchers are actively exploring their potential to transform healthcare-powering intelligent virtual health assistants, crafting personalized patient care plans, and facilitating early detection and intervention for medical conditions. With ongoing research and development, the future of generative AI and LLMs in healthcare is promising; however, issues such as bias in AI models, lack of explainability, ethical concerns, and integration difficulties must be addressed.}
}
@article{DAUNGSUPAWONG2024105498,
title = {Correspondence: Generative artificial intelligence in healthcare},
journal = {International Journal of Medical Informatics},
volume = {189},
pages = {105498},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105498},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001618},
author = {Hineptch Daungsupawong and Viroj Wiwanitkit},
keywords = {Generative, Artificial intelligence, Healthcare}
}
@article{SOLORZANOREQUEJO2024102157,
title = {Fostering creativity in engineering design through constructive dialogues with generative artificial intelligence},
journal = {Cell Reports Physical Science},
volume = {5},
number = {9},
pages = {102157},
year = {2024},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2024.102157},
url = {https://www.sciencedirect.com/science/article/pii/S2666386424004429},
author = {William {Solórzano Requejo} and Francisco {Franco Martínez} and Carlos {Aguilar Vega} and Rodrigo {Zapata Martínez} and Adrián {Martínez Cendrero} and Andrés {Díaz Lantada}},
keywords = {artificial intelligence, engineering design, creativity promotion, biohybrid materials, medical devices, product design, architected materials: architectural structures},
abstract = {Summary
Artificial intelligence (AI) is progressively reshaping the way that researchers design and study highly complex systems. In this perspective, we introduce an engineering design methodology aimed at fostering creativity through “constructive dialogues with a generative AI” and exemplify its potential through a set of methodically developed case studies. This creativity promotion approach starts with computer-aided design (CAD) models of lattices, metamaterials, and architected materials, which are provided as initial inputs to a generative AI through a chat. Then, the conversation starts with researchers asking the generative AI to modify the provided CAD model images by incorporating new elements, placing them in quasi-real-life environments, or adapting the provided designs to the structures of new products. To illustrate the methodology, a varied set of selected case studies of constructive dialogues leading to highly innovative designs are provided, bridging the gap between tissue engineering scaffolds and building architectures, biohybrid materials and product design, and innovative structures and medical devices, to cite a few.}
}
@article{MESSER2025100108,
title = {How do people react to political bias in generative artificial intelligence (AI)?},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100108},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100108},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000689},
author = {Uwe Messer},
keywords = {Artificial intelligence, Alignment, Political orientation, Bias, Acceptance, Large language model},
abstract = {Generative Artificial Intelligence (GAI) such as Large Language Models (LLMs) have a concerning tendency to generate politically biased content. This is a challenge, as the emergence of GAI meets politically polarized societies. Therefore, this research investigates how people react to biased GAI-content based on their pre-existing political beliefs and how this influences the acceptance of GAI. In three experiments (N = 513), it was found that perceived alignment between user's political orientation and bias in generated content (in text and images) increases acceptance and reliance on GAI. Participants who perceived alignment were more likely to grant GAI access to sensitive smartphone functions and to endorse the use in critical domains (e.g., loan approval; social media moderation). Because users see GAI as a social actor, they consider perceived alignment as a sign of greater objectivity, thus granting aligned GAI access to more sensitive areas.}
}
@article{CURRIE2025103,
title = {Gender bias in text-to-image generative artificial intelligence depiction of Australian paramedics and first responders},
journal = {Australasian Emergency Care},
volume = {28},
number = {2},
pages = {103-109},
year = {2025},
issn = {2588-994X},
doi = {https://doi.org/10.1016/j.auec.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2588994X24000757},
author = {Geoffrey Currie and Johnathan Hewis and Phillip Ebbs},
keywords = {First responder, Generative artificial intelligence, Diversity, Inclusivity},
abstract = {Introduction
In Australia, almost 50 % of paramedics are female yet they remain under-represented in stereotypical depictions of the profession. The potentially transformative value of generative artificial intelligence (AI) may be limited by stereotypical errors, misrepresentations and bias. Increasing use of text-to-image generative AI, like DALL-E 3, could reinforce gender and ethnicity biases and, therefore, is important to objectively evaluate.
Method
In March 2024, DALL-E 3 was utilised via GPT-4 to generate a series of individual and group images of Australian paramedics, ambulance officers, police officers and firefighters. In total, 82 images were produced including 60 individual-character images, and 22 multiple-character group images. All 326 depicted characters were independently analysed by three reviewers for apparent gender, age, skin tone and ethnicity.
Results
Among first responders, 90.8 % (N = 296) were depicted as male, 90.5 % (N = 295) as Caucasian, 95.7 % (N = 312) as a light skin tone, and 94.8 % (N = 309) as under 55 years of age. For paramedics and police the gender distribution was a statistically significant variation from that of actual Australian workforce data (all p < 0.001). Among the images of individual paramedics and ambulance officers (N = 32), DALL-E 3 depicted 100 % as male, 100 % as Caucasian and 100 % with light skin tone.
Conclusion
Gender and ethnicity bias is a significant limitation for text-to-image generative AI using DALL-E 3 among Australian first responders. Generated images have a disproportionately high misrepresentation of males, Caucasians and light skin tones that are not representative of the diversity of paramedics in Australia today.}
}
@article{REN2024100073,
title = {Rapid estimation of γ' solvus temperature for composition design of Ni-based superalloy via physics-informed generative artificial intelligence},
journal = {Journal of Alloys and Metallurgical Systems},
volume = {6},
pages = {100073},
year = {2024},
issn = {2949-9178},
doi = {https://doi.org/10.1016/j.jalmes.2024.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2949917824000208},
author = {Yunfei Ren and Tao Hu and Songzhe Xu and Chaoyue Chen and Weidong Xuan and Zhongming Ren},
keywords = {Ni-based superalloy, γ' Solvus temperature, Composition deviation index, Generative artificial intelligence, Thermodynamic calculation},
abstract = {The exceptional high-temperature mechanical properties of Ni-based superalloys are mainly stemmed from the L12 γ' phase, therefore it is crucial to discover Ni-based superalloys with high γ' solvus temperatures. Utilizing generative artificial intelligence, we have developed a framework to swiftly evaluate the γ' solvus temperature and tailor Ni-based superalloys, accelerating the process of discovering Ni-based superalloys. Physics-informed artificial neural network emerged as the optimal choice for reverse engineering, outperforming other models with an R2 score of 0.917 and a mean absolute error of 15 K. In the reverse design process, 20,000 virtual alloy samples were generated based on divide-and-conquer variational autoencoder which divides the dataset into distinct clusters by K-means algorithm provides a structured representation of the alloy composition space, thereby facilitating a more nuanced understanding of its inherent complexities. In a specific alloy design example, 563 samples were identified through screening based on criteria like γ' solvus temperature, composition deviation index, price, and density. Thermodynamic calculations were used to further screen Ni-based superalloys with exceptional high-temperature properties. The showcase of BA alloy discovery through generative artificial intelligence demonstrates the potential of our research to steer the creation of novel compositions for Ni-based superalloys with outstanding high-temperature properties.}
}
@article{COHEN2025111646,
title = {Generative artificial intelligence and academic writing: friend or foe?},
journal = {Journal of Clinical Epidemiology},
volume = {179},
pages = {111646},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111646},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624004025},
author = {Jérémie F. Cohen and David Moher},
keywords = {Artificial Intelligence, Large language models, Medical writing, Publication ethics, Research ethics, Research integrity},
abstract = {This viewpoint examines the use of generative AI models in medical writing, discusses the opportunities and threats they represent, and highlights avenues for improvement and future research.}
}
@article{GUNTUKA2024140,
title = {Application of Generative Artificial Intelligence in Minimizing Cyber Attacks on Vehicular Networks},
journal = {Procedia Computer Science},
volume = {251},
pages = {140-149},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924033283},
author = {Sony Guntuka and Elhadi Shakshuki},
keywords = {Cyber attacks, GenAI, Vehicular Networks},
abstract = {This paper explores the innovative applications of Generative Artificial Intelligence (GenAI) for strengthening the cybersecurity of vehicular networks. With the advent of intelligent transport systems and autonomous vehicles, the cybersecurity landscape has evolved significantly, which necessitating new strategies to tackle sophisticated threats. GenAI provides advanced capabilities for automating defenses, enhancing threat intelligence, and fostering dynamic security frameworks in vehicular networks. However, the incorporation of GenAI also introduces new risks, requiring robust ethical, legal, and technical oversight. This research paper outlines the current state of GenAI in vehicular network cybersecurity, showcases the Vehicular Threat Intelligence Flowchart (VTIF), focuses on the threat detection rule algorithm in VTIF, highlights the potential benefits and challenges, and proposes future research directions for developing resilient and ethical cybersecurity mechanisms.}
}
@article{REASON2025,
title = {The “Artificial Intelligence Statistician”: Utilizing Generative Artificial Intelligence to Select an Appropriate Model and Execute Network Meta-Analyses},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525025112},
author = {Tim Reason and Yunchou Wu and Cheryl Jones and Emma Benbow and Kasper Johannesen and Bill Malcolm},
keywords = {automated analysis, health technology assessment (HTA), joint clinical assessments (JCAs), large language models (LLMs), network meta-analysis (NMA)},
abstract = {Objectives
This exploratory study aimed to develop a large language model (LLM)-based process to automate components of network meta-analysis (NMA), including model selection, analysis, output evaluation, and results interpretation. Automating these tasks with LLMs can enhance efficiency, consistency, and scalability in health economics and outcomes research, while ensuring that analyses adhere to established guidelines required by health technology assessment agencies. Improvements in efficiency and scalability may potentially become relevant as the European Union Health Technology Assessment Regulation comes into force, given anticipated analysis requirements and timelines.
Methods
Using Claude 3.5 Sonnet (V2), a process was designed to automate statistical model selection, NMA output evaluation, and results interpretation based on an “analysis-ready” data set. Validation was assessed by replicating examples from the National Institute for Health and Care Excellence Technical Support Document (TSD2), replicating results of non-Decision Support Unit-published NMAs, and generating comprehensive outputs (eg, heterogeneity, inconsistency, and convergence).
Results
The automated LLM-based process produced accurate results. Compared with TSD2 examples, differences were minimal, within expectations (given differences in sampling frameworks used), and comparable to those observed between estimates produced by the R vignettes against TSD2. Similar consistency was noted for non-Decision Support Unit-published NMA examples. Additionally, the LLM process generated and interpreted comprehensive NMA outputs.
Conclusions
This exploratory study demonstrates the feasibility of LLMs to automate key components of NMAs, determining the requisite NMA framework based only on input data. Further exploring these capabilities could clarify their role in streamlining NMA workflows.}
}
@article{CHUNG2025S-173,
title = {742: RANDOMIZED CONTROLLED TRIAL EVALUATING THE EFFICACY OF HUMAN-GENERATIVE ARTIFICIAL INTELLIGENCE TEAMING ON TECHNOLOGY ACCEPTANCE, USABILITY, AND TRUST: THE GUT-GPT SIMULATION STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-173},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01346-0},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525013460},
author = {Sunny Chung and Niroop Rajashekar and Yuan Pu and Yeo Eun Shin and Mauro Giuffrè and Colleen Chan and Kisung You and Theo Saarinen and Allen Hsiao and Jasjeet Sekhon and Ambrose Wong and Leigh Evans and Terika McCall and Rene F. Kizilcec and Loren Laine and Dennis Shung}
}
@article{SERRASIMON2025103033,
title = {Generative artificial intelligence in advertising. Field applications in Rio de Janeiro and Catalonia},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103033},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103033},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001302},
author = {Jordi Serra-Simón and Mònica Puntí-Brun and Sílvia Espinosa-Mirabet and Maria Alice {de Faria Nogueira} and Ramón Martín-Guart and Sandro {Tôrres de Azevedo}},
keywords = {AI, GenAI, Advertising agencies, Creativity, Digital media, Rio de Janeiro, Catalonia},
abstract = {The emergence of Artificial Intelligence has revolutionized industries in various productive sectors on an international level. Advertising agencies are not immune to this reality and have also experienced the effects of AI through the advent and widespread use of technologies that enable the design, creation, editing, and writing of content for the advertising industry. This article allows us to measure the impact of the arrival of AI in several advertising agencies, independent and holding companies (such as McCann and Havas Media) in Rio de Janeiro and Catalonia. The research analyses the use and integration of these programs in creative and productive processes based on 25 in-depth interviews with 13 directors and 12 creatives in both regions. The results show that agencies are using generative AI tools, but for different purposes, and that in some cases, AI is related to the advertising creation process, while in others, it is used for tasks related to the design of strategic communication plans or even the design of prototypes and models. Although there is unanimous agreement on the benefits of AI, there are concerns about ethical issues and its use in the finalists' work. This article allows us to glimpse new lines of research related to the implementation of generative AI tools in advertising creativity, customer relationship management, and advertising production.}
}
@article{HOSSEINI2025100520,
title = {A social-environmental impact perspective of generative artificial intelligence},
journal = {Environmental Science and Ecotechnology},
volume = {23},
pages = {100520},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2024.100520},
url = {https://www.sciencedirect.com/science/article/pii/S2666498424001340},
author = {Mohammad Hosseini and Peng Gao and Carolina Vivas-Valencia}
}
@article{FLEURENCE2025175,
title = {Generative Artificial Intelligence for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations: An ISPOR Working Group Report},
journal = {Value in Health},
volume = {28},
number = {2},
pages = {175-183},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3846},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524067548},
author = {Rachael L. Fleurence and Jiang Bian and Xiaoyan Wang and Hua Xu and Dalia Dawoud and Mitchell Higashi and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic modeling methods, generative AI, large language models, real world evidence, systematic reviews},
abstract = {Objectives
To provide an introduction to the uses of generative artificial intelligence (AI) and foundation models, including large language models, in the field of health technology assessment (HTA).
Methods
We reviewed applications of generative AI in 3 areas: systematic literature reviews, real-world evidence, and health economic modeling.
Results
(1) Literature reviews: generative AI has the potential to assist in automating aspects of systematic literature reviews by proposing search terms, screening abstracts, extracting data, and generating code for meta-analyses; (2) real-world evidence: generative AI can facilitate automating processes and analyze large collections of real-world data, including unstructured clinical notes and imaging; (3) health economic modeling: generative AI can aid in the development of health economic models, from conceptualization to validation. Limitations in the use of foundation models and large language models include challenges surrounding their scientific rigor and reliability, the potential for bias, implications for equity, as well as nontrivial concerns regarding adherence to regulatory and ethical standards, particularly in terms of data privacy and security. Additionally, we survey the current policy landscape and provide suggestions for HTA agencies on responsibly integrating generative AI into their workflows, emphasizing the importance of human oversight and the fast-evolving nature of these tools.
Conclusions
Although generative AI technology holds promise with respect to HTA applications, it is still undergoing rapid developments and improvements. Continued careful evaluation of their applications to HTA is required. Both developers and users of research incorporating these tools, should familiarize themselves with their current capabilities and limitations.}
}
@article{KUMAR2025102078,
title = {Evaluating Generative Artificial Intelligence Query of Pelvic Congestion Syndrome Management},
journal = {Journal of Vascular Surgery: Venous and Lymphatic Disorders},
volume = {13},
number = {2},
pages = {102078},
year = {2025},
issn = {2213-333X},
doi = {https://doi.org/10.1016/j.jvsv.2024.102078},
url = {https://www.sciencedirect.com/science/article/pii/S2213333X24004980},
author = {Arjun Kumar and Besher Tolaymat and Katherine McMackin and Patrick Conroy and Laurel Hastings and Bruce Tjaden and Philip Batista and Joseph Lombardi}
}
@article{DEEB20241724,
title = {The emerging role of generative artificial intelligence in transplant medicine},
journal = {American Journal of Transplantation},
volume = {24},
number = {10},
pages = {1724-1730},
year = {2024},
issn = {1600-6135},
doi = {https://doi.org/10.1016/j.ajt.2024.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1600613524003824},
author = {Maya Deeb and Anirudh Gangadhar and Madhumitha Rabindranath and Khyathi Rao and Michael Brudno and Aman Sidhu and Bo Wang and Mamatha Bhat},
keywords = {artificial intelligence, deep learning, generative adversarial networks, large language models, machine learning, natural language processing, variational autoencoders},
abstract = {Generative artificial intelligence (AI), a subset of machine learning that creates new content based on training data, has witnessed tremendous advances in recent years. Practical applications have been identified in health care in general, and there is significant opportunity in transplant medicine for generative AI to simplify tasks in research, medical education, and clinical practice. In addition, patients stand to benefit from patient education that is more readily provided by generative AI applications. This review aims to catalyze the development and adoption of generative AI in transplantation by introducing basic AI and generative AI concepts to the transplant clinician and summarizing its current and potential applications within the field. We provide an overview of applications to the clinician, researcher, educator, and patient. We also highlight the challenges involved in bringing these applications to the bedside and need for ongoing refinement of generative AI applications to sustainably augment the transplantation field.}
}
@article{LEBLEBICI2025111573,
title = {Generative artificial intelligence for integrated sensing and communication in 6G},
journal = {Computer Networks},
volume = {270},
pages = {111573},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111573},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625005407},
author = {Merih Leblebici and Ali Çalhan},
keywords = {6G mobile communication, Data link layer, Generative AI, ISAC, Network layer, Physical layer},
abstract = {The advent of sixth generation (6G) networks is poised to redefine wireless communication, promising unprecedented data rates, ultra-low latency, and transformative applications such as holographic communications and real-time digital twins. These advancements hinge on key enabling technologies, including terahertz communication, intelligent reflecting surfaces, and the integration of artificial intelligence (AI). Generative AI (GAI) emerges as a cornerstone of 6G, offering capabilities to overcome challenges such as data scarcity, network optimization, and personalized user experiences. Similarly, integrated sensing and communication (ISAC) stands as a pivotal innovation, merging communication and environmental sensing within a unified system, thereby enhancing spectrum efficiency and operational versatility. This paper examines the convergence of GAI and ISAC as foundational components of 6G. While much of the existing literature focuses on the physical layer, this study also highlights the untapped potential and challenges within the data link and network layers, presenting a comprehensive perspective on the transformative role of GAI and ISAC in next-generation networks.}
}
@article{ALBUSAIDI2024100630,
title = {Redefining boundaries in innovation and knowledge domains: Investigating the impact of generative artificial intelligence on copyright and intellectual property rights},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100630},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100630},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001690},
author = {Adil S. Al-Busaidi and Raghu Raman and Laurie Hughes and Mousa Ahmed Albashrawi and Tegwen Malik and Yogesh K. Dwivedi and Thuraiya {Al- Alawi} and Mohammed AlRizeiqi and Gareth Davies and Mark Fenwick and Parul Gupta and Shashikala Gurpur and Apeksha Hooda and Paulius Jurcys and Daryl Lim and Nicola Lucchi and Tanvi Misra and Ramakrishnan Raman and Anuragini Shirish and Paul Walton},
keywords = {ChatGPT, Generative artificial intelligence, GenAI, Generative scholar, Innovation, Intellectual property (IP) Risks, Large language models (LLMs), Misuse case analysis, Personality rights},
abstract = {The rapid integration of generative AI (GenAI) into industries and society has prompted a re-evaluation of copyright and intellectual property rights (IPR) frameworks. GenAI's ability to produce original content using data from human-created sources raises critical ethical and legal concerns. Current copyright and IPR frameworks, designed around human authorship, are insufficient to address these challenges. This study, using a multi-perspective approach, explores GenAI's disruptive potential in replicating or transforming copyrighted materials, challenging established IPR norms. Findings highlight gaps in legislation and the opacity of GenAI platforms. To address these issues, this study presents a Dynamic Ethical Framework linked to a future global fair use policy, aiming to guide responsible GenAI development and use. By incorporating insights from domain experts, this study contextualizes emerging challenges and potential solutions within broader societal and technological trends. That said, this study calls for international collaboration and further research to reform IPR related laws and frameworks, ensuring they remain relevant and equitable in a GenAI-driven era.}
}
@article{CARROLL2024102899,
title = {Integrating large language models and generative artificial intelligence tools into information literacy instruction},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {4},
pages = {102899},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102899},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000600},
author = {Alexander J. Carroll and Joshua Borycz},
keywords = {Generative artificial intelligence, Large language models, Information literacy, STEM education, Information retrieval, Critical thinking},
abstract = {Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likert-scale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to open-response questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework.}
}
@article{ZHANG20252238,
title = {Research on the impact of generative artificial intelligence (GenAI) on enterprise innovation performance: a knowledge management perspective},
journal = {Journal of Knowledge Management},
volume = {29},
number = {7},
pages = {2238-2257},
year = {2025},
issn = {1367-3270},
doi = {https://doi.org/10.1108/JKM-10-2024-1198},
url = {https://www.sciencedirect.com/science/article/pii/S136732702500033X},
author = {Qichao Zhang and Jiaxiang Zuo and Songlin Yang},
keywords = {Generative artificial intelligence, Knowledge management, Enterprise innovation performance, Human–AI collaboration},
abstract = {Purpose
This study aims to investigate the impact of generative artificial intelligence (GenAI) on enterprise innovation performance, particularly from the perspective of knowledge management. It addresses key challenges in GenAI adoption – such as data biases, information overload and technological dependence – and proposes strategies to overcome these obstacles to enhance innovation.
Design/methodology/approach
Adopting a theoretical approach, this research analyzes the role of knowledge management in bridging the gap between GenAI and enterprise innovation. A structured framework based on four essential knowledge management processes – knowledge creation, retrieval and storage, transfer and sharing and application – is developed to tackle these challenges effectively.
Findings
The study reveals that while GenAI presents both opportunities and challenges for enterprise innovation, leveraging a structured knowledge management framework is key to unlocking its potential. It underscores the critical role of human–AI collaboration in mitigating issues such as data biases and integration challenges, ultimately improving innovation performance. The findings highlight the importance of complementing AI capabilities with human judgment to ensure successful outcomes in GenAI-driven innovation.
Research limitations/implications
This conceptual study calls for further empirical research to validate the findings and expand their generalizability. Future studies should explore contextual factors such as organizational characteristics, business environments and policy frameworks to refine the proposed framework.
Originality/value
This research offers novel insights into the intersection of GenAI, knowledge management and enterprise innovation. It stresses the importance of human involvement alongside GenAI, providing actionable recommendations for organizations navigating the complexities of AI adoption. In addition, it contributes to the evolving discourse on AI and innovation management, offering pathways for businesses to harness GenAI’s full potential and drive performance.}
}
@article{ALHUSBAN202421,
title = {Exploring professional perspectives on integrating generative artificial intelligence into corporate learning and development: an organizational change perspective},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {21-24},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-05-2024-0131},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000522},
author = {Mohammad Issa Alhusban and Hashem Alshurafat and Ibrahim N. Khatatbeh},
keywords = {Learning and development, Expert interviews, Organizational change, ChatGPT, Generative artificial intelligence},
abstract = {Purpose
The primary aim of this study is to investigate the integration of generative artificial intelligence, specifically ChatGPT, into workplace L&D practices, exploring the associated advantages and challenges such integration from an organizational change perspective.
Design/methodology/approach
This study uses a qualitative approach, conducting semi-structured interviews with twelve learning and development (L&D) experts.
Findings
This study indicates that ChatGPT can positively impact L&D by streamlining processes and potentially enhancing employee performance, engagement and satisfaction. However, to mitigate employee resistance, organizations must clearly communicate the necessity and rationale behind the change, involve employees in the implementation process and address trust issues. Key challenges such as overreliance on ChatGPT, AI skill shortages and technology issues like privacy breaches and misinformation must be managed through strong governance frameworks, including policies, guidelines and regular audits.
Research limitations/implications
The study’s scope is confined to semi-structured interviews with L&D experts, potentially limiting its generalizability. Further research could explore the long-term effects and broader implications of ChatGPT integration in different organizational contexts.
Practical implications
By framing GenAI integration within the context of organizational change, this study offers insights into managing the transition effectively by providing guidance for managers on effectively integrating ChatGPT into L&D practices, emphasizing the importance of mitigating potential negative consequences while maximizing benefits.
Social implications
Integrating ChatGPT into organizational L&D has the potential to reshape how employees acquire new skills and knowledge, potentially influencing organizational culture and dynamics. However, careful consideration is required to ensure that the integration process aligns with ethical and social norms, minimizing adverse impacts.
Originality/value
This research contributes foundational insights into the integration of ChatGPT in corporate L&D by researching and understanding the opinions of corporate professionals. It serves as a starting point for organizations to identify challenges in adopting GenAI.}
}
@article{ICHIKAWA2025,
title = {Generative Artificial Intelligence in Medical Education—Policies and Training at US Osteopathic Medical Schools: Descriptive Cross-Sectional Survey},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/58766},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000236},
author = {Tsunagu Ichikawa and Elizabeth Olsen and Arathi Vinod and Noah Glenn and Karim Hanna and Gregg C Lund and Stacey Pierce-Talsma},
keywords = {artificial intelligence, medical education, faculty development, policy, AI, training, United States, school, university, college, institution, osteopathic, osteopathy, curriculum, student, faculty, administrator, survey, cross-sectional},
abstract = {Background
Interest has recently increased in generative artificial intelligence (GenAI), a subset of artificial intelligence that can create new content. Although the publicly available GenAI tools are not specifically trained in the medical domain, they have demonstrated proficiency in a wide range of medical assessments. The future integration of GenAI in medicine remains unknown. However, the rapid availability of GenAI with a chat interface and the potential risks and benefits are the focus of great interest. As with any significant medical advancement or change, medical schools must adapt their curricula to equip students with the skills necessary to become successful physicians. Furthermore, medical schools must ensure that faculty members have the skills to harness these new opportunities to increase their effectiveness as educators. How medical schools currently fulfill their responsibilities is unclear. Colleges of Osteopathic Medicine (COMs) in the United States currently train a significant proportion of the total number of medical students. These COMs are in academic settings ranging from large public research universities to small private institutions. Therefore, studying COMs will offer a representative sample of the current GenAI integration in medical education.
Objective
This study aims to describe the policies and training regarding the specific aspect of GenAI in US COMs, targeting students, faculty, and administrators.
Methods
Web-based surveys were sent to deans and Student Government Association (SGA) presidents of the main campuses of fully accredited US COMs. The dean survey included questions regarding current and planned policies and training related to GenAI for students, faculty, and administrators. The SGA president survey included only those questions related to current student policies and training.
Results
Responses were received from 81% (26/32) of COMs surveyed. This included 47% (15/32) of the deans and 50% (16/32) of the SGA presidents (with 5 COMs represented by both the deans and the SGA presidents). Most COMs did not have a policy on the student use of GenAI, as reported by the dean (14/15, 93%) and the SGA president (14/16, 88%). Of the COMs with no policy, 79% (11/14) had no formal plans for policy development. Only 1 COM had training for students, which focused entirely on the ethics of using GenAI. Most COMs had no formal plans to provide mandatory (11/14, 79%) or elective (11/15, 73%) training. No COM had GenAI policies for faculty or administrators. Eighty percent had no formal plans for policy development. Furthermore, 33.3% (5/15) of COMs had faculty or administrator GenAI training. Except for examination question development, there was no training to increase faculty or administrator capabilities and efficiency or to decrease their workload.
Conclusions
The survey revealed that most COMs lack GenAI policies and training for students, faculty, and administrators. The few institutions with policies or training were extremely limited in scope. Most institutions without current training or policies had no formal plans for development. The lack of current policies and training initiatives suggests inadequate preparedness for integrating GenAI into the medical school environment, therefore, relegating the responsibility for ethical guidance and training to the individual COM member.}
}
@article{NIKOLOPOULOS2024104690,
title = {P.6.1 CREATING VIRTUAL PATIENTS WITH A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR CLINICAL STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104690},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104690},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012882},
author = {A. Nikolopoulos and V. Karalis}
}
@article{WANG2025103791,
title = {EFL teachers’ generative artificial intelligence (GenAI) literacy: A scale development and validation study},
journal = {System},
volume = {133},
pages = {103791},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103791},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002015},
author = {Yongliang Wang and Ali Derakhshan and Farhad Ghiasvand},
keywords = {Generative artificial intelligence (GenAI), EFL teachers, GenAI literacy, Scale development, Scale validation},
abstract = {The application of Generative Artificial Intelligence (GenAI) in second language education (L2) has recently drawn significant scholarly attention. Nonetheless, in the context of English as a foreign language (EFL), the fundamental dimensions of GenAI literacy and its psychometric properties remain poorly defined. Without clarifying the factor structures and dimensionality of GenAI literacy, EFL teachers face challenges in effectively leveraging GenAI in their teaching. To address this gap, our study aimed to develop and validate a GenAI literacy scale for the Chinese EFL context, involving 603 EFL teachers. Specifically, a tentative scale comprising 38 five-point Likert items was administered to participants. Through Exploratory Factor Analysis (EFA) and Confirmatory Factor Analysis (CFA), the final scale was refined, evincing 32 items categorized into five dimensions: “GenAI Knowledge”, “GenAI Use”, “GenAI Evaluation”, “GenAI Design”, and “GenAI Ethics”. Moreover, statistical analysis also verified the scale's convergent validity and reliability in measuring the construct of GenAI literacy. We anticipate that this EFL teachers' GenAI literacy scale will guide teachers and teacher educators in enhancing GenAI capabilities for professional growth. It can also inspire them to innovate teaching with AI tools, thereby offering them fresh insights into GenAI literacy and its sub-components in the rapidly evolving landscape of AI-integrated EFL education.}
}
@article{LI2024112,
title = {On the Application of Generative Artificial Intelligence ChatGPT in Digital Trade},
journal = {Procedia Computer Science},
volume = {247},
pages = {112-120},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402814X},
author = {Rui Li and Qiaoling Zhong},
keywords = {Generative Artificial Intelligence ChatGPT, Natural Language Processing, Customer Service, Dialogue Interaction},
abstract = {The combination of human subjective judgment and machine data processing capabilities in human-machine collaborative evaluation can create a more efficient, accurate, and personalized customer service dialogue interaction system, thereby promoting digital trade efficiency and improving service quality. Generative artificial intelligence has the ability of intelligent interaction and contextual semantic understanding, which is an important means of implementing the concept of human-machine collaboration. This article introduces the basic principles and technical characteristics of ChatGPT, and explores in detail its various application scenarios in digital trade, including automated customer service, personalized recommendations, intelligent marketing, and data analysis. Finally, this article also discusses the challenges and future development directions of ChatGPT in digital trade, in order to provide certain reference value for research and practice in related fields. The data from the questionnaire survey shows that men, aged between 18-30 and 41-50 years old, with high education level, high monthly online shopping expenses, high monthly income, and frequent use of well-known e-commerce platforms, generally have a high level of understanding of ChatGPT.}
}
@article{BLEASE2025,
title = {Generative Artificial Intelligence in Primary Care: Qualitative Study of UK General Practitioners’ Views},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/74428},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125010520},
author = {Charlotte Blease and Carolina {Garcia Sanchez} and Cosima Locher and Brian McMillan and Jens Gaab and John Torous},
keywords = {generative AI, general practice, primary care, large language models, education, training, online survey questionnaire, qualitative research., artificial intelligence},
abstract = {Background
The potential for generative artificial intelligence (GenAI) to assist with clinical tasks is the subject of ongoing debate within biomedical informatics and related fields.
Objective
This study aimed to explore general practitioners’ (GPs’) opinions about GenAI on primary care.
Methods
In January 2025, we conducted a web-based survey of 1005 UK GPs’ experiences and opinions of GenAI in clinical practice. This study involved a qualitative inductive descriptive analysis of a written response (“comments”) to an open-ended question in the survey. After analysis, the interpretation of themes was also informed by the technology acceptance model.
Results
Out of 1005 respondents, 611 GPs (61%) provided written comments in response to the free text question, totaling 7990 words. Comments were classified into 3 major themes and 8 subthemes in relation to GenAI in clinical practice. The major themes were (1) unfamiliarity, (2) ambivalence and anxiety, and (3) role in clinical tasks. “Unfamiliarity” encompassed a lack of experience and knowledge, and the need for training on GenAI. “Ambivalence and anxiety” included mixed expectations among GPs in relation to these tools, beliefs about diminished human connection, and skepticism about AI accountability. Finally, commenting on the role of GenAI in clinical tasks, GPs believed it would help with documentation. However, respondents questioned AI’s clinical judgment and raised concerns about operational uncertainty concerning these tools. Female GPs were more likely to leave comments than male GPs, with 53% (324/611) of female GPs providing feedback compared to 41.1% (162/394) who did not. Chi-square tests confirmed this difference ((χ²₂= 14.6, P=.001). In addition, doctors who left comments were significantly more likely to have used GenAI in clinical practice compared with those who did not. Among all respondents, 71.7% (438/611) had not used GenAI. However, noncommenters were even less likely to have used it, with 80.7% (318/394) reporting no use. A chi-square test confirmed this difference (χ²₁=10.0, P=.002).
Conclusions
This study provides timely insights into UK GPs’ perspectives on the role, impact, and limitations of GenAI in primary care. However, the study has limitations. The qualitative data analyzed originates from a self-selected subset of respondents who chose to provide free-text comments, and these participants were more likely to have used GenAI tools in clinical practice. However, the substantial number of comments offers valuable insights into the diverse views held by GPs regarding GenAI. Furthermore, the majority of our respondents reported limited experience and training with these tools; however, many GPs perceived potential benefits of GenAI and ambient AI for documentation. Notably, 2 years after the widespread introduction of GenAI, GPs’ persistent lack of understanding and training remains a critical concern. More extensive qualitative work would provide a more in-depth understanding of GPs’ views.}
}