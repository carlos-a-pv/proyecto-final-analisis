@article{HUO2024,
title = {Generative Artificial Intelligence in Business Higher Education:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.364093},
url = {https://www.sciencedirect.com/science/article/pii/S1062737524000416},
author = {Xuenan Huo and Keng Leng Siau},
keywords = {Generative Artificial Intelligence, Agentic Artificial Intelligence, Artificial General Intelligence, Focus Group Study, Qualitative Research, Business Higher Education},
abstract = {ABSTRACT
This research investigates the opportunities and challenges of integrating generative artificial intelligence (GenAI) into business higher education, drawing insights from an asynchronous focus group research study with doctoral students who serve dual roles as both learners and educators. Key opportunities identified through thematic analysis include knowledge acquisition, intelligent co-ideation, supportive augmentation, and personalized learning. Challenges identified include AI trustworthiness, cognitive dependency, human value, policy and instruction, assessment integrity, and identity management. This study clarifies GenAI’s specific role in business education and provides practical insights for effectively integrating GenAI to enhance learning outcomes and address emerging challenges. An analysis theory on the opportunities and challenges of GenAI on business higher education is developed and described in the paper. The potential impact of Agentic Artificial Intelligence (autonomous AI agents) and Artificial General Intelligence (AGI) on education is also discussed.}
}
@article{HEROLD2025101012,
title = {Brave new procurement deals: An experimental study of how generative artificial intelligence reshapes buyer–supplier negotiations},
journal = {Journal of Purchasing and Supply Management},
volume = {31},
number = {4},
pages = {101012},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101012},
url = {https://www.sciencedirect.com/science/article/pii/S1478409225000214},
author = {Silke Herold and Jonas Heller and Frank Rozemeijer and Dominik Mahr},
keywords = {Artificial intelligence, Chatbots, Negotiation},
abstract = {The technological breakthrough of artificial intelligence (AI) is impacting buyer-supplier negotiations, which are increasingly moving toward human-to-machine negotiations using AI-based chatbots. While the first AI-powered negotiation solutions are currently being used by procurement professionals to negotiate for non-critical spend items, which is an example of structural influence, the behavioral influence of AI-based chatbots (i.e., on negotiation approach) remains unknown. It is unclear in which behavioral settings these chatbots deliver value to the buying firm in terms of economic, psychological, and relational outcomes. To fill this gap, we conduct three experiments in buyer–supplier negotiation settings, two in a lab-setting with undergraduate business students and one online experiment with professional negotiators. In our interactive simulations, participants play the role of the supplier, while a ChatGPT-based custom-trained chatbot acts as the buyer. We find that when the chatbot deploys a competitive, as compared to a collaborative, negotiation approach, it will achieve a higher price discount, better payment terms, and a quicker negotiation. However, suppliers trust a collaboratively prompted, as compared to a competitively prompted, chatbot more and demonstrate higher outcome satisfaction, as well as a stronger desire for future interaction. A text analysis of the chat interactions indicates a higher level of similarity when a competitively prompted chatbot is employed, which implies that suppliers also use more insistent and intimidating language, thereby matching the chatbot's negotiation approach to a greater degree. While the negotiation approach is a significant influencing factor, we do not find significant evidence that item type, in our case non-critical or bottleneck, matters, which indicates that AI-based chatbots can be effective in various buyer–supplier settings.}
}
@article{PARK20242355,
title = {Has generative artificial intelligence solved inverse materials design?},
journal = {Matter},
volume = {7},
number = {7},
pages = {2355-2367},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
author = {Hyunsoo Park and Zhenzhu Li and Aron Walsh},
abstract = {Summary
The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.}
}
@article{WAISBERG20251,
title = {Generative artificial intelligence in ophthalmology},
journal = {Survey of Ophthalmology},
volume = {70},
number = {1},
pages = {1-11},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000444},
author = {Ethan Waisberg and Joshua Ong and Sharif Amit Kamran and Mouayad Masalkhi and Phani Paladugu and Nasif Zaman and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning},
abstract = {Generative artificial intelligence (AI) has revolutionized medicine over the past several years. A generative adversarial network (GAN) is a deep learning framework that has become a powerful technique in medicine, particularly in ophthalmology for image analysis. In this paper we review the current ophthalmic literature involving GANs, and highlight key contributions in the field. We briefly touch on ChatGPT, another application of generative AI, and its potential in ophthalmology. We also explore the potential uses for GANs in ocular imaging, with a specific emphasis on 3 primary domains: image enhancement, disease identification, and generating of synthetic data. PubMed, Ovid MEDLINE, Google Scholar were searched from inception to October 30, 2022, to identify applications of GAN in ophthalmology. A total of 40 papers were included in this review. We cover various applications of GANs in ophthalmic-related imaging including optical coherence tomography, orbital magnetic resonance imaging, fundus photography, and ultrasound; however, we also highlight several challenges that resulted in the generation of inaccurate and atypical results during certain iterations. Finally, we examine future directions and considerations for generative AI in ophthalmology.}
}
@article{FELDMAN2023336,
title = {Beyond Clinical Accuracy: Considerations for the Use of Generative Artificial Intelligence Models in Gastrointestinal Care},
journal = {Gastroenterology},
volume = {165},
number = {2},
pages = {336-338},
year = {2023},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2023.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0016508523008740},
author = {Keith Feldman and Fredy Nehme}
}
@article{CHARLES2025177508,
title = {AI in action: Changes to student perceptions when using generative artificial intelligence for the creation of a multimedia project-based assessment},
journal = {European Journal of Pharmacology},
volume = {998},
pages = {177508},
year = {2025},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2025.177508},
url = {https://www.sciencedirect.com/science/article/pii/S0014299925002626},
author = {Kellie A. Charles and Arsalan Yousuf and Han Chow Chua and Slade Matthews and Joanna Harnett and Tina Hinton},
keywords = {Science education, Pharmacology education, Artificial intelligence, AI, ChatGPT},
abstract = {Introduction
New modes of assessments are needed to evaluate of the authenticity of student learning in an artificial intelligence (AI) world. In mid-2023, we piloted a new assessment type; a collaborative group multimedia assessment with AI allowance. The aim of the research study was to explore the experiences of students using AI in a multimedia assessment. We further aimed to determine whether these use cases changed student perceptions of the ways AI can be used in learning and assessment.
Methods
Students enrolled in a capstone Pharmacology interdisciplinary unit (n = 40) were included in an exploratory, qualitative case study methodology. Thematic analysis using an AI role-based conceptual framework was used to explore student perceptions of AI use prior to and during their projects from logbooks documenting the assessment process.
Results
AI was initially perceived by students as having a personal tutor-style role, which aligned with the taxonomy with AI acting as an Arbiter (49 %), Oracle (41 %) and Quant (10 %). In contrast to their earlier perceptions, AI was only used in a limited manner in the early stages of assessment in the idea generation in the role as an Oracle (86 %) or in data analytic purposes as a Quant (14 %), (n = 14 cases in 5 groups). No student group used AI to generate written text for the final assessment.
Discussion
Tension between perceived and actual use of AI is indicative of the uncertainty faced by students with the allowance of AI within assessments. Clear guidance for educators and students about how to assess the AI-supported learning process is needed to ensure the integrity of the assessment system.}
}
@article{CHEN2024100531,
title = {Generative Artificial Intelligence Enhancements for Reducing Image-based Training Data Requirements},
journal = {Ophthalmology Science},
volume = {4},
number = {5},
pages = {100531},
year = {2024},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524000678},
author = {Dake Chen and Ying Han and Jacque Duncan and Lin Jia and Jing Shan},
keywords = {Glaucoma, Generative AI, Data scarcity},
abstract = {Objective
Training data fuel and shape the development of artificial intelligence (AI) models. Intensive data requirements are a major bottleneck limiting the success of AI tools in sectors with inherently scarce data. In health care, training data are difficult to curate, triggering growing concerns that the current lack of access to health care by under-privileged social groups will translate into future bias in health care AIs. In this report, we developed an autoencoder to grow and enhance inherently scarce datasets to alleviate our dependence on big data.
Design
Computational study with open-source data.
Subjects
The data were obtained from 6 open-source datasets comprising patients aged 40–80 years in Singapore, China, India, and Spain.
Methods
The reported framework generates synthetic images based on real-world patient imaging data. As a test case, we used autoencoder to expand publicly available training sets of optic disc photos, and evaluated the ability of the resultant datasets to train AI models in the detection of glaucomatous optic neuropathy.
Main Outcome Measures
Area under the receiver operating characteristic curve (AUC) were used to evaluate the performance of the glaucoma detector. A higher AUC indicates better detection performance.
Results
Results show that enhancing datasets with synthetic images generated by autoencoder led to superior training sets that improved the performance of AI models.
Conclusions
Our findings here help address the increasingly untenable data volume and quality requirements for AI model development and have implications beyond health care, toward empowering AI adoption for all similarly data-challenged fields.
Financial Disclosure(s)
The authors have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{DEMIREL2025101127,
title = {Late gadolinium enhancement cardiovascular magnetic resonance with generative artificial intelligence},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101127},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2024.101127},
url = {https://www.sciencedirect.com/science/article/pii/S1097664724011542},
author = {Omer Burak Demirel and Fahime Ghanbari and Christopher W. Hoeger and Connie W. Tsao and Adele Carty and Long H. Ngo and Patrick Pierce and Scott Johnson and Kathryn Arcand and Jordan Street and Jennifer Rodriguez and Tess E. Wallace and Kelvin Chow and Warren J. Manning and Reza Nezafat},
keywords = {Late gadolinium enhancement, Highly accelerated, Deep learning},
abstract = {ABSTRACT
Background
Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging enables imaging of scar/fibrosis and is a cornerstone of most CMR imaging protocols. CMR imaging can benefit from image acceleration; however, image acceleration in LGE remains challenging due to its limited signal-to-noise ratio. In this study, we sought to evaluate a rapid two-dimensional (2D) LGE imaging protocol using a generative artificial intelligence (AI) algorithm with inline reconstruction.
Methods
A generative AI-based image enhancement was used to improve the sharpness of 2D LGE images acquired with low spatial resolution in the phase-encode direction. The generative AI model is an image enhancement technique built on the enhanced super-resolution generative adversarial network. The model was trained using balanced steady-state free-precession cine images, readily used for LGE without additional training. The model was implemented inline, allowing the reconstruction of images on the scanner console. We prospectively enrolled 100 patients (55 ± 14 years, 72 males) referred for clinical CMR at 3T. We collected three sets of LGE images in each subject, with in-plane spatial resolutions of 1.5 × 1.5-3-6 mm2. The generative AI model enhanced in-plane resolution to 1.5 × 1.5 mm2 from the low-resolution counterparts. Images were compared using a blur metric, quantifying the perceived image sharpness (0 = sharpest, 1 = blurriest). LGE image sharpness (using a 5-point scale) was assessed by three independent readers.
Results
The scan times for the three imaging sets were 15 ± 3, 9 ± 2, and 6 ± 1 s, with inline generative AI-based images reconstructed time of ∼37 ms. The generative AI-based model improved visual image sharpness, resulting in lower blur metric compared to low-resolution counterparts (AI-enhanced from 1.5 × 3 mm2 resolution: 0.3 ± 0.03 vs 0.35 ± 0.03, P < 0.01). Meanwhile, AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images showed similar blur metric (0.30 ± 0.03 vs 0.31 ± 0.03, P = 1.0) Additionally, there was an overall 18% improvement in image sharpness between AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images in the subjective blurriness score (P < 0.01).
Conclusion
The generative AI-based model enhances the image quality of 2D LGE images while reducing the scan time and preserving imaging sharpness. Further evaluation in a large cohort is needed to assess the clinical utility of AI-enhanced LGE images for scar evaluation, as this proof-of-concept study does not provide evidence of an impact on diagnosis.}
}
@article{RODMAN2025689,
title = {Is generative artificial intelligence capable of clinical reasoning?},
journal = {The Lancet},
volume = {405},
number = {10480},
pages = {689},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625003484},
author = {Adam Rodman and Eric J Topol}
}
@article{BLEASE2024115724,
title = {Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey},
journal = {Psychiatry Research},
volume = {333},
pages = {115724},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115724},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000118},
author = {Charlotte Blease and Abigail Worthen and John Torous},
keywords = {Chatbots, LLM, Workforce, Psychiatry, Artificial intelligence},
abstract = {Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists’ experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 “to assist with answering clinical questions.” Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed “documentation will be/is more efficient”. Three in four psychiatrists (75 %) somewhat agreed/agreed “the majority of their patients will consult these tools before first seeing a doctor”. Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession.}
}
@article{SAENKHUM2023101066,
title = {Generative artificial intelligence and second language writing},
journal = {Journal of Second Language Writing},
volume = {62},
pages = {101066},
year = {2023},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2023.101066},
url = {https://www.sciencedirect.com/science/article/pii/S1060374323001042},
author = {Tanita Saenkhum and Soo Hyon Kim}
}
@article{CUAYCONG2024106730,
title = {Abstract 1126 Generative Artificial Intelligence in Molecular Design and Virtual Screening of Novel Caspase-1 Inhibitors},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {3, Supplement },
pages = {106730},
year = {2024},
note = {Discover BMB 2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.106730},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824012031},
author = {Stephanie Cuaycong and Chidinma Ralph-Mbah and Amele Divo and Yufeng Wei},
keywords = {inflammasome, cell death, caspase-1, edothelial cells}
}
@article{JOWSEY2023971,
title = {Medical education empowered by generative artificial intelligence large language models},
journal = {Trends in Molecular Medicine},
volume = {29},
number = {12},
pages = {971-973},
year = {2023},
issn = {1471-4914},
doi = {https://doi.org/10.1016/j.molmed.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1471491423002113},
author = {Tanisha Jowsey and Jessica Stokes-Parish and Rachelle Singleton and Michael Todorovic},
keywords = {artificial intelligence, large language model, machine learning, education},
abstract = {Generative artificial intelligence (GAI) large language models (LLMs), like ChatGPT, have become the world’s fastest growing applications. Here, we provide useful strategies for educators in medical and health science (M&HS) to integrate GAI-LLMs into learning and teaching practice, ultimately enhancing students’ digital capability.}
}
@article{BHATTACHARYA2024100194,
title = {ChatGPT’s scorecard after the performance in a series of tests conducted at the multi-country level: A pattern of responses of generative artificial intelligence or large language models},
journal = {Current Research in Biotechnology},
volume = {7},
pages = {100194},
year = {2024},
issn = {2590-2628},
doi = {https://doi.org/10.1016/j.crbiot.2024.100194},
url = {https://www.sciencedirect.com/science/article/pii/S2590262824000200},
author = {Manojit Bhattacharya and Soumen Pal and Srijan Chatterjee and Abdulrahman Alshammari and Thamer H. Albekairi and Supriya Jagga and Elijah {Ige Ohimain} and Hatem Zayed and Siddappa N. Byrareddy and Sang-Soo Lee and Zhi-Hong Wen and Govindasamy Agoramoorthy and Prosun Bhattacharya and Chiranjib Chakraborty},
keywords = {ChatGPT, Accuracy, Reproducibility, Plagiarism, Answer length},
abstract = {Recently, researchers have shown concern about the ChatGPT-derived answers. Here, we conducted a series of tests using ChatGPT by individual researcher at multi-country level to understand the pattern of its answer accuracy, reproducibility, answer length, plagiarism, and in-depth using two questionnaires (the first set with 15 MCQs and the second 15 KBQ). Among 15 MCQ-generated answers, 13 ± 70 were correct (Median : 82.5; Coefficient variance : 4.85), 3 ± 0.77 were incorrect (Median: 3, Coefficient variance: 25.81), and 1 to 10 were reproducible, and 11 to 15 were not. Among 15 KBQ, the length of each question (in words) is about 294.5 ± 97.60 (mean range varies from 138.7 to 438.09), and the mean similarity index (in words) is about 29.53 ± 11.40 (Coefficient variance: 38.62) for each question. The statistical models were also developed using analyzed parameters of answers. The study shows a pattern of ChatGPT-derive answers with correctness and incorrectness and urges for an error-free, next-generation LLM to avoid users’ misguidance.}
}
@article{BEWERSDORFF2025102601,
title = {Taking the next step with generative artificial intelligence: The transformative role of multimodal large language models in science education},
journal = {Learning and Individual Differences},
volume = {118},
pages = {102601},
year = {2025},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001948},
author = {Arne Bewersdorff and Christian Hartmann and Marie Hornberger and Kathrin Seßler and Maria Bannert and Enkelejda Kasneci and Gjergji Kasneci and Xiaoming Zhai and Claudia Nerdel},
keywords = {Artificial Intelligence, Large Language Models (LLMs), ChatGPT, Multimodal learning, Cognitive Theory of Multimedia Learning, Science education},
abstract = {The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 Vision, capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. This paper derives a theoretical framework for integrating MLLMs into multimodal learning. This framework serves to explore the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs range from content creation to tailored support for learning, fostering engagement in scientific practices, and providing assessments and feedback. These applications are not limited to text-based and uni-modal formats but can be multimodal, thus increasing personalization, accessibility, and potential learning effectiveness. Despite the many opportunities, challenges such as data protection and ethical considerations become salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educators' roles, ensuring an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs for educators and to extend the discourse beyond science education to other disciplines. Through developing a theoretical framework for the integration of MLLMs into multimodal learning and exploring the associated potentials, challenges, and future implications, this paper contributes to a preliminary examination of the transformative role of MLLMs in science education and beyond.}
}
@article{WAQAS2023100255,
title = {Revolutionizing Digital Pathology With the Power of Generative Artificial Intelligence and Foundation Models},
journal = {Laboratory Investigation},
volume = {103},
number = {11},
pages = {100255},
year = {2023},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2023.100255},
url = {https://www.sciencedirect.com/science/article/pii/S0023683723001988},
author = {Asim Waqas and Marilyn M. Bui and Eric F. Glassy and Issam {El Naqa} and Piotr Borkowski and Andrew A. Borkowski and Ghulam Rasool},
keywords = {artificial intelligence, computational and digital pathology, foundation models, large language models, multimodal data, vision-language models},
abstract = {Digital pathology has transformed the traditional pathology practice of analyzing tissue under a microscope into a computer vision workflow. Whole-slide imaging allows pathologists to view and analyze microscopic images on a computer monitor, enabling computational pathology. By leveraging artificial intelligence (AI) and machine learning (ML), computational pathology has emerged as a promising field in recent years. Recently, task-specific AI/ML (eg, convolutional neural networks) has risen to the forefront, achieving above-human performance in many image-processing and computer vision tasks. The performance of task-specific AI/ML models depends on the availability of many annotated training datasets, which presents a rate-limiting factor for AI/ML development in pathology. Task-specific AI/ML models cannot benefit from multimodal data and lack generalization, eg, the AI models often struggle to generalize to new datasets or unseen variations in image acquisition, staining techniques, or tissue types. The 2020s are witnessing the rise of foundation models and generative AI. A foundation model is a large AI model trained using sizable data, which is later adapted (or fine-tuned) to perform different tasks using a modest amount of task-specific annotated data. These AI models provide in-context learning, can self-correct mistakes, and promptly adjust to user feedback. In this review, we provide a brief overview of recent advances in computational pathology enabled by task-specific AI, their challenges and limitations, and then introduce various foundation models. We propose to create a pathology-specific generative AI based on multimodal foundation models and present its potentially transformative role in digital pathology. We describe different use cases, delineating how it could serve as an expert companion of pathologists and help them efficiently and objectively perform routine laboratory tasks, including quantifying image analysis, generating pathology reports, diagnosis, and prognosis. We also outline the potential role that foundation models and generative AI can play in standardizing the pathology laboratory workflow, education, and training.}
}
@article{RAWLINSON2025,
title = {Generative Artificial Intelligence to Automate the Adaptation of Excel Health Economic Models and Word Technical Reports},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S109830152502399X},
author = {William Rawlinson and Siguroli Teitsson and Tim Reason and Bill Malcolm and Andy Gimblett and Sven L. Klijn},
keywords = {artificial intelligence, large language models},
abstract = {Objectives
In health economics and outcomes research (HEOR), many repetitive tasks could be performed by large language models (LLMs), including adapting Excel-based health economic models and associated Word technical reports to a new setting. However, it is vital to develop robust methods so that the LLM delivers at least human-level accuracy.
Methods
We developed LLM-based pipelines to automate parameter value adaptations for Excel-based models and subsequent reporting of the model results. Chain-of-thought prompting, ensemble shuffling, and task decomposition were used to enhance the accuracy of the LLM-generated content. We tested the pipelines by adapting 3 Excel-based models (2 cost-effectiveness models [CEMs] and 1 budget impact model [BIM]) and their associated technical reports. The quality of reporting was evaluated by 2 expert health economists.
Results
The accuracy of parameter value adaptations was 100% (147 of 147), 100% (207 of 207), and 98.7% (158 of 160) for the 2 CEMs and 1 budget impact model, respectively. The parameter value adaptations were performed without human intervention in 195 seconds, 245 seconds, and 189 seconds. For parameter value adaptations, the application programming interface costs associated with running the pipeline were $13.36, $6.48, and $2.65. The accuracy of report adaptations was 94.4% (17 of 18), 100% (54 of 54), and 95.1% (39 of 41), respectively. The report adaptations were performed in 128 seconds, 336 seconds, and 286 seconds. For report adaptations, the application programming interface costs associated with running the pipeline were $1.53, $4.24, and $4.05.
Conclusions
LLM-based toolchains have the potential to accurately and rapidly perform routine adaptations of Excel-based CEMs and technical reports at a low cost. This could expedite health technology assessments and improve patient access to new treatments.}
}
@article{ANNA2025105129,
title = {AI-driven digital humans for E-contact: A pre-registered study on reducing intergroup bias with generative artificial intelligence},
journal = {Acta Psychologica},
volume = {258},
pages = {105129},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105129},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825004421},
author = {Manfredi Anna and Puzella Giulio and David Landi and Iolanda Iacono and Jacopo Michilli and Gabbiadini Alessandro},
keywords = {E-contact interventions, Prejudice reduction, Artificial intelligence, Intergroup relations, intergroup contact},
abstract = {The present pre-registered report explores the potential of AI-driven contact interventions by integrating generative Artificial Intelligence-based artificial humans into E-contact paradigms. Grounded in Allport's (1954) Contact Hypothesis and the Dual Identity Model (DIM; Gaertner & Dovidio, 2000), the study examines whether structured interactions with artificial humans can foster positive intergroup attitudes. Following the framework of E-contact interventions (White & Abu-Rayya, 2012), participants (N = 70 Caucasian university students) will engage in a within-between mixed-design experiment over three days. They will interact daily with an AI-powered 3D digital assistant representing either an outgroup member (Black avatar) or an ingroup member (White avatar) depending on the experimental condition, with pre- and post-intervention measures of intergroup attitudes. The structured interactions will follow the two-phase design of E-contact interventions, initially fostering personal acquaintance, then emphasizing group salience, and finally reinforcing a shared superordinate identity—a process aligned with the principles of DIM to maximize the generalization of positive intergroup attitudes. The virtual assistant will facilitate cooperative activities designed to enhance inclusivity, promote cultural exchange, and maintain subgroup distinctiveness while fostering a common identity. To ensure the effectiveness and coherence of the intervention, the scripted interactions will be pretested through a pilot study before implementation. This research offers a preliminary step toward understanding how artificial intelligence might contribute to enhancing E-contact interventions, potentially providing scalable and structured tools for fostering positive intergroup relations and supporting social integration.}
}
@article{KATHAIT20241575,
title = {Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {10},
pages = {1575-1582},
year = {2024},
note = {Focus on Innovation},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400591X},
author = {Anjaneya Singh Kathait and Emiliano Garza-Frias and Tejash Sikka and Thomas J. Schultz and Bernardo Bizzo and Mannudeep K. Kalra and Keith J. Dreyer},
keywords = {generative AI, large language models, natural language processing, patient safety, radiology errors},
abstract = {Purpose
We compared the performance of generative artificial intelligence (AI) (Augmented Transformer Assisted Radiology Intelligence [ATARI, Microsoft Nuance, Microsoft Corporation, Redmond, Washington]) and natural language processing (NLP) tools for identifying laterality errors in radiology reports and images.
Methods
We used an NLP-based (mPower, Microsoft Nuance) tool to identify radiology reports flagged for laterality errors in its Quality Assurance Dashboard. The NLP model detects and highlights laterality mismatches in radiology reports. From an initial pool of 1,124 radiology reports flagged by the NLP for laterality errors, we selected and evaluated 898 reports that encompassed radiography, CT, MRI, and ultrasound modalities to ensure comprehensive coverage. A radiologist reviewed each radiology report to assess if the flagged laterality errors were present (reporting error—true-positive) or absent (NLP error—false-positive). Next, we applied ATARI to 237 radiology reports and images with consecutive NLP true-positive (118 reports) and false-positive (119 reports) laterality errors. We estimated accuracy of NLP and generative AI tools to identify overall and modality-wise laterality errors.
Results
Among the 898 NLP-flagged laterality errors, 64% (574 of 898) had NLP errors and 36% (324 of 898) were reporting errors. The text query ATARI feature correctly identified the absence of laterality mismatch (NLP false-positives) with a 97.4% accuracy (115 of 118 reports; 95% confidence interval [CI] = 96.5%-98.3%). Combined vision and text query resulted in 98.3% accuracy (116 of 118 reports or images; 95% CI = 97.6%-99.0%), and query alone had a 98.3% accuracy (116 of 118 images; 95% CI = 97.6%-99.0%).
Conclusion
The generative AI-empowered ATARI prototype outperformed the assessed NLP tool for determining true and false laterality errors in radiology reports while enabling an image-based laterality determination. Underlying errors in ATARI text query in complex radiology reports emphasize the need for further improvement in the technology.}
}
@article{WAISBERG2024849,
title = {Future directions of generative artificial intelligence in ophthalmology and vision science},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {849-850},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000729},
author = {Ethan Waisberg and Joshua Ong and Mouayad Masalkhi and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning}
}
@article{HIDAYATULLAH2025100213,
title = {Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling},
journal = {Neuroscience Informatics},
volume = {5},
number = {3},
pages = {100213},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000287},
author = {Hafidz Ihsan Hidayatullah and Muhammad Taufiq Saifullah and Muhammad Thesa Ghozali and Ayesha Aziz},
keywords = {Artificial intelligence, Communal pharmacy, Social intention, Procreative AI, Technology acceptance},
abstract = {Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ2=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.}
}
@article{DORTAGONZALEZ2024102187,
title = {Generative artificial intelligence usage by researchers at work: Effects of gender, career stage, type of workplace, and perceived barriers},
journal = {Telematics and Informatics},
volume = {94},
pages = {102187},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102187},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000911},
author = {Pablo Dorta-González and Alexis Jorge López-Puig and María Isabel Dorta-González and Sara M. González-Betancor},
keywords = {Artificial intelligence, Use of AI by researchers in the workplace, Challenges in implementing AI, Gender imbalance},
abstract = {The integration of generative artificial intelligence technology into research environments has become increasingly common in recent years, representing a significant shift in the way researchers approach their work. This paper seeks to explore the factors underlying the frequency of use of generative AI amongst researchers in their professional environments. As survey data may be influenced by a bias towards scientists interested in AI, potentially skewing the results towards the perspectives of these researchers, this study uses a regression model to isolate the impact of specific factors such as gender, career stage, type of workplace, and perceived barriers to using AI technology on the frequency of use of generative AI. It also controls for other relevant variables such as direct involvement in AI research or development, collaboration with AI companies, geographic location, and scientific discipline. Our results show that researchers who face barriers to AI adoption experience an 11 % increase in tool use, while those who cite insufficient training resources experience an 8 % decrease. Female researchers experience a 7 % decrease in AI tool usage compared to men, while advanced career researchers experience a significant 19 % decrease. Researchers associated with government advisory groups are 45 % more likely to use AI tools frequently than those in government roles. Researchers in for-profit companies show an increase of 19 %, while those in medical research institutions and hospitals show an increase of 16 % and 15 %, respectively. This paper contributes to a deeper understanding of the mechanisms driving the use of generative AI tools amongst researchers, with valuable implications for both academia and industry.}
}
@article{PREIKSAITIS2023,
title = {Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48785},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000697},
author = {Carl Preiksaitis and Christian Rose},
keywords = {medical education, artificial intelligence, ChatGPT, Bard, AI, educator, scoping, review, learner, generative},
abstract = {Background
Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications.
Objective
This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration.
Methods
We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data.
Results
Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions.
Conclusions
The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.}
}
@article{PERES2023269,
title = {On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {2},
pages = {269-275},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000162},
author = {Renana Peres and Martin Schreier and David Schweidel and Alina Sorescu},
keywords = {ChatGPT, Generative AI, Artificial intelligence, LLMs},
abstract = {How does ChatGPT, and other forms of Generative Artificial Intelligence (GenAI) affect the way we have been conducting—and evaluating—academic research, teaching, and business practice? What are the implications for the theory and practice of marketing? What are the opportunities and threats, and what are some interesting avenues for future research? This editorial aims to kick off an initial discussion and stimulate research that will help us better understand how the marketing field can fully exploit the potential of GenAI and effectively cope with its challenges.}
}
@article{POIRRIER2023S398,
title = {MSR26 The Use of Copilot, a Generative Artificial Intelligence Tool, as VBA Programming Assistant in Excel-Based Health Economic Models},
journal = {Value in Health},
volume = {26},
number = {12, Supplement },
pages = {S398},
year = {2023},
note = {ISPOR Europe 2023 Abstracts},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2023.09.2085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301523052154},
author = {J.E. Poirrier and R. Bergemann}
}
@article{WEN2025101010,
title = {Generative artificial intelligence for enzyme design: Recent advances in models and applications},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {52},
pages = {101010},
year = {2025},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2025.101010},
url = {https://www.sciencedirect.com/science/article/pii/S2452223625000148},
author = {Shuixiu Wen and Wen Zheng and Uwe T. Bornscheuer and Shuke Wu},
keywords = {artificial intelligence, biocatalysis, enzyme design, generative models},
abstract = {Enzyme catalysis is a key enabling technology for green and sustainable production of chemicals. Developing suitable enzymes is at the heart of this technology, which is currently changing by Artificial Intelligence (AI) such as machine learning. AI-based methods were used for enzyme discovery and design. We review the recent advances in generative AI models for enzyme design, with a particular focus on those that have been validated by experiments. Furthermore, we discuss the applications of the enzymes designed by generative AI, including artificial luciferases, non-heme iron (II)-dependent oxygenases, and P450 enzymes. We provide our opinions on several current issues encountered in computational enzyme design. With the fast development of new generative models in enzymes and the implementation of these models by the research community, we believe that the precise design of efficient enzymes with new catalytic functions and/or potential industrial applications will be a mature method in the near future.}
}
@article{2024S154,
title = {500 Hyponatremia Virtual Patient Simulator: An innovative educational tool with generative artificial intelligence and physiologic models},
journal = {American Journal of Kidney Diseases},
volume = {83},
number = {4, Supplement 2},
pages = {S154},
year = {2024},
note = {National Kidney Foundation 2024 Spring Clinical Meeting Abstracts},
issn = {0272-6386},
doi = {https://doi.org/10.1053/j.ajkd.2024.01.503},
url = {https://www.sciencedirect.com/science/article/pii/S027263862400550X}
}
@article{MORTLOCK2024100481,
title = {Generative artificial intelligence (Gen-AI) in pharmacy education: Utilization and implications for academic integrity: A scoping review},
journal = {Exploratory Research in Clinical and Social Pharmacy},
volume = {15},
pages = {100481},
year = {2024},
issn = {2667-2766},
doi = {https://doi.org/10.1016/j.rcsop.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S2667276624000787},
author = {R. Mortlock and C. Lucas},
keywords = {Artificial intelligence, Academic integrity, ChatGPT, Pharmacy education, Machine learning},
abstract = {Introduction
Generative artificial intelligence (Gen-AI), exemplified by the widely adopted ChatGPT, has garnered significant attention in recent years. Its application spans various health education domains, including pharmacy, where its potential benefits and drawbacks have become increasingly apparent. Despite the growing adoption of Gen-AI such as ChatGPT in pharmacy education, there remains a critical need to assess and mitigate associated risks. This review exploresthe literature and potential strategies for mitigating risks associated with the integration of Gen-AI in pharmacy education.
Aim
To conduct a scoping review to identify implications of Gen-AI in pharmacy education, identify its use and emerging evidence, with a particular focus on strategies which mitigate potential risks to academic integrity.
Methods
A scoping review strategy was employed in accordance with the PRISMA-ScR guidelines. Databases searched includedPubMed, ERIC [Education Resources Information Center], Scopus and ProQuestfrom August 2023 to 20 February 2024 and included all relevant records from 1 January 2000 to 20 February 2024 relating specifically to LLM use within pharmacy education. A grey literature search was also conducted due to the emerging nature of this topic. Policies, procedures, and documents from institutions such as universities and colleges, including standards, guidelines, and policy documents, were hand searched and reviewed in their most updated form. These documents were not published in the scientific literature or indexed in academic search engines.
Results
Articles (n = 12) were derived from the scientific data bases and Records (n = 9) derived from the grey literature. Potential use and benefits of Gen-AI within pharmacy education were identified in all included published articles however there was a paucity of published articles related the degree of consideration to the potential risks to academic integrity. Grey literature recordsheld the largest proportion of risk mitigation strategies largely focusing on increased academic and student education and training relating to the ethical use of Gen-AI as well considerations for redesigning of current assessments likely to be a risk for Gen-AI use to academic integrity.
Conclusion
Drawing upon existing literature, this review highlights the importance of evidence-based approaches to address the challenges posed by Gen-AI such as ChatGPT in pharmacy education settings. Additionally, whilst mitigation strategies are suggested, primarily drawn from the grey literature, there is a paucity of traditionally published scientific literature outlining strategies for the practical and ethical implementation of Gen-AI within pharmacy education. Further research related to the responsible and ethical use of Gen-AI in pharmacy curricula; and studies related to strategies adopted to mitigate risks to academic integrity would be beneficial.}
}
@article{ABUMALLOH2024104128,
title = {Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms},
journal = {Computers in Industry},
volume = {161},
pages = {104128},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000563},
author = {Rabab Ali Abumalloh and Mehrbakhsh Nilashi and Keng Boon Ooi and Garry Wei Han Tan and Hing Kai Chan},
keywords = {Generative AI models, ChatGPT, Citizen Data science, Retail firms, Industrial growth, Industrial and innovation},
abstract = {Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.}
}
@article{RODLER2024S947,
title = {A0193 - Exploring the efficiency of generative artificial intelligence in rapidly and accurately producing patient information for urological malignancy treatments aligned with the latest EAU guidelines},
journal = {European Urology},
volume = {85},
pages = {S947-S948},
year = {2024},
note = {Abstracts EAU24 - 39th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/S0302-2838(24)00773-5},
url = {https://www.sciencedirect.com/science/article/pii/S0302283824007735},
author = {S. Rodler and L.S. Ramacciotti and E. Checcucci and P. {De Backer} and I.R. Belenchon and M. Taraktin and S. Pulliatti and A. Veccia and P. Piazza and L. Baekelandt and K-F. Kowalewski and J.G. Rivas and A.L. Abreu and I.S. Gill and G.E. Cacciamani}
}
@article{ROBINSON2025212,
title = {Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {307},
pages = {212-220},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.12.059},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000216},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines},
keywords = {AI, Artificial intelligence, ChatGPT, Generative AI, Large language models},
abstract = {Artificial intelligence (AI) is rapidly being used in medicine due to its advanced capabilities in image and video recognition, clinical decision support, surgical education, and administrative task automation. Large language models such as OpenAI’s Generative Pretrained Transformer (GPT)-4 and Google’s Bard have particularly revolutionized text generation, offering substantial benefits for the academic surgeon, including aiding in manuscript and grant writing. However, integrating AI into academic surgery necessitates addressing ethical concerns such as bias, transparency, and intellectual property. This paper provides guidelines and recommendations based on current literature around the opportunities and ethical challenges of AI in academic surgery. We discuss the underlying mechanisms of large language models, their potential biases, and the importance of responsible usage. Furthermore, we explore the ethical implications of AI in clinical documentation, highlighting improved efficiency and necessary privacy concerns. This review also addresses the critical issue of intellectual property dilemmas posed by AI-generated innovations in university settings. Finally, we propose guidelines for the responsible adoption of AI in academic and clinical environments, stressing the need for transparency, ethical training, and robust governance frameworks to ensure AI enhances, rather than undermines, academic integrity and patient care.}
}
@article{THANGARAJ20242340,
title = {EVIDENCE FROM RANDOMIZED CONTROLLED TRIAL TO REAL-WORLD PATIENTS USING ELECTRONIC HEALTH RECORD-ADAPTED DIGITAL TWINS: A NOVEL APPLICATION OF GENERATIVE ARTIFICIAL INTELLIGENCE},
journal = {Journal of the American College of Cardiology},
volume = {83},
number = {13, Supplement },
pages = {2340},
year = {2024},
note = {ACC.24},
issn = {0735-1097},
doi = {https://doi.org/10.1016/S0735-1097(24)04330-4},
url = {https://www.sciencedirect.com/science/article/pii/S0735109724043304},
author = {Phyllis Thangaraj and Sumukh Vasisht Shankar and Evangelos K. Oikonomou and Rohan Khera}
}
@article{HALL2024100256,
title = {Generative Artificial Intelligence, Large Language Models, and JID Innovations},
journal = {JID Innovations},
volume = {4},
number = {2},
pages = {100256},
year = {2024},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000018},
author = {Russell P. Hall}
}
@article{LUBOWITZ2024651,
title = {Guidelines for the Use of Generative Artificial Intelligence Tools for Biomedical Journal Authors and Reviewers},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {40},
number = {3},
pages = {651-652},
year = {2024},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2023.10.037},
url = {https://www.sciencedirect.com/science/article/pii/S0749806323008812},
author = {James H. Lubowitz},
abstract = {Authors are permitted to use generative artificial intelligence (AI) large language models (LLM) to improve the readability of their own writing. However, authors must review and edit the output resulting from generative AI and are accountable for the accuracy of their publications. AI may not be listed, or cited, as an author. Authors who use AI in the scientific writing process must disclose the use of AI LLM in their manuscript including a description of the tool and reason for use. Authors are not permitted to use AI to create or alter images or videos, (unless this is part of the research design in which case a statement is required explaining what was created or altered, with what tools, how, and for what reason). Finally, AI use by reviewers and editors is not permitted and violates confidentiality and proprietary rights and may breach data privacy rights. In conclusion, scientific writing and peer review is the responsibility of humans.}
}
@article{AWIDI2024100226,
title = {Comparing expert tutor evaluation of reflective essays with marking by generative artificial intelligence (AI) tool},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100226},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000274},
author = {Isaiah T. Awidi}
}
@article{GARG2024178,
title = {Generative artificial intelligence ChatGPT-4: A transformative epoch in the realm of psychiatric care of children with intellectual developmental disorders},
journal = {General Hospital Psychiatry},
volume = {90},
pages = {178-180},
year = {2024},
issn = {0163-8343},
doi = {https://doi.org/10.1016/j.genhosppsych.2024.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0163834324000859},
author = {Sunny Garg and Alka Chauhan},
keywords = {ChatGPT-4, Children, Educational scenarios, Generative artificial intelligence, Intellectual developmental disorders, Personalized learning}
}
@article{SINGH2024100531,
title = {Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100531},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000702},
author = {Shiwangi Singh and Surabhi Singh and Sascha Kraus and Anuj Sharma and Sanjay Dhir},
keywords = {Generative AI, Technology roadmapping, Patents, Text-mining, Structural topic modeling, Patent data mining},
abstract = {This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.}
}
@article{CHAU2024616,
title = {Performance of Generative Artificial Intelligence in Dental Licensing Examinations},
journal = {International Dental Journal},
volume = {74},
number = {3},
pages = {616-621},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2023.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020653923009899},
author = {Reinhard Chun Wang Chau and Khaing Myat Thu and Ollie Yiru Yu and Richard Tai-Chiu Hsung and Edward Chin Man Lo and Walter Yu Hang Lam},
keywords = {Artificial intelligence, Communication, Dental education, Digital technology, Examination questions, Specialties, Dental},
abstract = {ABSTRACT
Objectives
Generative artificial intelligence (GenAI), including large language models (LLMs), has vast potential applications in health care and education. However, it is unclear how proficient LLMs are in interpreting written input and providing accurate answers in dentistry. This study aims to investigate the accuracy of GenAI in answering questions from dental licensing examinations.
Methods
A total of 1461 multiple-choice questions from question books for the US and the UK dental licensing examinations were input into 2 versions of ChatGPT 3.5 and 4.0. The passing rates of the US and UK dental examinations were 75.0% and 50.0%, respectively. The performance of the 2 versions of GenAI in individual examinations and dental subjects was analysed and compared.
Results
ChatGPT 3.5 correctly answered 68.3% (n = 509) and 43.3% (n = 296) of questions from the US and UK dental licensing examinations, respectively. The scores for ChatGPT 4.0 were 80.7% (n = 601) and 62.7% (n = 429), respectively. ChatGPT 4.0 passed both written dental licensing examinations, whilst ChatGPT 3.5 failed. ChatGPT 4.0 answered 327 more questions correctly and 102 incorrectly compared to ChatGPT 3.5 when comparing the 2 versions.
Conclusions
The newer version of GenAI has shown good proficiency in answering multiple-choice questions from dental licensing examinations. Whilst the more recent version of GenAI generally performed better, this observation may not hold true in all scenarios, and further improvements are necessary. The use of GenAI in dentistry will have significant implications for dentist–patient communication and the training of dental professionals.}
}
@article{KRUIDERING2024224,
title = {Can Generative Artificial Intelligence (AI) Reliably Score Open-Ended Questions (OEQs) in the Assessment of Medical Knowledge},
journal = {The Journal of Pharmacology and Experimental Therapeutics},
volume = {389},
pages = {224},
year = {2024},
issn = {0022-3565},
doi = {https://doi.org/10.1124/jpet.224.126248},
url = {https://www.sciencedirect.com/science/article/pii/S002235652417454X},
author = {Marieke Kruidering and Bao Bao Truongb and Kumiko Endo and Doreen M. Olvet and Tracy B. Fulton and Jeffrey B. Bird and Judith Brenner and Joanne M. Willey},
abstract = {Abstract ID 126248 Poster Board 224 Purpose: The objective of this study is to establish the accuracy of generative artificial intelligence (AI) when scoring medical student exam questions in an open-ended format (OEQ) compared to a faculty content expert. Background: Despite the numerous benefits to including OEQs in assessment of medical knowledge1,2, only 39% of US allopathic medical schools use them3. Faculty report that the biggest barrier is the time it takes to grade student responses1,2. Natural language processing has been explored to automate scoring of clinical reasoning4, but no study has evaluated the use of generative AI to score OEQ responses in the pre-clerkship curriculum. Methods: OEQ responses from two questions administered at the Zucker School of Medicine (ZSOM) and the University of California at San Francisco School of Medicine (UCSF) were used for the current study5. Responses from 54 students per site were analyzed. Content experts scored the responses using an analytic (ZSOM) or holistic rubric (UCSF). Questions, rubrics, and student responses were fed into the GPT-4 model via the Med2Lab platform. Once finalized, scores for each student’s response were generated. Cohen’s weighted kappa (kw) was used to evaluate inter-rater reliability (IRR) between the content expert and generative AI scores, with kw scores between 0.60 and 0.80 being considered substantial6. Prompt engineering was employed for question 1 (analytic rubric) to evaluate its impact on IRR. Results: IRR between the content expert and generative AI scores was substantial using the analytic rubric (question 1: kw = 0.71; question 2: kw = 0.63) and the holistic rubric (question 1: kw = 0.66; question 2: kw = 0.68). IRR for question 1 (analytic rubric) was initially kw = 0.61 but was increased to kw = 0.71 after adjustments with prompt engineering and re-run in GPT-4. Conclusions: Generative AI can score OEQs with substantial reliability. With the potential to alleviate grading burden, AI scoring will allow medical schools to broadly implement OEQs for assessment.}
}
@article{ZHAO2024191,
title = {Employees’ perception of generative artificial intelligence and the dark side of work outcomes},
journal = {Journal of Hospitality and Tourism Management},
volume = {61},
pages = {191-199},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1447677024001207},
author = {Hairong Zhao and Bocong Yuan and Yang Song},
keywords = {, , },
abstract = {Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.}
}
@article{ZHUANG2024102122,
title = {From hearing to seeing: Linking auditory and visual place perceptions with soundscape-to-image generative artificial intelligence},
journal = {Computers, Environment and Urban Systems},
volume = {110},
pages = {102122},
year = {2024},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2024.102122},
url = {https://www.sciencedirect.com/science/article/pii/S0198971524000516},
author = {Yonggai Zhuang and Yuhao Kang and Teng Fei and Meng Bian and Yunyan Du},
keywords = {Soundscape, Street view images, Sense of place, Stable diffusion, Generative AI, LLMs},
abstract = {People experience the world through multiple senses simultaneously, contributing to our sense of place. Prior quantitative geography studies have mostly emphasized human visual perceptions, neglecting human auditory perceptions at place due to the challenges in characterizing the acoustic environment vividly. Also, few studies have synthesized the two-dimensional (auditory and visual) perceptions in understanding human sense of place. To bridge these gaps, we propose a Soundscape-to-Image Diffusion model, a generative Artificial Intelligence (AI) model supported by Large Language Models (LLMs), aiming to visualize soundscapes through the generation of street view images. By creating audio-image pairs, acoustic environments are first represented as high-dimensional semantic audio vectors. Our proposed Soundscape-to-Image Diffusion model, which contains a Low-Resolution Diffusion Model and a Super-Resolution Diffusion Model, can then translate those semantic audio vectors into visual representations of place effectively. We evaluated our proposed model by using both machine-based and human-centered approaches. We proved that the generated street view images align with our common perceptions, and accurately create several key street elements of the original soundscapes. It also demonstrates that soundscapes provide sufficient visual information places. This study stands at the forefront of the intersection between generative AI and human geography, demonstrating how human multi-sensory experiences can be linked. We aim to enrich geospatial data science and AI studies with human experiences. It has the potential to inform multiple domains such as human geography, environmental psychology, and urban design and planning, as well as advancing our knowledge of human-environment relationships.}
}
@article{CHO2025101418,
title = {Exploring international students' perceptions of adopting generative artificial intelligence (GenAI) technologies in learning},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101418},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101418},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125001457},
author = {Changwhan Cho and Duke Ofosu-Anim},
abstract = {This study explores international students' perceptions of GenAI technologies in higher education, focusing on how gender and age influence their willingness to adopt. A survey of 122 international graduate students from a private university in South Korea showed that the students are generally familiar with GenAI and its uses in learning. However, its usage varied in frequency. The study also finds that male students are more likely to use GenAI than female students. Additionally, the study revealed age-related differences in the willingness of international students to adopt GenAI, with younger students showing more interest and willingness than older students. However, despite the differences in interest levels in adopting GenAI among genders and ages, the study revealed that overall, there is a general willingness among international students to learn and apply GenAI technologies to their studies. The South Korean education system can be reformed to accommodate the emerging and growing relevance of GenAI in education by developing ethical capacities that will enhance learning while addressing students’ concerns.}
}
@article{MOUSSA2025202990,
title = {Validation of a generative artificial intelligence tool for the critical appraisal of articles on the epidemiology of mental health: Its application in the Middle East and North Africa},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
number = {2},
pages = {202990},
year = {2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.202990},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325001843},
author = {Cheima Moussa and Sarah Altayyar and Marion Vergonjeanne and Thibaut Gelle and Pierre-Marie Preux},
keywords = {Artificial intelligence, ChatGPT, Critical appraisal, Mental health, MENA},
abstract = {Mental health disorders have a high disability-adjusted life years in the Middle East and North Africa. This rise has led to a surge in related publications, prompting researchers to use AI tools like ChatGPT to reduce time spent on routine tasks. Our study aimed to validate an AI-assisted critical appraisal (CA) tool by comparing it with human raters. We developed customized GPT models using ChatGPT-4. These models were tailored to evaluate studies using the Newcastle-Ottawa Scale (NOS) or the Jadad Scale in one model, while another model evaluated STROBE or CONSORT guidelines. Our results showed a moderate to good agreement between human CA and our GPTs for the NOS for cohort, case control and cross-sectional studies and for the Jadad scale, with an ICC of 0.68 [95 %CI: 0.24–0.82], 0.69 [95 %CI: 0.31–0.88], 0.76 [95 %CI: 0.47–0.90] and 0.84 [95 %CI: 0.57–0.94] respectively. There was also a moderate to substantial agreement between the two methods for STROBE in cross sectional, cohort, case control studies, and for CONSORT in trial design, with a K of 0.63 [95 %CI: 0.56–0.70], 0.57 [95 %CI: 0.47–0.66], 0.48 [95 %CI: 0.38–0.50] and 0.70 [95 %CI: 0.63–0.77] respectively. Our custom GPT models produced hallucinations in 6.5 % and 4.9 % of cases, respectively. Human raters took an average of 19.6 ± 4.3 min per article, whereas our customized GPTs took only 1.4. ChatGPT could be a useful tool for handling repetitive tasks yet its effective application relies on the critical expertise of researchers.}
}
@article{NEVIERE2024S474,
title = {MSR184 Leveraging Generative Artificial Intelligence for Assessing the Quality of Network Meta-Analysis: Methodological Considerations and Early Findings},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S474-S475},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2418},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052811},
author = {A Nevière and G Friedrich and K Papadimitropoulou and P {Le Nouveau} and A Gauthier}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{ASHRAF2024,
title = {Search Engines and Generative Artificial Intelligence Integration: Public Health Risks and Recommendations to Safeguard Consumers Online},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/53086},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000504},
author = {Amir Reza Ashraf and Tim Ken Mackey and András Fittler},
keywords = {generative artificial intelligence, artificial intelligence, comparative assessment, search engines, online pharmacies, patient safety, generative, safety, search engine, search, searches, searching, website, websites, Google, Bing, retrieval, information seeking, illegal, pharmacy, pharmacies, risk, risks, consumer, consumers, customer, customers, recommendation, recommendations, vendor, vendors, substance use, substance abuse, controlled substances, controlled substance, drug, drugs, pharmaceutic, pharmaceutics, pharmaceuticals, pharmaceutical, medication, medications},
abstract = {Background
The online pharmacy market is growing, with legitimate online pharmacies offering advantages such as convenience and accessibility. However, this increased demand has attracted malicious actors into this space, leading to the proliferation of illegal vendors that use deceptive techniques to rank higher in search results and pose serious public health risks by dispensing substandard or falsified medicines. Search engine providers have started integrating generative artificial intelligence (AI) into search engine interfaces, which could revolutionize search by delivering more personalized results through a user-friendly experience. However, improper integration of these new technologies carries potential risks and could further exacerbate the risks posed by illicit online pharmacies by inadvertently directing users to illegal vendors.
Objective
The role of generative AI integration in reshaping search engine results, particularly related to online pharmacies, has not yet been studied. Our objective was to identify, determine the prevalence of, and characterize illegal online pharmacy recommendations within the AI-generated search results and recommendations.
Methods
We conducted a comparative assessment of AI-generated recommendations from Google’s Search Generative Experience (SGE) and Microsoft Bing’s Chat, focusing on popular and well-known medicines representing multiple therapeutic categories including controlled substances. Websites were individually examined to determine legitimacy, and known illegal vendors were identified by cross-referencing with the National Association of Boards of Pharmacy and LegitScript databases.
Results
Of the 262 websites recommended in the AI-generated search results, 47.33% (124/262) belonged to active online pharmacies, with 31.29% (82/262) leading to legitimate ones. However, 19.04% (24/126) of Bing Chat’s and 13.23% (18/136) of Google SGE’s recommendations directed users to illegal vendors, including for controlled substances. The proportion of illegal pharmacies varied by drug and search engine. A significant difference was observed in the distribution of illegal websites between search engines. The prevalence of links leading to illegal online pharmacies selling prescription medications was significantly higher (P=.001) in Bing Chat (21/86, 24%) compared to Google SGE (6/92, 6%). Regarding the suggestions for controlled substances, suggestions generated by Google led to a significantly higher number of rogue sellers (12/44, 27%; P=.02) compared to Bing (3/40, 7%).
Conclusions
While the integration of generative AI into search engines offers promising potential, it also poses significant risks. This is the first study to shed light on the vulnerabilities within these platforms while highlighting the potential public health implications associated with their inadvertent promotion of illegal pharmacies. We found a concerning proportion of AI-generated recommendations that led to illegal online pharmacies, which could not only potentially increase their traffic but also further exacerbate existing public health risks. Rigorous oversight and proper safeguards are urgently needed in generative search to mitigate consumer risks, making sure to actively guide users to verified pharmacies and prioritize legitimate sources while excluding illegal vendors from recommendations.}
}
@article{ZHAO2025108654,
title = {“Positive” or “Threatened”? The impact of the features in generative artificial intelligence on continued behavior},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108654},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001013},
author = {Li Zhao and Yun Xu and Sheng-kai Zhou},
keywords = {Artificial intelligence generated content (AIGC), Positive awe, Threatened awe, Continued usage intention},
abstract = {Artificial intelligence technologies have empowered marketers with advanced tools and insights, fostering unparalleled efficiency and personalization decision-making. To provide marketers with targeted and actionable guidance, this study investigated the behavioral mechanisms underlying the adoption of artificial intelligence-generated content (AIGC) technology. Specifically, it examined the influence of AIGC features (accuracy, competence, anthropomorphism, and interactivity) and the distinct psychological mechanisms of awe on users' behavioral intentions. A mixed-methods approach was employed, combining quantitative data (N = 860) with qualitative research (user reviews). The analysis revealed that the awe experience significantly influences AIGC users' preferences to continue using the technology. Positive awe had a significant positive effect, while threatened awe had a comparatively weaker negative effect. The four features (accuracy, competence, anthropomorphism, and interactivity) of AIGC contribute significantly to its users' continued usage intention. Notably, positive awe induced by competence, anthropomorphism, and interactivity significantly outweighed threatened awe, with the exception of accuracy. The findings reveal that the unique features of AIGC not only evoke users’ perceived awe but also strengthen their intentions to continue using the technology.}
}
@article{VIJAYAN2025e68,
title = {The state of generative artificial intelligence (GAI) in radiology and dentistry},
journal = {Oral Surgery, Oral Medicine, Oral Pathology and Oral Radiology},
volume = {139},
number = {3},
pages = {e68},
year = {2025},
issn = {2212-4403},
doi = {https://doi.org/10.1016/j.oooo.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S221244032400796X},
author = {Dr. Suvendra Vijayan and Dr. Anitha Potluri},
abstract = {Objective
This oral presentation proposes to explain the current state of generative artificial intelligence (GAI) in health care and education. We will also showcase a research project that used GAI to create radiographic images and another ongoing project exploring the potential of GAI in dental education and research.
Study Design
Research 1—A pilot study was conducted to enhance ultra-low dose cone beam computed tomographic images of dry skulls to diagnostically acceptable standards. The images were trained using a pix2pix deep generative model. Research 2—A pilot study is being conducted exploring the accuracy of case reports generated by ChatGPT. We queried ChatGPT to create hypothetical case reports and modified the queries to get the best possible output.
Results
Research 1—Preliminary results indicated that the synthesized images are comparable with images made with normal exposure. Research 2—Preliminary results indicate that ChatGPT can create a convincing and accurate case report. Limitations in use of citations were observed.
Conclusion
GAI like Open AI's ChatGPT, Google's Bard, and Microsoft's CoPilot have caused a massive shift in public knowledge of AI. GAI will have major impact in health care and education. GAI tools like ChatGPT have huge potential for use and misuse in educational and research spheres. Creating questions and explanation on complex topics can be done on these tools. Websites like MidJourney can create interesting and novel images. Radiographic images can be created using specific algorithms. We intend to demonstrate how to effectively use GAI like ChatGPT, describe ethical concerns and how to address and regulate them in academia, and identify innovative uses for AI and ChatGPT in dental care and education. GAI is a freight train with no breaks and as educators and healthcare practitioners we need to discuss and propose policies and safeguards for responsible use of AI.}
}
@article{DIEN2023108595,
title = {Generative artificial intelligence in publishing - Reflection and discussion},
journal = {Biological Psychology},
volume = {181},
pages = {108595},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108595},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001126},
author = {Joseph Dien and Thomas Ritz},
keywords = {Plagiarism, Large Language Models, ChatGPT, Artificial Intelligence, Academic Misconduct}
}
@article{AMACHER2024100587,
title = {Prediction of outcomes after cardiac arrest by a generative artificial intelligence model},
journal = {Resuscitation Plus},
volume = {18},
pages = {100587},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100587},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000389},
author = {Simon A. Amacher and Armon Arpagaus and Christian Sahmer and Christoph Becker and Sebastian Gross and Tabita Urben and Kai Tisljar and Raoul Sutter and Stephan Marsch and Sabina Hunziker},
keywords = {Artificial intelligence, Cardiac arrest, Cardiopulmonary resuscitation, Mortality prediction, Neurological outcome},
abstract = {Aims
To investigate the prognostic accuracy of a non-medical generative artificial intelligence model (Chat Generative Pre-Trained Transformer 4 - ChatGPT-4) as a novel aspect in predicting death and poor neurological outcome at hospital discharge based on real-life data from cardiac arrest patients.
Methods
This prospective cohort study investigates the prognostic performance of ChatGPT-4 to predict outcomes at hospital discharge of adult cardiac arrest patients admitted to intensive care at a large Swiss tertiary academic medical center (COMMUNICATE/PROPHETIC cohort study). We prompted ChatGPT-4 with sixteen prognostic parameters derived from established post-cardiac arrest scores for each patient. We compared the prognostic performance of ChatGPT-4 regarding the area under the curve (AUC), sensitivity, specificity, positive and negative predictive values, and likelihood ratios of three cardiac arrest scores (Out-of-Hospital Cardiac Arrest [OHCA], Cardiac Arrest Hospital Prognosis [CAHP], and PROgnostication using LOGistic regression model for Unselected adult cardiac arrest patients in the Early stages [PROLOGUE score]) for in-hospital mortality and poor neurological outcome.
Results
Mortality at hospital discharge was 43% (n = 309/713), 54% of patients (n = 387/713) had a poor neurological outcome. ChatGPT-4 showed good discrimination regarding in-hospital mortality with an AUC of 0.85, similar to the OHCA, CAHP, and PROLOGUE (AUCs of 0.82, 0.83, and 0.84, respectively) scores. For poor neurological outcome, ChatGPT-4 showed a similar prediction to the post-cardiac arrest scores (AUC 0.83).
Conclusions
ChatGPT-4 showed a similar performance in predicting mortality and poor neurological outcome compared to validated post-cardiac arrest scores. However, more research is needed regarding illogical answers for potential incorporation of an LLM in the multimodal outcome prognostication after cardiac arrest.}
}
@article{RAMAN2024e24727,
title = {Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e24727},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24727},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024007588},
author = {Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan},
keywords = {Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal},
abstract = {In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.}
}
@article{DIEN2023108621,
title = {Editorial: Generative artificial intelligence as a plagiarism problem},
journal = {Biological Psychology},
volume = {181},
pages = {108621},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108621},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001382},
author = {Joseph Dien},
keywords = {Plagiarism, Large language models, ChatGPT, Artificial intelligence, Academic misconduct},
abstract = {There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology, the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved.}
}
@article{RUKADIKAR202427,
title = {Leadership development through self-upskilling: role of generative artificial intelligence},
journal = {Development and Learning in Organizations: An International Journal},
volume = {38},
number = {4},
pages = {27-30},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-01-2024-0005},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000170},
author = {Aaradhana Rukadikar and Komal Khandelwal},
keywords = {Leadership development, Leaders, Learning, Upskilling, Generative AI},
abstract = {Purpose
This viewpoint paper investigates the changing role of leadership in a dynamic, technologically driven society, and the vital requirement for leaders to engage in continuous self-upskilling to remain effective. It emphasizes the importance of generative artificial intelligence (GAI) in transforming personalized learning experiences for leaders and allowing them to adapt to an ever-changing world.
Design/methodology/approach
A review of current research papers, articles, and case studies is conducted to evaluate the integration of generative AI in leadership self-upskilling. It examines the possibilities and possible benefits of generative AI, and the issues it offers regarding data privacy, algorithmic bias, and learning requirements.
Findings
The findings highlight the transformational potential of GAI in self-upskilling for leaders. It demonstrates how GAI can build personalized learning materials, provide real-time feedback, and adapt content to individual learning styles. It identifies notable executives who have effectively embraced GAI for their self-upskilling journeys, resulting in increased productivity and competitiveness.
Practical implications
The paper investigates the application of GAI for self-improvement, addressing challenges such as data privacy and algorithmic bias while suggesting responsible AI use tactics.
Originality/value
This study investigates the relationship between leadership and AI, emphasizing the importance of leaders in self-improvement as well as the possibility of AI-powered self-upskilling to democratize leadership development while also promoting ethical use.}
}
@article{BOSCO2025,
title = {Designing a Multimodal and Culturally Relevant Alzheimer Disease and Related Dementia Generative Artificial Intelligence Tool for Black American Informal Caregivers: Cognitive Walk-Through Usability Study},
journal = {JMIR Aging},
volume = {8},
year = {2025},
issn = {2561-7605},
doi = {https://doi.org/10.2196/60566},
url = {https://www.sciencedirect.com/science/article/pii/S2561760525000027},
author = {Cristina Bosco and Ege Otenen and John {Osorio Torres} and Vivian Nguyen and Darshil Chheda and Xinran Peng and Nenette M Jessup and Anna K Himes and Bianca Cureton and Yvonne Lu and Carl V Hill and Hugh C Hendrie and Priscilla A Barnes and Patrick C Shih},
keywords = {multimodality, artificial intelligence, AI, generative AI, usability, black, African American, cultural, Alzheimer's, dementia, caregivers, mobile app, interaction, cognition, user opinion, geriatrics, smartphone, mHealth, digital health, aging},
abstract = {Background
Many members of Black American communities, faced with the high prevalence of Alzheimer disease and related dementias (ADRD) within their demographic, find themselves taking on the role of informal caregivers. Despite being the primary individuals responsible for the care of individuals with ADRD, these caregivers often lack sufficient knowledge about ADRD-related health literacy and feel ill-prepared for their caregiving responsibilities. Generative AI has become a new promising technological innovation in the health care domain, particularly for improving health literacy; however, some generative AI developments might lead to increased bias and potential harm toward Black American communities. Therefore, rigorous development of generative AI tools to support the Black American community is needed.
Objective
The goal of this study is to test Lola, a multimodal mobile app, which, by relying on generative AI, facilitates access to ADRD-related health information by enabling speech and text as inputs and providing auditory, textual, and visual outputs.
Methods
To test our mobile app, we used the cognitive walk-through methodology, and we recruited 15 informal ADRD caregivers who were older than 50 years and part of the Black American community living within the region. We asked them to perform 3 tasks on the mobile app (ie, searching for an article on brain health, searching for local events, and finally, searching for opportunities to participate in scientific research in their area), then we recorded their opinions and impressions. The main aspects to be evaluated were the mobile app’s usability, accessibility, cultural relevance, and adoption.
Results
Our findings highlight the users’ need for a system that enables interaction with different modalities, the need for a system that can provide personalized and culturally and contextually relevant information, and the role of community and physical spaces in increasing the use of Lola.
Conclusions
Our study shows that, when designing for Black American older adults, a multimodal interaction with the generative AI system can allow individuals to choose their own interaction way and style based upon their interaction preferences and external constraints. This flexibility of interaction modes can guarantee an inclusive and engaging generative AI experience.}
}
@article{ODRI2023103706,
title = {Detecting generative artificial intelligence in scientific articles: Evasion techniques and implications for scientific integrity},
journal = {Orthopaedics & Traumatology: Surgery & Research},
volume = {109},
number = {8},
pages = {103706},
year = {2023},
issn = {1877-0568},
doi = {https://doi.org/10.1016/j.otsr.2023.103706},
url = {https://www.sciencedirect.com/science/article/pii/S1877056823002244},
author = {Guillaume-Anthony Odri and Diane {Ji Yun Yoon}},
keywords = {Generative artificial intelligence, Academic writing, Scientific fraud},
abstract = {Background
Artificial intelligence (AI) tools, although beneficial for data collection and analysis, can also facilitate scientific fraud. AI detectors can help resolve this problem, but their effectiveness depends on their ability to track AI progress. In addition, many methods of evading AI detection exist and their constantly evolving sophistication can make the task more difficult. Thus, from an AI-generated text, we wanted to: (1) evaluate the AI detection sites on a text generated entirely by the AI, (2) test the methods described for evading AI detection, and (3) evaluate the effectiveness of these methods to evade AI detection on the sites tested previously.
Hypothesis
Not all AI detection tools are equally effective in detecting AI-generated text and some techniques used to evade AI detection can make an AI-produced text almost undetectable.
Materials and methods
We created a text with ChatGPT-4 (Chat Generative Pre-trained Transformer) and submitted it to 11 AI detection web tools (Originality, ZeroGPT, Writer, Copyleaks, Crossplag, GPTZero, Sapling, Content at scale, Corrector, Writefull et Quill), before and after applying strategies to minimise AI detection. The strategies used to minimize AI detection were the improvement of command messages in ChatPGT, the introduction of minor grammatical errors such as comma deletion, paraphrasing, and the substitution of Latin letters with similar Cyrillic letters (а and о) which is also a method used elsewhere to evade the detection of plagiarism. We have also tested the effectiveness of these tools in correctly identifying a scientific text written by a human in 1960.
Results
From the initial text generated by the AI, 7 of the 11 detectors concluded that the text was mainly written by humans. Subsequently, the introduction of simple modifications, such as the removal of commas or paraphrasing can effectively reduce AI detection and make the text appear human for all detectors. In addition, replacing certain Latin letters with Cyrillic letters can make an AI text completely undetectable. Finally, we observe that in a paradoxical way, certain sites detect a significant proportion of AI in a text written by a human in 1960.
Discussion
AI detectors have low efficiency, and simple modifications can allow even the most robust detectors to be easily bypassed. The rapid development of generative AI raises questions about the future of scientific writing but also about the detection of scientific fraud, such as data fabrication.
Level of evidence
III Control case study.}
}
@article{BUGHIN2024658,
title = {What drives the corporate payoffs of using generative artificial intelligence?},
journal = {Structural Change and Economic Dynamics},
volume = {71},
pages = {658-668},
year = {2024},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X24001413},
author = {Jacques Bughin},
keywords = {AI, Generative AI, Productivity impact, Capabilities, Entropy},
abstract = {Artificial Intelligence, a set of technologies that aim to replicate human cognitive functions, has seen remarkable improvements over the last decade. In particular, generative AI (GenAI), a subset of AI able to generate content tasks based on Large Language Models (LLM), has recently gained momentum. Based on an extensive analysis of generative AI use cases in large enterprises, we find that Gen AI shows strong labor productivity improvements across metrics such as throughput time, unit cost, and task effectiveness. However, the distribution of gains is asymmetric in favor of a few companies. While the current distribution of gains does not provide evidence of a power law effect, the current asymmetry reflects differences in AI resources/capabilities across companies - mainly data access, AI talent, or AI governance.}
}
@article{STERPETTI2025388,
title = {Letter Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {388-389},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001325},
author = {Antonio V. Sterpetti}
}
@article{MILES2024S478,
title = {MSR201 Optimising Performance of Generative Artificial Intelligence (GenAI) in Systematic Literature Review (SLR) Screening Using PICOS Criteria},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S478},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2435},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052987},
author = {G Miles and L Giles and B.C. Kerr and B Norman and GC Sibbring}
}
@article{LEE20241318,
title = {Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1318-1320},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024001303},
author = {Christoph I. Lee and Jonathan H. Chen and Marc D. Kohli and Andrew D. Smith and Joshua M. Liao}
}
@article{TRIANARODRIGUEZ20241158,
title = {Generative Artificial Intelligence: A Promising Instrument for Daily Living and Clinical Practice},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1158-1159},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2023.12.030},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024000577},
author = {Gustavo Adolfo {Triana Rodriguez} and María M. Rojas-Rojas and Katherine Sotomayor and Juan P. Ovalle and José David {Cardona Ortegón}}
}
@article{NA2025103614,
title = {1376 Virtual H&E Staining Using Generative Artificial Intelligence: A Novel Technique for Digital Transformation of Unstained Pathology Slides},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103614},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032926},
author = {Sei Na and Dawoon Na and Kyoungsook Park and SangYong Song and Byullee Park and Hyung Kyung Kim}
}
@article{ISLEEM202427,
title = {Can generative artificial intelligence pass the orthopaedic board examination?},
journal = {Journal of Orthopaedics},
volume = {53},
pages = {27-33},
year = {2024},
issn = {0972-978X},
doi = {https://doi.org/10.1016/j.jor.2023.10.026},
url = {https://www.sciencedirect.com/science/article/pii/S0972978X23002593},
author = {Ula N. Isleem and Bashar Zaidat and Renee Ren and Eric A. Geng and Aonnicha Burapachaisri and Justin E. Tang and Jun S. Kim and Samuel K. Cho},
abstract = {Background
Resident training programs in the US use the Orthopaedic In-Training Examination (OITE) developed by the American Academy of Orthopaedic Surgeons (AAOS) to assess the current knowledge of their residents and to identify the residents at risk of failing the Amerian Board of Orthopaedic Surgery (ABOS) examination. Optimal strategies for OITE preparation are constantly being explored. There may be a role for Large Language Models (LLMs) in orthopaedic resident education. ChatGPT, an LLM launched in late 2022 has demonstrated the ability to produce accurate, detailed answers, potentially enabling it to aid in medical education and clinical decision-making. The purpose of this study is to evaluate the performance of ChatGPT on Orthopaedic In-Training Examinations using Self-Assessment Exams from the AAOS database and approved literature as a proxy for the Orthopaedic Board Examination.
Methods
301 SAE questions from the AAOS database and associated AAOS literature were input into ChatGPT's interface in a question and multiple-choice format and the answers were then analyzed to determine which answer choice was selected. A new chat was used for every question. All answers were recorded, categorized, and compared to the answer given by the OITE and SAE exams, noting whether the answer was right or wrong.
Results
Of the 301 questions asked, ChatGPT was able to correctly answer 183 (60.8%) of them. The subjects with the highest percentage of correct questions were basic science (81%), oncology (72.7%, shoulder and elbow (71.9%), and sports (71.4%). The questions were further subdivided into 3 groups: those about management, diagnosis, or knowledge recall. There were 86 management questions and 47 were correct (54.7%), 45 diagnosis questions with 32 correct (71.7%), and 168 knowledge recall questions with 102 correct (60.7%).
Conclusions
ChatGPT has the potential to provide orthopedic educators and trainees with accurate clinical conclusions for the majority of board-style questions, although its reasoning should be carefully analyzed for accuracy and clinical validity. As such, its usefulness in a clinical educational context is currently limited but rapidly evolving.
Clinical relevance
ChatGPT can access a multitude of medical data and may help provide accurate answers to clinical questions.}
}
@article{XIAO20232973,
title = {Generative Artificial Intelligence GPT‑4 Accelerates Knowledge Mining and Machine Learning for Synthetic Biology},
journal = {ACS Synthetic Biology},
volume = {12},
number = {10},
pages = {2973-2982},
year = {2023},
issn = {2161-5063},
doi = {https://doi.org/10.1021/acssynbio.3c00310},
url = {https://www.sciencedirect.com/science/article/pii/S2161506323000323},
author = {Zhengyang Xiao and Wenyu Li and Hannah Moon and Garrett W. Roell and Yixin Chen and Yinjie J. Tang},
keywords = {feature selection, natural language processing, human intervention, prompt engineering, transfer learning,   },
abstract = {Knowledge mining from synthetic biology journal articles for machine learning (ML) applications is a labor-intensive process. The development of natural language processing (NLP) tools, such as GPT-4, can accelerate the extraction of published information related to microbial performance under complex strain engineering and bioreactor conditions. As a proof of concept, we proposed prompt engineering for a GPT-4 workflow pipeline to extract knowledge from 176 publications on two oleaginous yeasts (Yarrowia lipolytica and Rhodosporidium toruloides). After human intervention, the pipeline obtained a total of 2037 data instances. The structured data sets and feature selections enabled ML approaches (e.g., a random forest model) to predict Yarrowia fermentation titers with decent accuracy (R 2 of 0.86 for unseen test data). Via transfer learning, the trained model could assess the production potential of the engineered nonconventional yeast, R. toruloides, for which there are fewer published reports. This work demonstrated the potential of generative artificial intelligence to streamline information extraction from research articles, thereby facilitating fermentation predictions and biomanufacturing development.
}
}
@article{FIJACKO2024100584,
title = {Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses},
journal = {Resuscitation Plus},
volume = {18},
pages = {100584},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100584},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000353},
author = {Nino Fijačko and Ruth Masterson Creber and Benjamin S. Abella and Primož Kocbek and Špela Metličar and Robert Greif and Gregor Štiglic},
keywords = {Emergency medicine, European Resuscitation Council, Congress, Bibliometrics analysis, Generative artificial intelligence},
abstract = {Aims
The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade.
Methods
In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics.
Results
From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence.
Conclusion
This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.}
}
@article{AZIZOGLU2025162359,
title = {Generative Artificial Intelligence Accuracy in Interpreting Forest Plots in Pediatric Surgery Meta-analyses: A Perspective From Pediatric Surgery Meta-analysis Study Group (PESMA)},
journal = {Journal of Pediatric Surgery},
volume = {60},
number = {7},
pages = {162359},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162359},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825002040},
author = {Mustafa Azizoglu and Maria Escolino and Tahsin Onat Kamci and Sergey Klyuev and Sonia {Perez Bertolez} and Toni Risteski and Ismael Elhalaby and Nitinkumar Borkar and Ciro Esposito and Mehmet Hanifi Okur and Martin Lacher and Annika Mutanen and Sameh Shehata and Fabio Chiarenza and Mark Davenport}
}
@article{RAY20231457,
title = {Generative Artificial Intelligence (AI) and Medical Ethics: A Symbiotic Dance for the Future},
journal = {Journal of Oral and Maxillofacial Surgery},
volume = {81},
number = {12},
pages = {1457-1459},
year = {2023},
issn = {0278-2391},
doi = {https://doi.org/10.1016/j.joms.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278239123011588},
author = {Partha Pratim Ray}
}
@article{WHEATLEY2024102942,
title = {Comparing generative artificial intelligence tools to voice assistants using reference interactions},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {5},
pages = {102942},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102942},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324001034},
author = {Amanda Wheatley and Sandy Hervieux},
keywords = {Artificial intelligence, Voice assistants, Generative AI, Reference},
abstract = {This study investigates the ability of voice assistants and generative AI tools to respond to reference questions traditionally received by academic librarians. The authors created a sample of 25 questions based on queries received on the virtual reference service at their institution. They then created a rubric to evaluate the quality of the answers that the AI powered tools provided. The authors determined that the tools understand reference questions well and provide relevant answers but that the quality of the references provided, and the accuracy of the answers can be lacking. They suggest that more research needs to be done to understand the place of AI powered tools in reference services.}
}
@article{WENGREEN2024A70,
title = {Dietetic Students' Knowledge and Perceptions of Their Use of Generative Artificial Intelligence Now and in the Future},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A70},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.07.064},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224006245},
author = {H. Wengreen and S. Bevan and K. Kraus}
}
@article{LENGUYEN2024138836,
title = {Generative artificial intelligence and optimisation framework for concrete mixture design with low cost and embodied carbon dioxide},
journal = {Construction and Building Materials},
volume = {451},
pages = {138836},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.138836},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824039783},
author = {Khuong {Le Nguyen} and Minhaz Uddin and Thong M. Pham},
keywords = {Concrete mixture design, Machine learning approach, Generative AI, Compressive strength prediction, Multi-objective optimisation},
abstract = {This research presents a generative Artificial Intelligence (AI) and design framework that integrates machine learning (ML) and optimisation methodologies to discover new concrete mixture designs. Unlike traditional ML models that predict based on existing data, this framework innovatively generates new concrete mix designs that meet specific requirements such as strength, cost-efficiency, and reduced embodied CO2. To propose a powerful and reliable generative AI model, several advanced ML algorithms were considered, e.g., CatBoost, XGBoost, and LGBM. These models were trained on a unique dataset consisting of 4,936 data points collected from five different batching plants and have not been published yet. Bayesian Optimisation was employed to fine-tune model hyperparameters, resulting in the most effective models attaining R2 values of 0.94 and 0.89 for raw and grouped data, respectively. To verify the trained generative AI model, a case study was conducted, in which the model was requested to provide designs of a mix with pre-determined strength and optimised cost and embodied CO2. The mix designs generated by the framework were successfully validated through experimental tests, corroborating the predictive outcomes. The research culminated in the development of a web application, a tool crafted to streamline the concrete mixture design and optimisation process. This generative AI design framework can be applied to many other aspects of material design and engineering problems.}
}
@article{MOTOKI2025106904,
title = {Assessing political bias and value misalignment in generative artificial intelligence},
journal = {Journal of Economic Behavior & Organization},
volume = {234},
pages = {106904},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2025.106904},
url = {https://www.sciencedirect.com/science/article/pii/S0167268125000241},
author = {Fabio Y.S. Motoki and Valdemar {Pinho Neto} and Victor Rangel},
keywords = {Generative AI, Societal values, Large language models, Multimodal, AI governance},
abstract = {Our analysis reveals a concerning misalignment of values between ChatGPT and the average American. We also show that ChatGPT displays political leanings when generating text and images, but the degree and direction of skew depend on the theme. Notably, ChatGPT repeatedly refused to generate content representing certain mainstream perspectives, citing concerns over misinformation and bias. As generative AI systems like ChatGPT become ubiquitous, such misalignment with societal norms poses risks of distorting public discourse. Without proper safeguards, these systems threaten to exacerbate societal divides and depart from principles that underpin free societies.}
}
@article{LIU2024124511,
title = {Generative artificial intelligence and data augmentation for prognostic and health management: Taxonomy, progress, and prospects},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124511},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124511},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013782},
author = {Shen Liu and Jinglong Chen and Yong Feng and Zongliang Xie and Tongyang Pan and Jingsong Xie},
keywords = {Fault diagnosis, Generative artificial intelligence, Data augmentation, Data generation, Prognostics and health management},
abstract = {Intelligent fault diagnosis, detection, and prognostics (DDP) for complex equipment prognostics and health management (PHM) have achieved remarkable breakthroughs. Equipment in industrial scenarios often operates in normal conditions, resulting in missing anomalies, limited failures, and incomplete degradation paths. Thus the limited information on the state of the equipment collected from sensor readings severely hinders the cognitive capabilities of discriminative artificial intelligence (AI) for PHM. Data augmentation and generation (DA&G) techniques, represented by generative AI, have shown great promise in overcoming the limitations of PHM application scenarios. Research on DA&G has yielded significant achievements, but a comprehensive review in the mechanical field is still lacking. To this end, this paper provides a comprehensive review of DA&G techniques aimed at solving the DDP problems, which are divided into three categories insights of data, mechanism, and features. The data-based randomized approach applies controlled randomness for augmentation. The mechanism-based domain-specific techniques advocate for exploring relationships between the physical entity and monitoring data for generating by reasoned inference. The feature-based generative model aims to identify the latent space of data and subsequently resample it. Finally, the paper explores strategies for evaluating DA&G and provides a deep insight into the challenges and opportunities of DA&G techniques.}
}
@article{DAS2025102546,
title = {Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer’s genetic and immune landscape},
journal = {Molecular Therapy Nucleic Acids},
volume = {36},
number = {2},
pages = {102546},
year = {2025},
issn = {2162-2531},
doi = {https://doi.org/10.1016/j.omtn.2025.102546},
url = {https://www.sciencedirect.com/science/article/pii/S2162253125001003},
author = {Arpita Das and Manojit Bhattacharya and Ali Saber Abdelhameed and Sang-Soo Lee and Chiranjib Chakraborty},
keywords = {Bioinformatics, GenAI, single-cell analysis, Alzheimer’s disease, genetic and immune landscape},
abstract = {The research aims to understand Alzheimer’s genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer’s disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8+ T cells (33.42%) and naive T cells (45.95%). The single-cell study found that effector memory T cells have two subsets. It also found that the macrophage population has started to spread and dendritic cells have decreased in Alzheimer’s patients. The single-cell gene expression study reveals the top ten highly expressed genes (NDUFV2, CAT, MRPS34, PBX3, THOC2, CCDC57, PBXIP1, SDHAF3, PPP4C, and MAP3K8). The clonal frequency indicates that CD8+ T and naive T cell populations show the highest clonal frequency in healthy and AD individuals and are further noted them in the clonotype cell proportion study. Following our GenAI and single-cell profiling strategy, future studies will help in quickly understanding the genetic and immune basis of many diseases.}
}
@article{KAPLAN2025106080,
title = {New generative artificial intelligence model: ScholarGPT’s performance on dental avulsion},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106080},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106080},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002977},
author = {Taibe Tokgöz Kaplan},
keywords = {Artificial intelligence, ChatGPT, Dental avulsion, Gemini, Large Language Models, ScholarGPT},
abstract = {Background
This study aims to evaluate the performance of ScholarGPT, a Large Language Model (LLM) developed for academic purposes, on questions related to dental avulsion. In addition, to analyze and compare it with the results of the previous study evaluating the performance of ChatGPT and Gemini.
Method
A total of 22 technical questions (11 multiple-choice questions (MCQs), 11 true/false (T/F)) were posed to the ScholarGPT. ScholarGPT responses were assessed using a modified Global Quality Scale (GQS). Responses were randomized using an online randomizer (www.randomizer.org) before scoring. A single researcher carried out the assessments at three different times, two weeks apart, and a new randomization was performed before each scoring.
Results
When the answers given by ScholarGPT according to the question groups were analyzed by the Mann-Whitney U test, the mean value was found to be 4.64 for MCQ questions and 4.82 for T/F questions. ScholarGPT provided similarly high-quality and consistent answers in both question types (p = 0.590). When the performance of ScholarGPT was compared with Gemini and ChatGPT via the Friedman test, the mean score of ScholarGPT responses was significantly higher than both ChatGPT and Gemini (mean difference with Gemini = 0.75; mean difference with ChatGPT = 1.62, p < 0.001). ScholarGPT produced statistically significantly more consistent and higher-quality responses than ChatGPT and Gemini.
Conclusion
ScholarGPT showed high performance on technical questions related to dental avulsion and produced more consistent and higher-quality answers than ChatGPT and Gemini. According to the findings, LLMs based on academic databases can provide more accurate and reliable information. In the future, through the development of LLMs specific to the branches of dentistry, artificial intelligence systems can produce higher quality and consistent information.}
}
@article{BRITOZERON2025570,
title = {POS0311 SARCOIDOSIS AS A SYSTEMIC DISEASE: IDENTIFYING PATTERNS OF MULTIORGAN-SPECIFIC INVOLVEMENT AND EPIDEMIOLOGICAL PROFILING THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE-DRIVEN CLUSTERING},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {570-571},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.698},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725017315},
author = {P. Brito-Zerón and A. Flores-Chávez and C. Feijoo-Masso and G. Policarpo-Torres and R. {Gómez de la Torre} and B. Escalante and J.M. Lopez-Dupla and C. Soler-i-Ferrer and E. Fonseca-Aizpuru and A. González-García and J.C. Herranz-Pérez and S. {GARCÍA MORILLO} and A. Alguacil and Á. {Robles Marhuenda} and M. Bonet and M.V. Villalba-García and A.J. Chamorro and B. {De Miguel-Campo} and M.G. {CRUZ CAPARROS} and M. {Akasbi Montalvo} and A. Mayer-Fuentes and M. Ramos-Casals},
keywords = {Registries, Artificial Intelligence, Prognostic factors, Epidemiology, Comorbidities},
abstract = {Background:
Sarcoidosis is a heterogeneous granulomatous disease characterized by a wide range of clinical manifestations stemming from multiple organ involvement. While clustering techniques offer a robust method for uncovering these patterns, traditional approaches may fail to fully capture the complexity of multisystem diseases like sarcoidosis. Leveraging generative artificial intelligence (AI) offers a unique opportunity to improve data analysis and interpretation in complex systemic settings, providing novel insights into multifaceted disease patterns and guiding both hypothesis generation and clinical decision-making.
Objectives:
This study aimed to identify distinct clusters of organ involvement in patients with sarcoidosis, assess their corresponding epidemiological characteristics, and highlight the benefits of AI-driven methodologies in handling complex multisystem data—underscoring the feasibility and advantages of advanced AI-based approaches for systemic phenotypes in this heterogeneous disease.
Methods:
We conducted an AI-assisted analysis to identify organ-involvement clusters in a dataset of 2,187 anonymized sarcoidosis patients (Spanish National Registry SarcoGEAS, all fulfilling the 1999 ATS/ERS/WASOG criteria). Organ involvement was retrospectively determined in each patient at the time of diagnosis using the 2014 WASOG organ assessment instrument. Clustering was carried out via the k-means algorithm in Python's scikit-learn library (version 1.0.2). The optimal number of clusters was determined using the elbow method, supported by silhouette scores to evaluate cluster quality. Statistical comparisons (ANOVA, Kruskal-Wallis, and Chi-square tests—using exact tests for low-frequency data) were applied to characterize cluster differences. Significance was set at p < 0.05, ensuring rigorous evaluation of epidemiological and clinical distinctions. The analysis was conducted in a secure computational environment using generative AI (via OpenAI's GPT-4 model) using Python (version 3.9) with essential libraries including pandas (1.4.3) for data manipulation, numpy (1.21.5) for numerical computations, and matplotlib (3.5.1) and seaborn (0.11.2) for visualizations. Data processing and analysis workflows adhered to GDPR standards to ensure patient privacy. All patient data were anonymized prior to analysis, and no identifiable information was accessed at any point. Code modularity and reproducibility were prioritized, with all scripts managed in version control systems (e.g., Git) to enable transparency.
Results:
The cohort comprised 2,187 patients, with a female predominance (61.4%), a mean age at diagnosis of 48.6 years (range: 5-95), and a majority identifying as White (88%). Cluster quality analysis identified 5 as the optimal number of clusters potential; an additional clinically significant cluster (hepatic-splenic) was manually identified and confirmed post hoc through statistical validation. Ultimately, we defined six distinct clusters of systemic involvement: the lymphadenopathic cluster (Cluster 1, characterized by 100% lymphadenopathy), the pulmonary cluster (Cluster 2, characterized by 100% lung involvement and co-occurring 100% lymphadenopathy), the cutaneous cluster (Cluster 3, 100% of cutaneous involvement), the ocular cluster (Cluster 4, 100% ocular involvement), the hepato-splenic cluster (Cluster 5, defined by 100% hepatic and splenic involvement), and the multisystemic cluster (Cluster 6, exhibiting generalized, but not predominant, organ involvement). Each cluster demonstrated statistically significant epidemiological differences (Figure 1). For age, the lymphadenopathic cluster had the highest mean (51.7 years), whereas the cutaneous cluster had the lowest (42.9 years) (p = 0.00056). For sex, the proportion of females ranged from 49.0% in the hepato-splenic cluster to 65.9% in the ocular cluster (p = 0.000017). For ethnicity, the proportion of White patients ranged from 81.4% in the ocular cluster to 94.6% in the lymphadenopathic cluster (p = 0.00135).
Conclusion:
This generative AI-driven clustering study successfully identified six distinct patterns of systemic involvement in sarcoidosis, offering a deeper understanding of the disease's heterogeneity. Each cluster exhibited specific epidemiological profiles: cutaneous cluster was associated with the youngest age at sarcoidosis diagnosis, lymphadenopathic cluster with the oldest age and the highest frequency of White patients, ocular cluster with the highest frequency of women and highest frequency of non-White patients, and the hepato-splenic cluster with the highest rate of men. The significant epidemiological disparities among clusters underscore the disease's variability and offer a framework for refined patient stratification.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{BRITOZERON20252097,
title = {ABS0885 COMPLEMENT CONSUMPTION PATTERNS AS AN EARLY PREDICTOR OF SYSTEMIC SJÖGREN DISEASE: GENERATIVE ARTIFICIAL INTELLIGENCE-ASSISTED ANALYSIS USING STRATIFIED CROSS-VALIDATION GENERALIZABILITY MODELS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2097-2098},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1702},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037550},
author = {P. Brito-Zerón and A. Flores-Chávez and L.T. {Delgado Garcia} and I.F. Horváth and R. Priori and H. Bootsma and B. Armagan and V. Manfrè and S. Praprotnik and G. Hernandez-Molina and R. {Pereira da Costa} and R. Gerli and M. Rischmueller and Y. Suzuki and R. Solans-Laqué and S. Pasoto and E. Skoglund and I. Sanchez-Berna and A. Alunno and V. {Fernandes Moça Trevisani} and V. Valim and S. {Melchor Díaz} and B. {Maure Noia} and E. Fonseca-Aizpuru and H. Nakamura and L.D. Miguel and M. Vázquez and M. {Akasbi Montalvo} and G. Policarpo-Torres and B. {De Miguel-Campo} and A. Szántó and A. Gattamelata and A. Vissink and L. Quartuccio and L. Kiliç and K. Perdan-Pirkmajer and V.C. Romão and E. Bartoloni and S. Downie-Doyle and Y. Fujisawa and M. Ramos-Casals},
keywords = {Validation, Artificial Intelligence},
abstract = {Background:
Complement consumption, characterized by decreased C3 and/or C4 levels, is a hallmark of immune complex-mediated inflammation and vascular involvement in patients with systemic autoimmune diseases. In patients with Sjögren Disease (SjD), hypocomplementemia at diagnosis has been mainly linked to an increased risk of lymphoma. By analysing the relationship between complement consumption profiles and systemic activity in the largest international cohort, we aim to refine early prognostic paradigms and inform tailored clinical surveillance strategies in SjD, thereby addressing a critical gap in precision medicine for this complex autoimmune disease.
Objectives:
The objectives of this study were to identify and classify complement consumption patterns, investigate their association with an early phenotype consisting of systemic activity across ESSDAI domains while adjusting for age and gender, and explore how cross-validation techniques may validate the predictive accuracy and generalizability of developed models.
Methods:
This study analyzed data from the International Sjögren Big Data Registry. Patients were categorized into four distinct groups according to their complement consumption patterns (isolated low C3, isolated low C4, combined low C3 and C4, and normal C3 and C4 levels). We used Chi-square tests to evaluate univariate associations, and Kruskal-Wallis H-test and Mann-Whitney U test to investigate significant differences with respect to systemic activity (mean ESSDAI score and DAS categories). Multivariable logistic regression models were developed to analyze associations between complement patterns and ESSDAI domains, adjusting for age and gender. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated. A five-fold stratified cross-validation was carried out to rigorously evaluate the models' generalizability, with the Area Under the Curve (AUC) serving as the primary performance metric. Generative Artificial Intelligence (AI) (ChatGPT-4o model) was used within a secure offline environment to automate anonymized data recoding and statistical scripting. Python libraries, including pandas, statsmodels, and scikit-learn, were integral for data processing, model development, and cross-validation.
Results:
Complement values determined at diagnosis were available in 13,710 patients. Stratification according to the 4 complement consumption patterns identified that 79.58% of patients had normal levels of C3 and C4, 7.42% exhibited isolated low C3, 6.90% showed isolated low C4, and 6.09% presented combined low C3 and C4 levels. Combined low C3-C4 levels exhibited the highest mean ESSDAI score (11.41), follwed by isolated low C3, isolated low C4 and normocomplementemia (mean ESSDAI score of 9.26, 7.39, and 5.66, respectively) (Figure 1); Kruskal-Wallis H-test revealed a highly significant difference between the groups (p<0.001), as well as pairwise comparisons using the Mann-Whitney U test (p<0.001). The Chi-square test revealed significant differences in the distribution of DAS categories across the C3-C4 combined groups (χ2=476.41, p<0.001) (Figure 2). However, multivariate logistic regression confirmed significant associations in only three domains. For the pulmonary domain, combined low C3 and C4 levels were associated with the highest odds of activity (OR: 3.12, 95% CI: 2.50–3.91, p < 0.001; AUC: 0.591). In the biological domain, isolated low C3 strongly correlated with activity (OR: 2.45, 95% CI: 1.98–3.03, p < 0.001; AUC: 0.580). For constitutional symptoms, isolated low C3 was associated with the highest activity frequency (18.54%), whereas normal complement levels showed the lowest frequency (11.06%, OR: 0.56, 95% CI: 0.48–0.67, p < 0.001; AUC: 0.563). After adjusting for epidemiological factors, sex and age emerged as influential variables: men had higher odds of constitutional activity (OR 1.24, 95% CI: 1.02–1.52, p = 0.03), while older age had a protective effect, reducing systemic activity by about 1% per year (OR: 0.99, 95% CI: 0.99–1.00, p = 0.0003). The AUC values obtained after running the five-fold stratified cross-validation generalizability models ranged between 0.56 and 0.59, indicating modest ability to discriminate between active and inactive states.
Conclusion:
This study demonstrates that complement consumption patterns are strongly associated with baseline systemic activity in SjD, highlighting their potential as early prognostic markers. While complement patterns provide valuable insights for risk stratification, the current predictive models exhibit modest discriminatory ability (AUC values between 0.5 and 0.6), suggesting that complement patterns are relevant but insufficient alone as predictors to improve clinical applicability. The nuanced influence of epidemiological factors—such as the protective effect of age and the increased susceptibility of men to systemic disease—adds complexity to our understanding of early systemic Sjögren.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{ZHU2024114132,
title = {OpenAI’s GPT-4o in surgical oncology: Revolutionary advances in generative artificial intelligence},
journal = {European Journal of Cancer},
volume = {206},
pages = {114132},
year = {2024},
issn = {0959-8049},
doi = {https://doi.org/10.1016/j.ejca.2024.114132},
url = {https://www.sciencedirect.com/science/article/pii/S0959804924007883},
author = {Ning Zhu and Nan Zhang and Qipeng Shao and Kunming Cheng and Haiyang Wu}
}
@article{BAGENAL20241118,
title = {Generative artificial intelligence and scientific publishing: urgent questions, difficult answers},
journal = {The Lancet},
volume = {403},
number = {10432},
pages = {1118-1120},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)00416-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624004161},
author = {Jessamy Bagenal}
}
@article{MARTIN2024100265,
title = {Navigating the data frontier in science assessment: Advancing data augmentation strategies for machine learning applications with generative artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100265},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000687},
author = {Paul P. Martin and Nicole Graulich},
keywords = {Assessment, Large language models (LLMs), Machine learning (ML), Data augmentation, Science education},
abstract = {Machine learning (ML) techniques are commonly seen as an inductive learning procedure, typically involving the identification of patterns in a specific training dataset to make predictions in novel contexts. By doing so, the performance and generalizability of these techniques often rely on the quality and quantity of the available training data. However, gathering a diverse training dataset that captures multiple nuances of students’ reasoning poses challenges in educational settings due to resource constraints. We compared three data augmentation strategies to address this issue: collecting additional student data, utilizing chatbots to paraphrase existing responses, and prompting chatbots to generate synthetic responses. We found that leveraging data augmentation significantly improved ML model performance. In detail, combining authentic and/or paraphrased responses with chatbot responses yielded the best machine-human score agreements across various validation conditions. This data augmentation allowed us to expand our applied scoring rubric by introducing a more detailed categorization that better captured the level of causality in undergraduate chemistry students’ reasoning about reaction mechanisms. Together, these findings highlight effective possibilities for augmenting the size and heterogeneity of the training data to improve ML model performance and generalizability, introduce a more fine-grained categorization, and reduce human effort in data collection. In the future, these benefits may enhance the scalability of formative assessments that adaptively support students’ reasoning in postsecondary chemistry classes.}
}
@article{KHOSRAVI2024101503,
title = {Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity},
journal = {Arthroplasty Today},
volume = {29},
pages = {101503},
year = {2024},
issn = {2352-3441},
doi = {https://doi.org/10.1016/j.artd.2024.101503},
url = {https://www.sciencedirect.com/science/article/pii/S2352344124001882},
author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J. Erickson and Hillary W. Garner and Doris E. Wenger and Michael J. Taunton and Cody C. Wyles},
keywords = {Generative AI, Explainability, Dataset curation, Equity, Bias},
abstract = {Background
Discrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.
Methods
Utilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fréchet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that showed transforming White pelvises to their closest African American counterparts and vice versa while controlling for patients’ sex, age, and body mass index. Two expert surgeons and 2 radiologists carefully studied these videos to understand the systematic differences that are present in the 2 races’ radiographs.
Results
Our data set included 480,407 pelvic radiographs, with a predominance of White patients over African Americans. The generative denoising diffusion probabilistic model created high-quality images and reached an Fréchet Inception Distance of 6.8. Experts identified 6 characteristics differentiating races, including interacetabular distance, osteoarthritis degree, obturator foramina shape, femoral neck-shaft angle, pelvic ring shape, and femoral cortical thickness.
Conclusions
This study demonstrates the potential of generative models for understanding disparities in medical imaging data sets. By visualizing race-based differences, this method aids in identifying bias in downstream tasks, fostering the development of fairer healthcare practices.}
}
@article{GLYNN2024596,
title = {Suspected undeclared use of generative artificial intelligence},
journal = {Intelligent Pharmacy},
volume = {2},
number = {5},
pages = {596-597},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000492},
author = {Alex Glynn},
keywords = {Generative artificial intelligence, Transparency, Accountability},
abstract = {In a recent article in Intelligent Pharmacy, a portion of the text appears to have been generated by a generative artificial intelligence (AI) system. The usage of AI is not documented in the article. If AI was used, therefore, the article is in violation of the journal's policy on generative AI use and declaration.}
}
@article{SHASTRI20247668,
title = {Use of Generative Artificial Intelligence for Development of Plain Language Summaries: A Blinded Assessment of Education Preferences of the Sickle Cell Disease Community},
journal = {Blood},
volume = {144},
pages = {7668},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-206965},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124104934},
author = {Oliver Shastri and Orlando Agrippa and Valerie Moss and Eleanor Millard and Lianne More and Eleanor Rose Brown and Seraj Sharif and Chris Finch},
abstract = {Introduction: Sickle cell disease (SCD) is an inherited condition that reduces life expectancy and has a profound impact on quality of life. Assessment of social media conversations in the SCD community in the UK highlighted health inequities, including issues with access to emergency care, low levels of healthcare professional empathy, and racial bias/stigmatization (Shastri O, et al. ASH 2023; abstract 1057). This emphasizes the urgent unmet need for additional education. Use of generative artificial intelligence (GenAI) to facilitate the development of medical content, including plain language summaries (PLS) of research may increase efficiency, reduce resource cost and ultimately improve accessibility to educational information across a range of audiences. We assessed the ability of GenAI to develop a PLS of our social media listening study. Methods: We developed 3 written versions of a PLS of this study: human-written by a medical writer, AI-generated, and hybrid AI-human, where a person living with SCD edited the AI version for readability. Each was ~300-400 words and with a target reading age of 12 years. The AI PLS was developed using Pfizer's GenAI tool, MAIA (Medical AI assistant). A video version of each written PLS was developed using the AI tool, Synthesia. People with SCD and their carers (≥18 years of age) were recruited via telephone to complete an online survey to assess the understandability of the 3 written PLS and preference for written versus video PLS. Participants were presented with 1 of the 3 written PLS at random and asked to assess how easily they understood it on a 5-point scale (1=very difficult; 2=difficult; 3=neither difficult nor easy; 4=easy; 5=very easy). They were then asked 3 multiple-choice questions to gauge their understanding. Participants then rated the other 2 written PLS and were asked to rank all 3 in order of most easily understood. Finally, participants watched the video version of their top-rated written PLS and stated which format they preferred. Participants were blinded to PLS source. The Flesch-Kincaid calculator (https://goodcalculators.com/flesch-kincaid-calculator/) was used to provide an objective measure of readability for each PLS. Results: Of 93 participants, there were 88 living with SCD and 5 caring for someone with SCD. The AI versions of the PLS achieved similar scores for understandability to the human-written version: mean ± standard deviation understandability scores were 4.1 ± 0.9 (human), 4.0 ± 0.9 (AI), and 3.9 ± 0.8 (AI-hybrid). Overall, 81% of participants identified the human PLS as easy or very easy to read, similar to 76% for the AI PLS, and 74% for the AI-hybrid PLS. Overall, 41 participants (44%) ranked the human PLS in first place for understandability, 31 (33%) the AI PLS, and 21 (23%) the AI-hybrid PLS. For the multiple-choice questions, results were similar regardless of which PLS participants saw first, with over 85% correctly identifying the main findings of the study and the conclusions of the author; however, 63% incorrectly thought the data on which the PLS was based were obtained from interviewing people affected by SCD rather than social media listening. Fifty-four participants (58%) preferred the video PLS over the written PLS, 27 participants (29%) preferred the written PLS and 12 (13%) had no preference. Flesch-Kincaid scores for the three PLS were as follows: human (reading ease score, 62; reading level, 8th to 9th grade); AI (reading ease score, 58; reading level, 10th to 12th grade); AI-hybrid (reading ease score, 63; reading level, 8th to 9th grade). Conclusion: There is a clear need for additional resources and education in SCD, which may be supported by the development of PLS. The limited studies that have assessed the capabilities of AI to generate PLS to date have focussed on clinical research. We have now expanded this to assess use of AI to develop PLS from a social media listening study that evaluated real-world experiences of the UK SCD community. Our study suggests that GenAI can generate PLS that are as informative as conventional, human-written PLS, and achieve similar readability scores as judged by people living with SCD in the UK (mean 4.1 for human-written, 4.0 for AI and 3.9 for AI-hybrid). We propose that GenAI may offer an alternative to conventional human-written PLS, providing a time- and resource-efficient solution to increase accessibility to educational resources.}
}
@article{BAKER2024101054,
title = {Student Perceptions of Generative Artificial Intelligence in Didactic Patient Presentations},
journal = {American Journal of Pharmaceutical Education},
volume = {88},
number = {9},
pages = {101054},
year = {2024},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2024.101054},
url = {https://www.sciencedirect.com/science/article/pii/S0002945924107735},
author = {Carrie N. Baker and Jordan Powe and Sophia Jones and Emily Ghassemi and Riley Bowers}
}
@article{KHENE2024160,
title = {Development of a Personalized Chat Model Based on the European Association of Urology Oncology Guidelines: Harnessing the Power of Generative Artificial Intelligence in Clinical Practice},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {160-162},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001396},
author = {Zine-Eddine Khene and Pierre Bigot and Romain Mathieu and Morgan Rouprêt and Karim Bensalah}
}
@article{DHAWAN202447,
title = {Generative artificial intelligence in surgery: balancing innovation with ethical challenges},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {90},
pages = {47-48},
year = {2024},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2024.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1748681524000731},
author = {Ravi Dhawan and Akshay Nair and Denys Shay}
}
@article{HEINKE2024100089,
title = {A review of ophthalmology education in the era of generative artificial intelligence},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100089},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100089},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000902},
author = {Anna Heinke and Niloofar Radgoudarzi and Bonnie B. Huang and Sally L. Baxter},
keywords = {Generative AI, Large Language Models (LLMs), Ophthalmology Education, Artificial Intelligence (AI)},
abstract = {Purpose
To explore the integration of generative AI, specifically large language models (LLMs), in ophthalmology education and practice, addressing their applications, benefits, challenges, and future directions.
Design
A literature review and analysis of current AI applications and educational programs in ophthalmology.
Methods
Analysis of published studies, reviews, articles, websites, and institutional reports on AI use in ophthalmology. Examination of educational programs incorporating AI, including curriculum frameworks, training methodologies, and evaluations of AI performance on medical examinations and clinical case studies.
Results
Generative AI, particularly LLMs, shows potential to improve diagnostic accuracy and patient care in ophthalmology. Applications include aiding in patient, physician, and medical students’ education. However, challenges such as AI hallucinations, biases, lack of interpretability, and outdated training data limit clinical deployment. Studies revealed varying levels of accuracy of LLMs on ophthalmology board exam questions, underscoring the need for more reliable AI integration. Several educational programs nationwide provide AI and data science training relevant to clinical medicine and ophthalmology.
Conclusions
Generative AI and LLMs offer promising advancements in ophthalmology education and practice. Addressing challenges through comprehensive curricula that include fundamental AI principles, ethical guidelines, and updated, unbiased training data is crucial. Future directions include developing clinically relevant evaluation metrics, implementing hybrid models with human oversight, leveraging image-rich data, and benchmarking AI performance against ophthalmologists. Robust policies on data privacy, security, and transparency are essential for fostering a safe and ethical environment for AI applications in ophthalmology.}
}
@article{PILLAI2023100213,
title = {Accuracy of generative artificial intelligence models in differential diagnoses of familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist},
journal = {Journal of Translational Autoimmunity},
volume = {7},
pages = {100213},
year = {2023},
issn = {2589-9090},
doi = {https://doi.org/10.1016/j.jtauto.2023.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2589909023000266},
author = {Joshua Pillai and Kathryn Pillai},
keywords = {DIRA, Deficiency of Interleukin-1 receptor antagonist, Familial Mediterranean fever, FMF, Artificial intelligence},
abstract = {With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases.}
}
@article{HYUNBAEK2023102030,
title = {Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence},
journal = {Telematics and Informatics},
volume = {83},
pages = {102030},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102030},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000941},
author = {Tae {Hyun Baek} and Minseong Kim},
keywords = {ChatGPT, Generative artificial intelligence (AI), Uses and gratifications theory, Creepiness, Trust, Continuance intention},
abstract = {Few studies have examined user motivations to use generative artificial intelligence (AI). This research aims to address this gap by examining how user motivations for ChatGPT usage affect perceived creepiness, trust, and the intention to continue using AI chatbot technology. The findings of an online survey (N = 421) reveal a negative relationship between personalization and creepiness, while task efficiency and social interaction are positively associated with creepiness. Increased levels of creepiness, in turn, result in decreased continuance intention. Furthermore, task efficiency and personalization have a positive impact on trust, leading to increased continuance intention. The results contribute to the field of human–computer interaction by investigating the motivations for utilizing generative AI chatbots and advancing our comprehension of AI creepiness, trust, and continuance intention. The practical ramifications of this research can inform the design of user interfaces and the development of features for generative AI chatbots.}
}
@article{PATEL2024105791,
title = {Generative artificial intelligence versus clinicians: Who diagnoses multiple sclerosis faster and with greater accuracy?},
journal = {Multiple Sclerosis and Related Disorders},
volume = {90},
pages = {105791},
year = {2024},
issn = {2211-0348},
doi = {https://doi.org/10.1016/j.msard.2024.105791},
url = {https://www.sciencedirect.com/science/article/pii/S2211034824003687},
author = {Mahi A. Patel and Francisco Villalobos and Kevin Shan and Lauren M. Tardo and Lindsay A. Horton and Peter V. Sguigna and Kyle M. Blackburn and Shanan B. Munoz and Tatum M. Moog and Alexander D. Smith and Katy W. Burgess and Morgan McCreary and Darin T. Okuda},
keywords = {Multiple sclerosis, Artificial intelligence, ChatGPT, Diagnosis, Generative AI},
abstract = {Background
Those receiving the diagnosis of multiple sclerosis (MS) over the next ten years will predominantly be part of Generation Z (Gen Z). Recent observations within our clinic suggest that younger people with MS utilize online generative artificial intelligence (AI) platforms for personalized medical advice prior to their first visit with a specialist in neuroimmunology. The use of such platforms is anticipated to increase given the technology driven nature, desire for instant communication, and cost-conscious nature of Gen Z. Our objective was to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in individuals earlier than their clinical timeline, and to assess if the accuracy differed based on age, sex, and race/ethnicity.
Methods
People with MS between 18 and 59 years of age were studied. The clinical timeline for people diagnosed with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). Chats were conducted using both actual and derivatives of their age, sex, and race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was estimated for time to diagnosis, clustered by subject. The p-value testing for differences in time to diagnosis was accomplished using a general Wilcoxon test. Logistic regression (subject-specific intercept) was used to capture intra-subject correlation to test the accuracy prior to and after the inclusion of MRI data.
Results
The study cohort included 100 unique people with MS. Of those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a total of 529 people that represented digital simulations of the original cohort of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing for 629 scripted conversations to be analyzed. The estimated median time to diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no difference in the diagnostic accuracy between ages and by race/ethnicity prior to the inclusion of MRI data. However, prior to including the MRI data, males had a 47% less likely chance of a correct diagnosis relative to females (p=0.05). Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 4.0-fold greater for Gen Z participants, relative to non-Gen Z participants (p=0.01) with the diagnostic accuracy being 68% less in males relative to females (p=0.009), and 75% less for White subjects, relative to non-White subjects (p=0.0004).
Conclusion
Although generative AI platforms enable rapid information access and are not principally designed for use in healthcare, an increase in use by Gen Z is anticipated. However, the obtained responses may not be generalizable to all users and bias may exist in select groups.}
}
@article{WINNIFRITH2024102794,
title = {Generative artificial intelligence for de novo protein design},
journal = {Current Opinion in Structural Biology},
volume = {86},
pages = {102794},
year = {2024},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2024.102794},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X24000216},
author = {Adam Winnifrith and Carlos Outeiral and Brian L. Hie},
abstract = {Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called ‘de novo’ design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example, in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.}
}
@article{MATSUBARA2025172,
title = {Research misconduct: Use of generative artificial intelligence in writing may lower the threshold},
journal = {European Journal of Obstetrics & Gynecology and Reproductive Biology},
volume = {304},
pages = {172-173},
year = {2025},
issn = {0301-2115},
doi = {https://doi.org/10.1016/j.ejogrb.2024.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S030121152400650X},
author = {Shigeki Matsubara and Daisuke Matsubara}
}
@article{MACKENZIE20239,
title = {Surprising Advances in Generative Artificial Intelligence Prompt Amazement—and Worries},
journal = {Engineering},
volume = {25},
pages = {9-11},
year = {2023},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2023.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095809923001613},
author = {Dana Mackenzie}
}
@article{MAY2024155,
title = {Would Uro_Chat, a Newly Developed Generative Artificial Intelligence Large Language Model, Have Successfully Passed the In-Service Assessment Questions of the European Board of Urology in 2022?},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {155-156},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001785},
author = {Matthias May and Katharina Körner-Riffard and Martin Marszalek and Klaus Eredics}
}
@article{HUESO2023309,
title = {Is Generative Artificial Intelligence the Next Step Toward a Personalized Hemodialysis?},
journal = {Revista de Investigación Clínica},
volume = {75},
number = {6},
pages = {309-317},
year = {2023},
issn = {0034-8376},
doi = {https://doi.org/10.24875/RIC.23000162},
url = {https://www.sciencedirect.com/science/article/pii/S0034837625001597},
author = {Miguel Hueso and Rafael Álvarez and David Marí and Vicent Ribas-Ripoll and Karim Lekadir and Alfredo Vellido},
keywords = {Personalized hemodialysis, Artificial intelligence, Natural language processing, Large Language Models},
abstract = {ABSTRACT
Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI’s chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients’ lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients’ engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients’ care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists’ collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients’ quality of life. (REV INVEST CLIN. 2023;75(6):309-17)}
}
@article{WOBST2025115571,
title = {Avoiding algorithm errors in textual analysis: A guide to selecting software, and a research agenda toward generative artificial intelligence},
journal = {Journal of Business Research},
volume = {199},
pages = {115571},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115571},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325003947},
author = {Janice Wobst and Rainer Lueg},
keywords = {Generative AI, Large language models, Textual analysis, Software selection, Algorithm error, Validity, Reliability, Value-based management},
abstract = {The use of textual analysis is expanding in organizational research, yet software packages vary in their compatibility with complex constructs. This study helps researchers select suitable tools by focusing on phrase-based dictionary methods. We empirically evaluate four software packages—LIWC, DICTION, CAT Scanner, and a custom Python tool—using the complex construct of value-based management as a test case. The analysis shows that software from the same methodological family produces highly consistent results, while popular but mismatched tools yield significant errors such as miscounted phrases. Based on this, we develop a structured selection guideline that links construct features with software capabilities. The framework enhances construct validity, supports methodological transparency, and is applicable across disciplines. Finally, we position the approach as a bridge to AI-enabled textual analysis, including prompt-based workflows, reinforcing the continued need for theory-grounded construct design.}
}
@article{COLBRAN2023105008,
title = {Generative artificial intelligence in Journal of Biological Chemistry},
journal = {Journal of Biological Chemistry},
volume = {299},
number = {8},
pages = {105008},
year = {2023},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2023.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0021925823020367},
author = {Roger J. Colbran and Alex Toker}
}
@article{KSHETRI2024102716,
title = {Generative artificial intelligence in marketing: Applications, opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {75},
pages = {102716},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102716},
url = {https://www.sciencedirect.com/science/article/pii/S026840122300097X},
author = {Nir Kshetri and Yogesh K. Dwivedi and Thomas H. Davenport and Niki Panteli},
keywords = {ChatGPT, Customer engagement, Customer experience, Generative AI, Personalization},
abstract = {While all functional areas in organizations are benefiting from the recent development in generative artificial intelligence (GAI), marketing has been particularly affected positively by this breakthrough innovation. However, scholars have not paid attention to the transformative impacts GAI has on marketing activities. This editorial article aims to fill this void. It outlines the current state of generative artificial intelligence in marketing. The article discusses the facilitators and barriers for the use of generative artificial intelligence in marketing. It highlights the effectiveness of insights generated by GAI in personalizing content and offerings and argues that marketing content generated by GAI is likely to be more personally relevant than that produced by earlier generations of digital technologies. The article explains how higher efficiency and productivity of marketing activities can be achieved by using GAI to create marketing content. It also describes the roles of insights and marketing content generated by GAI to improve the sales lead generation process. Implications for research, practice and policy are also discussed.}
}
@article{SALMAN2024S776,
title = {ID: 4120624 Building Patient Archetypes to Analyze Willingness to Change using New Technologies: Generative Artificial Intelligence with the Goal of More Optimally Influencing Change in Patient Behaviors with Atrial Fibrillation},
journal = {Heart Rhythm},
volume = {21},
number = {9, Supplement },
pages = {S776-S777},
year = {2024},
note = {HRX AbstracX 2024},
issn = {1547-5271},
doi = {https://doi.org/10.1016/j.hrthm.2024.07.043},
url = {https://www.sciencedirect.com/science/article/pii/S1547527124029904},
author = {S. Salman and I. Tripuraneni and K. Lingineni and A. Vemulapalli and S. Venigalla and A. Tripuraneni}
}
@article{RICHTER2023385,
title = {Foot and Ankle Surgery declares use of generative artificial intelligence like Chat Generative Pre-trained Transformer (ChatGPT) for scientific publications},
journal = {Foot and Ankle Surgery},
volume = {29},
number = {5},
pages = {385-386},
year = {2023},
issn = {1268-7731},
doi = {https://doi.org/10.1016/j.fas.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1268773123000802},
author = {Martinus Richter}
}
@article{WALTERS2024S626,
title = {SA62 Evaluating Generative Artificial Intelligence (GenAI) in Health Technology Assessment (HTA) Content Generation: A Proof-of-Concept Using Canadian Agency for Drugs and Technologies in Health (CADTH) Reimbursement Dossier Forms},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S626},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3143},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524060066},
author = {J. Walters and I. Guerra and K. Rtveladze and J. Joseph and R. Shankar and T. Wiemken and P.A. Dubé and T.C. Woodward}
}
@article{KOHNKE2023100156,
title = {Exploring generative artificial intelligence preparedness among university language instructors: A case study},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100156},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000358},
author = {Lucas Kohnke and Benjamin Luke Moorhouse and Di Zou},
keywords = {Artificial intelligence, AI, Generative AI, University language instructors, Higher education, English},
abstract = {The integration of generative artificial intelligence (AI) in English language teaching presents opportunities and challenges for instructors. This study explores the attitudes of higher education English language instructors towards generative AI tools, their intentions to use them and the institutional support and professional development necessary to teach and learn with them. As the field continues to evolve rapidly, it is essential to comprehend the readiness of front-line language instructors. This qualitative interpretive study seeks to identify the digital competencies and pedagogical knowledge required to implement generative AI in education and provide guidance for the design of professional development programmes that address the challenges and concerns associated with adopting AI. Drawing on semi-structured interviews with twelve instructors at a higher education institution in Hong Kong, the findings reveal the significance of familiarity and confidence with using AI-driven teaching tools, the challenges and concerns language instructors face and the need for tailored support and professional development. The study offers ten practical implications to cultivate language instructors’ digital competencies, pedagogical knowledge and positive attitudes towards integrating AI to enhance their students’ learning experiences.}
}