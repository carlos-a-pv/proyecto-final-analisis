@article{CHIOSA2024114802,
title = {A portable application framework for energy management and information systems (EMIS) solutions using Brick semantic schema},
journal = {Energy and Buildings},
volume = {323},
pages = {114802},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114802},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824009186},
author = {Roberto Chiosa and Marco Savino Piscitelli and Marco Pritoni and Alfonso Capozzoli},
keywords = {Energy management and information systems, Portable application, Brick metadata schema, Anomaly detection, Machine learning},
abstract = {This paper introduces a portable framework for developing, scaling and maintaining energy management and information systems (EMIS) applications using an ontology-based approach. Key contributions include an interoperable layer based on Brick schema, the formalization of application constraints pertaining metadata and data requirements, and a field demonstration. The framework allows for querying metadata models, fetching data, preprocessing, and analyzing data, thereby offering a modular and flexible workflow for application development. Its effectiveness is demonstrated through a case study involving the development and implementation of a data-driven anomaly detection tool for the photovoltaic systems installed at the Politecnico di Torino, Italy. During eight months of testing, the framework was used to tackle practical challenges including: (i) developing a machine learning-based anomaly detection pipeline, (ii) replacing data-driven models during operation, (iii) optimizing model deployment and retraining, (iv) handling critical changes in variable naming conventions and sensor availability (v) extending the pipeline from one system to additional ones.}
}
@article{MENG2025104166,
title = {Personal information organization literacy in the academic context: Scale development, performance assessment, and influence exploration},
journal = {Information Processing & Management},
volume = {62},
number = {5},
pages = {104166},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104166},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001074},
author = {Gaohui Meng and Chang Liu},
keywords = {Personal information management, Information literacy, Scale development and validation, Learning performance, Academic procrastination},
abstract = {Personal information management literacy (PIML) is a literacy that has been increasingly valued and highlighted in the emerging knowledge society, yet the related research is insufficient. This study focuses on personal information organization literacy (PIOL) as an essential component of PIML, examining its measurement, assessment, and influence in the academic context. We conducted two linked studies to address the research questions. In Study 1, we developed a scale to measure PIOL in the academic context through three phases: generating a sample of items, exploring the factorial structure, and examining the reliability and validity. In Study 2, based on the developed scale, we assessed the performance of college students in PIOL and explored the influence of PIOL on their learning performance. The results indicate that PIOL in the academic context is a five-dimensional construct. There is a gap between college students’ real performance and the ideal level of PIOL in the academic context, and their PIOL performance differ significantly, allowing them to be categorized into four groups. Moreover, it is verified that college students’ PIOL has a beneficial effect on their learning performance, including mitigating procrastination, alleviating passive procrastination, and elevating academic grades. This study takes a pioneering step in measuring PIOL and discovering its effect, with the potential to inspire educators to incorporate more PIOL elements into information literacy standards and to define PIOL education.}
}
@article{HARMS2024114364,
title = {Dark clouds on the horizon: Dark personality traits and the frontiers of the entrepreneurial economy},
journal = {Journal of Business Research},
volume = {171},
pages = {114364},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114364},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323007233},
author = {P.D. Harms and Joshua V. White and Tyler N.A. Fezzey},
keywords = {Dark personality, Gig economy, Remote work, Dark triad, Entrepreneurship, Self-employment},
abstract = {Recent developments in technology and shifting societal patterns threaten to upend norms surrounding the world of work. The present paper introduces the idea of an emerging entrepreneurial economy and describes how it is reshaping our understanding of work, provides a framework for understanding whether and why individuals with dark personality traits may be attracted to careers in this new occupational frontier. Specifically, we will discuss how dark traits shape interest in remote work, the gig economy, social media and podcasting careers, and occupations related to cryptocurrencies, blockchain technologies, and crowdfunding. We also note how technologies enhanced by artificial intelligence (AI) might contribute to uncertainty concerning how individuals with dark traits may function in these vocational contexts. We finish by making arguments for how future research can be improved in order to attain a more comprehensive understanding of dark personality in the entrepreneurial economy.}
}
@article{MUNUZURI202264,
title = {Unified representation of Life's basic properties by a 3-species Stochastic Cubic Autocatalytic Reaction-Diffusion system of equations},
journal = {Physics of Life Reviews},
volume = {41},
pages = {64-83},
year = {2022},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2022.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1571064522000185},
author = {Alberto P. Muñuzuri and Juan Pérez-Mercader},
keywords = {Living systems, Turing instability, Top-down approach, Bottom-up approach, Non-linear reaction-diffusion equations, Properties of life},
abstract = {Today we can use physics to describe in great detail many of the phenomena intervening in the process of life. But no analogous unified description exists for the phenomenon of life itself. In spite of their complexity, all living creatures are out of equilibrium chemical systems sharing four fundamental properties: they (1) handle information, (2) metabolize, (3) self-reproduce and (4) evolve. This small number of features, which in terran life are implemented with biochemistry, point to an underlying simplicity that can be taken as a guide to motivate and implement a theoretical physics style unified description of life using tools from the non-equilibrium physical-chemistry of extended systems. Representing a system with general rules is a well stablished approach to model building and unification in physics, and we do this here to provide an abstract mathematical description of life. We start by reviewing the work of previous authors showing how the properties in the above list can be individually represented with stochastic reaction-diffusion kinetics using polynomial reaction terms. These include “switches” and computation, the kinetic representation of autocatalysis, Turing instability and adaptation in the presence of both deterministic and stochastic environments. Thinking of these properties as existing on a space-time lattice each of whose nodes are subject to a common mass-action kinetics compatible with the above, leads to a very rich dynamical system which, just as natural life, unifies the above properties and can therefore be interpreted as a high level or “outside-in” theoretical physics representation of life. Taking advantage of currently available advanced computational techniques and hardware, we compute the phase plane for this dynamical system both in the deterministic and stochastic cases. We do simulations and show numerically how the system works. We review how to extract useful information that can be mapped into emergent physical phenomena and attributes of importance in life such as the presence of a “membrane” or the time evolution of an individual system's negentropy or mass. Once these are available, we illustrate how to perform some basic phenomenology based on the model's numerical predictions. Applying the above to the idealization of the general Cell Division Cycle (CDC) given almost 25 years ago by Hunt and Murray, we show from the numerical simulations how this system executes a form of the idealized CDC. We also briefly discuss various simulations that show how other properties of living systems such as migration towards more favorable regions or the emergence of effective Lotka-Volterra populations are accounted for by this general and unified view from the “top” of the physics of life. The paper ends with some discussion, conclusions, and comments on some selected directions for future research. The mathematical techniques and powerful simulation tools we use are all well established and presented in a “didactical” style. We include a very rich but concise SI where the numerical details are thoroughly discussed in a way that anyone interested in studying or extending the results would be able to do so.}
}
@article{LV2025113417,
title = {MDF-FND: A dynamic fusion model for multimodal fake news detection},
journal = {Knowledge-Based Systems},
volume = {317},
pages = {113417},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113417},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125004642},
author = {Hongzhen Lv and Wenzhong Yang and Yabo Yin and Fuyuan Wei and Jiaren Peng and Haokun Geng},
keywords = {Fake news detection, Dynamic fusion, Dempster–Shafer evidence theory, Information fusion},
abstract = {Fake news detection has received increasing attention from researchers in recent years, especially in the area of multimodal fake news detection involving both text and images. However, many previous studies have simply fed the semantic features of both text and image modalities into a binary classifier after applying basic concatenation or attention mechanisms, where these features often contain a significant amount of inherent noise. This, in turn, leads to both intra- and inter-modal uncertainty. In addition, while methods based on simple concatenation of the two modalities have achieved notable results, they often ignore the drawback of applying fixed weights across modalities, which causes some high-impact features to be ignored. To address these issues, we propose a novel semantic-level multimodal dynamic fusion framework for fake news detection (MDF-FND). To the best of our knowledge, this is the first attempt to develop a dynamic fusion framework for semantic-level multimodal fake news detection. Specifically, our model consists of two main components: (1) the Uncertainty Estimation Module (UEM), which is an uncertainty modeling module that uses a multi-head attention mechanism to model intra-modal uncertainty, and (2) the Dynamic Fusion Network, which is based on Dempster–Shafer evidence theory (DFN) and is designed to dynamically integrate the weights of both text and image modalities. To further enhance the dynamic fusion framework, a graph attention network is employed for inter-modal uncertainty modeling before DFN. Extensive experiments have demonstrated the effectiveness of our model across three datasets, with a performance improvement of up to 4% on the Twitter dataset, achieving state-of-the-art performance. We also conducted a systematic ablation study to gain insights into our motivation and architectural design. Our model is publicly available at https://github.com/CoisiniStar/MDF-FND.}
}
@article{FAMTA202530,
title = {Despicable role of epithelial–mesenchymal transition in breast cancer metastasis: Exhibiting de novo restorative regimens},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {1},
pages = {30-47},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000016},
author = {Paras Famta and Saurabh Shah and Biswajit Dey and Kondasingh Charan Kumar and Deepkumar Bagasariya and Ganesh Vambhurkar and Giriraj Pandey and Anamika Sharma and Dadi A. Srinivasarao and Rahul Kumar and Santosh Kumar Guru and Rajeev Singh Raghuvanshi and Saurabh Srivastava},
keywords = {Breast cancer, Epithelial-to-mesenchymal transition, Metastases, Cancer stem cells, Epigenetics},
abstract = {Breast cancer (BC) is the most prevalent cancer in women globally. Anti-cancer advancements have enabled the killing of BC cells through various therapies; however, cancer relapse is still a major limitation and decreases patient survival and quality of life. Epithelial-to-mesenchymal transition (EMT) is responsible for tumor relapse in several cancers. This highly regulated event causes phenotypic, genetic, and epigenetic changes in the tumor microenvironment (TME). This review summarizes the recent advancements regarding EMT using de-differentiation and partial EMT theories. We extensively review the mechanistic pathways, TME components, and various anti-cancer adjuvant and neo-adjuvant therapies responsible for triggering EMT in BC tumors. Information regarding essential clinical studies and trials is also discussed. Furthermore, we also highlight the recent strategies targeting various EMT pathways. This review provides a holistic picture of BC biology, molecular pathways, and recent advances in therapeutic strategies.}
}
@article{MAJRASHI2024,
title = {Determinants of Public Sector Managers’ Intentions to Adopt AI in the Workplace},
journal = {International Journal of Public Administration in the Digital Age},
volume = {11},
number = {1},
year = {2024},
issn = {2334-4520},
doi = {https://doi.org/10.4018/IJPADA.342849},
url = {https://www.sciencedirect.com/science/article/pii/S2334452024000018},
author = {Khalid Majrashi},
keywords = {AI Adoption, AI Ethics, Artificial Intelligence, Attitudes, Behavioral Intentions, Managers, Public Sector, Technology Acceptance Model, Trust in AI, Workplace},
abstract = {ABSTRACT
This study investigated the determinants of public sector managers' intentions to adopt artificial intelligence (AI) systems within their organizations. An extended technology acceptance model (TAM) was developed, incorporating additional constructs including fairness, humanity, reliability, safety, transparency, accountability, privacy, security, trust, social norms, tolerance, impact, and isomorphic pressure. A survey was conducted among 330 public sector managers, and the data were analyzed using linear regression tests to evaluate the model. The results showed significant positive influences of both perceived usefulness and perceived impact on managers' attitudes and behavioral intentions toward AI adoption. Isomorphic pressure was also a significant determinant of managers' behavioral intentions toward adopting AI systems. Our findings also indicated that perceptions related to AI ethical principles, such as transparency, privacy, and security, influenced managers' trust in AI systems.}
}
@article{KANG2023100824,
title = {Learner innovativeness, course interaction, and the use of a new educational technology system after the COVID-19 pandemic},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100824},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100824},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000629},
author = {Dongsuk Kang and Min Jae Park},
keywords = {Learner innovativeness, Learning interaction, Blended learning, Educational management, Educational innovation},
abstract = {Due to the global COVID-19 pandemic and social distancing policies, higher education has adopted a new online learning system (e.g., viewing recorded lectures at one's own pace or participating in online streaming courses) as a necessary education service. Although many universities have switched to face-to-face courses in light of the reduced spread of the coronavirus, the new system could be a meaningful complement to the traditional learning method. This study focuses on identifying factors that influence students' utilization of new lecture systems in universities. This research investigated undergraduates majoring in management and other fields in South Korea through structural questionnaires. It analyzes the data using the partial least squares methodology of structural equation analysis. The results show that learners' innovativeness could increase their willingness to use the system, and the learning interaction in a course could improve students' learning satisfaction. Furthermore, the innovativeness could lead to a positive relationship between learning satisfaction, intention to use, and the system's potential impact. These findings suggest that instructors and universities need to offer new opportunities to promote students' willingness and motivation, as well as their preparation for online courses and learning interactions.}
}
@article{YIN2025105434,
title = {The association between groups' interactions with the Visual-GenAI learning analytics feedback and student engagement in CSCL},
journal = {Computers & Education},
volume = {239},
pages = {105434},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105434},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002027},
author = {Xinghan Yin and Junmin Ye and Shuang Yu and Honghui Li and Qingtang Liu and Gang Zhao},
keywords = {Cooperative/collaborative learning, Distance education and online learning, Data science applications in education, Evaluation methodologies},
abstract = {Promoting student engagement has long been a vital subject in the research of Computer-Supported Collaborative Learning (CSCL). Previous research has indicated the potential of AI-based visual learning analytics feedback and generative AI (GenAI) feedback in this context. However, there is currently a lack of definitive research on the combined impact of these two types of intelligent feedback in CSCL. Additionally, limited attention has been paid to how groups utilize these tools in CSCL practice and the differences that may exist. In this study, we developed an Visual-GenAI learning analytics feedback tool that integrates AI-based visual learning analytics feedback and GenAI-based feedback. We then evaluated the differences in groups' interactions with this Visual-GenAI learning analytics feedback and its association with student engagement and academic performance. The study employed a mixed-methods approach, combining quantitative analysis of feedback interaction log data, content analysis of group discussion data, and qualitative analysis of students' perceptions of different feedback tools through surveys. Our results show that groups exhibit four distinct levels of feedback interaction behavior patterns with the Visual-GenAI learning analytics feedback. These four patterns exhibit significant differences in behavioral engagement, emotional engagement, cognitive engagement, and academic performance. This study's significance lies in its potential contribution to future research on examining group behavior and optimizing learning using AI-based visual learning analytics feedback and GenAI-based feedback.}
}
@article{GAO2025102907,
title = {Time-frequency dependence and dynamic linkages between digital economy and education markets},
journal = {Technology in Society},
volume = {82},
pages = {102907},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102907},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000971},
author = {Wang Gao},
keywords = {Digital economy, Education, Time-frequency},
abstract = {This study utilizes a comprehensive analytical framework, incorporating both time and frequency domain methodologies, to investigate the complex interdependencies between the digital economy and the education market. The evaluation encompasses several critical dimensions, including return, volatility, and liquidity interconnectedness. The principal findings of this research are as follows: (1) There is a substantial co-dependence observed between the digital economy and the education sector, with a particular focus on components such as mobile internet, artificial intelligence, and big data—elements that exhibit the most pronounced linkages to educational infrastructures. Frequency domain analysis indicates that return spillover effects are potent in the short term, whereas spillovers related to volatility become increasingly significant in the long term. (2) The analysis reveals cloud computing and big data as the principal sources of spillover effects, while artificial intelligence, mobile internet, virtual reality, and online education serve as critical intermediaries. Importantly, vocational and K-12 education emerge as the primary beneficiaries of these spillover phenomena. (3) The interrelationships between the digital economy and educational markets exhibit time-varying characteristics, particularly marked by heightened fluctuations during pivotal events such as the COVID-19 pandemic and the implementation of the "Double Reduction" policy. Additionally, a notable strengthening of these trends has been observed after 2022. (4) The study demonstrates that assets associated with cloud computing, 5G technology, big data, artificial intelligence, and online education possess robust hedging effectiveness. The findings of this research aspire to inform educational policymakers regarding optimal resource allocation strategies, facilitate the seamless integration of digital technologies within educational frameworks, and provide strategic insights for asset investors seeking to navigate cross-market investments while enhancing risk management practices.}
}
@article{MENG202532,
title = {“Design nature”: A color interpretation of Bauhaus school building in Dessau and its conceptual origins},
journal = {Frontiers of Architectural Research},
volume = {14},
number = {1},
pages = {32-61},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2024.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095263524001043},
author = {Yuan Meng and Wei Liu},
keywords = {Dessau Bauhaus, Walter Gropius, Architectural space color design, Educational philosophy, Origin tracing research},
abstract = {In modernist architecture, color serves as a crucial tool in shaping spatial experiences. However, due to historical reasons, the color design of early modernist architecture has not been fully explored. The paper focuses on the iconic modernist work, the Bauhaus school building in Dessau. Through historical investigation and theoretical research, it elucidates the evolution of color cognition from the perspectives of color theory development, architectural color characteristics, and the interaction between visual perception and color. On this basis, it explores the color theory origins of the Bauhaus and Gropius, dissecting the conceptual framework and methods behind the color design of the Bauhaus school building in Dessau. Additionally, this article analyzes the spatial characteristics of architectural color from an experiential standpoint. The paper argues that Gropius conveyed his concept of “natural perspective” through color design, emphasizing the eternal value of natural internal logic. The Bauhaus redefined the role of color in architectural expression, based on natural laws, and deduced a scientifically designed method related to perception, promoting a shift in color design from subjective to objective and injecting deeper connotations into architectural color.}
}
@article{BRICE2024101159,
title = {Selected bibliography of recent scholarship in second language writing},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101159},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101159},
url = {https://www.sciencedirect.com/science/article/pii/S1060374324000663},
author = {Colleen Brice and Carolina Pelaez-Morales}
}
@article{ZHANG2025108457,
title = {Flow in ChatGPT-based logic learning and its influences on logic and self-efficacy in English argumentative writing},
journal = {Computers in Human Behavior},
volume = {162},
pages = {108457},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108457},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400325X},
author = {Ruofei Zhang and Di Zou and Gary Cheng and Haoran Xie},
keywords = {AI in education, ChatGPT-based learning, Engagement, Flow experience, Learning affection and cognition, Logic learning},
abstract = {Flow is a state of full engagement in an activity. Learning environments featured by Skill-challenge balance, Clear goal, Feedback, and Playability — collectively known as flow antecedents – can induce flow experiences and improve learning outcomes. ChatGPT-based environment seems to encourage a flow in learners: By customising tasks to match students' abilities, aligning materials with clear objectives, providing instant feedback, and ensuring ease of use, ChatGPT can help learners enter a flow state, which, in turn, leads to improved learning. However, there hasn't been much research on flow in ChatGPT-based learning. To bridge the gap, we developed a ChatGPT-based environment for developing logic in English argumentative writing. We studied 40 Chinese university English-as-a-foreign-language (EFL) students in the learning using questionnaires, eye-tracking data, knowledge tests, essay writing tasks, and semi-structured interviews to understand how they experienced flow and how it affected their learning. Our findings showed that the ChatGPT-based environment strongly supports flow antecedents. Skill-challenge balance and Playability were particularly influential for inducing flow experiences. Students who experienced a deeper flow showed better understanding of argumentative writing logic, although their writing self-efficacy became lower. Drawing from the findings, our study highlights how AI like ChatGPT can influence experiences and outcomes of logic learning and language learning, which may be applicable across various domains and disciplines.}
}
@article{UZOCHUKWU2023101820,
title = {Optimizing feed utilization and reducing deterioration of African catfish feed with sodium propionate supplementation},
journal = {Aquaculture Reports},
volume = {33},
pages = {101820},
year = {2023},
issn = {2352-5134},
doi = {https://doi.org/10.1016/j.aqrep.2023.101820},
url = {https://www.sciencedirect.com/science/article/pii/S2352513423003599},
author = {Ifeanyi Emmanuel Uzochukwu and Patrick Emeka Aba and Nelson Ike Ossai and Hillary Chukwuemeka Ugwuoke and Krisztián Nyeste and Ndubuisi Samuel Machebe},
keywords = {Sodium propionate, African catfish, Growth performance, Feed quality, Feed deterioration, Aquaculture production},
abstract = {A 56-day, two-phased experiment was conducted to investigate the effect of sodium propionate (NaP) on the growth performance of African catfish and the feed quality. One hundred juveniles with an average body weight of 50.47 g ( ± 4.60) were procured and used for the study’s first phase. Fish were randomly assigned to five groups (A, control group), B, C, D, and E) and replicated four times with five fish each. Respective groups were fed diets containing NaP at 0, 1.67, 3.33, 5.00, and 6.67 g kg−1 feed, respectively. For the second trial, the individual diets were analyzed for quality characteristics on 0-, 28- and 56-days of storage, using a mixed-model analysis of variance. Results showed significant differences in most growth performance parameters among groups except for the final body length and condition factor. Group C had lower final body weight (FW), weight gain (WG), average feed intake (AFI), specific growth rate (SGR), and higher feed conversion ratio (FCR) than the control. However, these parameters did not differ in Group D, which also showed lower AFI compared to the control. Increasing NaP decreased the sensory attribute scores of the feed and its crude protein (CP), ether, and ash levels while increasing moldiness, crude fiber, nitrogen-free extract, and thiobarbituric acid reactive substances (TBARs). NaP inclusion in feed resulted in a dose-dependent reduction in the feed deterioration, as seen in the lowered aggregate changes in sensory attributes, CP, moisture, and ash levels, with Group D having an optimal effect. The TBARs level (rancidity) decreased in Group B but increased in Group E during the study. The study concludes that there was a loss of fish feed quality with increasing storage time and that NaP particularly at 5.0 g kg−1 feed optimally improves feed utilization and effectively lowers feed deterioration for 56 days. Therefore, the use of NaP is recommended for improved aquaculture production.}
}
@incollection{DAVILADELGADO2025463,
title = {Chapter 23 - Demystifying machine learning for predictive analytics in construction},
editor = {Ehsan Noroozinejad Farsangi and Mohammad Noori and T.Y Yang and Vasilis Sarhosis and Seyedali Mirjalili and Mirosław J. Skibniewski},
booktitle = {Digital Transformation in the Construction Industry},
publisher = {Woodhead Publishing},
pages = {463-486},
year = {2025},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-29861-5},
doi = {https://doi.org/10.1016/B978-0-443-29861-5.00023-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443298615000238},
author = {Juan Manuel {Davila Delgado}},
keywords = {Machine learning, artificial intelligence, computer vision, construction, AEI.},
abstract = {This is a horizontal analysis on the state of research of machine learning (ML) for construction applications. The objective is to identify relevant topics in the research area and clarify the actual capabilities and limitations of ML approaches for construction. A literature review and thematic analyses were conducted to identify significant topics as well as an analysis of the most cited papers and use cases. A discussion of relevant applications and challenges is presented as well. The key findings are (1) there has been a massive increase on research efforts in the area; however, research is still behind in the use of state-of-the-art models, such as large language models, transformers, and reinforcement learning. Most importantly, it is usually limited to the use of relatively small datasets. (2) There are still significant challenges regarding the creation of sufficiently large datasets, but there are effective manners to address those challenges including the creation of synthetic data. This study provides construction practitioners and researchers with an overview of the key aspects of research on ML in construction that will help improve the understanding in this research area.}
}
@article{ZHANG2024104911,
title = {Strategies and conditions for crafting managerial responses to online reviews},
journal = {Tourism Management},
volume = {103},
pages = {104911},
year = {2024},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.104911},
url = {https://www.sciencedirect.com/science/article/pii/S026151772400030X},
author = {Xin Zhang and Lei La and GuoQiong Ivanka Huang and Haoxiang Xie},
keywords = {Managerial response, Customer reviews, Helpfulness votes, Uncertainty reduction theory, Rapport management model},
abstract = {The present study investigates how managerial responses to online reviews can help managers maintain relationships with past and future customers, exploring the question through the lens of the uncertainty reduction theory and the rapport management model. The present work crawled 446,663 customer reviews and 96,633 tour managerial responses on Ctrip.com using Python. Through randomly selecting 1000 responses, Study 1 manually identified nine managerial response strategies to customer online reviews. The Bidirectional Encoder Representations from Transformers (BERT) model was then adopted to automatically label the strategies used in all of the managerial responses. Employing negative binomial regression models, Study 2 then examined the interactions between attributes of customer reviews and managerial responses as a method for estimating helpfulness votes. The results indicate that excessively lengthy, highly templated, and unfocused managerial responses to customer reviews can dampen the relationship between customers’ information processing and their perception of the helpfulness of online reviews.}
}
@article{HUSSAIN2024344,
title = {Temperature, topography, woody vegetation cover and anthropogenic disturbance shape the orchids distribution in the western Himalaya},
journal = {South African Journal of Botany},
volume = {166},
pages = {344-359},
year = {2024},
issn = {0254-6299},
doi = {https://doi.org/10.1016/j.sajb.2024.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0254629924000541},
author = {Karamit Hussain and Muhammad Ejaz-Ul-Islam Dar and Arshad Mahmood Khan and Taskeen Iqbal and Ansar Mehmood and Tariq Habib and Ihab Mohamed Moussa and Ryan Casini and Hosam O. Elansary},
keywords = {Climate variability, Orchids microhabitats, Community ecology, Species interactions, Diversity and distribution},
abstract = {Orchid species require unique microhabitat conditions and are globally distributed from the tropics to alpine regions. These plant species are important both ecologically and economically but are facing multiple threats, especially habitat destruction, climate change, and overexploitation. Therefore, documenting species richness, diversity, distribution, and important driving factors is crucial for biodiversity conservation. The orchid species distribution patterns and order of importance of the main driving environmental factors in the western Himalayas of Azad Jammu and Kashmir remain unclear. The main aims of this study were to explore the richness and distribution of orchids and neighboring vascular flora and to identify the principal driving environmental factors, as no study has yet targeted these plant species specifically in the study area. Field data collection surveys were conducted from August 2018 to July 2021 using the vegetation sampling method. The presence of ≥ two individuals belonging to any orchid species in a 20 × 20 m² land area criterion was used to select the study sites along the elevation gradient for data collection. Multivariate statistical tools, such as hierarchical classification and ordination, were used to analyze the data. A total of 32 orchid species belonging to 18 different Orchidaceae genera were recorded at the 57 study sites. Only one individual each of Herminium monorchis, Habenaria furcifera, and Malaxis muscifera was collected, depicting these orchids as extremely rare in the study area. A total of 324 vascular plant species (including orchids and their neighboring plant species in the studied plots) were classified into seven significantly (p < 0.05) different plant associations, each with a unique species composition. The results of canonical correspondence analysis showed that temperature variability was the most influential among the 28 environmental factors considered. Different microhabitats with an elevation range of ≥1500–3500 m a.s.l. in the central part of the study area are moister and richer in organic matter and support high orchid diversity. It was observed that a higher density of co-existing tree and shrub species and a higher geographic slope were supporting the growth and survival of orchid species as well. Conversely, higher deforestation activities and potassium levels in the soil were observed as negatively influencing factors. The influence of non-native plant species on orchid species distribution was not significant, indicating that the local orchid species were not remarkably affected when growing in microhabitats with optimal conditions. This study concluded that the central part of the study area is richer in orchid abundance and diversity and needs effective conservation and management planning.}
}
@article{NG20241113,
title = {Megatrends affecting the world of work: Implications for human resource management},
journal = {Personnel Review},
volume = {54},
number = {5},
pages = {1113-1149},
year = {2024},
issn = {0048-3486},
doi = {https://doi.org/10.1108/PR-02-2025-0100},
url = {https://www.sciencedirect.com/science/article/pii/S0048348624000049},
author = {Eddy S. Ng and Pauline Stanton and Chidozie Umeh and Greg J. Bamber and Dianna Stone and Kimberly Lukaszewski and Sherry Aw and Sean Lyons and Linda Schweitzer and Shuang Ren and Mustafa F. Özbilgin and Arup Varma},
keywords = {Megatrends, Technological change, Artificial intelligence, Demographic shift, Globalization, Climate change, Populism, Future of work},
abstract = {Purpose
The purpose of the anthology is to explore how major societal shifts or “megatrends” are impacting the world of work and to provide guidance for human resource management (HRM) professionals.
Design/methodology/approach
The anthology adopts a varied approach encompassing literature reviews, empirical research and conceptual frameworks to offer informed perspectives on identifying and interpreting megatrends' impact on HRM.
Findings
The synthesis highlights several key impacts on the future of work: the transformative power of technological advancements, particularly AI and other new technologies; the challenges posed by globalization and shifting demographics; the lasting effects of the COVID-19 pandemic on work practices; the significant risks of climate change; the negative influence of populism and political polarization on diversity, equity and inclusion (DEI) initiatives; and the need for nuanced HRM approaches to address generational differences.
Research limitations/implications
There is inherent subjectivity in identifying and interpreting megatrends. Individual authors’ perspectives and biases might influence their analyses of megatrends and their recommendations for HRM. The analyses predominantly focus on Western contexts, limiting the generalizability of findings to other geographical regions and cultures.
Practical implications
The anthology encourages a more proactive, adaptable and inclusive approach to HRM, emphasizing the need for strategic foresight, investment in employee development and a focus on building organizational resilience in the face of significant societal changes.
Social implications
The anthology underscores the social responsibility of organizations and policymakers to mitigate negative social consequences arising from megatrends, promoting social justice, equity and the well-being of all members of society, particularly those most vulnerable to disruption. The findings highlight a need for societal adaptation and proactive measures to address potential inequities.
Originality/value
The anthology offers a comprehensive and insightful exploration of the significant transformations in the world of work, offering actionable guidance and laying the groundwork for future research into how HRM can successfully adapt to the evolving landscape.}
}
@article{HUYNH2025114159,
title = {Joint state-parameter estimation for the reduced fracture model via the united filter},
journal = {Journal of Computational Physics},
volume = {538},
pages = {114159},
year = {2025},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2025.114159},
url = {https://www.sciencedirect.com/science/article/pii/S0021999125004425},
author = {Phuoc Toan Huynh and Thi-Thao-Phuong Hoang and Guannan Zhang and Feng Bao},
keywords = {Reduced fracture model, Data assimilation, Joint state-parameter estimation, Ensemble score filter, Bayesian inference},
abstract = {In this paper, we introduce an effective United Filter method for jointly estimating the solution state and physical parameters in flow and transport problems within fractured porous media. Fluid flow and transport in fractured porous media are critical in subsurface hydrology, geophysics, and reservoir geomechanics. Reduced fracture models, which represent fractures as lower-dimensional interfaces, enable efficient multi-scale simulations. However, reduced fracture models also face accuracy challenges due to modeling errors and uncertainties in physical parameters such as permeability and fracture geometry. To address these challenges, we propose a United Filter method, which integrates the Ensemble Score Filter (EnSF) for state estimation with the Direct Filter for parameter estimation. EnSF, based on a score-based diffusion model framework, produces ensemble representations of the state distribution without deep learning. Meanwhile, the Direct Filter, a recursive Bayesian inference method, estimates parameters directly from state observations. The United Filter combines these methods iteratively: EnSF estimates are used to refine parameter values, which are then fed back to improve state estimation. Numerical experiments demonstrate that the United Filter method surpasses the state-of-the-art Augmented Ensemble Kalman Filter, delivering more accurate state and parameter estimation for reduced fracture models. This framework also provides a robust and efficient solution for PDE-constrained inverse problems with uncertainties and sparse observations.}
}
@article{MARKOVITCH2024103847,
title = {Consumer reactions to chatbot versus human service: An investigation in the role of outcome valence and perceived empathy},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103847},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103847},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924001437},
author = {Dmitri G. Markovitch and Rusty A. Stough and Dongling Huang},
keywords = {Chatbot, Empathy, Chatbot appearance, Anthropomorphic, Humanoid, Attribution theory},
abstract = {Service outcome valence is a prominent contextual factor that has been under-researched in studies of consumer response to automated service-givers. We investigate whether consumers respond differently to chatbot and human customer service when faced with positive versus negative service outcomes. We also explore the role of perceived empathy as a potential mediator in the focal relationship. 714 individuals participated in three studies based on the vignette method. Study participants reported significantly lower satisfaction, repatronage intentions, recommendation acceptance, and recommending the provider to others following interactions with a chatbot compared with a human agent in both positive and negative service outcome conditions. The effect was fully mediated by the service-giver's perceived empathy. Increasing a chatbot's perceived empathy via more empathetic communication (but not human-like appearance) improved consumer evaluations of chatbot service relative to a less empathetic chatbot configuration and matched evaluations of the human agent. A fourth study involved a quasi-experiment in which 100 individuals interacted with ChatGPT to obtain medical advice. This study corroborated our conclusions about the impact of perceived empathy on consumers' service experience and provider ratings.}
}
@article{BAO2023,
title = {A Preliminary Study on Graduate Student Instructors’ Exploration, Perception, and Use of ChatGPT},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {13},
number = {1},
year = {2023},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.332873},
url = {https://www.sciencedirect.com/science/article/pii/S2155709823000099},
author = {Yingling Bao and Belle Li},
keywords = {ChatGPT, Exploration, Foreign Language, Novice Instructors, Perception, TPACK},
abstract = {ABSTRACT
Research on teachers’ technological pedagogical content knowledge (TPACK) has been burgeoning recently. Yet, little is known about how teachers integrate AI tools such as ChatGPT in language teaching. This preliminary qualitative study investigates the exploration and incorporation of ChatGPT in language teaching by graduate student instructors (GSIs). By analyzing data from questionnaires, focus group interviews, screenshots of interactions with ChatGPT, and participants' lesson plans, this study shows how instructors develop their knowledge about ChatGPT and mobilize content and pedagogy knowledge to enact technology integration. Findings reveal that GSIs adopted various strategies when exploring the affordances of ChatGPT. Furthermore, while GSIs form positive perceptions of ChatGPT affordances, negative perceptions pertain to its limited capacity to process the Chinese language. Lastly, GSIs drew on various aspects of TPACK to design lessons, among which content knowledge and its interplay with technology seem to be prominent.}
}
@article{DHAIGUDE2025100293,
title = {Supply chain integration and culture under globalization: A systematic review and global research agenda},
journal = {Research in Globalization},
volume = {11},
pages = {100293},
year = {2025},
issn = {2590-051X},
doi = {https://doi.org/10.1016/j.resglo.2025.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2590051X25000267},
author = {Amol S. Dhaigude and Debmallya Chatterjee and Giridhar B Kamath},
keywords = {Supply chain integration, Culture, Cross-cultural supply chains, Global operations management, Systematic literature review, SPAR-4 SLR},
abstract = {Cultural peculiarities affect how corporations in global supply chains integrate, but unfortunately, there has been a lack of systematic documentation of this amalgamation. This study explores a complex global-level relationship among supply chain integration (SCI) and culture. This study synthesized current research from premier academic publications (A and A* levels) through text analysis, the SPAR-4 systematic literature review (SLR), and the theory, characteristics, context, and methodology(TCCM) framework to elucidate the intricacies of cross-cultural collaboration. This study proposes 60 research questions spread across the theoretical development, context, characteristics, and methodology to enhance the research on the amalgamation of SCI and culture at a global level. This study also proposes a research framework to guide future research on chaotic global supply networks. This study provides comprehensive knowledge of cross-cultural collaborative dynamics for practitioners and scholars, laying the groundwork for future empirical research and strategic management.}
}
@article{SONTADRACZKOWSKA2025321,
title = {Co-creating innovations with users: A systematic literature review and future research agenda for project management},
journal = {European Management Journal},
volume = {43},
number = {2},
pages = {321-339},
year = {2025},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0263237324000902},
author = {Ewa Sońta-Drączkowska and Marzenna Cichosz and Patrycja Klimas and Tomasz Pilewicz},
keywords = {NPD, User-driven innovation, User engagement, Co-innovation, PM, Domain-based review, Meta-systematic review},
abstract = {This study aimed to systematically review the extensive literature on user innovation co-creation and connect the findings to the project management domain. It focused specifically on new product development, offering a domain-based systematic review of methods, tools, and user types involved in the co-creation process. Analyzing a total of 266 articles, the authors synthesize the types of users and methods discussed in the domain of user innovation, aligning them across the new product development cycle and specific phases of co-innovation. Additionally, the authors formulate research questions and propositions that may inspire the project management domain. This study provides insights into innovation-oriented, exploratory project management and enhances the configuration approach to project management. From a practical perspective, it provides a comprehensive overview of methods that can enrich a managerial toolkit for leading innovative projects.}
}
@article{ROSCOE2023103059,
title = {Automated strategy feedback can improve the readability of physicians’ electronic communications to simulated patients},
journal = {International Journal of Human-Computer Studies},
volume = {176},
pages = {103059},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103059},
url = {https://www.sciencedirect.com/science/article/pii/S107158192300068X},
author = {Rod D. Roscoe and Renu Balyan and Danielle S. McNamara and Michelle Banawan and Dean Schillinger},
keywords = {Automated feedback, Natural language processing, Patient-physician communication, Readability, Electronic health records, Health literacy},
abstract = {Modern communication between health care professionals and patients increasingly relies upon secure messages (SMs) exchanged through an electronic patient portal. Despite the convenience of secure messaging, challenges include gaps between physician and patient expertise along with the asynchronous nature of such communication. Importantly, less readable SMs from physicians (e.g., too complicated) may result in patient confusion, non-adherence, and ultimately poorer health outcomes. The current simulation trial synthesizes work on patient-physician electronic communication, message readability assessments, and feedback to explore the potential for automated strategy feedback to improve the readability of physicians’ SMs to patients. Within a simulated secure messaging portal featuring multiple simulated patient scenarios, computational algorithms assessed the complexity of SMs written by 67 participating physicians to patients. The messaging portal provided strategy feedback for how physician responses might be improved (e.g., adding details and information to reduce complexity). Analyses of changes in SM complexity revealed that automated strategy feedback indeed helped physicians compose and refine more readable messages. Although the effects for any individual SM were slight, the cumulative effects within and across patient scenarios showed trends of decreasing complexity. Physicians appeared to learn how to craft more readable SMs via interactions with the feedback system. Implications for secure messaging systems and physician training are discussed, along with considerations for further investigation of broader physician populations and effects on patient experience.}
}
@article{WANG2024102809,
title = {Exploring product rendering generation design catering to multi-emotional needs through the Superiority Chart-Entropy Weight method and Stable Diffusion model},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102809},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102809},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004579},
author = {Zeng Wang and Hui-ru Pan and Jiang-shan Li and Shi-fan Niu},
keywords = {Superiority Chart-Entropy Weight method, Stable Diffusion model, Product rendering, Multi-emotional needs, Tunable weight allocation mechanism, Data driven},
abstract = {The experience economy has shifted user demands towards emotionalization, emphasizing multi-emotional considerations as pivotal in design. This study addresses challenges in accurately determining emotional needs and the inadequacy of current intelligent design approaches. It proposes a method for designing multi-emotional product renderings by integrating the Superiority Chart-Entropy Weight method with the Stable Diffusion model within a big data framework. Initially, online user comments, hand-drawn sketches, and renderings of target products are collected. The Superiority Chart-Entropy Weight is then adopted to establish weights for multi-emotional needs, creating an allocation mechanism of these weights. Incorporating these multi-emotional weights, a Stable Diffusion model embedded with LoRa is trained to generate diverse rendering schemes. Finally, the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is employed to select the optimal rendering scheme for 3D display. An experimental case study focusing on new energy vehicle renderings demonstrates the efficiency of this approach in precisely meeting users’ multi-emotional needs, thereby enhancing design efficiency and quality. Comparative experiments indicate that the method proposed in this study offers advantages in creating multi-emotional renderings. This study innovatively introduces a finer-grained multi-emotional needs confirmation method for users, overcoming the ambiguity and uncertainty of traditional recognition approaches, and develops a Stable Diffusion generation method tailored for product renderings, providing practical value in streamlining the conventional product design representation cycle and enhancing design efficiency, quality and user satisfaction.}
}
@article{LIU2024103191,
title = {Does modality matter? A meta-analysis of the effect of video input in L2 listening assessment},
journal = {System},
volume = {120},
pages = {103191},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2023.103191},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X23002130},
author = {Tingting Liu and Vahid Aryadoust},
keywords = {Audio-based listening assessment, Meta-Analysis, Meta-regression, Target language use (TLU) domain, Video-based listening assessment, Visual cues},
abstract = {Over the past two decades, there has been a growing research interest in examining the effects of video-based second language (L2) listening tests. However, these studies have shown inconsistency in their findings, prompting the need for a comprehensive analysis. This study aims to address this issue by conducting a meta-analysis to synthesize the quantitative research in this field. Our primary objective is to determine the pooled effect of video-based L2 listening assessment on test-takers’ listening comprehension and identify moderators that could potentially influence this effect. These potential moderators encompassed participants' characteristics, research method, video input features, and outcome measures. Through an extensive search process, we identified a total of 28 primary studies (years 1984–2022) that contributed data from 43 independent samples. We found that video input had a small overall positive effect on test-takers’ performance (g = 0.297). Additionally, we observed patterns in the effect of video input across different levels of moderators such as test-takers’ language proficiency, research design, reporting of reliability, speaker presentation, video length, question accessibility, note-taking availability, and item format. We discuss the implications of these findings and conclude with the limitations and several perspectives for future research.}
}
@article{DONG2024116666,
title = {Ship pipe route design based on NSGA-III and multi-population parallel evolution},
journal = {Ocean Engineering},
volume = {293},
pages = {116666},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.116666},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824000039},
author = {Zong-ran Dong and Wan-wan Luo},
keywords = {Ship pipe route design, Multi-objective optimization, NSGA-III, Heuristic pathfinding, OpenMP, Parallel evolution},
abstract = {Ship pipe route design (SPRD) aims to generate pipe layouts while considering various objectives and constraints in a confined 3D space, leading to extremely high complexity. To solve the problem of SPRD, traditional methods often adopt weighted summation of sub-objectives, introduce penalty functions to convert it to a single-objective optimization problem. However, these methods tend to yield a single optimal pipe route design pattern, and some existing multi-objective pipe routing algorithms do not have high search performance or sufficient treatment of constraints. Based on the grid-space decomposition model, this paper establishes a multi-objective pipe routing optimization model with several sub-objectives including path length, bends number, path energy, number of air-pockets, and number of violated bending distance, which also considers pipe routing for different diameters and interface direction requirements. A ship pipe route design framework based on the NSGA-III (Non-dominated Sorting Genetic algorithm III) is proposed, and its embedded pathfinding algorithm can explore pipe route using heuristic information and failure retry strategy, which greatly reduces the algorithm complexity compared to the classical algorithms such as A* and LEE and also facilitates parallel implementation. By employing OpenMP technology to achieve parallel evolution of multiple populations, more Pareto optimal solutions can be obtained in approximately the same timeframe as single population evolution. Finally, through comparative experiments using simulated cases, the feasibility and advancement of the proposed method are verified.}
}
@article{MELO2025322,
title = {An overview of randomized phase III clinical trials of cancer nanomedicines},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {4},
pages = {322-336},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000867},
author = {Micael N. Melo and Ricardo G. Amaral and Lucas R. {Melo de Andrade} and Patricia Severino and Cristina Blanco-Llamero and Luciana N. Andrade and Eliana B. Souto},
keywords = {Antineoplastic drugs, Chemotherapy, Nanomedicine, Drug delivery systems, Personalized medicine, Clinical trials},
abstract = {Background
Cancer therapy has undergone significant advances in recent decades attributed to personalized medicine and targeted drug delivery. Among the promising approaches, the use of nano-based delivery systems has become a relevant approach capable of improving treatment by releasing antineoplastic drugs at the target site, improving therapeutic efficacy, minimizing cytotoxicity in healthy tissues, and ultimately, reducing the intensity of adverse effects of chemotherapy. This study prospectively evaluated the impact of formulating anti-neoplastic drugs as nanomedicines on clinical response, overall survival, safety, and quality of life of cancer patients, based on the outcomes of randomized clinical trials.
Methods
A literature review was carried out by systematically searching the PubMed/MEDical Literature Analysis and Retrieval System Online (MEDLINE), Excerpta Medica Database (EMBASE), and Latin American and Caribbean Health Sciences Literature (LILACS) databases for phase III clinical trials, comparing nanomedicines with conventional therapies for the treatment of various cancer types.
Results
The nanomedicines analyzed were those that are approved and used in Brazil, considering the country's emerging market for advanced cancer treatments. From a total of 303 articles found, 26 articles were selected for systematic review. Studies showed that PEGylated l-asparaginase achieved a similar therapeutic effect to that of l-asparaginase, with fewer applications due to its longer half-life. Paclitaxel bound to albumin improved therapeutic efficacy as well as reduced infusion time and solvent-related toxicity of the conventional paclitaxel formulation. PEGylated liposomal doxorubicin showed better pharmacokinetics, reduced cardiotoxicity, and improved quality of life in cancer patients compared to that of free doxorubicin.
Conclusions
This study reinforces the scientific evidence of the added value of nanomedicines to improve therapeutic efficacy and reduce toxicity in patients under chemotherapy.}
}
@article{HARWOOD2024104013,
title = {“Anything you can do, I can do”: Examining the use of ChatGPT in situational judgement tests for professional program admission},
journal = {Journal of Vocational Behavior},
volume = {154},
pages = {104013},
year = {2024},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2024.104013},
url = {https://www.sciencedirect.com/science/article/pii/S000187912400054X},
author = {Harley Harwood and Nicolas Roulin and Muhammad Zafar Iqbal},
keywords = {Generative AI, ChatGPT, Situational judgement tests, Faking},
abstract = {We explored the transformative impact of ChatGPT on applicants' responses and performance in situational judgement tests (SJTs), as well as the role played by faking-prevention mechanisms, in two complementary studies. Study 1 examined how the availability of ChatGPT influenced response content and performance of real applicants (N = 107,805), who completed an SJT for admission before vs. after the release of the technology. We found only small differences in content (e.g., slightly less “authentic” words used) and performance (slight score improvements when controlling for response length, no differences otherwise). In Study 2, we used an experimental approach with (N = 138) Prolific participants completing a mock SJT, while being instructed to use ChatGPT when responding (vs. use online resources or no resources). We found only slightly higher SJT scores for the ChatGPT users, but no difference in response content. Additionally, GPTZero (i.e., a popular AI detection tool) struggled to detect ChatGPT content, and generated many false positives, in both studies. This research advances our understanding of how the release and popularization of ChatGPT can influence applicant behaviors. Given the “arms race” nature of applicant selection, they also highlight the importance of designing assessments to prevent or limit faking. Yet, the ever-evolving nature of AI calls for continuous research on the topic.}
}
@article{2023A5,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {36},
number = {7},
pages = {A5-A13},
year = {2023},
note = {34th ASE Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(23)00276-6},
url = {https://www.sciencedirect.com/science/article/pii/S0894731723002766}
}
@article{HIGGINS2025103630,
title = {Evaluating empathic responses to bimodal realism in emotionally expressive virtual humans: An eye-tracking and facial electromyography study},
journal = {International Journal of Human-Computer Studies},
volume = {205},
pages = {103630},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103630},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925001879},
author = {Darragh Higgins and Benjamin R. Cowan and Rachel McDonnell},
keywords = {Virtual humans, Emotion perception, Empathy, Realism},
abstract = {With the expanding range of uses for advancements in animation and voice synthesis, more opportunities arise for interactions with animated virtual humans. Such interactions may be influenced by improved portrayals of character features such as emotion and realism. The present study aimed to examine how variations in animated facial detail and vocal prosody shape user perception of emotion in virtual characters. This impact was assessed via facial electromyography and eye-tracking measures, as well as self-reports of state empathy and character appeal. Results indicate that participants were influenced by emotional valence in terms of zygomaticus major and corrugator supercilii muscle activation. Survey data appear to show greater empathy for conditions of increased facial detail and more human-like vocal prosody. Moreover, eye tracking results suggest a preference for eye contact regardless of detail or prosody, with participants fixating more on facial areas of interest overall for the positively valenced conditions. Finally, there is evidence that trait empathy and mismatches between higher facial detail and lower vocal human-likeness may influence zygomaticus major activity in response to positively valenced stimuli. These results are discussed in the context of virtual character design, contemporary understandings of empathy and the phenomenon of the Uncanny Valley.}
}
@article{LI2025175,
title = {Generative AI-powered planning: A hybrid graph-diffusion approach for demand-driven flexible manufacturing systems},
journal = {Journal of Manufacturing Systems},
volume = {83},
pages = {175-195},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525002109},
author = {Chen Li and Qing Chang},
keywords = {Flexible smart manufacturing systems (FSMS), Generative AI, Diffusion model, Graph neural network (GNN), Manufacturing system planning, Robot assignment},
abstract = {Flexible Smart Manufacturing Systems (FSMS) are critical to achieving mass customization and operational agility under Industry 4.0. However, planning effective FSMS configurations remains challenging due to fluctuating market demands, heterogeneous system components, complex interdependencies, and the need to optimize resource utilization. Conventional planning methods often require predefined line configurations and lack adaptability, scalability, and awareness of dynamic system properties. This paper presents a novel Hybrid Graph-Diffusion Based Planning Framework that integrates generative AI with system-theoretic modeling to autonomously generate optimal FSMS configurations based on different market demands. Specifically, we introduce a system model-embedded Heterogeneous Graph (HG) to represent the structure and properties of an FSMS and infuse it within a system property-tailored diffusion model to generate reconfigurable plan configurations. The final system property-guided refinement guarantees that the final plan configuration is optimal in both demand satisfaction and resource use. Furthermore, our ablation studies validate that our framework significantly outperforms conventional approaches in both demand satisfaction and resource efficiency. Furthermore, our ablation studies validate the effectiveness of the system property guidance and HG-based representation in enhancing planning feasibility, robustness, and adaptability.}
}
@article{2025iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {258},
pages = {iii-xxvi},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(25)01840-X},
url = {https://www.sciencedirect.com/science/article/pii/S187705092501840X}
}
@incollection{TAC2024432,
title = {4.18 - A Modeler׳s Guide to Soft Tissue Mechanics},
editor = {Vadim Silberschmidt},
booktitle = {Comprehensive Mechanics of Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {432-451},
year = {2024},
isbn = {978-0-323-90647-0},
doi = {https://doi.org/10.1016/B978-0-323-90646-3.00053-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323906463000538},
author = {Vahidullah Tac and Adrian B. Tepole},
keywords = {Continuum damage mechanics, Data-driven material modeling., Fractional viscoelasticity, Growth and remodeling, Hyperelasticity, Hyper-viscoelasticity, Mechanobiology, Multiscale modeling, Reactive mixtures, Tissue biomechanics},
abstract = {Soft tissue mechanical behavior and its change with age, physiological adaption, and disease, are key to our health and survival. Soft tissues are divided in four main categories, epithelial, muscle, connective, and nervous system tissues. Different types of tissues have unique composition and microstruture to perform their specific functions. Musculoskeletal and connective soft tissues, in particular, have evolved to address important mechano-physiological needs. All soft tissues, whether or not their primary function is mechanical in nature, show extreme mechanics, with large deformation, nonlinear stress-strain stiffening, various modes of energy dissipation such as viscoelasticity and damage, and, most remarkably, show the ability to adapt to external stimulus through growth and remodeling. This chapter outlines the essential theoretical frameworks for modeling the complex behavior of soft tissue. The role of data-driven tools as well as the soft tissues that have received increasing attention in recent years are also discussed.}
}
@article{CORLATESCU2024108154,
title = {The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108154},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108154},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000219},
author = {Dragos-Georgian Corlatescu and Micah Watanabe and Stefan Ruseti and Mihai Dascalu and Danielle S. McNamara},
keywords = {Natural language processing, Reading comprehension, Automated model of comprehension, ChatGPT, Large language models},
abstract = {Modeling reading comprehension processes is a critical task for Learning Analytics, as accurate models of the reading process can be used to match students to texts, identify appropriate interventions, and predict learning outcomes. This paper introduces an improved version of the Automated Model of Comprehension, namely version 4.0. AMoC has its roots in two theoretical models of the comprehension process (i.e., the Construction-Integration model and the Landscape model), and the new version leverages state-of-the-art Large Language models, more specifically ChatGPT, to have a better contextualization of the text and a simplified construction of the underlying graph model. Besides showcasing the usage of the model, the study introduces three in-depth psychological validations that argue for the model's adequacy in modeling reading comprehension. In these studies, we demonstrated that AMoC is in line with the theoretical background proposed by the Construction-Integration and Landscape models, and it is better at replicating results from previous human psychological experiments than its predecessor. Thus, AMoC v4.0 can be further used as an educational tool to, for example, help teachers design better learning materials personalized for student profiles. Additionally, we release the code from AMoC v4.0 as open source in a Google Collab Notebook and a GitHub repository.}
}
@article{RENAUD2024103877,
title = {VISTA: An inclusive insider threat taxonomy, with mitigation strategies},
journal = {Information & Management},
volume = {61},
number = {1},
pages = {103877},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2023.103877},
url = {https://www.sciencedirect.com/science/article/pii/S0378720623001258},
author = {Karen Renaud and Merrill Warkentin and Ganna Pogrebna and Karl {van der Schyff}},
keywords = {Insider threats, Taxonomy, Mitigations, Cybersecurity},
abstract = {Insiders have the potential to do a great deal of damage, given their legitimate access to organisational assets and the trust they enjoy. Organisations can only mitigate insider threats if they understand what the different kinds of insider threats are, and what tailored measures can be used to mitigate the threat posed by each of them. Here, we derive VISTA (inclusiVe InSider Threat tAxonomy) based on an extensive literature review and a survey with C-suite executives to ensure that the VISTA taxonomy is not only scientifically grounded, but also meets the needs of organisations and their executives. To this end, we map each VISTA category of insider threat to tailored mitigations that can be deployed to reduce the threat.}
}
@article{LIU2026107910,
title = {Singular Value Decomposition-based lightweight LSTM for time series forecasting},
journal = {Future Generation Computer Systems},
volume = {174},
pages = {107910},
year = {2026},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107910},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25002055},
author = {Changwei Liu and Hao Ren and Guoqiang Li and Haojie Ren and Xiaojun Liang and Chunhua Yang and Weihua Gui},
keywords = {Long–short-term memory, LSTM lightweight, Singular Value Decomposition, Model compression},
abstract = {Long–short-term memory (LSTM) neural networks are known for their exceptional performance in various domains, particularly in handling time series data and managing long-term dependencies. However, deploying LSTM often faces challenges due to limitations in memory and computational resources, especially in edge computing and real-time processing scenarios. To maximize the advantages of LSTM in resource-constrained environments, this paper presents a lightweight LSTM method that uses weight matrix decomposition. Specifically, it employs Singular Value Decomposition (SVD) to decompose the weight matrices within the LSTM Cell and fully connected layers. Then, an optimization method is addressed to enable the efficient development of a lightweight model by dynamically assessing and enhancing storage and computational efficiency through adjustments of the learning rate and weight parameters. The experimental results indicate that this method reduces the parameters of the LSTM model by 45%, compresses the model size to 45% of its original size, and maintains prediction accuracy without decline. It means that the proposed method based on weight matrix decomposition allows LSTM to operate with less computational power and memory, making them more feasible for deploying resource-constrained devices.}
}
@article{LEE2024102520,
title = {Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102520},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102520},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400168X},
author = {Ching-Hung Lee and Xuejiao Zhao},
keywords = {Customer Complaint Handling System, Customer Temperament, Data Mining, Correspondence Analysis, Interactive marketing},
abstract = {One of the most significant sources of information from customers is customer complaints. Successful and effective complaint management can end complaint crises and ensure client loyalty, which is a sign of great service performance. In this paper, we proposed a novel customer temperament-centered and e-CCH system-based data collection and data mining method titled “3D” model for customer complaint data analysis. Three phases are (1) Development and launch of e-Customer Complaint Handling system, (2) Data collection and transfer of learning by e-Customer Complaint Handling system, and (3) Data mining by e-Customer Complaint Handling system. An advanced electronic Customer Complaint Handling System called the e-CCH system was then developed and launched. This system adapts the seasonal associations model based on Hippocrates's customer temperament theory to the whole stages of customer complaint reporting and handling. With this system, we conducted a dataset collection work from restaurant chains of two brands over four years. As a result, we collect thousands of real-world temperament-centred customer complaint cases by four years to form the one-of-a-kind CCH dataset. This one-of-a-kind CCH dataset was open-sourced with detailed customer complaint attributes and heuristic decision-making for valuable industrial handling manner. After further analysis of this dataset, we found that customers with different temperament types tend to have different types of complaints. In addition, adapting the temperament theory to the e-CCH system can classify customer types better and provide personalized solutions. To our best knowledge, this rich and the one-of-a-kind CCH dataset reported in this paper is the first comprehensive study of customer complaint handling in an industrial service management context. Meanwhile, data mining with cross analysis and correspondence analysis and an ChatGPT experiment for transfer of learning based on this yearly and one-of-a-kind industrial customer complaint dataset was analyzed and discussed. In addition, how this dataset may contribute to more realistic complaint-handling theoretic studies for better service failure recovery and interactive marketing is discussed in-depth.}
}
@article{KARAKOLTZIDIS2025100012,
title = {AI-driven parametrization of Michaelis–Menten maximal velocity: Advancing in silico new approach methodologies (NAMs)},
journal = {NAM Journal},
volume = {1},
pages = {100012},
year = {2025},
issn = {3050-6204},
doi = {https://doi.org/10.1016/j.namjnl.2025.100012},
url = {https://www.sciencedirect.com/science/article/pii/S3050620425000077},
author = {Achilleas Karakoltzidis and Spyros P. Karakitsios and Dimosthenis Α. Sarigiannis},
keywords = {Deep learning, , Maximal velocity, Enzyme structure, QSPR, NAMs},
abstract = {The development of mechanistic systems biology models necessitates the utilization of numerous kinetic parameters once the enzymatic mode of action has been identified. Simultaneously, wet lab experimentation is associated with particularly high costs, does not adhere to principles of reducing the number of animal tests, and is a time-consuming procedure. Alternatively, an artificial intelligence-based method is proposed that utilizes enzyme amino acid structures as input data. This method combines NLP techniques with molecular fingerprints of the catalysed reaction to determine Michaelis–Menten maximal velocities (Vmax). The molecular fingerprints employed include RCDK standard fingerprints (1024 bits), MACCS keys (166 bits), PubChem fingerprints (881 bits), and E-States fingerprints (79 bits). These were integrated to produce reaction fingerprints. The data entries were sourced from SABIO RK, providing a concrete framework to support training procedures. After the data preprocessing stage, the dataset was randomly split into the training set (70 %), validation set (10 %), and test set (20 %) ensuring unique amino acid sequences for each subset. The data points with structures similar to the ones used to train the model as well as uncommon reactions were employed to further test the model. The developed models were optimized during the training procedure to predict Vmax values efficiently and reliably. Utilizing a fully connected neural network, these models can be applied to all organisms. Amino acid proportions of enzymes were also tested resulting in an unreliable predictor for the Vmax value. During testing, the model demonstrated better performance on known structures compared to unseen data. In the given use case, the model trained solely on enzyme representations achieved an R-squared of 0.45 on unseen data and 0.70 on known structures. When enzyme representations were integrated with RCDK fingerprints, the model achieved an R-squared of 0.46 on unseen data and 0.62 on known structures.}
}
@article{MANCHEL2024111322,
title = {From sampling to simulating: Single-cell multiomics in systems pathophysiological modeling},
journal = {iScience},
volume = {27},
number = {12},
pages = {111322},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.111322},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224025471},
author = {Alexandra Manchel and Michelle Gee and Rajanikanth Vadigepalli},
keywords = {Systems biology, Data processing in systems biology, In silico biology, Biological constraints, Omics},
abstract = {Summary
As single-cell omics data sampling and acquisition methods have accumulated at an unprecedented rate, various data analysis pipelines have been developed for the inference of cell types, cell states and their distribution, state transitions, state trajectories, and state interactions. This presents a new opportunity in which single-cell omics data can be utilized to generate high-resolution, high-fidelity computational models. In this review, we discuss how single-cell omics data can be used to build computational models to simulate biological systems at various scales. We propose that single-cell data can be integrated with physiological information to generate organ-specific models, which can then be assembled to generate multi-organ systems pathophysiological models. Finally, we discuss how generic multi-organ models can be brought to the patient-specific level thus permitting their use in the clinical setting.}
}
@article{CANANAU2025104816,
title = {Critical thinking in preparation for student teachers’ professional practice: A case study of critical thinking conceptions in policy documents framing teaching placement at a Swedish university},
journal = {Teaching and Teacher Education},
volume = {153},
pages = {104816},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104816},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24003494},
author = {Iulian Cananau and Silvia Edling and Björn Haglund},
keywords = {Critical thinking, Teacher education, Placement, Teacher profession, Concept, Policy documents},
abstract = {This paper explores the conceptions of critical thinking in national and local policy documents for teaching placement, using the case of teacher education programs at a Swedish university. The concept under scrutiny is based on three contemporary theoretical models of critical thinking in education: critical thinking movement, critical pedagogy, and “criticality” movement. In Sweden, the teacher profession is framed with a broader socio-ethical scope than the focus on individual cognitive skills of the critical thinking movement. Critical reflection and self-reflection, two conceptions identified with the criticality ideal of education for critical being, prevail in the analyzed documents.}
}
@article{CANIGLIA2025107605,
title = {FOBICS: Assessing project security level through a metrics framework that evaluates DevSecOps performance},
journal = {Information and Software Technology},
volume = {178},
pages = {107605},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107605},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924002106},
author = {Alessandro Caniglia and Vincenzo Dentamaro and Stefano Galantucci and Donato Impedovo},
keywords = {DevSecOps, Metrics framework, Project security, Software engineering, Evaluating security, DevOps, Security assessment, Software metrics, Secure software development, Business metrics},
abstract = {Context:
In today’s software development landscape, the DevSecOps approach has gained traction due to its focus on the software development process and bolstering security measures in projects, a task in light of the ever-evolving cybersecurity threats.
Objective:
This study aims to address the lack of metrics for quantitatively assessing its efficacy from both security and business logic perspectives.
Methods:
To tackle this issue, the research introduces the Framework of Business Index Concerning Security (FOBICS), a set of metrics designed to enable transparent evaluations of project security. FOBICS considers various perspectives relevant to DevSecOps practices. It includes factors such as project duration and financial outcomes, making it appealing for implementation in business settings.
Results:
The effectiveness of FOBICS is validated theoretically and empirically via its application in two real-world projects: the results from these implementations show a correlation between FOBICS metrics and the security strategies employed as the development methodologies adopted by diverse teams throughout the projects.
Conclusion:
Hence, FOBICS emerges as a tool for assessing and continuously monitoring project security, offering insights into areas of strength and areas that may require enhancement. FOBICS is shown to be effective in assessing the level of DevSecOps implementation. The ease of calculating FOBICS metrics makes them easily interpretable and continuously verifiable. Moreover, FOBICS summarizes most of the other quantitative and qualitative metrics in the literature.}
}
@article{LO2024102435,
title = {Understanding momentary engagement in university students: Exploring the interaction between competence and value beliefs on emotions and cognitive engagement – A multilevel investigation},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102435},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102435},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000281},
author = {Meng-Ting Lo},
keywords = {Momentary engagement, Achievement emotions, Cognitive engagement, Situated competence and value beliefs, Experience sampling method},
abstract = {Using an intensive longitudinal design, this study investigated the predictive role of and interaction between competence beliefs and task value in relation to four achievement emotions (enthusiasm, excitement, anxiety, and irritation) as well as cognitive engagement. Data were collected using an experience sampling method to capture the momentary experiences of 81 university students over 14 days. Using a multilevel modeling approach, the study disentangled variations between and within individuals across learning situations. The results indicated that associations between competence and value beliefs and emotions were primarily observed at the situational level. Both competence and value beliefs played important roles in predicting cognitive engagement. In addition, high competence beliefs acted as a buffer, mitigating the positive association between opportunity cost and anxiety and reducing the negative impact of low intrinsic value on irritation. Positive value beliefs emerged as instrumental in fostering cognitive engagement, particularly in situations characterized by limited competence beliefs.
Educational relevance statement
The motivation and engagement displayed by university students in diverse learning events offer valuable insights into their dedication and academic involvement in pursuing their degrees. This study highlights the importance of perceiving both high competence beliefs and intrinsic value, which results in stronger associations with enthusiasm and excitement during learning. Conversely, high opportunity cost is linked to greater anxiety, but high competence beliefs act as a protective factor, mitigating this effect. High competence beliefs also counteract the negative impact of low intrinsic value on irritation. Value beliefs, particularly importance and intrinsic value, have a compensatory effect on cognitive engagement. Positive value beliefs play a crucial role in driving cognitive engagement, especially when competence beliefs are lacking. Gaining insight into changes within individuals and variations between students enables educators to effectively tailor instructional strategies and provide support, which in turn fosters students' motivation and engagement.}
}
@article{SUH2024,
title = {Toward Tailoring Just-in-Time Adaptive Intervention Systems for Workplace Stress Reduction: Exploratory Analysis of Intervention Implementation},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/48974},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000982},
author = {Jina Suh and Esther Howe and Robert Lewis and Javier Hernandez and Koustuv Saha and Tim Althoff and Mary Czerwinski},
keywords = {workplace stress, just-in-time, just-in-time adaptive intervention, JITAI, engagement, microintervention, stress reduction, psychotherapy},
abstract = {Background
Integrating stress-reduction interventions into the workplace may improve the health and well-being of employees, and there is an opportunity to leverage ubiquitous everyday work technologies to understand dynamic work contexts and facilitate stress reduction wherever work happens. Sensing-powered just-in-time adaptive intervention (JITAI) systems have the potential to adapt and deliver tailored interventions, but such adaptation requires a comprehensive analysis of contextual and individual-level variables that may influence intervention outcomes and be leveraged to drive the system’s decision-making.
Objective
This study aims to identify key tailoring variables that influence momentary engagement in digital stress reduction microinterventions to inform the design of similar JITAI systems.
Methods
To inform the design of such dynamic adaptation, we analyzed data from the implementation and deployment of a system that incorporates passively sensed data across everyday work devices to send just-in-time stress reduction microinterventions in the workplace to 43 participants during a 4-week deployment. We evaluated 27 trait-based factors (ie, individual characteristics), state-based factors (ie, workplace contextual and behavioral signals and momentary stress), and intervention-related factors (ie, location and function) across 1585 system-initiated interventions. We built logistical regression models to identify the factors contributing to momentary engagement, the choice of interventions, the engagement given an intervention choice, the user rating of interventions engaged, and the stress reduction from the engagement.
Results
We found that women (odds ratio [OR] 0.41, 95% CI 0.21-0.77; P=.03), those with higher neuroticism (OR 0.57, 95% CI 0.39-0.81; P=.01), those with higher cognitive reappraisal skills (OR 0.69, 95% CI 0.52-0.91; P=.04), and those that chose calm interventions (OR 0.43, 95% CI 0.23-0.78; P=.03) were significantly less likely to experience stress reduction, while those with higher agreeableness (OR 1.73, 95% CI 1.10-2.76; P=.06) and those that chose prompt-based (OR 6.65, 95% CI 1.53-36.45; P=.06) or video-based (OR 5.62, 95% CI 1.12-34.10; P=.12) interventions were substantially more likely to experience stress reduction. We also found that work-related contextual signals such as higher meeting counts (OR 0.62, 95% CI 0.49-0.78; P<.001) and higher engagement skewness (OR 0.64, 95% CI 0.51-0.79; P<.001) were associated with a lower likelihood of engagement, indicating that state-based contextual factors such as being in a meeting or the time of the day may matter more for engagement than efficacy. In addition, a just-in-time intervention that was explicitly rescheduled to a later time was more likely to be engaged with (OR 1.77, 95% CI 1.32-2.38; P<.001).
Conclusions
JITAI systems have the potential to integrate timely support into the workplace. On the basis of our findings, we recommend that individual, contextual, and content-based factors be incorporated into the system for tailoring as well as for monitoring ineffective engagements across subgroups and contexts.}
}
@article{KANG2025111189,
title = {A trust and bundling-based task allocation scheme to enhance completion rate and data quality for mobile crowdsensing},
journal = {Computer Networks},
volume = {262},
pages = {111189},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111189},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625001574},
author = {Yunchuan Kang and Houbing Herbert Song and Tian Wang and Shaobo Zhang and Mianxiong Dong and Anfeng Liu},
keywords = {Mobile crowdsensing, Task bundling, Task assignment scheme, Truth discovery, Multi-objective optimization},
abstract = {In Mobile CrowdSensing (MCS), task bundling has shown promise in improving task completion rate by pairing unpopular tasks with popular ones. However, existing methods often assume truthful data from workers, an assumption misaligned with real-world MCS scenarios. Workers tend to submit low-quality or false data to maximize their rewards, particularly given the Information Elicitation Without Verification (IEWV) problem, which hinders the detection of dishonest behavior. To address this, we propose a Trust and Bundling-based Task Allocation (TBTA) scheme to enhance task completion rates and data quality at a low cost. The TBTA scheme includes three main strategies: (1) a trusted worker identification algorithm that evaluates workers' trust degrees by considering the IEWV challenge, allowing for the selection of reliable workers and thus ensuring higher data quality; (2) a task bundling method using the Non-dominated Sorting Genetic Algorithm II to bundle unpopular tasks with popular ones strategically, maximizing platform utility and completion rates; and (3) an optimal allocation algorithm that assigns trusted workers to tasks best suited to their capabilities, thus improving data reliability and minimizing costs. Experimental results demonstrate that compared to the state-of-the-art methods, the TBTA scheme achieves a 15.54 % improvement in task completion rate, and a 1.83 % reduction in worker travel distance.}
}
@article{WANG2024,
title = {Applications and Concerns of ChatGPT and Other Conversational Large Language Models in Health Care: Systematic Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/22769},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400757X},
author = {Leyao Wang and Zhiyu Wan and Congning Ni and Qingyuan Song and Yang Li and Ellen Clayton and Bradley Malin and Zhijun Yin},
keywords = {large language model, ChatGPT, artificial intelligence, natural language processing, health care, summarization, medical knowledge inquiry, reliability, bias, privacy},
abstract = {Background
The launch of ChatGPT (OpenAI) in November 2022 attracted public attention and academic interest to large language models (LLMs), facilitating the emergence of many other innovative LLMs. These LLMs have been applied in various fields, including health care. Numerous studies have since been conducted regarding how to use state-of-the-art LLMs in health-related scenarios.
Objective
This review aims to summarize applications of and concerns regarding conversational LLMs in health care and provide an agenda for future research in this field.
Methods
We used PubMed, ACM, and the IEEE digital libraries as primary sources for this review. We followed the guidance of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) to screen and select peer-reviewed research articles that (1) were related to health care applications and conversational LLMs and (2) were published before September 1, 2023, the date when we started paper collection. We investigated these papers and classified them according to their applications and concerns.
Results
Our search initially identified 820 papers according to targeted keywords, out of which 65 (7.9%) papers met our criteria and were included in the review. The most popular conversational LLM was ChatGPT (60/65, 92% of papers), followed by Bard (Google LLC; 1/65, 2% of papers), LLaMA (Meta; 1/65, 2% of papers), and other LLMs (6/65, 9% papers). These papers were classified into four categories of applications: (1) summarization, (2) medical knowledge inquiry, (3) prediction (eg, diagnosis, treatment recommendation, and drug synergy), and (4) administration (eg, documentation and information collection), and four categories of concerns: (1) reliability (eg, training data quality, accuracy, interpretability, and consistency in responses), (2) bias, (3) privacy, and (4) public acceptability. There were 49 (75%) papers using LLMs for either summarization or medical knowledge inquiry, or both, and there are 58 (89%) papers expressing concerns about either reliability or bias, or both. We found that conversational LLMs exhibited promising results in summarization and providing general medical knowledge to patients with a relatively high accuracy. However, conversational LLMs such as ChatGPT are not always able to provide reliable answers to complex health-related tasks (eg, diagnosis) that require specialized domain expertise. While bias or privacy issues are often noted as concerns, no experiments in our reviewed papers thoughtfully examined how conversational LLMs lead to these issues in health care research.
Conclusions
Future studies should focus on improving the reliability of LLM applications in complex health-related tasks, as well as investigating the mechanisms of how LLM applications bring bias and privacy issues. Considering the vast accessibility of LLMs, legal, social, and technical efforts are all needed to address concerns about LLMs to promote, improve, and regularize the application of LLMs in health care.}
}
@article{SAXENA2025532,
title = {COMPARATIVE ANALYSIS OF LARGE LANGUAGE MODELS FOR THE APPLICATION OF SCIENTIFIC ARTICLE SUMMARIZATION},
journal = {Procedia Computer Science},
volume = {259},
pages = {532-542},
year = {2025},
note = {Sixth International Conference on Futuristic Trends in Networks and Computing Technologies (FTNCT06), held in Uttarakhand, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925010993},
author = {Rishabh Saxena and Shubhangi Singh and Preeti Dubey},
keywords = {LLMs, LLaMa-3, GPT-3, Mixtral, Gemma, ROUGE, BLEU, BERT, Automatic text summarization},
abstract = {Automatic text summarization has become an essential tool for academics to stay up to date with the newest advancements due to the high rise of scientific publications. Abstractive text summarisation tasks can be done using LLMs. However current summarization methods often struggle to capture the nuanced and technical details present in research papers and there are prevalent research gaps in the realm of abstractive summarisation using generative AI. This study aims to analyse the efficiency of LLM models – GPT-3.5, LLaMa 3, Mixtral 8x7b and Gemma-2, in condensing detailed scientific literature into manageable summaries, and their further evaluation based on ROUGE, BERT and BLEU scores. The results show that GPT-3.5 and LLaMa 3 generate more coherent and contextually accurate summaries with a BERT score of 0.21 and 0.19 respectively, even though Mixtral 8x7B performs exceptionally well in quantitative measurements. Despite its coherence, Gemma-2 receives poorer performance in both qualitative and quantitative assessments. These findings bring out the value of integrating quantitative and qualitative evaluations to gain a thorough understanding of summarization.}
}
@article{ZHENG2025113524,
title = {Comprehensive survey of large models-driving intelligent decision making},
journal = {Applied Soft Computing},
volume = {181},
pages = {113524},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113524},
url = {https://www.sciencedirect.com/science/article/pii/S156849462500835X},
author = {Yuanhang Zheng and Tong Wu and Xiangyu Xiao and Zeshui Xu},
keywords = {Intelligent decision making, Large models, Survey, Interaction, Multi-modal information, Interpretability},
abstract = {In recent years, intelligent decision making has become a national strategic level to attach great importance to the focus of the fields, in medicine, business, manufacturing, agriculture, etc. Exemplified by breakthroughs such as GPT-4, LLaMA, Deepseek, and multimodal systems like AlphaFold, large models have catalyzed a paradigm shift in artificial intelligence—from perceptual tasks to complex decision-making scenarios. This paper presents a comprehensive survey on large models (LMs)-driving intelligent decision making, where the main contributions are as follows: 1) innovatively give a definition of LM-driving intelligent decision making, and establish a novel multi-role functional framework distinguishing LMs as data synthesizers (preparers), contextual reasoners (facilitators), and ethical validators (reflectors). 2) cross-disciplinary bibliometric analysis reveals the current research landscape in this field, demonstrating a wide range of interests within the community. 3) conduct a profound and comprehensive analysis of key components and applications of LMs-driving intelligent decision making, and deeply analyze the advantages, limitations, and challenges associated with this approach while also suggesting future research directions. Furthermore, we recommend three priority research directions: 1) Develop reasoning-enhanced LMs overcoming parameter limits via non-parametric activation. 2) Create interpretable LMs mirroring human decision processes (intuition vs. systematic thought) through problem-solving transparency. 3) Combine fuzzy/probabilistic methods with Transformers for real-world adaptability and adaptive evaluation frameworks. This work advances both theoretical understanding through its interdisciplinary perspective and offers concrete implementation blueprints for industry practitioners navigating LM adoption in decision-critical contexts.}
}
@article{ALLALCHERIF2025123906,
title = {Stepping out of the innovation race to embrace outnovation: Fostering well-being and responsible consumption through sustainability, simplicity, authenticity, and nostalgia},
journal = {Technological Forecasting and Social Change},
volume = {210},
pages = {123906},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123906},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524007042},
author = {Oihab Allal-Chérif and José Fernando Gallego-Nicholls and Agustin Carrilero-Castillo and Francisco Javier {Sendra Garcia}},
keywords = {Outnovation, Innovation, Sustainability, Simplicity, Authenticity, Nostalgia, Excellence},
abstract = {This article theorizes and characterizes the concept of “outnovation” as an alternative or a complement to innovation within the framework of grounded theory. Outnovation consists of stepping out of the unrelenting innovation race and removing all unnecessary innovations from a product, focusing instead on sustainability, simplicity, authenticity, and nostalgia. After presenting the dangers and limits of innovative strategies and disasters resulting from poorly mastered innovations, the research studies four different cases, which examples demonstrate that not innovating or suppressing innovations is not synonymous with bankruptcy. At a time when customers are looking for more sustainable products and when many economists advocate degrowth and less unbridled consumption, companies are looking for new forms of differentiation and value creation. Outnovating is a way of getting out of the vicious circle of endless innovation and meeting United Nations' Sustainable Development Goals.}
}
@article{ZHANG2024106553,
title = {Pre-gating and contextual attention gate — A new fusion method for multi-modal data tasks},
journal = {Neural Networks},
volume = {179},
pages = {106553},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106553},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024004775},
author = {Duoyi Zhang and Richi Nayak and Md Abul Bashar},
keywords = {Multi-modal data learning, Cross-attention module, Neural networks},
abstract = {Multi-modal representation learning has received significant attention across diverse research domains due to its ability to model a scenario comprehensively. Learning the cross-modal interactions is essential to combining multi-modal data into a joint representation. However, conventional cross-attention mechanisms can produce noisy and non-meaningful values in the absence of useful cross-modal interactions among input features, thereby introducing uncertainty into the feature representation. These factors have the potential to degrade the performance of downstream tasks. This paper introduces a novel Pre-gating and Contextual Attention Gate (PCAG) module for multi-modal learning comprising two gating mechanisms that operate at distinct information processing levels within the deep learning model. The first gate filters out interactions that lack informativeness for the downstream task, while the second gate reduces the uncertainty introduced by the cross-attention module. Experimental results on eight multi-modal classification tasks spanning various domains show that the multi-modal fusion model with PCAG outperforms state-of-the-art multi-modal fusion models. Additionally, we elucidate how PCAG effectively processes cross-modality interactions}
}
@article{MUSARAT2024102057,
title = {Automated monitoring innovations for efficient and safe construction practices},
journal = {Results in Engineering},
volume = {22},
pages = {102057},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102057},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024003116},
author = {Muhammad Ali Musarat and Abdul Mateen Khan and Wesam Salah Alaloul and Noah Blas and Saba Ayub},
keywords = {Construction monitoring, Traditional, Automation, Photogrammetry, Sensors, BIM},
abstract = {As construction projects increase in complexity, there are growing challenges with conventional monitoring methods in terms of efficiency, safety, and competitiveness. Traditional supervision techniques are labour-intensive, intermittent, and prone to errors. Hence, this study statistically evaluates the potential advantages of photogrammetry, sensors, and algorithms to enable continuous automated monitoring. The results of this survey were analysed to compare manual and automated monitoring systems. The outcome shows that the Malaysian construction industry is aware of Automated Monitoring Innovations for Efficient and Safe Construction Practices. The top ranked factor was Photogrammetry which had a relative importance index (RII) of 0.821 for straightforward site monitoring and 0.812 for accelerated 3D BIM modelling. The RII for sensors to track labourers, apparatus, and progress in real time was 0.82, while the RII for hazard anticipation was 0.796. Automation achieved a reduction in fatigue by 0.784, labour intensity by 0.792, and time demands by 0.768, as measured by the RII. A conceptual framework was developed that incorporates measurable improvements in schedules, safety, and quality control. Automated solutions, as opposed to human examinations which are prone to error, provided exhaustive geographical data and ongoing surveillance notwithstanding obstacles pertaining to cost, cybersecurity, privacy, and integration. Construction monitoring must incorporate new technology, strategic change management, data investments, and supporting regulations to increase profitability, safety, and efficiency as competition and complexity increase.}
}
@article{MOBARAK2023100523,
title = {Scope of machine learning in materials research—A review},
journal = {Applied Surface Science Advances},
volume = {18},
pages = {100523},
year = {2023},
issn = {2666-5239},
doi = {https://doi.org/10.1016/j.apsadv.2023.100523},
url = {https://www.sciencedirect.com/science/article/pii/S2666523923001575},
author = {Md Hosne Mobarak and Mariam Akter Mimona and Md. Aminul Islam and Nayem Hossain and Fatema Tuz Zohura and Ibnul Imtiaz and Md Israfil Hossain Rimon},
keywords = {Machine learning, Materials research, Machine learning methods, Material synthesis, Image processing},
abstract = {This comprehensive review investigates the multifaceted applications of machine learning in materials research across six key dimensions, redefining the field's boundaries. It explains various knowledge acquisition mechanisms starting with supervised, unsupervised, reinforcement, and deep learning techniques. These techniques are transformative tools for transforming unactionable data into insightful actions. Moving on to the materials synthesis, the review emphasizes the profound influence of machine learning, as demonstrated by predictive models that speed up material selection, structure-property relationships that reveal crucial connections, and data-driven discovery that fosters innovation. Machine learning reshapes our comprehension and manipulation of materials by accelerating discovery and enabling tailored design through property prediction models and structure-property relationships. Machine learning extends its influence to image processing, improving object detection, classification, and segmentation precision and enabling methods like image generation, revolutionizing the potential of image processing in materials research. The most recent developments show how machine learning can have a transformative impact at the atomic level by enabling precise property prediction and intricate data extraction, representing significant advancements in material understanding and innovation. The review highlights how machine learning has the potential to revolutionize materials research by accelerating discovery, improving performance, and stimulating innovation. It does so while acknowledging obstacles like poor data quality and complicated algorithms. Machine learning offers a wide range of exciting prospects for scientific investigation and technological advancement, positioning it as a powerful force for influencing the future of materials research.}
}
@article{KHATUA2024100812,
title = {FedGen: Federated learning-based green edge computing for optimal route selection using genetic algorithm in Internet of Vehicular Things},
journal = {Vehicular Communications},
volume = {49},
pages = {100812},
year = {2024},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2024.100812},
url = {https://www.sciencedirect.com/science/article/pii/S2214209624000871},
author = {Sushovan Khatua and Anwesha Mukherjee and Debashis De},
keywords = {Internet of Vehicular Things, Federated learning, Vehicular networks, Optimal route, Time consumption, Power consumption},
abstract = {Time-efficient route planning is a significant research area of Internet of Vehicular Things. Optimal route selection is important to reach the destination in minimal time. Further, energy efficiency is vital for route planning in a sustainable environment. To address these issues, this paper proposes a federated learning and genetic algorithm-based green edge computing framework for optimal route planning in Internet of Vehicular Things. The vehicles are connected to the road side unit. The road side unit processes the image and video of the road, and predicts the number of vehicles on the road. For video processing Region-based Convolutional Neural Network is used. The road side units send the result and the local model parameters to the regional server. The regional server determines the optimal route using modified genetic algorithm, and sends it to the vehicles and the cloud. Also, the regional server updates its model and sends the updated model parameters to the road side units. The road side units update their local models accordingly. The regional server also sends the model parameters to the cloud, and the cloud updates the global model. The cloud sends the updated model parameters to the regional servers. The regional servers update their models accordingly. The results present that above 90% accuracy is achieved by the proposed model. The results also present that using modified GA the proposed approach reduces time and power consumption to find the optimal route by ∼62% and ∼66% than the cloud-only model.}
}
@incollection{FREITASDEARAUJOFILHO2025111,
title = {Chapter 5 - Safeguarding IoT networks with generative adversarial networks},
editor = {Dinh Thai Hoang and Nguyen Quang Hieu and Diep N. Nguyen and Ekram Hossain},
booktitle = {Advanced Machine Learning for Cyber-Attack Detection in IoT Networks},
publisher = {Academic Press},
pages = {111-142},
year = {2025},
isbn = {978-0-443-29032-9},
doi = {https://doi.org/10.1016/B978-0-44-329032-9.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290329000105},
author = {Paulo {Freitas de Araujo-Filho} and Georges Kaddoum and Divanilson R. Campelo and Cleber Zanchettin},
keywords = {Generative adversarial networks, Cybersecurity, Internet of things},
abstract = {Although generative adversarial networks (GANs) were initially developed to generate images, they have proven to be extremely useful in various other domains, including IoT security. By simultaneously training two competing neural networks, namely the generator and the discriminator, GANs successfully estimate generative models by capturing data distributions. Additionally, they provide a discriminative model that estimates the probability of a sample being real rather than produced by the generator. These capabilities are particularly valuable in the unsupervised detection of attacks, where labeled attack data is not available. Hence, GANs have an important role in securing IoT devices. Furthermore, GANs have shown promising results in other IoT security tasks, such as defending against adversarial attacks and evaluating authentication systems. In this chapter, we present different formulations and variations of GANs, discuss their applications in IoT security, showcase state-of-the-art GAN-based security solutions, and explore the challenges and future research opportunities in the field of IoT security.}
}
@article{LEI2023110491,
title = {Prior knowledge-embedded meta-transfer learning for few-shot fault diagnosis under variable operating conditions},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110491},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110491},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023003990},
author = {Zihao Lei and Ping Zhang and Yuejian Chen and Ke Feng and Guangrui Wen and Zheng Liu and Ruqiang Yan and Xuefeng Chen and Chunsheng Yang},
keywords = {Intelligent fault diagnosis, Prior knowledge embedding, Few-shot learning, Meta-transfer learning, Variable operating conditions},
abstract = {In recent years, intelligent fault diagnosis based on deep learning has achieved vigorous development thanks to its powerful feature representation ability. However, scarcity of high-quality data, especially samples under severe fault states, and variable operating conditions have limited the industrial application of intelligent fault diagnosis. To alleviate this predicament, a novel prior knowledge-embedded meta-transfer learning (PKEMTL) is proposed for few-shot fault diagnosis with limited training data and scarce test data. The method focuses on the problem of few-shot fault diagnosis under variable operating conditions to improve adaptability. Different from traditional models, the PKEMTL employs a metric-based meta-learning framework and embeds prior knowledge to enable cross-task learning under variable operating conditions. Specifically, order tracking is firstly introduced as preliminary prior information for data augmentation, and then the augmented data are divided into a series of meta-tasks. Secondly, the meta-tasks are performed by lightweight multiscale feature encoding to obtain high-level feature representations. Next, the meta-learning module based on diagnostic knowledge embedding guides the model to acquire meta-knowledge of speed generalization by constructing the self-supervised task to embed additional prior knowledge into the meta-training process. The generalization performance of the model is further improved by adaptive information fusion learning as a comprehensive decision-making module. Two case studies under variable operating conditions are implemented to validate the effectiveness and superiority of the proposed few-shot fault diagnosis method.}
}
@article{AKKEM2024107881,
title = {A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {131},
pages = {107881},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000393},
author = {Yaganteeswarudu Akkem and Saroj Kumar Biswas and Aruna Varanasi},
keywords = {Variational autoencoders, Generative adversarial networks, Smart farming},
abstract = {In this study, we propose the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to generate synthetic data for crop recommendation (CR). CR is critical in agriculture, assisting farmers in making informed decisions about crop cultivation, considering factors like soil conditions, weather patterns etc. Unfortunately, the availability of labeled data for CR is often limited, posing a significant challenge in training accurate recommendation models. VAEs and GANs are employed to create synthetic data that closely mirrors real-world crop data. VAEs are utilized to extract latent representation from the input data, enabling the generation of new samples with similar characteristics. GANs play a crucial role in generating data by training a generator network to produce synthetic samples that closely resemble real data, while a discriminator network distinguishes between genuine and synthetic data. The generated synthetic data serves as a valuable resource to prepare datasets for CR, enhancing the performance of recommendation models. Our research explores the effectiveness of VAEs and GANs in producing high-quality synthetic CR data, facilitating improved training and evaluation of recommendation systems. This paper presents the architecture and training process of the proposed models and evaluates the quality and utility of the generated synthetic data using various experiments, including visualizations such as heatmaps, scatter plots, cumulative sum per feature plots, and distribution per feature plots. The results of this study hold the potential to make a significant contribution to the field of agriculture by providing a reliable and abundant source of training data for CR systems.}
}
@article{ZHAO2024109964,
title = {Domain generalization for cross-domain fault diagnosis: An application-oriented perspective and a benchmark study},
journal = {Reliability Engineering & System Safety},
volume = {245},
pages = {109964},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.109964},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024000395},
author = {Chao Zhao and Enrico Zio and Weiming Shen},
keywords = {Fault diagnosis, Domain shift, Domain generalization, Deep learning},
abstract = {Most data-driven methods for fault diagnostics rely on the assumption of independently and identically distributed data of training and testing. However, domain shift between the phases of training and testing is common in practice. Recently, domain generalization-based fault diagnosis (DGFD) has gained widespread attention for learning fault diagnosis knowledge from multiple source domains and applying it to unseen target domains. This paper summarizes the developments in DGFD from an application-oriented perspective. Firstly, basic definitions of DGFD and its variant applications are formulated. Then, motivations, goals, challenges and state-of-the-art solutions for different applications are discussed. The limitations of existing technologies are highlighted. A comprehensive benchmark study is carried out on eight open-source and two self-collected datasets to provide an understanding of the existing methods and a unified framework for researchers. Finally, several future directions are given. Our code is available at https://github.com/CHAOZHAO-1/DG-PHM.}
}
@incollection{OZCAN2025111,
title = {Chapter 5 - Dynamic relationalities across (stacked) strata},
editor = {Kerimcan Ozcan and Venkat Ramaswamy},
booktitle = {Dynamic Relationality Theory of Creative Transformation},
publisher = {Elsevier},
pages = {111-136},
year = {2025},
isbn = {978-0-443-30159-9},
doi = {https://doi.org/10.1016/B978-0-443-30159-9.00005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443301599000050},
author = {Kerimcan Ozcan and Venkat Ramaswamy},
keywords = {Becoming, Experiencial computing, Machinic generalized intelligence, Natural transformation, Reterritorialization, Technological singularity, Transcendence},
abstract = {In this chapter, explores the synergy between human intelligence (HI) and artificial intelligence (AI), emphasizing the transformative power of AI in digital ecosystems. It articulates the shift toward Machinic Generalized Intelligence (MGI), highlighting AI's role in creating immersive, personalized experiences. Through the lens of Dynamic Relationality Theory (DRT), it delves into “becoming” via lines of flight, marking departures from established structures toward new formations, with AI fostering technological singularity and healthcare evolution. It examines reterritorialization, where foundational cognitive processes evolve into complex systems, and the enrichment of the Experience-verse, blending organic and artificial elements for enhanced digital ecosystems. The chapter concludes by addressing identity and structure transformations within digital realms, underpinning the fluidity and continuous change integral to DRT's framework. This comprehensive analysis underscores the interdependent evolution of HI and AI, reinforcing their collective impact on advancing digital ecosystems.}
}
@article{ZHANG2025226,
title = {Targeting cuproptosis for cancer therapy: Focus on the anti-tumor immune system},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {3},
pages = {226-243},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000569},
author = {Xuan Zhang and Xiaohong Han},
keywords = {Cuproptosis, Copper homeostasis, Immunotherapy, Drug synergism},
abstract = {Copper (Cu) is an indispensable micronutrient that maintains signaling pathways and biological homeostasis in almost all cell types; however, its excess affects the tricarboxylic acid cycle, causes the accumulation of fatty acylated proteins, destabilization of iron–sulfur cluster proteins, and increases the levels of intracellular reactive oxygen species, leading to proteotoxic stress and cell death. Cuproptosis, a form of Cu-dependent cell death, differs from other types of regulated cell death (RCD) and was first reported in Science in 2022. Recently, the RCD pathways have been targeted in cancer therapy. However, the escape of apoptosis in tumor cells causes resistance to treatment and tumor recurrence. Therefore, there is an urgent need to study the alternative mechanisms of cancer cell mortality. Compared to normal patients, a significant increase in serum Cu ion levels has been observed in patients with tumors. Moreover, tumor cell proliferation, angiogenesis, and metastasis are associated with cuproptosis. Thus, exploring cancer signaling pathways related to cuproptosis will provide a new perspective for the development of anti-cancer drugs. Importantly, cuproptosis is closely associated with the modulation of anti-tumor immunity. The expression of cuproptosis-related genes (CRGs) is significantly correlated with immune cell infiltration and the immune checkpoint programmed cell death protein 1 (PD-1)/programmed death-ligand 1 (PD-L1). Based on these findings, a series of cuproptosis-related drugs have been used in tumor-targeted combination therapy or as immune synergists. Therefore, elucidating the role of cuproptosis per cancer stage and in the tumor immune microenvironment (TIME) is helpful in clarifying the potential value of Cu in the treatment of specific cancers. In this review, we summarize specific cancer signaling pathways related to cuproptosis and cancer treatment based on the regulation of Cu concentration. The combination of these two approaches may help researchers develop more therapies targeting cuproptosis-related pathways. Importantly, we focused on the effect of cuproptosis on the TIME and systematically discussed the role of CRGs in tumor immunity considering CRG-related anti-tumor immune signaling pathways, tumor prognosis scoring system, anti-tumor immunotherapy, and biological experiments and bioinformatics prediction models, to provide new ideas for the development of anticancer therapy targeting cuproptosis-related pathways.}
}
@article{DASGUPTA2025117425,
title = {Conditional score-based diffusion models for solving inverse elasticity problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {433},
pages = {117425},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.117425},
url = {https://www.sciencedirect.com/science/article/pii/S0045782524006807},
author = {Agnimitra Dasgupta and Harisankar Ramaswamy and Javier Murgoitio-Esandi and Ken Y. Foo and Runze Li and Qifa Zhou and Brendan F. Kennedy and Assad A. Oberai},
keywords = {Conditional generative models, Inverse problems, Bayesian inference, Diffusion-based modeling, Uncertainty quantification, Elastography},
abstract = {We propose a framework to perform Bayesian inference using conditional score-based diffusion models to solve a class of inverse problems in mechanics involving the inference of a specimen’s spatially varying material properties from noisy measurements of its mechanical response to loading. Conditional score-based diffusion models are generative models that learn to approximate the score function of a conditional distribution using samples from the joint distribution. More specifically, the score functions corresponding to multiple realizations of the measurement are approximated using a single neural network, the so-called score network, which is subsequently used to sample the posterior distribution using an appropriate Markov chain Monte Carlo scheme based on Langevin dynamics. Training the score network only requires simulating the forward model. Hence, the proposed approach can accommodate black-box forward models and complex measurement noise. Moreover, once the score network has been trained, it can be re-used to solve the inverse problem for different realizations of the measurements. We demonstrate the efficacy of the proposed approach on a suite of high-dimensional inverse problems in mechanics that involve inferring heterogeneous material properties from noisy measurements. Some examples we consider involve synthetic data, while others include data collected from actual elastography experiments. Further, our applications demonstrate that the proposed approach can handle different measurement modalities, complex patterns in the inferred quantities, non-Gaussian and non-additive noise models, and nonlinear black-box forward models. The results show that the proposed framework can solve large-scale physics-based inverse problems efficiently.}
}
@article{MIRONE2024108754,
title = {Combined rate-temperature effects in postnecking plasticity of A2-70 stainless steel},
journal = {International Journal of Mechanical Sciences},
volume = {262},
pages = {108754},
year = {2024},
issn = {0020-7403},
doi = {https://doi.org/10.1016/j.ijmecsci.2023.108754},
url = {https://www.sciencedirect.com/science/article/pii/S0020740323006562},
author = {Giuseppe Mirone and Raffaele Barbagallo and Luca Corallo},
keywords = {Thermal softening, Strain rate effect, Flow stress, Hopkinson bar, Necking},
abstract = {In this paper, a comprehensive study that integrates theoretical, experimental and FE analyses, elucidates the combined effect of strain, strain rate, and temperature on the mechanical response of A2-70 stainless steel. A wide series of tensile experiments on cylindrical specimens is presented, including low to high temperatures and quasi-static to dynamic rates. Opportune combinations of temperatures and strain rates are imposed in order to possibly separate and identify their respective effects on the flow curve of the material. The adopted experimental procedures based on neck-related measurements revealed the onset of secondary phenomena affecting dynamic tensile tests. Classical material models were found not suitable to correctly predict the complex elastoplastic deformation of this material. Thus, a new general material model is presented and used to account for the complex interplay between strain, temperature, and rate-dependent effects. Finite element simulations are conducted using both the proposed constitutive model and another classical model of dynamic hardening, to investigate and compare their predictive capability over the entire experimental campaign.}
}
@article{AGUSTI2024117377,
title = {Christensenella minuta mitigates behavioral and cardiometabolic hallmarks of social defeat stress},
journal = {Biomedicine & Pharmacotherapy},
volume = {180},
pages = {117377},
year = {2024},
issn = {0753-3322},
doi = {https://doi.org/10.1016/j.biopha.2024.117377},
url = {https://www.sciencedirect.com/science/article/pii/S0753332224012629},
author = {A. Agusti and GV. Molina-Mendoza and M. Tamayo and V. Rossini and MC. Cenit and C. Frances-Cuesta and V. Tolosa-Enguis and EM. {Gómez Del Pulgar} and A. Flor-Duro and Y. Sanz},
keywords = {Microbiota, Gut-brain axis, Behavior, Dopamine, Social defeat, Depression},
abstract = {Psychological stress during early development and adolescence may increase the risk of psychiatric and cardiometabolic comorbidities in adulthood. The gut microbiota has been associated with mental health problems such as depression and anxiety and with cardiometabolic disease, but the potential role of the gut microbiota in their comorbidity is not well understood. We investigated the effects and mode of action of the intestinal bacterium Christensenella minuta DSM 32891 on stress-induced mental health and cardiometabolic disturbances in a mouse model of social defeat stress. We demonstrate that administered C. minuta alleviates chronic stress-induced depressive, anxiogenic and antisocial behavior. These effects are attributed to the bacterium’s ability to modulate the hypothalamic-pituitary-adrenal axis, which mediates the stress response. This included the oversecretion of corticosterone and the overexpression of its receptors, as well as the metabolism of dopamine (DA) and the expression of its receptors (D1, D2L and D2S). Additionally, C. minuta administration reduced chronically induced inflammation in plasma, spleen and some brain areas, which likely contribute to the recovery of physical and behavioral function. Furthermore, C. minuta administration prevented chronic stress-induced cardiovascular damage by regulating key enzymes mediating liver fibrosis and oxidative stress. Finally, C. minuta increased the abundance of bacteria associated with mental health. Overall, our study highlights the potential of microbiota-directed interventions to alleviate both the physical and mental effects of chronic stress.}
}
@incollection{STANCIU2025443,
title = {Chapter 28 - Artificial intelligence for cancer care 4.0/5.0},
editor = {Tuan Anh Nguyen},
booktitle = {IoT-WSN-DT Based Medical Systems and Nanotechnology for Smart Cancer Care},
publisher = {Academic Press},
pages = {443-460},
year = {2025},
isbn = {978-0-443-33984-4},
doi = {https://doi.org/10.1016/B978-0-443-33984-4.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339844000079},
author = {Alexandru Stanciu and Elena Paraschiv},
keywords = {Artificial intelligence, Digital twins, Explainable AI, Generative AI, Machine learning, Oncology},
abstract = {The integration of artificial intelligence (AI) in healthcare has revolutionized cancer care, enabling earlier detection, more accurate prognoses, and tailored treatment strategies. This chapter explores the transition from Healthcare 4.0 to Healthcare 5.0, highlighting the shift from a technology-centric approach to one that is deeply personalized and patient-centered. In Healthcare 5.0, we envision the focus will be on leveraging AI to empower patients and create a truly patient-centric experience. This includes using predictive modeling to anticipate treatment outcomes, employing explainable AI (XAI) to ensure transparency and trust, and utilizing cutting-edge technologies such as generative AI and digital twins to simulate patient-specific disease progressions and treatment responses. The chapter delves into the foundational machine-learning techniques used in cancer diagnosis, such as supervised learning, unsupervised learning, deep learning, and reinforcement learning. It then explores more advanced AI technologies, including generative AI, XAI, and digital twins, and discusses their applications in cancer care. Additionally, the chapter emphasizes the importance of data curation and augmentation in ensuring the availability of high-quality, diverse datasets for AI systems. It also examines computational pathology, which combines traditional pathology with AI to analyze pathology data in unprecedented ways. This chapter provides a comprehensive overview of the current and future applications of AI in cancer care, highlighting its potential to transform the way cancer is diagnosed and treated.}
}
@article{BERKOWITZ2024102890,
title = {Filling successive technologically-induced governance gaps: Meta-organizations as regulatory innovation intermediaries},
journal = {Technovation},
volume = {129},
pages = {102890},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2023.102890},
url = {https://www.sciencedirect.com/science/article/pii/S0166497223002018},
author = {Heloise Berkowitz and Antoine Souchaud},
keywords = {Meta-Organization, Technologically-induced governance gap, Sectoral governance, Regulation, Innovation intermediaries, Digital innovation, Organizationality, Meta-organizational filiation},
abstract = {Successive digital innovations create technologically-induced governance gaps that make public regulation quickly obsolete and that might be filled by sectoral governance. The literature has shown that most sectoral governance happens at the level of meta-organizations, organizations whose members are themselves organizations, although we lack a temporal understanding of this phenomenon. Further, while regulation is generally understood as a salient function of innovation intermediaries, the literature on innovation intermediaries has focused mostly on other functions such as idea sourcing, knowledge sharing, or capacity building. We know relatively little about regulatory innovation intermediaries, especially how they might evolve in response to the emergence of technologically-induced governance gaps. In this paper, we conduct an in-depth case study of the evolutions of the FinTech sector in France over almost 30 years, using more than 3000 min of interviews, 4500 pages of archives, and non-participant observations. We study three successive (non)digital financial innovations: business angels, crowdfunding platforms for SMEs, and blockchain technologies. We develop a meta-organizational analysis to investigate meta-organizations as regulatory innovation intermediaries. We describe the evolutions and interrelations of new technologies and meta-organizations, and unpack mechanisms of meta-organizational capacity building for multiple contributors, effects of innovation on organizationality and trajectories of meta-organizational filiation.}
}
@article{ACERORUGE2025102434,
title = {Inteligencia artificial para el abordaje integral de las enfermedades huérfanas/raras: revisión sistemática exploratoria},
journal = {Medicina de Familia. SEMERGEN},
volume = {51},
number = {5},
pages = {102434},
year = {2025},
issn = {1138-3593},
doi = {https://doi.org/10.1016/j.semerg.2024.102434},
url = {https://www.sciencedirect.com/science/article/pii/S1138359324002442},
author = {L.M. {Acero Ruge} and D.A. {Vásquez Lesmes} and E.H. {Hernández Rincón} and L.P. {Avella Pérez}},
keywords = {Enfermedad huérfana, Enfermedad rara, Inteligencia artificial, Aprendizaje profundo, Aprendizaje automático, Diagnóstico por ordenador, Diagnóstico por imagen, Redes neuronales de la computación, Orphan diseases, Rare diseases, Artificial intelligence, Deep learning, Machine learning, Diagnosis, Computer assisted, Diagnostic imaging, Neuronal networks computer},
abstract = {Resumen
Introducción
Las enfermedades huérfanas (EH) son raras, pero colectivamente comunes, presentan desafíos como diagnósticos tardíos, progresión de la enfermedad y escasa oferta terapéutica. Recientemente, la inteligencia artificial (IA) ha ganado interés en la investigación de estas enfermedades.
Objetivo
Sintetizar la evidencia disponible sobre el uso de la IA en el abordaje integral de las enfermedades huérfanas.
Métodos
Se realizó una revisión sistemática exploratoria tipo «Scoping Review» en PubMed, Bireme, Scopus entre 2019 al 2024.
Resultados
Se identificaron 56 artículos con un 21,4% de estudios experimentales; 28 documentos no especifican una EH, 8 documentos tenían como grupo más estudiado enfermedades genéticas; el 53,57% se enfocaban en diagnóstico y se encuentran 36 algoritmos diferentes.
Conclusiones
La información encontrada muestra el desarrollo de algoritmos de IA en diferentes escenarios clínicos, los resultados confirman los potenciales beneficios en tiempo de diagnósticos, opciones terapéuticas y mayor sensibilización de los profesionales de la salud.
Introduction
Orphan diseases (OD) are rare but collectively common, presenting challenges such as late diagnoses, disease progression, and limited therapeutic options. Recently, artificial intelligence (AI) has gained interest in the research of these diseases.
Objective
To synthesize the available evidence on the use of AI in the comprehensive approach to orphan diseases.
Methods
An exploratory systematic review of the Scoping Review type was conducted in PubMed, Bireme, and Scopus from 2019 to 2024.
Results
fifty-six articles were identified, with 21.4% being experimental studies; 28 documents did not specify an OD, 8 documents focused primarily on genetic diseases; 53.57% focused on diagnosis, and 36 different algorithms were identified.
Conclusions
The information found shows the development of AI algorithms in different clinical settings, confirming the potential benefits in diagnosis times, therapeutic options, and greater awareness among health professionals.}
}
@incollection{EGHBAL202591,
title = {Chapter Five - Modernizing distribution networks for an electrified future: case study of Queensland, Australia},
editor = {Fereidoon Sioshansi},
booktitle = {Electrification and the Future of Decentralized Electricity Supply},
publisher = {Elsevier},
pages = {91-120},
year = {2025},
isbn = {978-0-443-34268-4},
doi = {https://doi.org/10.1016/B978-0-443-34268-4.00015-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443342684000159},
author = {Daniel Eghbal and Glenn Springall},
keywords = {Distributed Energy Resources (DER), distribution system operator (DSO), dynamic connections, grid modernization, Queensland, rooftop solar},
abstract = {This chapter summarizes key strategies that enabled Energex and Ergon Energy Network to achieve one of the highest per-capita uptakes of rooftop solar globally. The chapter outlines key foundational distribution system operator capabilities such as dynamic connections, distributed energy resource orchestration, and optimal operation of local renewable energy zones. The chapter concludes with recommendations for modernizing distribution networks, drawing on the case study of Queensland that collectively pave the way for a resilient, efficient, and customer-centric energy system.}
}
@article{TESSELAAR2025106325,
title = {Psychiatric comorbidity in substance use disorders, a systematic review of neuro-imaging findings},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {177},
pages = {106325},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106325},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425003264},
author = {Debbie R.M. Tesselaar and Arnt F.A. Schellekens and Judith R. Homberg and Jan Booij and Cyprien Guerrin},
keywords = {SUD, Addiction, Psychopathology, Comorbidity, Co-occurring psychiatric disorders, Neuro-imaging},
abstract = {Substance use disorder (SUD) have negative consequences for affected individuals and society. Current treatments are moderately effective, partly due to the large heterogeneity in SUDs, including co-occurring psychopathology. A better understanding of the mechanisms underlying these frequently co-occurring psychiatric conditions is required to develop individualized treatments to increase treatment success rates. We systematically reviewed case-control studies investigating neurobiological differences measured using neuroimaging between participants with SUD only and participants with SUD and co-occurring psychiatric disorders. We searched articles in four databases. Inclusion criteria further existed of an ICD and/or DSM diagnoses based on interview assessment or Fagerström test for Nicotine Dependence scores ≥ 5. We hypothesised that co-occurring psychopathology could (1) amplify the neurobiological effects of SUD, (2) attenuate it, (3) have unique neurobiological effects, or (4) have no additional neurobiological effects. From 10,076 unique records screened, we included a total of 26 articles investigating the effect of personality disorder cluster B and/or C (6), depression (4), PTSD (4), ADHD (4), schizophrenia (8), bipolar disorder (1) or anxiety disorders (1) on SUD. We found amplifying effects of co-occurring schizophrenia and personality disorder, unique effects of schizophrenia, ADHD and personality disorder, and attenuating or no effect of depression on SUD. Findings on PTSD were contradictory. In conclusion, different co-occurring psychiatric disorder have distinct effects on the neurobiology of SUD.}
}
@article{THOMAS2024121823,
title = {Leaf traits of Central-European beech (Fagus sylvatica) and oaks (Quercus petraea/robur): Effects of severe drought and long-term dynamics},
journal = {Forest Ecology and Management},
volume = {559},
pages = {121823},
year = {2024},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2024.121823},
url = {https://www.sciencedirect.com/science/article/pii/S037811272400135X},
author = {Frank M. Thomas and Sebastian Preusser and Bernhard Backes and Willy Werner},
keywords = {Climatic water balance, Compositional Nutrient Diagnosis, Drought stress, Leaf morphology, Nutrient concentration, Summer drought},
abstract = {In 2018—2020, Central-European forests suffered from extremely hot and dry summers. We used data from long-term forest monitoring of six stands of European beech (Fagus sylvatica) and two stands of oak (Quercus petraea/Q. robur) growing on different geological substrates in the climatically uniform state of Saarland (south-western Germany) for analyzing leaf traits of the period 2004—2021. We aimed at detecting overall effects of the drought on foliar morphology, nutrient concentrations, and injury, and long-term alterations in these traits. Across sites, drought resulted in a decrease in leaf size and specific leaf area (SLA) and increased fruiting in the beech and a decrease in the foliar nitrogen (N) concentrations in both tree genera. During drought, foliar calcium and manganese concentrations were lower and potassium (K) concentrations higher across the beech stands, whereas in the oak stands, drought led to a reduction in the foliar phosphorus (P) and magnesium (Mg) concentrations. High rates of anthropogenic N deposition during recent decades have resulted in high foliar N concentrations and low to deficient concentrations of P and, in the beech, of Mg. However, a significant (negative) long-term trend in leaf traits across the study sites was only found for the K concentration and necroses of the beech leaves. Foliar N correlated positively with SLA in the beech and with leaf size in the oak but was not related to herbivory. Chlorosis was the only leaf trait that, in the beech, correlated (negatively) with the climatic water balance. We conclude that even severe drought during three consecutive years does not seem to critically affect the nutrient supply to the two most important deciduous forest tree genera of Central Europe. In the beech, a decrease in leaf size and SLA might be used as an early indication of severe drought stress effects in regular monitoring programs.}
}
@article{VINOI2025106,
title = {Charting the course for adaptive selling: A systematic review and meta-analysis},
journal = {Industrial Marketing Management},
volume = {130},
pages = {106-127},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2025.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019850125001324},
author = {Nivin Vinoi and Amit Shankar and Priyavrat Sanyal},
keywords = {Adaptive selling, Systematic literature review, Lexicometric analysis, TCCM framework, Meta-analysis},
abstract = {This study aims to comprehensively analyze the current body of literature on adaptive selling behavior. Accordingly, it employs a hybrid review methodology that integrates systematic literature review, lexicometric analysis, and meta-analysis. This multifaceted approach facilitates both thematic and theoretical syntheses while revealing empirical inconsistencies through quantitative validation. The study further advances the field by developing a conceptual framework based on the antecedents–decisions–outcomes model and proposing a future research agenda based on theory-context-characteristics-method framework, encompassing emerging phenomena, such as technology-driven adaptive selling, gamification, and corporate social responsibility alignment. This novel triangulation of methods and the resulting integrated framework offer rich insights, charting a future roadmap for adaptive selling research.}
}
@article{SCHIFANO2025107591,
title = {High throughput edit distance computation on FPGA-based accelerators using HLS},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107591},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107591},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005557},
author = {Sebastiano Fabio Schifano and Marco Reggiani and Enrico Calore and Rino Micheloni and Alessia Marelli and Cristian Zambelli},
keywords = {DNA-based storage, Bioinformatics, Edit distance, HLS programming, FPGA, Performance analysis},
abstract = {Edit distance is a computational grand challenge problem to quantify the minimum number of editing operations required to modify one string of characters to the other, finding many applications of natural language processing. In recent years, relevant and increasing interest has also emerged from deoxyribonucleic acid (DNA) applications, like Next Generation Sequencing and DNA storage technologies. Both applications share two crucial features: i) the information is coded into the four bases of DNA and ii) the level of operational noise is still high causing errors in the data, requiring inclusion in the workflow of the computation of algorithms such as the edit distance for finding similarities between sequences. To boost this computation many solutions are available in the literature. Among them, the FPGAs are largely used since the data domain of those applications is strings of 4 characters represented as two-bit values, inconveniently fitting the basic data types of ordinary CPUs and GPUs, with additional benefits of providing a high level of parallelism and low processing latency. This contribution presents a computing- and energy-efficient design implementing the edit distance algorithm combining metaprogramming and High-Level Synthesis. We also assess the performance of our design targeting recent FPGA-based accelerators. Our solution uses nearly 90% of FPGA basic-block hardware resources achieving about 90% of computing efficiency delivering a maximum throughput of 16.8 TCUPS and an energy efficiency of 46 Mpair/Joule, enabling the use of FPGAs as a new class of accelerators for High Performance Computing in DNA applications.}
}
@article{FANG2025105264,
title = {Understanding the gender divide in digital literacy in four European countries: A comprehensive decomposition analysis using unconditional quantile regression},
journal = {Computers & Education},
volume = {229},
pages = {105264},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105264},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000326},
author = {Guangbao Fang and Jiaxin Wang and Philip Wing Keung Chan and Penelope Kalogeropoulos},
keywords = {Gender divide, Computer and information literacy, Computational thinking, Oaxaca-Blinder decomposition, Unconditional quantile regression decomposition},
abstract = {Digital literacy is crucial for adolescents’ future, yet significant gender divides persist, particularly in Computer and Information Literacy (CIL) and Computational Thinking (CT). This study examines the gender divide in CIL and CT among adolescents in four European countries, highlighting the gender-based disparities in digital literacy development. Based on ICILS 2018 data, this research identifies factors contributing to gender divides in CIL and CT using regression and decomposition methods. Findings indicate that females outperform males in CIL, while males excel in CT. Gender divides decrease as the percentiles of students’ proficiency levels increase. The explained portion of the gender divide in CIL and CT is consistently smaller than the unexplained portion across countries, suggesting that gender divide or unobserved factors may drive these divides. A comparison of OLS regression results with decomposition approaches indicates that the factors influencing digital literacy development differ from those contributing to the gender divide. Variation in the factors contributing to gender divides is greater across countries than within countries for both CIL and CT. These findings highlight the need to consider national digital environments and socio-cultural contexts in addressing gender divides in digital literacy. This study offers insights for policymakers and educators to address the gender divide in digital literacy.}
}
@article{KSHETRI2024101931,
title = {Metaverse for advancing government: Prospects, challenges and a research agenda},
journal = {Government Information Quarterly},
volume = {41},
number = {2},
pages = {101931},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101931},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X24000236},
author = {Nir Kshetri and Yogesh K. Dwivedi and Marijn Janssen},
keywords = {Augmented reality, Digital avatars, Electronic government, Digital government, Metaverse, Cityverse, Virtual reality},
abstract = {A number of government agencies have started deploying the Metaverse to connect better with their constituents. The Metaverse provides a rich interaction environment and has the potential to engage with, especially, the younger generation. However, the Metaverse's potential impact on the government sector has been given limited attention. This discussion paper aims to fill this void by reviewing the state of the art, analyzing possible roles of the Metaverse for governments and providing research directions. We found six facilitators and nine barriers and risks. The Metaverse offers much more than a virtual presence or copy of the physical world; significant transformations are needed in government to reap the benefits. Given the evolution of the Metaverse, government presence also needs to evolve, and different governments make different decisions about their Metaverse presence. We recommend more research into the nature, use, applications, transformations, and implications of the Metaverse on government functioning.}
}
@article{NGUYEN2024112059,
title = {GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT},
journal = {Journal of Systems and Software},
volume = {214},
pages = {112059},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001043},
author = {Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta}},
keywords = {ChatGPT, Code classification, CodeBERT, Pre-trained Models},
abstract = {Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.}
}
@article{CHAN2025112330,
title = {Effectiveness of symmetric metamorphic relations on validating the stability of code generation LLM},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112330},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112330},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003741},
author = {Pak Yuen Patrick Chan and Jacky Keung and Zhen Yang},
keywords = {Metamorphic testing, Metamorphic relation, True satisfaction, Large language model, Code generation},
abstract = {Pre-trained large language models (LLMs) are increasingly used in software development for code generation, with a preference for private LLMs over public ones to avoid the risk of exposing corporate secrets. Validating the stability of these LLMs’ outputs is crucial, and our study proposes using symmetric Metamorphic Relations (MRs) from Metamorphic Testing (MT) for this purpose. Our study involved an empirical experiment with ten LLMs (eight private and two public) and two publicly available datasets. We defined seven symmetric MRs to generate “Follow-up” datasets from “Source” datasets for testing. Our evaluation aimed to detect violations (inconsistent predictions) between “Source” and “Follow-up” datasets and assess the effectiveness of MRs in identifying correct and incorrect non-violated predictions from ground truths. Results showed that one public and four private LLMs did not violate “Case transformation of prompts” MR. Furthermore, effectiveness and performance results indicated that proposed MRs are effective tools for explaining the instability of LLM's outputs by “Case transformation of prompts”, “Duplication of prompts”, and “Paraphrasing of prompts”. The study underscored the importance of enhancing LLMs’ semantic understanding of prompts for better stability and highlighted potential future research directions, including exploring different MRs, enhancing semantic understanding, and applying symmetry to prompt engineering.}
}
@article{WANG2023109593,
title = {Verifying empirical predictive modeling of societal vulnerability to hazardous events: A Monte Carlo experimental approach},
journal = {Reliability Engineering & System Safety},
volume = {240},
pages = {109593},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109593},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023005070},
author = {Yi Victor Wang and Seung Hee Kim and Menas C. Kafatos},
keywords = {Hazard loss, Machine learning, Simulation, Social vulnerability, Societal system},
abstract = {With the emergence of large amounts of historical records on adverse impacts of hazardous events, empirical predictive modeling has been revived as a foundational paradigm for quantifying disaster vulnerability of societal systems. This paradigm models societal vulnerability to hazardous events as a vulnerability curve indicating an expected loss rate of a societal system with respect to a possible spectrum of intensity measure (IM) of an event. Although the empirical predictive models (EPMs) of societal vulnerability are calibrated on historical data, they should not be experimentally tested with data derived from field experiments on any societal system. Alternatively, in this paper, we propose a Monte Carlo simulation-based approach to experimentally test EPMs of societal vulnerability. Our study applied an eigenvalue-based method to generate data on societal experiences of IM and pre-event vulnerability indicators. True models were designed to simulate event loss data. Supervised machine learning (ML) models were then trained on simulated data and were found to provide similar predictive performances as the true models. Our results suggested that the calibrated ML-EPMs could effectively quantify societal vulnerability given a normally experienced IM. To extrapolate a vulnerability curve for large IMs, however, simple models should be preferred.}
}
@article{TAO2024361,
title = {Research of Preventive Maintenance Plans for Wind Power Equipment Based on Maintenance Knowledge Fusion Large Model},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {29},
pages = {361-366},
year = {2024},
note = {7th IFAC Conference on Engine and Powertrain Control, Simulation and Modeling E-COSM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.11.171},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324023127},
author = {Laifa Tao and Shangyu Li and Qixuan Huang and Zhengduo Zhao and Xuanyuan Su and Kaixin Jin},
keywords = {Fault prediction and health management, Wind power equipment, Large language models, Preventive maintenance, Supervised fine-tuning, Prompt learning},
abstract = {As an important energy equipment, wind power equipment have a wide range of applications worldwide. But its high equipment maintenance costs seriously affect the profits of wind power generation enterprises. Fault prediction and health management technology, as key technologies for optimizing maintenance methods and reducing maintenance costs, are of great significance for reduce the failure rate of wind power equipment, reduce maintenance costs, and promote the rapid development of the clean energy industry to generate excellent preventive maintenance plans for wind power equipment. However, the current development of wind power equipment maintenance plans heavily relies on expert experience and lacks reliable explanatory support. In this case, we propose a preventive maintenance plan generation method for wind power equipment based on maintenance knowledge fusion large model. Our solution generation process no longer relies on expert experience, but relies on the reasoning ability of the latest artificial intelligence technology large language model. We fine tune the pretrained base large model using data and knowledge from wind power equipment fault manuals and maintenance manuals, and design reasonable question and answer prompts to achieve intelligent generation of wind power equipment preventive maintenance plans. Finally, the effectiveness of the above method was verified through the manual materials of UP77 and UP82 fan equipment.}
}
@article{LI2025100894,
title = {A concise review of intelligent game agent},
journal = {Entertainment Computing},
volume = {52},
pages = {100894},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100894},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002623},
author = {Hui Li and Xinyi Pang and Bixia Sun and Kexin Liu},
keywords = {Intelligent agent, Artificial intelligence, Monte Carlo tree, Reinforcement learning, Large language models},
abstract = {Intelligent game agents are crafted using AI technologies to mimic player behavior and make decisions autonomously. Over the past decades, the scope of intelligent agents has broadened from chess to encompass content generation, player modeling, and result prediction, reflecting the field’s evolving and multifaceted nature. In this paper, we conduct a systematic review of recent literature on intelligent methods and applications of game agents, along with general game agent frameworks. Our findings suggest that creating general intelligent agents remains a significant challenge, yet it is worthwhile to explore methods that better integrate the strengths of different techniques to build more robust and adaptable intelligent game agents.}
}
@article{DENG2025127500,
title = {Research on intelligent prediction method of supersonic flow field in scramjet based on deep learning: A review},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127500},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127500},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425011224},
author = {Xue Deng and Ye Tian and Erda Chen and Maotao Yang and Hua Zhang and Jialing Le},
keywords = {Deep learning, Flow field prediction, Model lightweight, Physical constraints, Scramjet},
abstract = {Direct numerical simulation (DNS) serves as a crucial method for optimizing and validating scramjets, significantly advancing their design process. Nonetheless, solving the Navier-Stokes equations numerically entails substantial computational expenses, particularly for large-scale projects characterized by intricate hysteresis and high-precision thermochemical reactions. In recent years, numerous studies have demonstrated the rationality and efficacy of deep learning in reconstructing the evolutionary characteristics of flow fields. To reduce neural network models’ dependence on high-fidelity data and prevent the generation of non-physical solutions, neural networks incorporating physical information constraints offer a novel learning paradigm. This approach encodes prior knowledge and physical interpretability, which traditional neural networks lack. Based on this, this study investigates, analyzes, and summarizes traditional prediction methods for supersonic combustion flow, data-driven intelligent solution algorithms for supersonic flow fields, lightweight neural network models, and intelligent prediction algorithms for flow fields using physical information neural networks.}
}
@article{ZHU2025103412,
title = {Fostering children's dispositional autonomy and AI understanding through co-designing AI systems: A learning science perspective},
journal = {International Journal of Human-Computer Studies},
volume = {196},
pages = {103412},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103412},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001952},
author = {Yumeng Zhu and Samantha-Kaye Johnston and Caifeng Zhu and Yan Li},
keywords = {AI education, Co-design, Learning science, K-12, Child-centered AI, Design methods, Autonomy},
abstract = {Co-designing AI systems with children to foster their autonomy has gained traction in the child-computer interaction community. However, the prerequisites for co-designing with a focus on children's dispositional autonomy, their intentional inclination to determine their own actions, and their understanding of AI, have not been thoroughly examined. This study contributes to child-centered co-design research methodologies from the perspective of learning science, aiming to enhance children's dispositional autonomy and AI understanding through co-design activities. A 14-week curriculum based on the Learning by Design (LBD) framework was developed, incorporating activities that require co-designing AI systems with students. 116 middle school students, organized into 24 groups, engaged with the curriculum. Through the analysis of pre-and post-questionnaires, storytelling drawings, and co-design worksheets, we assessed how the LBD curriculum influenced students’ dispositional autonomy and how students’ understandings (perceptions and demands) of AI systems changed during this process. Our findings indicate that the LBD curriculum significantly impacted students’ dispositional autonomy in two of the three dimensions that were assessed (authorship/congruence and interest-taking), and students transitioned from passive users to active engagers of AI. Based on students’ designs, we further propose designing AI systems with children-in-the-loop approaches. We provide a conceptual framework for categorizing the types of digital nudges provided by AI systems. This framework aims to foster children's dispositional autonomy and enhance their understanding of AI by facilitating self-regulation in their interactions with these systems.}
}
@article{BOUCHER2024104041,
title = {Smart PSS modelling language for value offer prototyping: A design case study in the field of heating appliance offers},
journal = {Computers in Industry},
volume = {155},
pages = {104041},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104041},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001914},
author = {Xavier Boucher and Camilo Murillo Coba and Damien Lamy},
keywords = {Smart PSS, Design prototypes, Value offer design, Conceptual models},
abstract = {The recent convergence between two industrial transitions towards digitalization on the one side and servitization on the other side led to the new business strategies of digital servitization and smart PSS delivery. While inheriting from the previous scientific literature on PSS, because of the multiple impacts of digitalization in the overall system, the processes of ensuring the design and engineering of smart PSS solutions poses new challenges. This research addresses the specific needs to develop conceptual prototypes of smart PSS value offers, at early stages of the design process. The paper presents the development and experimentation of a modelling language and its associated modelling toolkit (sPS²Modeller). The application case study addresses the design of a smart PSS in the field of heating appliances, developed in collaboration with the company elm.leblanc, Bosch Group – France.}
}
@article{ERRAZURIZ2025101057,
title = {Prevalence of anxiety disorders in Latin America: a systematic review and meta-analysis},
journal = {The Lancet Regional Health - Americas},
volume = {45},
pages = {101057},
year = {2025},
issn = {2667-193X},
doi = {https://doi.org/10.1016/j.lana.2025.101057},
url = {https://www.sciencedirect.com/science/article/pii/S2667193X25000675},
author = {Antonia Errazuriz and Dalia Avello-Vega and Alvaro Passi-Solar and Rafael Torres and Felix Bacigalupo and Nicolas A. Crossley and Eduardo A. Undurraga and Peter B. Jones},
keywords = {Anxiety disorders, Prevalence, Latin America, Systematic review, Meta-analysis, Global mental health},
abstract = {Summary
Background
The prevalence of anxiety disorders among the adult population in Latin America (LATAM) and its association with development indicators is insufficiently characterised. We estimated pooled regional, country, and sex-specific prevalence rates of anxiety disorders in LATAM based on International Classification of Diseases (ICD) or Diagnostic and Statistical Manual of Mental Disorders (DSM) criteria. Additionally, we examined the association between its prevalence and four country-level development indicators: Human Development Index (HDI), income inequality (Gini coefficient), Gender Inequality Index (GII), and Intentional Homicide Rate (IHR).
Methods
We conducted a systematic review and meta-analysis of population-based studies on the prevalence of ICD/DSM anxiety disorders in LATAM from 1990 to 2024, irrespective of language. We searched PubMed, PsycINFO, Cochrane Library, SciELO, LILACS, and grey literature. Study quality was assessed using JBI's critical appraisal tools. Pooled estimates were generated using random-effects meta-analysis, and heterogeneity was evaluated using the I-squared (I2) statistic. Meta-regression analyses were performed to examine the ecological association between anxiety disorders prevalence and four development indicators. The study was registered with PROSPERO (CRD42020190238).
Findings
Using data from 36 studies in LATAM, we calculated the lifetime, 12-month, and current prevalence of ICD/DSM anxiety disorders at 14.55% (95% Confidence Interval 12.32%–17.11%; I2 = 97.9%); 6.61% (5.20–8.37; I2 = 98.1%), and 3.27% (2.34–4.56; I2 = 97.5%), respectively. Heterogeneity was high across prevalence periods, sexes, and countries (all I2 ≥ 91.4%), warranting caution in interpreting pooled estimates. Elevated 12-month and current prevalence rates of anxiety disorders were associated with higher Gini coefficients (p ≤ 0.0013). Additionally, higher current prevalence was associated with lower HDI (p = 0.0103) and higher GII (p = 0.0023), while elevated 12-month prevalence was associated with higher IHR (p = 0.011).
Interpretation
This study shows that approximately one in seven people in LATAM experience anxiety disorders at some point in their lives. These findings highlight the need to strengthen mental health systems in the region, and evidence the association between prevalence of anxiety disorders and development indicators. Our results can serve as a baseline for tracking anxiety disorders and for informed decision-making at the national and regional levels. The substantial heterogeneity between studies and the underrepresentation of some countries underscore the imperative for enhancing regional mental health capacities.
Funding
Pfizer Independent Medical Education Grant (69879319).}
}
@article{GWAGWA2024101078,
title = {How could the United Nations Global Digital Compact prevent cultural imposition and hermeneutical injustice?},
journal = {Patterns},
volume = {5},
number = {11},
pages = {101078},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101078},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400237X},
author = {Arthur Gwagwa and Warmhold Jan Thomas Mollema},
keywords = {AI governance, AI regulation, Global Digital Compact, United Nations, cultural imposition, hermeneutical injustice, domination, artificial intelligence, AI ethics, AI colonialism},
abstract = {Summary
As the geopolitical superpowers race to regulate the digital realm, their divergent rights-centered, market-driven, and social-control-based approaches require a global compact on digital regulation. If diverse regulatory jurisdictions remain, forms of domination entailed by cultural imposition and hermeneutical injustice related to AI legislation and AI systems will follow. We argue for consensual regulation on shared substantive issues, accompanied by proper standardization and coordination. Failure to attain consensus will fragment global digital regulation, enable regulatory capture by authoritarian powers or bad corporate actors, and deepen the historical geopolitical power asymmetries between the global South and the global North. To prevent an unjust regulatory landscape where the global South’s cultural and hermeneutic resources are absent, two principles for the Global Digital Compact to counter these prospective harms are proposed and discussed: (1) “recognitive consensus on key substantive benefits and harms” and (2) “procedural consensus on global coordination and essential standards.”}
}
@article{JACOB2025,
title = {AI for IMPACTS Framework for Evaluating the Long-Term Real-World Impacts of AI-Powered Clinician Tools: Systematic Review and Narrative Synthesis},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67485},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125001797},
author = {Christine Jacob and Noé Brasier and Emanuele Laurenzi and Sabina Heuss and Stavroula-Georgia Mougiakakou and Arzu Cöltekin and Marc K Peter},
keywords = {eHealth, assessment, adoption, implementation, artificial intelligence, clinician, efficiency, health technology assessment, clinical practice},
abstract = {Background
Artificial intelligence (AI) has the potential to revolutionize health care by enhancing both clinical outcomes and operational efficiency. However, its clinical adoption has been slower than anticipated, largely due to the absence of comprehensive evaluation frameworks. Existing frameworks remain insufficient and tend to emphasize technical metrics such as accuracy and validation, while overlooking critical real-world factors such as clinical impact, integration, and economic sustainability. This narrow focus prevents AI tools from being effectively implemented, limiting their broader impact and long-term viability in clinical practice.
Objective
This study aimed to create a framework for assessing AI in health care, extending beyond technical metrics to incorporate social and organizational dimensions. The framework was developed by systematically reviewing, analyzing, and synthesizing the evaluation criteria necessary for successful implementation, focusing on the long-term real-world impact of AI in clinical practice.
Methods
A search was performed in July 2024 across the PubMed, Cochrane, Scopus, and IEEE Xplore databases to identify relevant studies published in English between January 2019 and mid-July 2024, yielding 3528 results, among which 44 studies met the inclusion criteria. The systematic review followed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) guidelines and the Cochrane Handbook for Systematic Reviews. Data were analyzed using NVivo through thematic analysis and narrative synthesis to identify key emergent themes in the studies.
Results
By synthesizing the included studies, we developed a framework that goes beyond the traditional focus on technical metrics or study-level methodologies. It integrates clinical context and real-world implementation factors, offering a more comprehensive approach to evaluating AI tools. With our focus on assessing the long-term real-world impact of AI technologies in health care, we named the framework AI for IMPACTS. The criteria are organized into seven key clusters, each corresponding to a letter in the acronym: (1) I—integration, interoperability, and workflow; (2) M—monitoring, governance, and accountability; (3) P—performance and quality metrics; (4) A—acceptability, trust, and training; (5) C—cost and economic evaluation; (6) T—technological safety and transparency; and (7) S—scalability and impact. These are further broken down into 28 specific subcriteria.
Conclusions
The AI for IMPACTS framework offers a holistic approach to evaluate the long-term real-world impact of AI tools in the heterogeneous and challenging health care context and lays the groundwork for further validation through expert consensus and testing of the framework in real-world health care settings. It is important to emphasize that multidisciplinary expertise is essential for assessment, yet many assessors lack the necessary training. In addition, traditional evaluation methods struggle to keep pace with AI’s rapid development. To ensure successful AI integration, flexible, fast-tracked assessment processes and proper assessor training are needed to maintain rigorous standards while adapting to AI’s dynamic evolution.
Trial Registration
reviewregistry1859; https://tinyurl.com/ysn2d7sh}
}
@article{YAO2024e33531,
title = {The evolution of the ambidextrous innovation synergy strategy of new entrants from the perspective of key core technology monopoly},
journal = {Heliyon},
volume = {10},
number = {13},
pages = {e33531},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e33531},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024095628},
author = {Shuang Yao and Leke Wu and Donghua Yu},
keywords = {Key core technology, New entrants, Ambidextrous innovation synergy, Original innovation search, Network embedding},
abstract = {Ambidextrous innovation synergy is an effective way for new entrants and R&D entities to break the blockade of key core technologies. This paper constructs a tripartite evolutionary game model of new entrants, the R&D entity, and monopoly enterprises under the monopoly situation of key core technologies, discusses the dynamic equilibrium process of how new entrants cooperate with the R&D entity to carry out the ambidextrous innovation synergy strategy, and extends the model to the policy subsidy situations of different development stages of key core technology. The results show that the monopoly of key core technologies enhances the original innovation search ability of new entrants and promotes the evolution of enterprise imitation innovation to the exploratory innovation strategy. In the basic research stage of key core technology, the exploratory innovation strategy of new entrants is more sensitive to the cost of network embedding and the original innovation knowledge search. New entrants prefer the imitation innovation strategy, and policy subsidies have no significant effect on exploratory innovation. In the promotion stage of the key core technology market, fiscal and tax subsidies can more easily promote the evolution of new entrants from the imitative innovation strategy to the exploratory innovation strategy than R&D subsidies, and network embeddedness can induce enterprises to carry out exploratory innovation only when a certain threshold is reached. In addition, this paper discusses the influence mechanism of monopoly enterprises' suppression intensities and key core technology breakthrough probabilities on the evolution equilibrium of new entrants' ambidextrous innovation synergy strategies.}
}
@article{LASTAUSKAS2024106918,
title = {Labor market policies in high- and low-interest rate environments: Evidence from the euro area},
journal = {Economic Modelling},
volume = {141},
pages = {106918},
year = {2024},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2024.106918},
url = {https://www.sciencedirect.com/science/article/pii/S026499932400275X},
author = {Povilas Lastauskas and Julius Stakėnas},
keywords = {Labor market policies, Non-linear responses, Mallow’s  criterion, Average local projections, Low and high interest rate environments},
abstract = {Do labor market policies initiated in periods of loose monetary policy yield different outcomes from those introduced when monetary tightening prevails? Using data from 11 euro-area members up to 2010 – and extending to 17 countries up to 2020 – we analyze three labor market policies: replacement rates, spending on active labor market policies (ALMPs), and employment protection. We find that these policies deliver different macroeconomic outcomes in low- and high-interest rate environments. In particular, ALMPs reduce unemployment if implemented under a loose monetary policy but not otherwise, whereas higher employment protection delivers expansionary effects under a tight monetary policy. These findings highlight that the effectiveness of labor market policies is significantly influenced by the monetary policy environment, emphasizing the need for coordinated policy design. Methodologically, we contribute by proposing to average local projections using Mallow’s Cp criterion, allowing for inferences that are robust to mis-specification and accommodate non-linearities.}
}
@article{HASAN2025,
title = {Mushrooms as Potent Autophagy Modulators in Cancer Therapy: Current Evidence and Therapeutic Prospects},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000916},
author = {Md.Mahmudul Hasan and Eva Azme and Rashedul Alam and Md.Jahirul Islam Mamun and Md.Tanvir Chowdhury and Md.Hossain Rasel and Md.Safayat Hossen Momen and Neamul Hoque and Md.Ekramul Haque Ekram and Nazmul Hasan Eshaque and Shakil Ahmed and Md.Tashrif Rahman Tipu and Sanjida Shahid Juthi and Mohammad Fazlul Kabir and Ahsan Ullah and Md.Liakot Ali and S.M.Moazzem Hossen and Hea-Jong Chung},
keywords = {Mushroom, autophagy, cancer, traditional medicine, functional food, Endoplasmic reticulum stress},
abstract = {Mushrooms, recognized for their culinary and medicinal applications, are emerging as potential sources of autophagy modulators in cancer treatment. Autophagy is cellular degradation triggered by organelle damage, protein aggregation, metabolic disturbances, or nutrient scarcity. It contributes to the suppression of early tumor development and the promotion of cancer cell survival at advanced stages. This review systematically assesses the current evidence on the anticancer potential of mushrooms and their bioactive compounds, focusing on their ability to modulate autophagy. The review lists over 18 mushroom species (e.g., Ganoderma lucidum, Cordyceps, Phellinus) and 28 bioactive compounds (such as Ganoderic acid DM, Cordycepin, Hispidin) that affect autophagy, demonstrating efficacy against 15 cancer types, including colorectal, lung, breast, and liver cancers. Essential compounds modulate autophagy through phosphoinositide 3-kinase (PI3K)/protein kinase B (Akt)/mechanistic target of rapamycin (mTOR), AMP-activated protein kinase (AMPK), and Beclin-1 pathways, resulting in notable anticancer effects. G. lucidum extracts quantitatively reduced colorectal tumor growth by up to 60% in vivo. Additionally, Cordycepin induced autophagic cell death in lung cancer cells, with IC50 values as low as 25 μmol/L.The findings highlight the potential of mushrooms as low-toxicity adjuvants to conventional therapies, providing advantages such as immune modulation and antioxidant activity. Mushrooms and their bioactive components present promising avenues for cancer therapy through the modulation of autophagy. The context-dependent effects of autophagy, along with the limited clinical evidence, present considerable challenges. Future clinical trials must focus on developing standardized extracts and personalized approaches to effectively translate this potential into clinical practice.}
}
@article{SPRUTE2025101609,
title = {Land use and land cover classification on high-resolution UAV images for heavy rainfall hazard maps using deep neural networks},
journal = {Remote Sensing Applications: Society and Environment},
volume = {38},
pages = {101609},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101609},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525001624},
author = {Dennis Sprute and Hanne Hendrickx and Pedro Zamboni and Muhtasimul Islam Rushdi and Florian Brodrecht and Anette Eltner and Holger Flatt},
keywords = {Land use/cover classification, UAV, RGB images, Heavy rainfall hazard maps, Semantic segmentation, Deep neural networks},
abstract = {The increasing frequency and intensity of extreme weather events due to climate change highlight the need for accurate hazard mapping for heavy rainfall. Land use and land cover (LULC) maps, along with digital elevation models (DEMs) and meteorological data, are essential to construct these hazard maps. For this purpose, LULC maps must be of high resolution to capture small hydrodynamically relevant structures and up-to-date to reflect constant changes driven by human activities. Uncrewed aerial vehicles (UAVs) are ideal for acquiring these high-resolution images because of their cost effectiveness, flexibility, and detail. However, no publicly available datasets and approaches currently provide urban LULC maps at this level of detail (<5 cm) while considering classes relevant for constructing heavy rainfall hazard maps. Therefore, this article presents a novel approach for LULC classification using high-resolution UAV imagery to enhance the generation of heavy rainfall hazard maps. We develop a comprehensive processing pipeline that includes UAV data collection, orthophoto creation, and LULC classification using advanced deep learning architectures. Our method tackles challenges such as differing between 22 LULC classes with objects of varying sizes and managing imbalanced datasets. Additionally, we create a high-resolution UAV image dataset with more than 12K annotated images. A comprehensive evaluation of 29 deep learning architectures reveals that CFNet with an EfficientNetB4 backbone achieves the best performance, with an accuracy of 0.911 and a Mean Intersection over Union (IoU) of 0.738. The results demonstrate that our approach effectively classifies hydrodynamically relevant structures, such as different roof types, street materials, and drainage facilities. This work establishes a solid foundation for future research and practical applications in the automated generation of accurate heavy rainfall hazard maps, ultimately aiming to improve risk management strategies in the context of climate change.}
}
@article{ALMOGREN2024e31887,
title = {Exploring factors influencing the acceptance of ChatGPT in higher education: A smart education perspective},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31887},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31887},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079180},
author = {Abeer S. Almogren and Waleed Mugahed Al-Rahmi and Nisar Ahmed Dahri},
keywords = {Smart education, ChatGPT, Higher education, Acceptance factors, Technology adoption},
abstract = {AI-powered chatbots hold great promise for enhancing learning experiences and outcomes in today's rapidly evolving education system. However, despite the increasing demand for such technologies, there remains a significant research gap regarding the factors influencing users' acceptance and adoption of AI-powered chatbots in educational contexts. This study aims to address this gap by investigating the factors that shape users' attitudes, intentions, and behaviors towards adopting ChatGPT for smart education systems. This research employed a quantitative research approach, data were collected from 458 of participants through a structured questionnaire designed to measure various constructs related to technology acceptance, including perceived ease of use, perceived usefulness, feedback quality, assessment quality, subject norms, attitude towards use, and behavioral intention to use ChatGPT. Structural model analysis (SEM) Statistical techniques were then utilized to examine the relationships between these constructs. The findings of the study revealed that Perceived ease of use and perceived usefulness emerged as significant predictors of users' attitudes towards ChatGPT for smart education. Additionally, feedback quality, assessment quality, and subject norms were found to positively influence users' behavioral intentions to use ChatGPT for smart educational purposes. Moreover, users' attitudes towards use and behavioral intentions were significantly proved for the actual adoption of ChatGPT. However, a few hypotheses, such as the relationship between trust in ChatGPT and perceived usefulness, were not supported by the data. This study contributes to the existing body information systems applications for the determining factor of technology acceptance in smart education context.}
}
@article{BAABDULLAH2024122951,
title = {Generative conversational AI agent for managerial practices: The role of IQ dimensions, novelty seeking and ethical concerns},
journal = {Technological Forecasting and Social Change},
volume = {198},
pages = {122951},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122951},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523006364},
author = {Abdullah M. Baabdullah},
keywords = {Generative conversational AI agent, Information quality, Novelty seeking, Ethical concerns, Decision-making efficiency, Innovation performance},
abstract = {This study aims to identify and empirically examine the influence of the main factors related to the content quality of generative conversational AI agents on decision-making efficiency. Additionally, this study explores the ramifications of decision-making efficiency facilitated by generative conversational AI agents in organisational innovation performance. This study proposes a model based on the information quality model as well as other factors, such as novelty seeking and ethical concerns. Data from this study was collected using online questionnaires from a purposive sample size of 228 employees in business organisations. Based on Structural Equation Modelling (SEM) analyses using AMOS, the results support the significant impact of information quality (intrinsic information quality, contextual information quality, representational information quality, and accessibility of information quality) on decision-making efficiency. The results also support the significant impact of novelty seeking and ethical concerns on decision-making efficiency. Decision-making efficiency was also found to have a significant positive impact on innovation performance. This empirical study makes a considerable contribution as it is among the first to expand the current understanding of the effective use of generative conversational AI agents in managerial practices (i.e. decision-making and innovation).}
}
@article{JENKINSON2024114908,
title = {Pizza3: A general simulation framework to simulate food-mechanical and food-deconstruction problems},
journal = {Food Research International},
volume = {194},
pages = {114908},
year = {2024},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2024.114908},
url = {https://www.sciencedirect.com/science/article/pii/S0963996924009785},
author = {William Jenkinson and Brian Guthrie and Denis Flick and Olivier Vitrac},
keywords = {Food Micromechanics, Hybrid numerical simulation, Smoothed Particle Hydrodynamics, Molecular Dynamics-like simulation, LAMMPS, Oral processing, Texture Perception, Mesoscopic modeling, Soft matter, Granular flow},
abstract = {Current mesh-based simulation approaches face significant challenges in continuously modeling the mechanical behaviors of foods through processing, storage, deconstruction, and digestion. This is primarily due to the limitations of continuum mechanics in dealing with systems characterized by free boundaries, substantial deformations, mechanical failures, and non–homogenized mechanical properties. The dynamic nature of food microstructure and the transformation of the food bolus, in relation to its composition, present formidable obstacles in computer-aided food design. In response, the Pizza3 project adopts an innovative methodology, utilizing an explicit microstructural representation to construct and subsequently deconstruct food products in a modular, Lego-like fashion. Central to this simulation approach are “food atoms”, conceptualized from the principles of smoothed particle hydrodynamics. These units are significantly larger than actual atoms but are finely scaled to represent both solid and liquid states of food faithfully. In solid phases, food atoms interact via pairwise forces akin to bond-peridynamic methods, thus extending the capabilities of continuum mechanics to encompass large deformations and fracturing phenomena. For liquids, the model employs artificial conservative and dissipative forces, enabling the simulation of a variety of phenomena within the framework of partial compressibility. The interaction dynamics between rigid and soft objects and fluids are accurately captured through Hertzian contact mechanics, offering a versatile parameterization applicable to impermeable (but possibly penetrable) surfaces and enforcing no-slip conditions. The efficacy of this framework is showcased through the successful modeling of three time-dependent 3D scenarios, each rigorously validated against established analytical and experimental models. Advancing beyond these initial applications, the framework is further extended to more intricate cases inadequately addressed in current literature. This extension sheds light on the underlying mechanisms of in-mouth texture perception, offering new insights and tools for food engineering and design.}
}
@article{SILVA2024107698,
title = {Mapping the landscape of energy markets research: A bibliometric analysis and predictive assessment using machine learning},
journal = {Energy Economics},
volume = {136},
pages = {107698},
year = {2024},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2024.107698},
url = {https://www.sciencedirect.com/science/article/pii/S0140988324004067},
author = {Thiago Christiano Silva and Tercio Braz and Benjamin Miranda Tabak},
keywords = {Clean energy, Bibliometrics, Machine learning, Volatility spillover, Energy markets, Crude-oil},
abstract = {This study examines the evolving dynamics of research on the energy market that focuses on understanding its interactions and interdependencies with other markets. Using published articles from 2002 to 2022 indexed by the Web of Science, we employ bibliometric methods, complex network measurements, and machine learning algorithms to analyze trends and predict academic success or interest. Our bibliometric analysis highlights the growing emphasis on new topics, such as clean energy, over traditional energy topics like crude oil and volatility spillovers. In a horse-race setup, we use supervised regression techniques to predict the paper’s academic success, measured in terms of the average number of citations over the years. We use meta-information from the paper, including keywords, as predictive attributes. The Random Forest achieves the best out-of-sample performance. We complement this analysis by using Shapley Additive Explanations to assess the contribution of each attribute to the overall prediction, thus allowing model interpretability. We find non-linear relationships between some numeric attributes, such as the number of keywords in the paper, and the target variable, highlighting the flexibility of non-linear methods compared to linear ones. Our findings offer valuable insights into emerging research trends and provide educators, policymakers, and finance professionals with critical information to navigate the evolving landscape of energy market research.}
}
@article{LIPNICKAS2025101017,
title = {Adaptive online course design: Analysis of changes in student behaviour throughout the degree lifecycle},
journal = {The Internet and Higher Education},
volume = {66},
pages = {101017},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101017},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000260},
author = {Gediminas Lipnickas and Joanne Harris and Bora Qesja and Svetlana {De Vos}},
keywords = {Learning analytics, Learning design, Engagement patterns, Academic performance, Online learning environments, Course design},
abstract = {With the growth of the online higher education sector, educational institutions are increasingly creating asynchronous online courses resembling Massive Open Online Courses (MOOCs), characterised by reduced interpersonal interactions. While these courses offer higher flexibility for students, much remains unknown about how the design of these courses impacts student behaviour and performance. This study combines learning analytics and learning design (via Open University Learning Design Initiative (OULDI) taxonomy) to examine effective online course design elements in a 100 % online environment. Effectiveness is evaluated based on the impact of design elements on student engagement and performance. Student engagement patterns throughout the degree are also explored. Results show that while assimilative activities are those most frequently undertaken by students, they rank as fourth in impact on performance. Experiential, interactive/adaptive, and productive activities, though more impactful, are less common and constitute only a fraction of online course design activities. Students were also more likely to engage with videos as opposed to readings, indicating a preference for this type of content in the online learning environment. Furthermore, an inverse correlation was found between students attempting a range of activities, and the need to communicate with staff (i.e., asking for clarification/guidance). Results also identified six types of student engagement patterns, revealing a transition over time towards an assessment focus, where students self-optimise and prioritise assessment completion (over other content/activities). In an online environment, where introducing sequential/scaffolding activities may prove difficult, findings indicate that activities should be clearly linked to assessments to cater for student engagement patterns.}
}
@article{202584,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {5},
number = {1},
pages = {84-90},
year = {2025},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(25)00007-5},
url = {https://www.sciencedirect.com/science/article/pii/S2667102625000075}
}
@article{WANG2024105965,
title = {Do not go gentle into that good night: The European Union's and China's different approaches to the extraterritorial application of artificial intelligence laws and regulations},
journal = {Computer Law & Security Review},
volume = {53},
pages = {105965},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105965},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000323},
author = {Yan Wang},
keywords = {Artificial intelligence, Extraterritorial effects, Global governance},
abstract = {The extraterritorial application of artificial intelligence (AI) laws and regulations is a form of global AI governance. The EU and China serve as two different examples of how to achieve the extraterritorial applicability of AI laws and regulations. The former shows an explicit territorial extension with more trigger factors, whereas the latter shows vertical regulation with a narrower territorial scope. Both countries’ legislative motivations differ but also have some commonalities. One of the primary goals of extraterritorial application of domestic laws is to protect citizens within their territory. The digital economy's characteristics make it necessary for AI laws to have extraterritorial effects. Without international conventions or treaties, there is a legal vacuum in AI regulation. Additionally, the extraterritorial application of AI laws and regulations helps a state become a global standard-setter and gain an international sphere of influence. However, the extraterritorial application of AI laws and regulations sometimes functions as a form of legal imperialism. This exacerbates the injustice between great powers and weak countries in AI competition. To justify the legitimacy of the extraterritorial application of AI laws and regulations, it is beneficial to adopt the ‘inner morality of extraterritoriality’, a theoretical framework proposed by Professor Dan Svantesson. In fact, extraterritorial applicability depends on the market size and attractiveness. For other countries, whether their AI laws and regulations are endowed with extraterritorial effects is their prerogative. However, they should consider their soft power before implementing legislation.}
}
@article{SUNMOLA2024813,
title = {Artificial Intelligence Opportunities for Resilient Supply Chains},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {19},
pages = {813-818},
year = {2024},
note = {18th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.09.195},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324016148},
author = {Funlade Sunmola and George Baryannis},
keywords = {supply chain resilience, artificial intelligence, explainability, industry 5.0},
abstract = {The need for supply chains to be resilient is increasingly being recognised, following recent disruptions caused by global socioeconomic crises. Supply chain resilience allows for sustainable growth and development through adaptive capabilities, principally including the ability to effectively respond to disruptions to maintain consistent operations. This paper explores the opportunities presented by Artificial Intelligence (AI) in enhancing supply chain resilience. We first conceptualise resilience through a 4-C model: context, capabilities, choices, and contingencies. We then explore a range of AI approaches and develop a research roadmap that attempts to map particular technologies holding potential to the 4-C model.}
}
@article{GUO2025104804,
title = {The impact of parental involvement, social support, and peer relationships on L2 learning motivation: A mixed-methods study of Chinese university EFL students},
journal = {Acta Psychologica},
volume = {254},
pages = {104804},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.104804},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825001179},
author = {Zikai Guo and Chen Chen and Ruifang Guo},
keywords = {Parental involvement, Social support, Peer relationships, L2 learning motivation, EFL, Mixed-methods approach, Chinese university students},
abstract = {This mixed-methods study investigated the impact of parental involvement, social support, and peer relationships on L2 learning motivation among Chinese university students learning English as a foreign language (EFL). Quantitative data from 326 students and qualitative data from semi-structured interviews with 20 students were analyzed. Hierarchical regression analyses revealed that parental involvement significantly predicted all three components of L2 motivation: ideal L2 self, ought-to L2 self, and L2 learning experience. Peer relationships also positively predicted ideal L2 self and L2 learning experience. While social support was not a significant predictor in the quantitative analyses, the analysis of the qualitative data revealed its nuanced role, with students emphasizing the importance of diverse sources of support, including peers, teachers, mentors, and online communities, in fostering a sense of belonging and enhancing motivation. The study highlights the complex interplay of familial and social influences on L2 motivation, offering valuable insights for educators and parents in supporting EFL learners.}
}
@article{GUEVARA2025101090,
title = {Trends and perspectives on bacterial nanocellulose: A comprehensive analysis from the three helixes of innovation},
journal = {Materials Today Sustainability},
volume = {30},
pages = {101090},
year = {2025},
issn = {2589-2347},
doi = {https://doi.org/10.1016/j.mtsust.2025.101090},
url = {https://www.sciencedirect.com/science/article/pii/S2589234725000193},
author = {Kleber Mora Guevara and Gustavo Martínez-Valenzuela and Viviana Sánchez-Vásquez and Keyla Guerrero-Ruiz and Manuel Fiallos-Cárdenas},
keywords = {Bacterial cellulose, Sustainability, Biorefinery, Bioprocesses, Waste biomass, Bibliometry},
abstract = {Bacterial nanocellulose (BNC) stands out as a nanocrystalline material with a wide range of unique properties, including high mechanical strength, biodegradability, biocompatibility, and transparency. This versatility has attracted great interest in various fields, from biomedicine and materials engineering to the food industry and environmental technology. The present study focused on assessing the impact of BNC's scientific production within the framework of the three helixes of innovation and identifying trends in research and technological development. To this end, a comprehensive bibliometric analysis of 4814 peer-reviewed articles published between 2013 and 2023 was conducted, using the SCOPUS database and analyzing the information through Rstudio's Bibliometrix package. The results revealed an approximate annual growth of 15.67% in BNC's scientific output, with an average of 33.56 citations per paper. China was positioned as a leader in this output, backed by strong government commitment and considerable funding for sustainability-focused research. It is notable that BNC studies contribute mainly to the Sustainable Development Goals (SDGs), with SDGs 3, 6, 7, 9, 12, and 17 standing out. Despite the current trend towards process optimization and exploration of BNC-producing microorganisms, a lack of research in life cycle analysis and techno-economic analysis was identified. It is suggested that the implementation of biorefinery approaches, the utilization of residual biomass, and the evaluation of energy efficiency and exergy analysis could potentially significantly improve the process of obtaining BNC, providing a more sustainable and efficient approach to its production with multiple applications in various industrial sectors.}
}
@article{ZHANG2024103140,
title = {Media opinion divergence and stock returns: Evidence from China},
journal = {International Review of Financial Analysis},
volume = {93},
pages = {103140},
year = {2024},
issn = {1057-5219},
doi = {https://doi.org/10.1016/j.irfa.2024.103140},
url = {https://www.sciencedirect.com/science/article/pii/S1057521924000723},
author = {Zuochao Zhang and John W. Goodell and Dehua Shen and Oumaima Lahmar},
keywords = {Media opinion divergence, Textual analysis, Latent Dirichlet Allocation, Generative probabilistic modeling},
abstract = {We construct a proxy for media opinion divergence using Latent Dirichlet Allocation. With this proxy, we investigate the impact of media opinion divergence on Chinese stocks. Findings indicate that higher media opinion divergence results in higher stock returns, but leads to lower future stock returns, consistent with Miller (1987). Additionally, we similarly explore the impact of divergence between traditional media and new media on stock returns, obtaining similar results. Findings are robust to controlling for firm characteristics and the number of news articles. Our study provides valuable insights into how the media can influence investor opinions and in turn the stock market in the digital media era.}
}
@article{MARTINEZPANDIANI2025100317,
title = {‘Toxic’ memes: A survey of computational perspectives on the detection and explanation of meme toxicities},
journal = {Online Social Networks and Media},
volume = {47},
pages = {100317},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100317},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000187},
author = {Delfina S. {Martinez Pandiani} and Erik {Tjong Kim Sang} and Davide Ceolin},
keywords = {Internet memes, Toxicity, Information quality, Multimodal discourse},
abstract = {Internet memes are multimodal, highly shareable cultural units that condense complex messages into compact forms of communication, making them a powerful vehicle for information spread. Increasingly, they are used to propagate hateful, extremist, or otherwise ‘toxic’ narratives, symbols, and messages. Research on computational methods for meme toxicity analysis has expanded significantly over the past five years. However, existing surveys cover only studies published until 2022, resulting in inconsistent terminology and overlooked trends. This survey bridges that gap by systematically reviewing content-based computational approaches to toxic meme analysis, incorporating key developments up to early 2024. Using the PRISMA methodology, we extend the scope of prior analyses, resulting in a threefold increase in the number of reviewed works. This study makes four key contributions. First, we expand the coverage of computational research on toxic memes, reviewing 158 content-based studies, including 119 newly analyzed papers, and identifying over 30 datasets while examining their labeling methodologies. Second, we address the lack of clear definitions of meme toxicity in computational research by introducing a new taxonomy that categorizes different toxicity types, providing a more structured foundation for future studies. Third, we observe that existing content-based studies implicitly focus on three key dimensions of meme toxicity—target, intent, and conveyance tactics. We formalize this perspective by introducing a structured framework that models how these dimensions are computationally analyzed across studies. Finally, we examine emerging trends and challenges, including advancements in cross-modal reasoning, the integration of expert and cultural knowledge, the increasing demand for automatic toxicity explanations, the challenges of handling meme toxicity in low-resource languages, and the rising role of generative AI in both analyzing and generating ‘toxic’ memes.}
}
@article{HOSSEINI2024142594,
title = {Mutual impacts of changing climate and flexible pavement performance considering resilience and sustainable aspects},
journal = {Journal of Cleaner Production},
volume = {460},
pages = {142594},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.142594},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624020420},
author = {Fatemeh Hosseini and Mahdi Nasimifar and Nadarajah Sivaneswaran and Amir Golalipour},
keywords = {Changing climate, Pavement performance, Life-cycle assessment, Sustainability, Resilience},
abstract = {Roads play a vital role in transportation systems, and their construction and maintenance expenses are high. Those reasons make crucial the examination of factors that accelerate road deterioration and those factors' negative impacts on societies. Climatic-related elements, especially temperature and precipitation, significantly affect the quality and lifespans of roads. The Intergovernmental Panel on Climate Change has reported that increasing greenhouse gas (GHG) emissions is causing changes in climate and that the rate of change has accelerated during the past several decades. To assess the impacts of changing climatic parameters on flexible-pavement performance, this study used 32 climate models to evaluate the performance of interstate, primary, and secondary roads across 11 diverse locations with varying traffic and climatic conditions. The study's findings reveal that changing climate exacerbates pavement distresses, leading to reduced pavement lifespans and increased numbers of reconstruction projects, which in turn raise demands for materials and equipment and contribute to higher GHG emissions. The effects of changing climate and changing climate's associated economic and environmental costs make the application of various engineering solutions to enhance pavement resilience essential, as described in this paper, in the absence of comprehensive emissions reduction strategies.}
}