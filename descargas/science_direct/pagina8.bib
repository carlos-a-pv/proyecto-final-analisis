@article{ZHU2024,
title = {The Evaluation of Generative AI Should Include Repetition to Assess Stability},
journal = {JMIR mHealth and uHealth},
volume = {12},
year = {2024},
issn = {2291-5222},
doi = {https://doi.org/10.2196/57978},
url = {https://www.sciencedirect.com/science/article/pii/S2291522224000792},
author = {Lingxuan Zhu and Weiming Mou and Chenglin Hong and Tao Yang and Yancheng Lai and Chang Qi and Anqi Lin and Jian Zhang and Peng Luo},
keywords = {large language model, generative AI, ChatGPT, artificial intelligence, health care},
abstract = {The increasing interest in the potential applications of generative artificial intelligence (AI) models like ChatGPT in health care has prompted numerous studies to explore its performance in various medical contexts. However, evaluating ChatGPT poses unique challenges due to the inherent randomness in its responses. Unlike traditional AI models, ChatGPT generates different responses for the same input, making it imperative to assess its stability through repetition. This commentary highlights the importance of including repetition in the evaluation of ChatGPT to ensure the reliability of conclusions drawn from its performance. Similar to biological experiments, which often require multiple repetitions for validity, we argue that assessing generative AI models like ChatGPT demands a similar approach. Failure to acknowledge the impact of repetition can lead to biased conclusions and undermine the credibility of research findings. We urge researchers to incorporate appropriate repetition in their studies from the outset and transparently report their methods to enhance the robustness and reproducibility of findings in this rapidly evolving field.}
}
@article{BRAGAZZI2025,
title = {Proficiency, Clarity, and Objectivity of Large Language Models Versus Specialists’ Knowledge on COVID-19's Impacts in Pregnancy: Cross-Sectional Pilot Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/56126},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25001064},
author = {Nicola Luigi Bragazzi and Michèle Buchinger and Hisham Atwan and Ruba Tuma and Francesco Chirico and Lukasz Szarpak and Raymond Farah and Rola Khamisy-Farah},
keywords = {COVID-19, vaccine, reproductive health, generative artificial intelligence, large language model, chatGPT, google bard, microsoft copilot, vaccination, natural language processing, obstetric, gynecology, women, text mining, sentiment, accuracy, zero shot, pregnancy, readability, infectious},
abstract = {Background
The COVID-19 pandemic has significantly strained health care systems globally, leading to an overwhelming influx of patients and exacerbating resource limitations. Concurrently, an “infodemic” of misinformation, particularly prevalent in women’s health, has emerged. This challenge has been pivotal for health care providers, especially gynecologists and obstetricians, in managing pregnant women’s health. The pandemic heightened risks for pregnant women from COVID-19, necessitating balanced advice from specialists on vaccine safety versus known risks. In addition, the advent of generative artificial intelligence (AI), such as large language models (LLMs), offers promising support in health care. However, they necessitate rigorous testing.
Objective
This study aimed to assess LLMs’ proficiency, clarity, and objectivity regarding COVID-19’s impacts on pregnancy.
Methods
This study evaluates 4 major AI prototypes (ChatGPT-3.5, ChatGPT-4, Microsoft Copilot, and Google Bard) using zero-shot prompts in a questionnaire validated among 159 Israeli gynecologists and obstetricians. The questionnaire assesses proficiency in providing accurate information on COVID-19 in relation to pregnancy. Text-mining, sentiment analysis, and readability (Flesch-Kincaid grade level and Flesch Reading Ease Score) were also conducted.
Results
In terms of LLMs’ knowledge, ChatGPT-4 and Microsoft Copilot each scored 97% (32/33), Google Bard 94% (31/33), and ChatGPT-3.5 82% (27/33). ChatGPT-4 incorrectly stated an increased risk of miscarriage due to COVID-19. Google Bard and Microsoft Copilot had minor inaccuracies concerning COVID-19 transmission and complications. In the sentiment analysis, Microsoft Copilot achieved the least negative score (–4), followed by ChatGPT-4 (–6) and Google Bard (–7), while ChatGPT-3.5 obtained the most negative score (–12). Finally, concerning the readability analysis, Flesch-Kincaid Grade Level and Flesch Reading Ease Score showed that Microsoft Copilot was the most accessible at 9.9 and 49, followed by ChatGPT-4 at 12.4 and 37.1, while ChatGPT-3.5 (12.9 and 35.6) and Google Bard (12.9 and 35.8) generated particularly complex responses.
Conclusions
The study highlights varying knowledge levels of LLMs in relation to COVID-19 and pregnancy. ChatGPT-3.5 showed the least knowledge and alignment with scientific evidence. Readability and complexity analyses suggest that each AI’s approach was tailored to specific audiences, with ChatGPT versions being more suitable for specialized readers and Microsoft Copilot for the general public. Sentiment analysis revealed notable variations in the way LLMs communicated critical information, underscoring the essential role of neutral and objective health care communication in ensuring that pregnant women, particularly vulnerable during the COVID-19 pandemic, receive accurate and reassuring guidance. Overall, ChatGPT-4, Microsoft Copilot, and Google Bard generally provided accurate, updated information on COVID-19 and vaccines in maternal and fetal health, aligning with health guidelines. The study demonstrated the potential role of AI in supplementing health care knowledge, with a need for continuous updating and verification of AI knowledge bases. The choice of AI tool should consider the target audience and required information detail level.}
}
@article{CHANG2025116501,
title = {Assessing bias in AI-driven psychiatric recommendations: A comparative cross-sectional study of chatbot-classified and CANMAT 2023 guideline for adjunctive therapy in difficult-to-treat depression},
journal = {Psychiatry Research},
volume = {348},
pages = {116501},
year = {2025},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2025.116501},
url = {https://www.sciencedirect.com/science/article/pii/S0165178125001490},
author = {Yu Chang and Yi-Chun Liu and Si-Sheng Huang and Wen-Yu Hsu},
keywords = {Generative artificial intelligence, Artificial intelligence, Depression, Guideline, Evidence-based medicine},
abstract = {The integration of chatbots into psychiatry introduces a novel approach to support clinical decision-making, but biases in their recommendations pose significant concerns. This study investigates potential biases in chatbot-generated recommendations for adjunctive therapy in difficult-to-treat depression, comparing these outputs with the Canadian Network for Mood and Anxiety Treatments (CANMAT) 2023 guidelines. The analysis involved calculating Cohen’s kappa coefficients to measure the overall level of agreement between chatbot-generated classifications and CANMAT guidelines. Differences between chatbot-generated and CANMAT classifications for each medication were assessed using the Wilcoxon signed-rank test. Results reveal substantial agreement for high-performing models, such as Google AI's Gemini 2.0 Flash, which achieved the highest Cohen’s kappa value of 0.82 (SE = 0.052). In contrast, OpenAI’s o1 model showed a lower agreement of 0.746 (SE = 0.057). Notable discrepancies were observed in the overestimation of medications such as quetiapine and lithium and the underestimation of modafinil and ketamine. Additionally, a distinct bias pattern was observed in OpenAI’s chatbots, which demonstrated a tendency to over-recommend lithium and bupropion. Our study highlights both the promise and the challenges of employing AI tools in psychiatric practice, and advocates for multi-model approaches to mitigate bias and improve clinical reliability.}
}
@article{SIRNOORKAR2024100318,
title = {Student and AI responses to physics problems examined through the lenses of sensemaking and mechanistic reasoning},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100318},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100318},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001218},
author = {Amogh Sirnoorkar and Dean Zollman and James T. Laverty and Alejandra J. Magana and N. Sanjay Rebello and Lynn A. Bryan},
keywords = {Generative-AI, Sensemaking, Mechanistic reasoning, Physics problem solving},
abstract = {Several reports in education have called for transforming physics learning environments by promoting sensemaking of real-world scenarios in light of curricular ideas. Recent advancements in Generative-Artificial Intelligence have garnered increasing traction in educators' community by virtue of its potential to transform STEM learning. In this exploratory study, we adopt a mixed-methods approach in comparatively examining student- and AI-generated responses to two different formats of a physics problem through the theoretical lenses of sensemaking and mechanistic reasoning. The student data is derived from think-aloud interviews of introductory students and the AI data comes from ChatGPT's (versions 3.5 and 4o) solutions collected using Zero shot approach. The results highlight AI responses to evidence most features of the two processes through well-structured solutions and student responses to effectively leverage representations in their solutions through iterative refinement of arguments. In other words, while AI responses reflect how physics is talked about, the student responses reflect how physics is practiced. Implications of these results in light of development and deployment of AI systems in physics pedagogy are discussed.}
}
@article{BEGHETTO2025101121,
title = {Partnering with AI for instrument development: Possibilities and pitfalls},
journal = {New Ideas in Psychology},
volume = {76},
pages = {101121},
year = {2025},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2024.101121},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X24000497},
author = {Ronald A. Beghetto and Wendy Ross and Maciej Karwowski and Vlad P. Glăveanu},
keywords = {, , , , , , , },
abstract = {Recent advances in generative artificial intelligence (AI), specifically large language models (LLMs), provide new possibilities for researchers to partner with AI when developing and refining psychological instruments. In this paper we demonstrate how LLMs, such as OpenAI's ChatGPT 4 model, might be used to support the development of new psychometric scales. Partnering with AI for the purpose of developing and refining instruments, however, comes with its share of potential pitfalls. We thereby discuss throughout the paper that instrument development and refinement start and end with human judgment and expertise. We open with two use-cases that describe how we used LLMs in the development and refinement of two new psychological instruments. Next, we discuss possibilities for where and how researchers can use LLMs in the process of instrument development more broadly, including considerations for maximizing the benefits of LLMs and addressing the potential hazards when working with LLMs. Finally, we close by offering initial suggestions for psychology researchers interested in partnering with LLMs in this capacity.}
}
@article{VERMA2025139,
title = {Industry 6.0: Vision, technical landscape, and opportunities},
journal = {Alexandria Engineering Journal},
volume = {130},
pages = {139-174},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1110016825009354},
author = {Ashwin Verma and Vivek Kumar Prasad and Aparna Kumari and Pronaya Bhattacharya and Gautam Srivastava and Kai Fang and Wei Wang and Thippa Reddy Gadekallu},
keywords = {Industry 6.0, Explainable AI, 6G, Dew computing, Quantum computing, Internet-of-Anything},
abstract = {Industry 5.0 is designed with the objective of leveraging collaboration between human intelligence and cyber-driven processes. It aims to present customized manufacturing solutions to the end users as per demand. Despite its promising benefits in the current production landscape, Industry 5.0 faces critical challenges in scalability, workforce transition to collaborate with advanced technologies, high production costs, and privacy and security challenges in the post-quantum era. Thus, necessitates a shift towards more advanced Industrial paradigm that modernize and reinvent operations to synergize with high end sustainable and scalable machineries, products and processes. Industry 6.0 is defined as ubiquitous, hyper-customer driven, virtualized, and sustainable manufacturing, where focus is towards hyper-connected factories and dynamic supply chains. Industry 6.0 is expected to connect cross-vertical applications, and in this paper, we present a tutorial-based survey on the vision, technical landscape, and advancements which would drive the Industry 6.0. New concepts are introduced over Industry 5.0 processes to support industrial applications like supply-chain based productions, human–robotic industrial pipelines, green computing, and generative artificial intelligence (GAI) induction in control processes. We highlight the key enablers to support the 6.0 vision-automated digital twins, metaverse-assisted virtual production, 6G, dew computing, GAI Cobots Networks (GOBOTs), Internet-of-Anything (IoX), quantum-assisted nano production, and other technologies. We highlight the reference architecture, Industry 6.0 vision, features, components, and the threats surrounding Industry 6.0, and solutions. We also present the sustainability aspects of Industry 6.0, and finally discuss future challenges and directions. The article is presented to assist researchers, industry practitioners, and allied stakeholders to design cost-effective, customized, and process driven Industrial operations.}
}
@article{MISHRA202589,
title = {Leveraging Generative AI for Drug Safety and Pharmacovigilance},
journal = {Current Reviews in Clinical and Experimental Pharmacology},
volume = {20},
number = {2},
pages = {89-97},
year = {2025},
issn = {2772-4328},
doi = {https://doi.org/10.2174/0127724328311400240823062829},
url = {https://www.sciencedirect.com/science/article/pii/S2772432825000121},
author = {Hara Prasad Mishra and Rachna Gupta},
keywords = {Generative AI, Chat -GPT, pharmacovigilance, drug safety, patient safety, artificial intelligence, machine learning},
abstract = {Predictions are made by artificial intelligence, especially through machine learning, which uses algorithms and past knowledge. Notably, there has been an increase in interest in using artificial intelligence, particularly generative AI, in the pharmacovigilance of pharmaceuticals under development, as well as those already in the market. This review was conducted to understand how generative AI can play an important role in pharmacovigilance and improving drug safety monitoring. Data from previously published articles and news items were reviewed in order to obtain information. We used PubMed and Google Scholar as our search engines, and keywords (pharmacovigilance, artificial intelligence, machine learning, drug safety, and patient safety) were used. In toto, we reviewed 109 articles published till 31st January 2024, and the obtained information was interpreted, compiled, evaluated, and conclusions were reached. Generative AI has transformative potential in pharmacovigilance, showcasing benefits, such as enhanced adverse event detection, data-driven risk prediction, and optimized drug development. By making it easier to process and analyze big datasets, generative artificial intelligence has applications across a variety of disease states. Machine learning and automation in this field can streamline pharmacovigilance procedures and provide a more efficient way to assess safety-related data. Nevertheless, more investigation is required to determine how this optimization affects the caliber of safety analyses. In the near future, the increased utilization of artificial intelligence is anticipated, especially in predicting side effects and Adverse Drug Reactions (ADRs).}
}
@article{BAUCON2024112027,
title = {Life in an Artinskian (Cisuralian) Permian megacaldera: Benthic palaeoecology in the shadow of the Bolzano Supervolcano (Athesian Volcanic District, Italy)},
journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
volume = {638},
pages = {112027},
year = {2024},
issn = {0031-0182},
doi = {https://doi.org/10.1016/j.palaeo.2024.112027},
url = {https://www.sciencedirect.com/science/article/pii/S0031018224000166},
author = {Andrea Baucon and Corrado Morelli and Carlos {Neto de Carvalho} and Evelyn Kustascher},
keywords = {Supervolcano, Freshwater, Trace fossils, Caldera, Planolites, Artificial intelligence},
abstract = {Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment.}
}
@article{HUANG2024100302,
title = {Examining the relationship between the L2 motivational self system and technology acceptance model post ChatGPT introduction and utilization},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100302},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100302},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400105X},
author = {Jerry Huang and Atsushi Mizumoto},
keywords = {The L2 motivational self system, Ideal L2 self, Ought-to L2 self, L2 learning experience, Technology acceptance model, ChatGPT},
abstract = {Since the introduction of the L2 Motivational Self System (L2MSS), numerous studies worldwide have highlighted its effectiveness in elucidating Second Language Acquisition. However, the influence of generative artificial intelligence (GenAI) technology on this model remains largely unexplored. The Technology Acceptance Model (TAM) is a widely employed framework for examining the impact of a new technology, and this study explores the intercorrelation when these two models are considered together. Conducted with 35 s-year university English as a foreign language (EFL) students in humanities, the study involved two sessions of instructor-led ChatGPT usage writing workshops, followed by the collection of survey responses. Data analysis unveiled a notable correlation between the L2 Motivational Self System and the Technology Acceptance Model. Particularly noteworthy is the finding that Ought-to L2 Self positively predict Actual Usage. The study discusses pedagogical and theoretical implications, along with suggesting future research directions.}
}
@article{SHARMASHARMA2023150,
title = {How does transformational leadership impact organizational unlearning: insights from persistence theories},
journal = {Journal of Organizational Change Management},
volume = {37},
number = {1},
pages = {150-172},
year = {2023},
issn = {0953-4814},
doi = {https://doi.org/10.1108/JOCM-07-2023-0302},
url = {https://www.sciencedirect.com/science/article/pii/S0953481423001641},
author = {ShubhamShubham SharmaSharma and UshaUsha LenkaLenka},
keywords = {Organizational unlearning, Transformational leadership, Persistence theories, Higher education},
abstract = {Purpose
Empirical attempts to recommend enabling mechanisms for organizational unlearning are sparse and have almost neglected the vital role of leadership in transforming organizations through unlearning. Based on the tenets of persistence theories like path-dependence and imprinting theory, this study examines the relationship between transformational leadership and unlearning with the mediating role of knowledge sharing, transparent internal communication and intrapreneurship.
Design/methodology/approach
To analyze the hypothesized relationship between these constructs, data were collected from 452 faculty members working in Centrally Funded Technical Institutions (CFTIs) in India. The data were analyzed using Process macro (Hayes, 2022).
Findings
The results show a significant effect of transformational leadership on organizational unlearning. This effect is mediated by transparent internal communication and intrapreneurship. However, knowledge sharing did not mediate the relationship between transformational leadership and organizational unlearning.
Practical implications
The Fourth Industrial Revolution, Covid-19, the rise of generative artificial intelligence tools like ChatGPT and policy reforms have pushed higher educational institutions to transform by unlearning old practices and experimenting with new ones. This paper informs how educational institutions can initiate and sustain the unlearning process.
Originality/value
Persistence theories like path-dependence and imprinting theory suggest that organizations often stick with proven success formulas and find it challenging to adopt new practices. Moreover, path dependence theorists advocate the role of an external intervening mechanism to break away from rigid and inefficient routines (or paths). This paper argues that in addition to external events (e.g. crisis, etc.), transformational leaders combined with organizational processes also help in unlearning obsolete knowledge and routines.}
}
@article{ILLE20231014,
title = {AI interprets the Central Dogma and Genetic Code},
journal = {Trends in Biochemical Sciences},
volume = {48},
number = {12},
pages = {1014-1018},
year = {2023},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S096800042300230X},
author = {Alexander M. Ille and Michael B. Mathews},
keywords = {artificial intelligence, ChatGPT, natural language processing, large language models, Central Dogma, Sequence Hypothesis},
abstract = {Generative artificial intelligence (AI) is a burgeoning field with widespread applications, including in science. Here, we explore two paradigms that provide insight into the capabilities and limitations of Chat Generative Pre-trained Transformer (ChatGPT): its ability to (i) define a core biological concept (the Central Dogma of molecular biology); and (ii) interpret the genetic code.}
}
@article{CHRISTENSEN2025102557,
title = {To hasten slowly: The prudence of slow AI implementation in public relations},
journal = {Public Relations Review},
volume = {51},
number = {2},
pages = {102557},
year = {2025},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2025.102557},
url = {https://www.sciencedirect.com/science/article/pii/S0363811125000190},
author = {Emma Christensen and Rickard Andersson},
keywords = {Generative artificial intelligence, Implementation, STS, Qualitative case study, Slow implementation, Employee participation},
abstract = {Public relations professionals’ use of generative artificial intelligence (GenAI) tripled during 2023. Despite this surge, there is a notable lack of in-field studies examining GenAI and other CommTech implementation in public relations. To address this research gap, we adopt the view of the digital transformation of public relations as a socio-technical change process and explore how a communication department in a large Danish municipality approached the implementation of AI, drawing upon the socio-technical system view of technology implementation (STS) as our analytic lens. Instead of hasty implementation, the department spent one year on a learning process, providing them with the knowledge and skills needed to secure a sound and sustainable implementation. We contribute to the emerging literature on CommTech, AI, and AI implementation in public relations by highlighting the importance of thoroughly exploring and evaluating GenAI prior to implementation and actively involving co-workers in organizing and executing such projects. To encapsulate our findings, we introduce the concept and practice of Slow Implementation, emphasizing the importance of dedicating time to the implementation phase.}
}
@article{HUO2025103222,
title = {Reporting guideline for chatbot health advice studies: The CHART statement},
journal = {Artificial Intelligence in Medicine},
volume = {168},
pages = {103222},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103222},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001575},
author = {Bright Huo and Gary Collins and David Chartash and Arun Thirunavukarasu and Annette Flanagin and Alfonso Iorio and Giovanni Cacciamani and Xi Chen and Nan Liu and Piyush Mathur and An-Wen Chan and Christine Laine and Daniela Pacella and Michael Berkwits and Stavros A. Antoniou and Jennifer C. Camaradou and Carolyn Canfield and Michael Mittelman and Timothy Feeney and Elizabeth Loder and Riaz Agha and Ashirbani Saha and Julio Mayol and Anthony Sunjaya and Hugh Harvey and Jeremy Y. Ng and Tyler McKechnie and Yung Lee and Nipun Verma and Gregor Stiglic and Melissa McCradden and Karim Ramji and Vanessa Boudreau and Monica Ortenzi and Joerg Meerpohl and Per Olav Vandvik and Thomas Agoritsas and Diana Samuel and Helen Frankish and Michael Anderson and Xiaomei Yao and Stacy Loeb and Cynthia Lokker and Xiaoxuan Liu and Eliseo Guallar and Gordon Guyatt},
keywords = {LLMs, Generative AI, Reporting standards},
abstract = {The Chatbot Assessment Reporting Tool (CHART) is a reporting guideline developed to provide reporting recommendations for studies evaluating the performance of generative artificial intelligence (AI)-driven chatbots when summarizing clinical evidence and providing health advice, referred to as Chatbot Health Advice (CHA) studies. CHART was developed in several phases after performing a comprehensive systematic review to identify variation in the conduct, reporting and methodology in CHA studies. Findings from the review were used to develop a draft checklist that was revised through an international, multidisciplinary modified asynchronous Delphi consensus process of 531 stakeholders, three synchronous panel consensus meetings of 48 stakeholders, and subsequent pilot testing of the checklist. CHART includes 12 items and 39 subitems to promote transparent and comprehensive reporting of CHA studies. These include Title (subitem 1a), Abstract/Summary (subitem 1b), Background (subitems 2ab), Model Identifiers (subitem 3ab), Model Details (subitems 4abc), Prompt Engineering (subitems 5ab), Query Strategy (subitems 6abcd), Performance Evaluation (subitems 7ab), Sample Size (subitem 8), Data Analysis (subitem 9a), Results (subitems 10abc), Discussion (subitems 11abc), Disclosures (subitem 12a), Funding (subitem 12b), Ethics (subitem 12c), Protocol (subitem 12d), and Data Availability (subitem 12e). The CHART checklist and corresponding methodological diagram were designed to support key stakeholders including clinicians, researchers, editors, peer reviewers, and readers in reporting, understanding, and interpreting the findings of CHA studies.}
}
@incollection{MYLREA2025315,
title = {14 - The generative AI weapon of mass destruction: Evolving disinformation threats, vulnerabilities, and mitigation frameworks},
editor = {William Lawless and Ranjeev Mittu and Donald Sofge and Hesham Fouad},
booktitle = {Interdependent Human-Machine Teams},
publisher = {Academic Press},
pages = {315-347},
year = {2025},
isbn = {978-0-443-29246-0},
doi = {https://doi.org/10.1016/B978-0-443-29246-0.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292460000079},
author = {Michael Mylrea},
keywords = {AI cybersecurity, AI explainability, AI governance, AI trust, Autonomous-human–machine-teams, Disinformation, Generative artificial intelligence, Guardrails},
abstract = {In the absence of ethical guardrails, generative artificial intelligence (GenAI) can be weaponized to autonomously generate and disseminate highly convincing and tailored disinformation at an unprecedented scale. Disinformation causes confusion, division between groups and undermines trust institutions to create societal chaos and destabilization. In an era of hyperconnectivity, GenAI can weaponize social media platforms that rapidly disseminate information without verifying the authenticity of content, creating new threats and vulnerabilities. But even as GenAI has emerged as a powerful tool in shaping society, disinformation threats, vulnerabilities, and mitigations remain underexplored. This chapter investigates the burgeoning threat posed by GenAI as a potential weapon of mass destruction within the domain of disinformation. Through a comprehensive analysis of its threats and vulnerabilities, including content manipulation, targeted dissemination, and the creation of deepfakes, this study elucidates how GenAI could impair decision-making in human–machine teams, polarize societies, and destabilize geopolitical landscapes. Furthermore, this chapter explores potential countermeasures and mitigations, emphasizing the critical need for improved governance and regulatory frameworks. Applying these mitigations may help to reduce the pernicious influence of GenAI-driven disinformation and to preserve societal resilience against its malevolent applications.}
}
@article{SPENNEMANN2024301821,
title = {Examining and detecting academic misconduct in written documents using revision save identifier numbers in MS Word as exemplified by multiple scenarios},
journal = {Forensic Science International: Digital Investigation},
volume = {51},
pages = {301821},
year = {2024},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2024.301821},
url = {https://www.sciencedirect.com/science/article/pii/S2666281724001458},
author = {Dirk HR. Spennemann and Rudolf J. Spennemann and Clare L. Singh},
keywords = {Academic misconduct, AI-Generated text, Authorship, Contract cheating, Document creation and editing, Digital forensics, Plagiarism},
abstract = {Deliberate academic misconduct by students often relies on the use of segments of externally authored text, generated either by commercial contract authoring services or by generative Artificial intelligence language models. While revision save identifier (rsid) numbers in Microsoft Word files are associated with edit and save actions of a document, MS Word does not adhere to the ECMA specifications for the Office Open XML. Existing literature shows that digital forensics using rsid requires access to multiple document versions or the user's machine. In cases of academic misconduct allegations usually only the submitted files are available for digital forensic examination, coupled with assertions by the alleged perpetrators about the document generation and editing process This paper represents a detailed exploratory study that provides educators and digital forensic scientists with tools to examine a single document for the veracity of various commonly asserted scenarios of document generation and editing. It is based on a series of experiments that ascertained whether and how common edit and document generation actions such as copy, paste, insertion of blocks of texts from other documents, leave tell-tale traces in the rsid encoding that is embedded in all MS Word documents. While digital forensics can illuminate document generation processes, the actions that led to these may have innocuous explanations. In consequence, this paper also provides academic misconduct investigators with a set of prompts to guide the interview with alleged perpetrators to glean the information required for cross-correlation with observations based on the rsid data.}
}
@article{HIROSAWA20231119,
title = {Comparative Evaluation of Diagnostic Accuracy Between Google Bard and Physicians},
journal = {The American Journal of Medicine},
volume = {136},
number = {11},
pages = {1119-1123.e18},
year = {2023},
issn = {0002-9343},
doi = {https://doi.org/10.1016/j.amjmed.2023.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0002934323005363},
author = {Takanobu Hirosawa and Kazuya Mizuta and Yukinori Harada and Taro Shimizu},
keywords = {Clinical decision supporting system, Diagnosis, Diagnostic excellence, Generative artificial intelligence, Large language model, Natural language processing},
abstract = {Background
In this study, we evaluated the diagnostic accuracy of Google Bard, a generative artificial intelligence (AI) platform.
Methods
We searched published case reports from our department for difficult or uncommon case descriptions and mock cases created by physicians for common case descriptions. We entered the case descriptions into the prompt of Google Bard to generate the top 10 differential-diagnosis lists. As in previous studies, other physicians created differential-diagnosis lists by reading the same clinical descriptions.
Results
A total of 82 clinical descriptions (52 case reports and 30 mock cases) were used. The accuracy rates of physicians were still higher than Google Bard in the top 10 (56.1% vs 82.9%, P < .001), the top 5 (53.7% vs 78.0%, P = .002), and the top differential diagnosis (40.2% vs 64.6%, P = .003). Even within the specific context of case reports, physicians consistently outperformed Google Bard. When it came to mock cases, the performances of the differential-diagnosis lists by Google Bard were no different from those of the physicians in the top 10 (80.0% vs 96.6%, P = .11) and the top 5 (76.7% vs 96.6%, P = .06), except for those in the top diagnoses (60.0% vs 90.0%, P = .02).
Conclusion
While physicians excelled overall, and particularly with case reports, Google Bard displayed comparable diagnostic performance in common cases. This suggested that Google Bard possesses room for further improvement and refinement in its diagnostic capabilities. Generative AIs, including Google Bard, are anticipated to become increasingly beneficial in augmenting diagnostic accuracy.}
}
@article{HAN2024112034,
title = {A GAI-based multi-scale convolution and attention mechanism model for music emotion recognition and recommendation from physiological data},
journal = {Applied Soft Computing},
volume = {164},
pages = {112034},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112034},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624008081},
author = {Xiao Han and Fuyang Chen and Junrong Ban},
keywords = {Music emotion recognition, Physiological signals, Three-dimensional emotion model, Music recommendation, Multi-scale parallel convolution, GAI-based-attention mechanism},
abstract = {Due to the subjectivity of emotions and the limited number of emotion categories, existing deep learning models require assistance to achieve objective, accurate, and flexible personalized music emotion recommendations. This paper introduces a deep learning approach that combines Generative Artificial Intelligence (GAI) and explicitly leverages physiological indicators to enhance the model's intelligence, versatility, and automation. Physiological indicators such as Heart Rate Variability (HRV) and Galvanic Skin Response (GSR) can be measured using sensors placed on the body's surface, providing more precise information about human emotional changes. This research employs a three-dimensional emotion model, including the tension-arousal axis, energy-arousal axis, and valence axis, to explain the correlation and accuracy between music data and emotions. Based on this, a music emotion classifier is designed, incorporating GAI algorithms to recommend music by matching users' physiological and emotional types with the emotional features of music. The classifier uses Mel-Frequency Cepstral Coefficients (MFCC) to transform audio into Mel-spectrogram as input features. The music emotion selection module adopts a GAI framework of Variational Autoencoder (VAE) and integrates multi-scale parallel convolution and attention mechanism modules. Experimental results demonstrate that this approach is competitive compared to existing deep learning architectures on PMEmo, RAVDESS, and Soundtrack datasets. Furthermore, due to GAI's efficient classification capability, this model is suitable for resource-constrained mobile devices and other smart devices. The results of this study can be applied to emotion-based music recommendation systems, contributing to emotional interventions and improving the performance of exercise and music therapy.}
}
@article{SUK2025102261,
title = {Communicative AI in the scientific public sphere: An analysis of Twitter discourse on generative AI tools},
journal = {Telematics and Informatics},
volume = {98},
pages = {102261},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102261},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000231},
author = {Jiyoun Suk and Yini Zhang and Jiawei Liu and Yukyung Yang},
keywords = {Generative artificial intelligence, Scientific public sphere, Social media, Diffusion of innovation},
abstract = {Drawing on the concept of the scientific public sphere, this study examines the public sense-making of communicative AI (e.g., generative AI) on social media. Advancing a framework encompassing cognitive (technology vs. use) and affective (positive vs. negative) dimensions of the public discourse on communicative AI, we analyzed global Twitter (now X) conversations about generative AI tools. Findings showed that the text generator (ChatGPT) discussions centered more on the technology-centered themes, whereas the image generator discussions emphasized their uses. ChatGPT received mixed sentiments in technology-related discussions, while there was more positive sentiment about the its uses. Theoretical and practical implications are discussed.}
}
@article{HUBBARD2025,
title = {AI and the Future of Language Teaching:},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.378304},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000106},
author = {Philip Hubbard and Mathias Schulze},
keywords = {Generative AI, GenAI, Professional Development, Ethics, Chatbots, Machine Translation, AI Competency, AI Literacy, Assessment, Large Language Models},
abstract = {ABSTRACT
The November 2022 release of ChatGPT revolutionized the accessibility, perception, and use of generative artificial intelligence (GenAI). In this position paper, we argue that a major goal of currently-practicing language teachers should be to acquire relevant knowledge and skills in GenAI, with teacher educators, professional organizations, and language programs co-responsible in that effort. As necessary background, we describe the history and current state of AI in language teaching, especially as it relates to GenAI. Then, drawing on recent research and in-service training sources, we offer guidance for practicing teachers at all stages of their careers to achieve a basic understanding of and facility with GenAI in a range of forms relevant for language teaching and learning. We propose that teachers engage in a targeted form of continuous professional development, GenAI sustained integrated professional development (SIPD), to accommodate the rapid, unpredictable, and likely transformative changes in GenAI for language education.}
}
@article{AKRAM2026102637,
title = {A review of generative AI in aquaculture: Applications, case studies and challenges for smart and sustainable farming},
journal = {Aquacultural Engineering},
volume = {112},
pages = {102637},
year = {2026},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2025.102637},
url = {https://www.sciencedirect.com/science/article/pii/S0144860925001268},
author = {Waseem Akram and Muhayy Ud Din and Lyes {Saad Saoud} and Irfan Hussain},
keywords = {Aquaculture, Marine robots, Generative AI, Autonomous systems, Large language models},
abstract = {Generative Artificial Intelligence (GAI) is revolutionizing aquaculture by providing practical and scalable solutions to longstanding industry challenges, including limited data availability, labor-intensive underwater inspections, disease outbreaks, and inefficiencies in resource management. As the sector evolves toward the Aquaculture 4.0 vision of intelligent, interconnected, and sustainable systems, GAI offers transformative capabilities across perception, planning, optimization, and communication. GAI enhances automation, decision support, and situational awareness across the aquaculture value chain through the intelligent synthesis of multimodal data ranging from sensor logs and underwater imagery to textual records and simulations. This review presents the first comprehensive synthesis of GAI in aquaculture, covering foundational models (e.g., diffusion models, transformers, and GANs), domain-specific applications, and emerging deployment scenarios. We demonstrate how GAI drives industry innovation in areas such as ROV-based infrastructure inspection, digital twins for farm design, synthetic data generation for fish health diagnostics, multimodal sensor fusion, and personalized advisory systems. Importantly, we map GAI models to specific aquaculture tasks, highlighting their suitability and advantages. We also offer a critical assessment of their operational readiness, including trust, performance, and environmental impact issues. In addition, we provide a systematic classification of applications, case studies, and future directions to guide the responsible and scalable integration of GAI in aquaculture. This review highlights GAI as a powerful tool and a foundational enabler of innovative, resilient, and ecologically aligned aquaculture systems, accelerating the industry’s transition toward more efficient, transparent, and adaptive practices.}
}
@article{LENG2025561,
title = {Diffusion model-driven smart design and manufacturing: Prospects and challenges},
journal = {Journal of Manufacturing Systems},
volume = {82},
pages = {561-577},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525001864},
author = {Jiewu Leng and Xuyang Su and Zean Liu and Lianhong Zhou and Chong Chen and Xin Guo and Yiwei Wang and Ru Wang and Chao Zhang and Qiang Liu and Xin Chen and Weiming Shen and Lihui Wang},
keywords = {Diffusion models, Smart manufacturing, Artificial Intelligence-Generated Content, Generative Artificial Intelligence, Industry 5.0, Product lifecycle management},
abstract = {Artificial Intelligence-Generated Content (AIGC), particularly diffusion models as a key component of Generative Artificial Intelligence (GenAI), are transforming smart design and manufacturing in the interplay of Industry 4.0 and Industry 5.0. This paper analyzes the applications of diffusion models in smart design and manufacturing, focusing on three key pillars: diffusion-driven generative design, smart control, and fault diagnosis. Diffusion models enhance manufacturing system flexibility, resilience, and sustainability through their applications as generative design engines, intelligent controllers for adaptive manufacturing processes, and predictive tools for fault diagnosis. This study provides a comprehensive review of the current state of diffusion model-driven smart design and manufacturing. It analyzes key challenges such as model efficiency, data dependency, and system integration, while providing a constructive perspective on potential solutions. This paper also integrates Industry 5.0 considerations by connecting the applications and technical solutions to the core values of human-centricity, sustainability, and resilience. It concludes by emphasizing the necessity of continuous refinement of diffusion models and interdisciplinary research to integrate them into smart design and manufacturing systems further, fostering a more human-centric, resilient, and sustainable industry.}
}
@article{CHAKRABORTY2024114737,
title = {Enhancing trust in online grocery shopping through generative AI chatbots},
journal = {Journal of Business Research},
volume = {180},
pages = {114737},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114737},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002418},
author = {Debarun Chakraborty and Arpan {Kumar Kar} and Smruti Patre and Shivam Gupta},
keywords = {Generative Artificial Intelligence (AI), Online Shopping, Elaboration Likelihood Model, Trust, Status Quo Bias Theory, Chatbots},
abstract = {Generative Artificial Intelligence (GAI) is witnessing a lot of adoption across industries, but literature is yet to fully document the nuances of these applications. We develop a comprehensive framework for understanding the factors that affect trust in online grocery shopping (OGS) using GAI chatbots. Our exploratory study was conducted via interviews, which helped to build our model. We integrate the Elaboration Likelihood Model (ELM) and Status Quo Bias (SQB) theory to develop the Unified Framework for Trust on Technology Platforms. In our confirmatory study, by analyzing 372 responses from users, using structural equation modelling (SEM), we initially validate our path model. Subsequently, we used fuzzy set qualitative comparative analysis (fsQCA) to check the causal combinations to explain different trust levels. Apart from perceived regret avoidance, all of the other factors had a significant effect on attitude and trust. Perceived anthropomorphism moderated the associations between interaction quality, credibility, threat, and attitude.}
}
@article{SENGUL2025104696,
title = {Annotating risk stratification of thyroid nodules: Assessing the suitability of ChatGPT for text-based analysis in thyroidology},
journal = {American Journal of Otolaryngology},
volume = {46},
number = {5},
pages = {104696},
year = {2025},
issn = {0196-0709},
doi = {https://doi.org/10.1016/j.amjoto.2025.104696},
url = {https://www.sciencedirect.com/science/article/pii/S0196070925000997},
author = {Ilker Sengul and Demet Sengul},
keywords = {Thyroid gland, Risk, Generative Artificial Intelligence, Artificial Intelligence, Thyroid nodule, Pathology, Thyroidology}
}
@article{HEREDIAALVARO2025103007,
title = {An advanced retrieval-augmented generation system for manufacturing quality control},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103007},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103007},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400658X},
author = {José Antonio {Heredia Álvaro} and Javier González Barreda},
keywords = {Knowledge-based systems, Quality control, Ceramic tile, Retrieval-augmented generation, Large language models},
abstract = {The rise of Large Language Models (LLMs) with generative artificial intelligence has revolutionized the development of knowledge-based systems, enabling intuitive interactions through natural language. This paper explores the implementation of an advanced Retrieval-Augmented Generation (RAG) system, designed to improve manufacturing quality control by utilizing the capabilities of LLMs, particularly OpenAI’s GPT models. We focus on the ceramic tile manufacturing process, where the system retrieves and analyzes specialized bibliographic sources to diagnose defects and propose solutions. In addition to core RAG functionalities, the system incorporates tailored pre-processing and post-processing mechanisms to optimize document retrieval and response generation. The system’s effectiveness in solving quality issues is demonstrated through its application in identifying defect causes and generating actionable solutions, significantly improving non-conformities management. This approach not only streamlines troubleshooting but also enhances the quality control system, providing a comprehensive, scalable tool for manufacturers.}
}
@article{KOHNKE2024100279,
title = {Exploring EAP students' perceptions of GenAI and traditional grammar-checking tools for language learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100279},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100279},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000821},
author = {Lucas Kohnke},
keywords = {Academic writing, ChatGPT, EAP, English language learners, GenAI},
abstract = {The rapid development of generative artificial intelligence (GenAI) tools (e.g. ChatGPT) has elicited mixed reactions among English language instructors and learners. This study explores how first-year students in an English for Academic Purposes (EAP) course at a Hong Kong university perceive GenAI and traditional grammar-checking tools (e.g. Grammarly, MS Word). We employed a qualitative methodology grounded in the interpretivist paradigm, conducting semi-structured interviews with 14 students. The findings revealed the students perceived GenAI tools to be more comprehensive and authoritative, as they provide detailed explanations and contextual insights that enhance language proficiency. However, they also noted concerns about overreliance, data privacy and equitable access to premium features. The study examines the ethical and pedagogical implications of integrating GenAI tools into higher education, highlighting their potential and the necessity of institutional guidance. It contributes to the ongoing discourse on the role of GenAI in academic writing instruction.}
}
@article{KUOWEI2025101164,
title = {An integrated framework for Gen AI-assisted management learning: Insights from Kolb's learning cycle theory and knowledge types perspectives},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101164},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101164},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725000345},
author = {Lee Kuo-Wei},
keywords = {Management learning, Gen AI-Assisted learning, Learning cycle theory, Knowledge types, ChatGPT},
abstract = {Generative Artificial Intelligence (Gen AI), particularly through advanced models such as ChatGPT developed on the foundation of sophisticated Large Language Models (LLMs), has shown the potential to revolutionize management education. Nevertheless, a comprehensive framework for employing Gen AI in this context remains to be developed. This study proposes a theoretical framework utilizing Gen AI, with a specific focus on ChatGPT, based on Kolb's learning cycle theory and the knowledge type perspective to facilitate systematic integration into management learning. Analyzing data from 348 business students through structural equation modeling, the study demonstrates that the Gen AI -assisted learning process enhances the acquisition of diverse knowledge types. The findings also highlight that teacher support partially strengthens the effectiveness of the Gen AI -assisted learning process in knowledge acquisition. The study contributes to the academic discourse by developing an integrated framework and practical guidelines for integrating Gen AI into management learning, thereby addressing an existing gap in current research.}
}
@article{DEALBUQUERQUE2025103,
title = {Generative AI applied for synthetic data in PMU},
journal = {Energy Reports},
volume = {14},
pages = {103-115},
year = {2025},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2025.05.062},
url = {https://www.sciencedirect.com/science/article/pii/S2352484725003439},
author = {Felipe Proença {de Albuquerque} and Eduardo Coelho Marques {da Costa} and Luisa Helena Bartocci Liboni},
keywords = {Synthetic data, Measurement series, Phasor measurements, Electrical engineering},
abstract = {The growing deployment of Phasor Measurement Units (PMUs) has enhanced power system observability but introduced new challenges related to data privacy, incompleteness, and measurement quality. To address these issues, this paper proposes a data-driven methodology for generating and completing PMU phasor measurements using Generative Artificial Intelligence. Specifically, we employ Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) trained on real-world PMU datasets to learn the underlying empirical data distributions without assuming predefined statistical models. The proposed deep generative models are evaluated against traditional statistical techniques based on Gaussian Copulas using a suite of distributional similarity metrics, including Kullback–Leibler (KL) divergence, Hellinger distance, Maximum Deviation Nearest Neighbor (MDNN), and the Kolmogorov–Smirnov (KS) test. The GAN model achieved the best distributional fidelity, with KL divergence as low as 0.0106 and Hellinger distance of 0.0435 for voltage signals. In a synthetic data reconstruction task with 0.5% missing values, the GAN reduced the percentage root mean squared error (PRMSE) to 0.52% for voltage and 2.19% for current—significantly outperforming baseline methods. Moreover, the GAN was able to augment the dataset from 1489 to 5000 samples while preserving key statistical properties, as validated by empirical distribution tests. These results demonstrate that deep generative models not only offer superior accuracy but also provide statistically consistent synthetic PMU data, making them a robust alternative to conventional methods for enhancing power system datasets.}
}
@article{SEYFI2025104105,
title = {Understanding tourist barriers and personality influences in embracing generative AI for travel planning and decision-making},
journal = {International Journal of Hospitality Management},
volume = {126},
pages = {104105},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104105},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925000283},
author = {Siamak Seyfi and Myung Ja Kim and Amin Nazifi and Samantha Murdy and Tan Vo-Thanh},
keywords = {Generative AI, ChatGPT, Innovation resistance, Personality traits, Tourist decision-making},
abstract = {As generative artificial intelligence (GAI) technologies become increasingly integrated into the travel industry, understanding the barriers tourists face in adopting these innovative technologies for their travel planning and decision-making has growingly become a critical area of focus. Drawing on the theoretical frameworks of innovation resistance and Big Five personality traits, this study surveyed potential travelers in Korea and the US to assess their personality characteristics, innovation resistance, and perceptions of AI-generated travel recommendations. The findings, derived from structural equation modeling, multi-group analysis, and fuzzy-set qualitative comparative analysis, reveal that variations in personality traits significantly affect tourists’ reluctance to adopting these technologies. Overall, the results of this study contribute to the theoretical understanding of acceptance of GAI and offer practical insights for tourism industry stakeholders, enabling them to tailor their offerings to different personality types and enhance the travel experience for a wide range of travelers.}
}
@article{GARCIAPEREZ2025103303,
title = {Improving automatic defect recognition on GDXRay castings dataset by introducing GenAI synthetic training data},
journal = {NDT & E International},
volume = {151},
pages = {103303},
year = {2025},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2024.103303},
url = {https://www.sciencedirect.com/science/article/pii/S0963869524002688},
author = {A. García-Pérez and M.J. Gómez-Silva and A. de la Escalera-Hueso},
keywords = {X-rays, Castings defects, Automated inspection, ADR, WGAN, Neural network, Generative AI},
abstract = {X-rays are a Non Destructive Testing (NDT) technique commonly employed by aerospace, automotive or nuclear industries when the structural integrity of some parts needs to be guaranteed. Industrial dataset are now available with the introduction of Digital Radiography (DR) X-ray machine and are the basis for Automated Defect Recognition (ADR) systems based on Neural Network (NN) object detection models. However, building a big enough dataset is not easy and takes a long time in a production environment, delaying the introduction of ADR models. A potential solution is to use Generative Artificial Intelligence (GenAI) to synthesise new images. However, these models fail to generate full realistic images due to the subtle nature of X-ray images. Hence, this paper propose a combination of flawless images and synthetic defects generated by a novel Scalable Conditional Wasserstein GAN (SCWGAN) model. Such synthetic defects are introduced in the target images by a location algorithm that uses a mask image defining the allowable defective areas, the expected Gaussian or Poisson noise level and the defect size and aspect ratio. By creating such synthetic dataset and combine it with the original GDXRay dataset, our proposed detection system achieves an improvement of 17% in mAP@IoU=0.5:0.95 (our target metric to reduced uncertainty on defect location) with regards the baseline model trained with only real images. As a secondary metric, to allow comparison with other studies, the model also achieves 96.0% mAP@IoU=0.50, which exceeds the maximum accuracy available on current literature for the evaluated dataset.}
}
@article{BREWER2024525,
title = {Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {525-535},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000569},
author = {Jordan Brewer and Dhru Patel and Dennie Kim and Alex Murray},
keywords = {Blockcain, Generative artificial intelligence (GenAI), ChatGPT, Large language models (LLMs), Chatbots},
abstract = {The transformative impact of generative AI (GenAI), extending beyond traditional AI, raises numerous concerns including the replacement of human roles and AI misuse in an array of industries. This article introduces blockchain technology as a complementary technological safeguard to address some of these challenges. We emphasize blockchain’s role in promoting transparency, verifiability, and decentralization in AI development and usage, thereby offering potential solutions for four distinct challenges: (1) AI toxicity, biases, hallucinations, (2) AI interest misalignment, (3) AI as a black box, and (4) AI misuse. This article proposes ways to ensure responsible and transparent AI usage through the integration of blockchain. We position the convergence of AI and blockchain as a means to manage AI’s societal impact and unlock its benefits—contingent upon collaborative efforts among various stakeholders such as businesses, developers, and regulatory bodies. We contribute to the discourse on ethical AI usage and the potential of blockchain to enhance AI’s reliability and accountability for organizations.}
}
@article{ZHUANG2025112143,
title = {Inverse structural design with generative and probabilistic autoencoders and diffusion models},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112143},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112143},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625021517},
author = {Bozhou Zhuang and Adrien Gallet and Danny Smyl},
keywords = {Generative artificial intelligence, Structural design, Inverse problem, Continuous beams, Conditional autoencoders, Denoising diffusion models, Tabular data},
abstract = {Traditional structural design is a forward trial-and-error process. Designers need to iterate through different design solutions and conduct structural analysis until the design meets the codes and standards. This study proposes and investigates a generative machine learning (ML) framework for inverse design of continuous beam systems. Three generative ML models, including conditional variational autoencoder (CVAE), conditional autoencoder with maximum likelihood estimation (CAE-MLE), and denoising diffusion models (DDMs) are trained and fine-tuned on the CBeamXP (Continuous Beam Cross-section Predictors) dataset with 1,000,000 beam sections to generate the cross sectional properties. Research results show that CAE-MLE achieves the highest generation accuracy and robustness, while CVAE offers more variability through latent space sampling. DDMs provide controllable generation variability via a stochasticity parameter in the inverse diffusion process. The proposed framework enables efficient generation of multiple design solutions and can potentially accelerate the conceptual design workflows in structural engineering. This work also demonstrated the feasibility toward artificial intelligence (AI)-assisted structural design using generative approaches and tabular datasets.}
}
@article{WUNSCHNAGY2025102909,
title = {From multimodal space to digital multimodal text: Making choices in digital multimodal compositions inspired by museum visits in higher education},
journal = {Computers and Composition},
volume = {75},
pages = {102909},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102909},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000859},
author = {Nóra Wünsch-Nagy},
keywords = {Multimodal literacy, Multimodal texts, Digital multimodal composition, Digital literacy, Critical AI literacy},
abstract = {Access to generative artificial intelligence (AI) has transformed the pedagogical and creative potential of digital practices in multimodal pedagogies, and more specifically, digital multimodal compositions (DMC). This study aims to explore and understand choices in a DMC project from the perspectives of student experiences and the teacher's pedagogical practices including learning design, assessment, and the integration of AI in the context of a semester-long university course. To answer these questions, the case study presents the analysis of the teacher's choices in terms of course design, and scaffolding and assessment practices. It also explores the challenges students face through the analysis of their pre- and post-course questionnaires, digital multimodal composition artefacts and reflective notes. The study makes suggestions in terms of pedagogical sequences to support students’ choice-making, and the integration of semiotic software and generative AI tools into DMC projects.}
}
@article{ZHOU2025104431,
title = {How do consumers react to AI-generated green marketing content? A hybrid analysis using PLS-SEM and text mining},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104431},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104431},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002103},
author = {Cheng Zhou and Bing Jiang},
keywords = {AI-generated green marketing content, Perceived pro-environmental, Skepticism to greenwashing, Perceived experience and agency, Green marketing, PLS-SEM and text mining},
abstract = {In the field of marketing, generative artificial intelligence(AI) is gradually becoming an assistant to human creators, enabling them to efficiently create marketing content based on different marketing objectives. Recently, green marketing has become an important strategy implemented by retailers to enhance their corporate image and consumer engagement. This study imitates human creators' strategies for creating green marketing content and categorizes three strategies for using AI-generated green marketing content. The results of two studies reveal that moderate green in AI-generated content (compared to non-green content) awakens consumers' pro-environmental perceptions, consequently increasing their purchase intention. However, excessive green in AI-generated content (compared to moderate green content) evokes skepticism related to greenwashing, which, in turn, negatively impacts their intention to purchase. Additionally, perceived experience and agency positively moderate the relationships between the different strategies of using AI-generated green marketing content and consumers' reactions. Our research highlights the importance of using thoughtful approaches to generative AI implementation in the field of green marketing, especially those aimed at reaping economic advantages (e.g., cost efficiency, enhanced consumer engagement, and improved innovation) while maintaining strong consumer relationships.}
}
@article{SHIBUYA2025103485,
title = {How do people evaluate the accuracy of video posts when a warning indicates they were generated by AI?},
journal = {International Journal of Human-Computer Studies},
volume = {199},
pages = {103485},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103485},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925000424},
author = {Yuya Shibuya and Tomoka Nakazato and Soichiro Takagi},
keywords = {Generative AI, GenAI, Artificial Intelligence, Misinformation, Disinformation, Social media, Facebook, TikTok},
abstract = {Given the rise of concerns about Generative Artificial Intelligence (GenAI) powered misinformation, major platforms like Google, Meta, and TikTok have implemented new policies to warn users of AI-generated content. However, we have not fully understood the impacts of such user interface designs that disclose AI made content on user perceptions. This study investigates how people assess the accuracy of video content when they are warned that it is created by GenAI. We conducted an online experiment in the U.S. (14,930 observations), showing half of the participants warning messages about AI before and after they viewed a mockup of true and false video content on social media, while the other half only viewed the same videos without the warning message. The results indicated that the warning message had an impact on the ability to discern between true and false content only among those who had a positive perception of AI. On the contrary, those with a negative perception of AI tended to perceive all AI-made video posts, including those not containing false information, as less accurate when they knew that a GenAI created the videos. These results indicated the limitations of merely relying on simple warnings to mitigate GenAI-based misinformation. Future research on continuous investigations on designing interfaces that go beyond simple warnings is needed.}
}
@article{FERRARO2024549,
title = {The paradoxes of generative AI-enabled customer service: A guide for managers},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {549-559},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000582},
author = {Carla Ferraro and Vlad Demsar and Sean Sands and Mariluz Restrepo and Colin Campbell},
keywords = {Artificial intelligence, Generative AI, AI chatbots, Customer service, Customer support},
abstract = {Generative artificial intelligence (GenAI) presents a disruptive innovation for brands and society, and the power of which is still yet to be realized. In the context of customer service, gen AI affords companies new possibilities to communicate, connect, and engage customers. This article draws on scholarly research and consultation with customer service leaders to present and discuss the possibilities for GenAI in the context of customer service, specifically GenAI chatbots. Importantly, this article presents potential paradoxes of GenAI-enabled customer service, adding to the debate about the role and impact of GenAI for brands. Specifically, we present six paradoxes of GenAI customer service: (1) connected yet isolated, (2) lower cost yet higher price, (3) higher quality yet less empathy, (4) satisfied yet frustrated, (5) personalized yet intrusive, and (6) powerful yet vulnerable. For each paradox, we suggest brand response strategies to mitigate downside and manage potential upside.}
}
@article{WIBOWO20258,
title = {Generative AI for library social media content creation and communication},
journal = {Library Hi Tech News},
volume = {42},
number = {8},
pages = {8-11},
year = {2025},
issn = {0741-9058},
doi = {https://doi.org/10.1108/LHTN-06-2025-0109},
url = {https://www.sciencedirect.com/science/article/pii/S0741905825000196},
author = {Muhamad Prabu Wibowo},
keywords = {Generative artificial intelligence, Library communication, Social media content},
abstract = {Purpose
This paper aims to examine the potential use of generative artificial intelligence (Gen AI) to enhance digital communication in libraries, with a particular emphasis on social media content creation. It seeks to identify emerging opportunities, explore key challenges and address ethical and institutional considerations related to the adoption of Gen AI in outward-facing communication practices.
Design/methodology/approach
The study draws on a combination of literature review and practitioner insights from a 2025 workshop hosted by the Librarian Empowerment Division of the Jakarta Public Library. It highlights how librarians are using Gen AI tools to generate posts, captions and visuals for social media, and presents selected examples and reflections from their experiences.
Findings
Gen AI tools enable libraries to produce social media content more efficiently, particularly in contexts with limited human or technical resources. However, their adoption also reveals challenges such as graphic inconsistencies, copyright ambiguity and ethical concerns. A key issue identified is the absence of clear institutional policies to guide responsible use. In addition, uneven levels of digital competence among staff may hinder experimentation and broader implementation.
Originality/value
This study contributes to the evolving discourse on AI adoption in libraries by focusing specifically on the underexplored area of Gen AI use in social media communication. It provides a contextualized account of how Indonesian libraries are beginning to apply Gen AI tools for creating public-facing content on social media platforms. By documenting early practices and institutional responses, the paper highlights both the creative possibilities and operational challenges of using AI in library outreach strategies.}
}
@article{SAHASHI2025458,
title = {AI-echocardiography: Current status and future direction},
journal = {Journal of Cardiology},
volume = {85},
number = {6},
pages = {458-464},
year = {2025},
issn = {0914-5087},
doi = {https://doi.org/10.1016/j.jjcc.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S091450872500053X},
author = {Yuki Sahashi and David Ouyang and Hiroyuki Okura and Nobuyuki Kagiyama},
keywords = {Artificial intelligence, Deep learning, Echocardiography, Generative artificial intelligence},
abstract = {Summary
Echocardiography, which provides detailed evaluations of cardiac structure and pathology, is central to cardiac imaging. Traditionally, the assessment of disease severity, treatment effectiveness, and prognosis prediction relied on detailed parameters obtained by trained sonographers and the expertise of specialists, which can limit access and availability. Recent advancements in deep learning and large-scale computing have enabled the automatic acquisition of parameters in a short time using vast amounts of historical training data. These technologies have been shown to predict the presence of diseases and future cardiovascular events with or without relying on quantitative parameters. Additionally, with the advent of large-scale language models, zero-shot prediction that does not require human labeling and automatic echocardiography report generation are also expected. The field of AI-enhanced echocardiography is poised for further development, with the potential for more widespread use in routine clinical practice. This review discusses the capabilities of deep learning models developed using echocardiography, their limitations, current applications, and research utilizing generative artificial intelligence technologies.}
}
@article{XIAOYU2025165,
title = {Evaluating the efficacy of ChatGPT in environmental education: findings from heuristic and usability assessments},
journal = {On the Horizon},
volume = {33},
number = {2},
pages = {165-185},
year = {2025},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-11-2024-0079},
url = {https://www.sciencedirect.com/science/article/pii/S1074812125000132},
author = {Wang Xiaoyu and Zamzami Zainuddin and Chin Hai Leng and Dong Wenting and Xiang Li},
keywords = {Environmental education, Usability testing, ChatGPT, Generative artificial intelligence, Heuristic evaluation},
abstract = {Purpose
This study aims to investigate ChatGPT’s potential in environmental education concerning sustainable development goals. Heuristic evaluation and usability testing identify critical usability issues, including inadequate multimedia support, language barriers and insufficient fact-checking capabilities.
Design/methodology/approach
The study uses heuristic evaluation and usability testing to assess ChatGPT’s efficacy in environmental education at a Chinese higher education institution. The evaluation identifies essential limitations, including reliance on text-only resources, absence of multimedia assets, technical deficiencies, language barriers, lack of fact-checking tools, context-related issues, delayed information, inconsistency and limited expertise. Data was collected through quantitative and qualitative analysis, with input from experts and students.
Findings
Findings suggest that while ChatGPT offers opportunities for interactive learning, its limitations hinder comprehensive educational outcomes. A proposed hybrid model combining generative AI and human elements aims to enhance engagement and learning effectiveness. This research offers a foundation for integrating AI tools into environmental education, addressing usability gaps and fostering sustainable learning environments.
Originality/value
This research contributes to a deeper understanding of the role of artificial intelligence in environmental education and underscores the importance of incorporating human intervention. The proposed hybrid approach offers a framework for creating more comprehensive and meaningful learning environments by leveraging the unique strengths of human engagement alongside generative AI technology.}
}
@article{FOUNG2024100250,
title = {Reinventing assessments with ChatGPT and other online tools: Opportunities for GenAI-empowered assessment practices},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100250},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100250},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000535},
author = {Dennis Foung and Linda Lin and Julia Chen},
keywords = {GenAI, Online tools, Language learning, Assessments},
abstract = {The recent emergence of generative artificial intelligence (GenAI) tools, such as ChatGPT, has brought profound changes to higher education. While many studies have examined the potential use of ChatGPT in teaching and learning, few have explored the opportunities to develop assessments that facilitate the use of multiple technological innovations (i.e. traditional AI and GenAI tools). We conducted qualitative research to address this gap. The assessments of an elective English course in Hong Kong were re-designed to incorporate GenAI and other tools. Students were asked to employ and reflect on their use of these tools for their writing assessments. We analyzed the written reflections of 74 students and conducted focus group interviews with 28 students. The results suggest that the students possess an acumen for choosing the appropriate online tools for specific purposes. When they can choose freely, they develop skills that allow them to evaluate and select between traditional AI and GenAI tools when appropriate. Some students mentioned concerns with the different features of the free and premium versions. The results of this study call for (1) assessment practices that allow the flexibility to use different AI tools and (2) the equitable use of various AI tools.}
}
@article{ANDERS2025100482,
title = {Developing Generative AI Literacies Through Self-Regulated Learning: A Human-Centered Approach},
journal = {Computers and Education: Artificial Intelligence},
pages = {100482},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100482},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001225},
author = {Abram D. Anders and Emily Dux Speltz},
keywords = {Artificial intelligence, Multimodal composition, Self-efficacy, Self-regulated learning, Teaching/learning strategies},
abstract = {Generative artificial intelligence (AI) creates both opportunities for enhanced learning and risks of skill erosion and dependency. This exploratory, mixed-methods study investigated how to design AI learning experiences using a human-centered approach that promotes student agency. We developed and investigated an integrated framework combining comprehensive generative AI literacies—functional, critical and ethical, and creative—with self-regulated learning (SRL) processes operationalized as a human-centered Plan, Iterate, Evaluate cycle. Thirty-eight undergraduate students enrolled in an “Artificial Intelligence and Writing” course completed scaffolded experiential challenges followed by self-directed creative projects. Quantitative analysis revealed significant growth in AI literacy self-efficacy across all dimensions, with students progressing from moderate initial confidence (M = 4.68, SD = 2.11) to high confidence levels (M = 8.39, SD = 1.04) on a 10-point scale (t = -9.86, p < .001). Qualitative analysis of project artifacts and student process reflections identified a taxonomy of human in the loop practices integrating AI literacies and self-regulation across the Plan, Iterate, Evaluate cycle. Planning practices involved activating domain knowledge to identify AI applications and establishing evaluative criteria. Iteration practices included developing multi-step workflows, refining prompts through dialogue, and monitoring output quality. Evaluation practices combined assessment of project outcomes with reflection on collaboration processes to inform future use. These practices illustrated adaptive human-AI collaboration strategies that augment rather than replace students’ disciplinary expertise and creative vision. These findings suggest scaffolded experiential learning integrating AI literacies and metacognitive processes can promote effective AI collaboration and empower students to actively direct their own learning.}
}
@article{DAI2024292,
title = {Facilitating Students’ Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
journal = {Procedia CIRP},
volume = {128},
pages = {292-297},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006735},
author = {Yun Dai and Ziyan Lin and Ang Liu},
keywords = {help-seeking, peer support, learning analytics, design thinking, engineering education},
abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year’s course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students’ focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students’ design thinking and collaborative design.}
}
@article{RAMKUMAR2025276,
title = {Editorial Commentary: Off-the-Shelf Large Language Models Are of Insufficient Quality to Provide Medical Treatment Recommendations, While Customization of Large Language Models Results in Quality Recommendations},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {2},
pages = {276-278},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324007709},
author = {Prem N. Ramkumar and Andrew F. Masotto and Joshua J. Woo},
abstract = {The content accuracy of off-the-shelf large language models (LLMs) mirrors the content accuracy of the unregulated Internet from which these generative artificial intelligence models are supplied. With error rates approximating 30% in terms of treatment recommendations for the management of common musculoskeletal conditions, seeking expert opinion remains paramount. However, custom LLMs represent an excellent opportunity to infuse niche, bespoke expertise from the many specialties and subspecialties within medicine. Methods of customizing these generative models broadly fall under the categories of prompt engineering; “retrieval-augmented generation” prioritizing retrieval of relevant information from a specific domain of data; “fine-tuning” of a basic pretrained model into one that is refined for health care–related vernacular and acronyms; and “agentic augmentation” including software that breaks down complex tasks into smaller ones, recruiting multiple LLMs (with or without retrieval-augmented generation), optimizing the output, internally deciding whether the response is appropriate or sufficient, and even passing on an unmet outcome to a human for supervision (“phone a friend”). Custom LLMs offer physicians and their associated organizations the rare opportunity to regain control of our profession by re-establishing authority in our increasingly digital landscape.}
}
@article{JONAHBARRETT2025,
title = {Documenting Disclosure: Limited Reporting of Generative AI Usage in Radiology Research Manuscripts},
journal = {Academic Radiology},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2025.06.057},
url = {https://www.sciencedirect.com/science/article/pii/S1076633225006373},
author = {D. {Jonah Barrett} and Richard Heng and Jordan D. Perchik},
keywords = {Large language models, Generative artificial intelligence, Research disclosure},
abstract = {Rationale and Objectives
Large language models (LLMs) show promise in radiology through various clinical applications as well as in assisting with research manuscript development. Recent studies show 52.6% of medical researchers use LLMs in manuscript development, with non-medical researchers showing similar rates. Given concerns about hallucinations, bias, etc., many publishers now require disclosure of LLM use. While most medical imaging journals have LLM policies as of 2025, the actual disclosure rates for LLM usage remain unknown. Our study examines trends in LLM disclosure by analyzing 1998 radiology publications for LLM disclosures.
Materials and Methods
A bibliometric analysis of nine radiology journals with LLM use disclosure requirements was performed. The study included primary investigations and secondary research while excluding short-form publications. The LLM disclosure rate was calculated overall. Logistic regression assessed temporal trends in disclosure rates, while a linear mixed effects model evaluated the relationship between disclosure status and peer review duration. Chi-square analysis examined associations between manuscript type and disclosure rates.
Results
Of 1998 manuscripts, 34 (1.7%) declared LLM use. Most disclosures involved ChatGPT (32, 94.1%), primarily for readability/grammar purposes (33, 97.1%). The majority of manuscripts disclosing LLM use originated from institutions in non-English speaking countries (22, 64.7%). No significant increase in disclosure rates over time was observed (OR: 1.06 [95% CI: 0.98, 1.16], p=0.15), and no relationship with peer review duration (coefficient: −4.85, SE=11.25, p=0.67) was found. Secondary research manuscripts disclosed LLM use more frequently (3.9% vs. 1.3%, p<0.001) with a small effect size (Cramer's V: 0.08 [0.04, 1.00]).
Conclusion
Our findings demonstrate remarkably low disclosure rates in radiology manuscripts despite surveys indicating significant LLM adoption among researchers. This discrepancy may result from true non-use, fear of stigma, perceived advantages of undisclosed use, disagreement with disclosure requirements for minor editing, or policy unawareness, among other reasons. These findings suggest a need for more accepting research environments that recognize legitimate LLM benefits while developing nuanced disclosure policies addressing risks.}
}
@article{WEI2025105356,
title = {Enhancing pre-service teachers' reflective thinking skills through generative AI-assisted digital storytelling creation: A three-dimensional framework analysis},
journal = {Computers & Education},
volume = {235},
pages = {105356},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105356},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001241},
author = {Xiaodong Wei and Lei Wang and Tiffany A. Koszalka and Lap-Kei Lee and Ruixue Liu},
keywords = {Improving classroom teaching, Media in education, Teacher professional development, Teaching/learning strategies, 21st century abilities},
abstract = {Developing reflective thinking skills (RTS) in pre-service teachers remains a challenge in teacher education, particularly in the context of integrating emerging technologies. While digital storytelling (DST) has shown promise in fostering reflective practice, traditional methods often present technical barriers that hinder deeper reflection. Few studies have explored how generative artificial intelligence (GAI) tools can support RTS during DST creation. This study addresses these gaps by adopting a three-dimensional framework of RTS, which included the time of reflection, objects of reflection, and levels of reflection, to guide and assess the impact of GAI-assisted DST creation on pre-service teachers' reflective patterns. Employing a post-test quasi-experimental design, eighty pre-service teachers were divided into two groups: an experimental group utilizing GAI tools (e.g., ChatGPT, Midjourney, Runway) for DST creation, and a control group utilizing traditional methods. Results revealed that the experimental group significantly improved RTS in time, objects, and levels of reflection. Pre-service teachers in the experimental group reflected more on problem definition and solution generation during the design stages of reflection time. Regarding reflection objects, the experimental group exhibited significantly higher reflection frequencies across self, artifacts, and circumstances aspects. Additionally, pre-service teachers in experimental group demonstrated significantly higher reflection frequencies at all levels—single-loop, double-loop, and triple-loop—compared to the control group. Single-loop reflection was the most common, while triple-loop reflection was the least frequent in both groups. These findings underline GAI's potential to scaffold RTS and enhance the DST creation process, offering valuable insights for integrating GAI into teacher education to foster deeper reflective practice.}
}
@article{ZHAO2025253,
title = {xml:lang="en">Lesson study as an approach to facilitate the integration of Gen-AI into EFL curriculum design in higher education},
journal = {International Journal for Lesson and Learning Studies},
volume = {14},
number = {3},
pages = {253-279},
year = {2025},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-01-2025-0029},
url = {https://www.sciencedirect.com/science/article/pii/S2046825325000101},
author = {Zhi Jian Zhao and Jiajia Li and Yujia Hong and Tian Ying Yun},
keywords = {Lesson study, Generative AI, EFL teachers, Curriculum design},
abstract = {Purpose
This study investigates how English as a Foreign Language (EFL) teachers from higher education develop and refine their curriculum design with Generative Artificial Intelligence (Gen-AI) collaboration during the Lesson Study (LS).
Design/methodology/approach
Through a qualitative case study approach, we followed six English teachers in their collaborative work with a Gen-AI teaching assistant (Kimi) over a 6-month semester. Data were collected through the recordings of LS cycles, teacher interviews and reflections and documentation of teacher-AI interactions etc.
Findings
The findings revealed three key aspects of Gen-AI integration in designing EFL curriculum: First, teachers progressively discovered Kimi’s capabilities in lesson planning, material development, and activity design, showing value in generating differentiated learning resources. Second, the teachers developed sophisticated collaboration patterns with the Gen-AI, demonstrating iterative refinement approaches and strategic integration of Gen-AI suggestions throughout the LS cycles. Third, teachers' critical reflections showed evolution in their evaluation and application of Gen-AI contributions, maintaining professional agency while leveraging Gen-AI capabilities effectively.
Research limitations/implications
This study has several limitations that inform future research directions. Our investigation focused specifically on EFL higher education using a single Gen-AI tool (Kimi), which may limit the generalizability of the findings to other educational contexts and AI platforms.
Practical implications
These findings suggest that Gen-AI integration through LS can enhance teachers' professional practice while promoting critical engagement with Gen-AI tools. The study provides insights into how Gen-AI can be meaningfully integrated into teacher professional development through collaborative LS approaches.
Originality/value
The study demonstrates how the LS framework supports balanced AI integration while maintaining teacher agency. In addition, it reveals the process of AI capability discovery and strategic implementation in EFL teaching.}
}
@article{ARSLAN20244534,
title = {Exploring Business Events using Multi-source RAG},
journal = {Procedia Computer Science},
volume = {246},
pages = {4534-4540},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.303},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023226},
author = {Muhammad Arslan and Saba Munawar and Christophe Cruz},
keywords = {Business events, Extraction methods, Large Language Models, Retrieval-Augmented Generation, Dynamic business environments},
abstract = {Business events signify crucial activities within a company, indicating growth opportunities and investment prospects. They encompass various developments such as recruitment drives, market expansions, mergers, and product launches. Understanding these events is vital for businesses seeking to stay updated with market dynamics, as they provide real-time insights into a company’s trajectory. Moreover, comprehending the business events of one company can offer strategic advantages to others, facilitating informed decision-making and fostering collaboration within the business ecosystem. Extracting information about these events involves diverse structured, semi-structured, and unstructured data sources, posing challenges for traditional extraction methods. Despite the promise shown by existing openly available LLMs driven by Generative Artificial Intelligence (GenAI), they face challenges when dealing with domain-specific queries. Retrieval-Augmented Generation (RAG) addresses this challenge by seamlessly integrating multiple external data sources of varying structures. In our study, we demonstrate how RAG with LLM facilitates precise extraction of business events, ensuring adaptability in dynamic business environments where datasets are constantly evolving.}
}
@article{VHATKAR2024104047,
title = {Leveraging digital technology in retailing business: Unboxing synergy between omnichannel retail adoption and sustainable retail performance},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {104047},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.104047},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924003436},
author = {Manjunath S. Vhatkar and Rakesh D. Raut and Ravindra Gokhale and Mukesh Kumar and Milind Akarte and Sudishna Ghoshal},
keywords = {Omnichannel retailing, Digital technologies, Retail company performance, TBL, Triple bottom line},
abstract = {The retail industry is undergoing a significant transformation driven by digital technology. Among the key challenges retailers face are the rise of e-commerce, changing customer behaviour, and growing supply chain complexity. These shifts have intensified the pressure on retailers’ margins, necessitating bold action to reverse the negative trajectory. By leveraging digital technology in retail, this study unboxes the synergy between omnichannel retail adoption and sustainable retail performance and explores the intersection of omnichannel retail adoption and sustainable performance. By embracing omnichannel strategies and harnessing data at scale, retailers can enhance customer experiences, optimize operations, and drive growth. Utilizing Structural Equation Modelling (SEM) on data from 485 employees of Indian retail respondents. Findings reveal that digital technology has a significant moderation effect that boosts omnichannel activities' financial, environmental, and social aspects. Specifically, Generative Artificial Intelligence (Gen-AI) tools such as chatbots, visual search, and personalized retail experiences play a pivotal role. The study underscores combining data-driven, process, and Gen-AI technologies with omnichannel strategies to elevate performance. These insights contribute to understanding how retailers can leverage digital innovation within omnichannel frameworks for sustainable success.}
}
@article{FRANCE2024649,
title = {Navigating software development in the ChatGPT and GitHub Copilot era},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {649-661},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000697},
author = {Stephen L. France},
keywords = {Generative AI, Large language models, Software developers, AI prompting, Prompt engineering, Capability maturity model},
abstract = {Generative artificial intelligence (GenAI) technologies using LLMs (large language models), such as ChatGPT and GitHub Copilot, with the ability to create code, have the potential to change the software-development landscape. Will this process be incremental, with software developers learning GenAI skills to supplement their existing skills, or will the process be more destructive, with the loss of large numbers of development jobs and a radical change in the responsibilities of the remaining developers? Given the rapid growth of AI capabilities, it is impossible to provide a crystal ball, but this article aims to give insight into the adoption of GenAI with LLMs in software development. The article gives an overview of the software-development industry and of the job functions of software developers. A literature review, combined with a content analysis of online comments from developers, gives insight into how GenAI implemented with LLMs is changing software development and how developers are responding to these changes. The article ties the academic and developer insights together into recommendations for software developers, and it describes a CMM (capability maturity model) framework for assessing and improving LLM development usage.}
}
@article{IBARRAMUNOZ2025100818,
title = {Artificial intelligence in the food and bioprocess industries: Addressing food security challenges},
journal = {Food and Humanity},
volume = {5},
pages = {100818},
year = {2025},
issn = {2949-8244},
doi = {https://doi.org/10.1016/j.foohum.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S2949824425003222},
author = {Lizbeth Alejandra Ibarra-Muñoz and Giselle Guadalupe Resendiz-Acosta and Roberto Muñoz-García and Litzy Yazmin Alvarado-Mata and Jazel Doménica Sosa-Martínez and Lourdes Morales-Oyervides and Julio Montañez and Nagamani Balagurusamy},
keywords = {Generative artificial intelligence, Predictive artificial intelligence, Bioprocess optimization, Food safety, Food security},
abstract = {Exponential population growth and increasing global food demand present significant challenges to food security, including risk of food shortages, declining quality and adverse environmental consequences associated with food production. Thus, emerging technologies are being applied to enhance and address challenges within production and safety of food. In this review, the potential of Artificial Intelligence (AI) is being explored as an emerging tool towards food industry and bioprocess concerns such as fermentation parameters, quality control contamination detection, food safety management and bioprocess optimization. By leveraging advanced AI techniques, such as Machine Learning (ML), Deep Learning (DL), Artificial Neural Networks (ANN), and Generative Adversarial Networks (GAN). However ethical implications, such as transparency, liability, AI autonomy and corporation’s awareness, remain critical. Despite its transformative potential, challenges like scalability, data availability, and public perception must be addressed for AI full integration into the food industry. Future perspectives highlight AI’s expanding role in preproduction, processing, and distribution, additionally AI is supported by advancements in synthetic biology and predictive modeling.}
}
@article{GOSAK2024103888,
title = {The ChatGPT effect and transforming nursing education with generative AI: Discussion paper},
journal = {Nurse Education in Practice},
volume = {75},
pages = {103888},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.103888},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324000179},
author = {Lucija Gosak and Lisiane Pruinelli and Maxim Topaz and Gregor Štiglic},
keywords = {Artificial Intelligence, ChatGPT, Documentation, Education, Nursing, Nursing Diagnosis},
abstract = {Aim
The aim of this study is to present the possibilities of nurse education in the use of the Chat Generative Pre-training Transformer (ChatGPT) tool to support the documentation process.
Background
The success of the nursing process is based on the accuracy of nursing diagnoses, which also determine nursing interventions and nursing outcomes. Educating nurses in the use of artificial intelligence in the nursing process can significantly reduce the time nurses spend on documentation.
Design
Discussion paper.
Methods
We used a case study from Train4Health in the field of preventive care to demonstrate the potential of using Generative Pre-training Transformer (ChatGPT) to educate nurses in documenting the nursing process using generative artificial intelligence. Based on the case study, we entered a description of the patient's condition into Generative Pre-training Transformer (ChatGPT) and asked questions about nursing diagnoses, nursing interventions and nursing outcomes. We further synthesized these results.
Results
In the process of educating nurses about the nursing process and nursing diagnosis, Generative Pre-training Transformer (ChatGPT) can present potential patient problems to nurses and guide them through the process from taking a medical history, setting nursing diagnoses and planning goals and interventions. Generative Pre-training Transformer (ChatGPT) returned appropriate nursing diagnoses, but these were not in line with the North American Nursing Diagnosis Association – International (NANDA-I) classification as requested. Of all the nursing diagnoses provided, only one was consistent with the most recent version of the North American Nursing Diagnosis Association – International (NANDA-I). Generative Pre-training Transformer (ChatGPT) is still not specific enough for nursing diagnoses, resulting in incorrect answers in several cases.
Conclusions
Using Generative Pre-training Transformer (ChatGPT) to educate nurses and support the documentation process is time-efficient, but it still requires a certain level of human critical-thinking and fact-checking.}
}
@article{BLAND2025,
title = {Enhancing Medical Student Engagement Through Cinematic Clinical Narratives: Multimodal Generative AI–Based Mixed Methods Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/63865},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000017},
author = {Tyler Bland},
keywords = {artificial intelligence, cinematic clinical narratives, cinemeducation, medical education, narrative learning, AI, medical student, pharmacology, preclinical education, long-term retention, AI tools, GPT-4, image, applicability},
abstract = {Background
Medical students often struggle to engage with and retain complex pharmacology topics during their preclinical education. Traditional teaching methods can lead to passive learning and poor long-term retention of critical concepts.
Objective
This study aims to enhance the teaching of clinical pharmacology in medical school by using a multimodal generative artificial intelligence (genAI) approach to create compelling, cinematic clinical narratives (CCNs).
Methods
We transformed a standard clinical case into an engaging, interactive multimedia experience called “Shattered Slippers.” This CCN used various genAI tools for content creation: GPT-4 for developing the storyline, Leonardo.ai and Stable Diffusion for generating images, Eleven Labs for creating audio narrations, and Suno for composing a theme song. The CCN integrated narrative styles and pop culture references to enhance student engagement. It was applied in teaching first-year medical students about immune system pharmacology. Student responses were assessed through the Situational Interest Survey for Multimedia and examination performance. The target audience comprised first-year medical students (n=40), with 18 responding to the Situational Interest Survey for Multimedia survey (n=18).
Results
The study revealed a marked preference for the genAI-enhanced CCNs over traditional teaching methods. Key findings include the majority of surveyed students preferring the CCN over traditional clinical cases (14/18), as well as high average scores for triggered situational interest (mean 4.58, SD 0.53), maintained interest (mean 4.40, SD 0.53), maintained-feeling interest (mean 4.38, SD 0.51), and maintained-value interest (mean 4.42, SD 0.54). Students achieved an average score of 88% on examination questions related to the CCN material, indicating successful learning and retention. Qualitative feedback highlighted increased engagement, improved recall, and appreciation for the narrative style and pop culture references.
Conclusions
This study demonstrates the potential of using a multimodal genAI-driven approach to create CCNs in medical education. The “Shattered Slippers” case effectively enhanced student engagement and promoted knowledge retention in complex pharmacological topics. This innovative method suggests a novel direction for curriculum development that could improve learning outcomes and student satisfaction in medical education. Future research should explore the long-term retention of knowledge and the applicability of learned material in clinical settings, as well as the potential for broader implementation of this approach across various medical education contexts.}
}
@article{TRAN2025101578,
title = {Students’ self-determination in using machine translation and generative AI tools for English for academic purposes},
journal = {Journal of English for Academic Purposes},
volume = {78},
pages = {101578},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101578},
url = {https://www.sciencedirect.com/science/article/pii/S1475158525001092},
author = {Hao Tran and Peter Crosthwaite and Quy Huynh Phu Pham},
keywords = {Generative AI, Self-determination theory, English for academic purposes, Machine translation, Self-regulated learning},
abstract = {The rise of machine translation (MT) and generative artificial intelligence (GAI) presents opportunities and challenges for English for Academic Purposes (EAP) instruction. While MT/GAI can support students' learning beyond the classroom, overreliance on MT/GAI may hinder development of essential research and composition skills. Despite some research on MT/GAI's role in self-regulated learning, little is known about students' motivations for its use, and the potential mediating influences of instructional context and discipline. This study applies Self-Determination Theory to examine how autonomy, competence, and relatedness influence students' use of MT/GAI in academic writing. Using a mixed-methods approach, the study compares EAP students in an English as a Second Language context in Australia and an English as a Foreign Language context in Vietnam. An online survey validated through confirmatory factor analysis and discriminant validity testing gathered 416 responses, complemented by interviews with 17 students. Findings reveal a complex interplay between MT/GAI use and students' motivational needs. While students generally report moderate autonomy, competence, and relatedness in using MT/GAI in the survey, mixed-effects regression showed Australian students experienced lower relatedness compared with Vietnamese students, with disciplinary differences also significantly influencing students' perceptions of this construct. Interview data further highlighted diversity and complexity of students' perceptions, variation in EAP instructional approaches and peer-teacher dynamics surrounding MT/GAI. These findings support the need for contextually tailored pedagogical approaches fostering collaboration between institutions, teachers, and students, illustrated through innovations from an Australian EAP course that bridge research and practice in MT/GAI-assisted academic writing.}
}
@article{SIDAOUI2024101045,
title = {Generative AI in Responsible Conversational Agent Integration: Guidelines for Service Managers},
journal = {Organizational Dynamics},
volume = {53},
number = {2},
pages = {101045},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101045},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000184},
author = {Karim Sidaoui and Dominik Mahr and Gaby Odekerken-Schröder},
keywords = {Conversational agents, Software development life cycle, Inclusive design, Ethics, Generative artificial intelligence, Corporate digital responsibility, Organizational sensemaking, European Union Artificial Intelligence Act},
abstract = {Responsible integration of conversational agents (CAs) like chatbots is crucial for service firms to mitigate risks and foster positive outcomes. This article provides managerial guidelines through a Corporate Digital Responsibility (CDR) lens, focusing on CDR Culture, Management Structure, and Digital Governance across the service firm, software provider, and customers/society. It examines how organizational sensemaking processes of creation, interpretation, and enactment are triggered by CA-related issues and events. The research highlights the role of generative AI (GenAI) in implementing CDR factors and responsible CA software development lifecycle phases during development and integration. Guidelines are provided for leveraging GenAI to enhance CDR Culture, incorporate ethical considerations into CDR Management Structure, and enable robust Digital Governance mechanisms to prioritize customer/societal well-being. A multilevel framework illustrates reinforcing the guidelines through organizational sensemaking processes, and fostering responsible CA integration aligned with ethical principles and societal values.}
}
@article{BECKMAN2025101036,
title = {The GenAI divide among university students: A call for action},
journal = {The Internet and Higher Education},
volume = {67},
pages = {101036},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101036},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000454},
author = {Karley Beckman and Tiffani Apps and Sarah Katherine Howard and Claire Rogerson and Ann Rogerson and Jo Tondeur},
keywords = {Generative AI in higher education, ChatGPT, AI literacy, Digital divide, Higher education},
abstract = {The rapid pace of technological change with generative artificial intelligence is accelerating much faster than our capacity to understand and regulate it. Higher education institutions have been firmly focused on the impacts of this innovation on academic integrity while grappling with unknown longer-term impacts on students' academic study and future work. This mixed method study aims to capture student perspectives on their self-reported understanding of GenAI and intentions to use GenAI for their academic study during the critical diffusion stage and policy vacuum. Through a survey with 194 university students, the study explored student's understanding, knowledge, experience and intended use of GenAI tools to support their academic study. The paper presents three distinct student profiles established through cluster analysis of measures of digital and AI literacy, which are then explored in-depth through presentation of qualitative items. Notably, the cluster profiles demonstrate variation across the profiles of novice, cautious and enthusiastic users and patterns related to their knowledge of ChatGPT and intended uses. The paper draws on digital divide empirical literature and explores the potential to repeat digital divides among groups of students based on their access, capabilities, and capacity to leverage these for educational advantage. We propose that building upon a vast existing body of educational research about digital literacy inequalities offers rich insights into the current problems facing education institutions, specifically, what role do universities play in supporting students to understand and harness GenAI, now and in their futures.}
}
@article{ZHANG2025129645,
title = {A comprehensive overview of Generative AI (GAI): Technologies, applications, and challenges},
journal = {Neurocomputing},
volume = {632},
pages = {129645},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129645},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003170},
author = {Zhijun Zhang and Jian Zhang and Xiaodong Zhang and Weijian Mai},
keywords = {Generative artificial intelligence, Content generation, Pre-trained language models},
abstract = {Generative Artificial Intelligence (GAI) represents a forefront research domain and demonstrates the ability to generate innovative and creative content spanning text, images, audio, videos, and other technological forms. Recent breakthroughs in GAI, exemplified by remarkable products like ChatGPT and stable diffusion, have garnered significant attention and hold immense potential to shape the trajectory of societal development. This paper undertakes a comprehensive analysis of the current capabilities and limitations of GAI while exploring optimal strategies for its future application. Specifically, we provide an extensive overview of technical approaches employed in GAI, encompassing text, images, videos, audio, and multi-modal generation models. Furthermore, we summarize the commonly utilized training datasets and evaluation benchmarks of various modalities. These benchmarks serve as integral components for assessing the performance of GAI models. Subsequently, we delve into the current applications and future prospects of GAI across various fields. Finally, we discuss the challenges inherent in GAI and outline prospective directions for future advancements in the field, with the intention of offering valuable insights and inspiration to researchers.}
}
@article{OU2024101156,
title = {Conceptualising and cultivating Critical GAI Literacy in doctoral academic writing},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101156},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101156},
url = {https://www.sciencedirect.com/science/article/pii/S1060374324000638},
author = {Amy Wanyu Ou and Baraa Khuder and Sindija Franzetti and Raffaella Negretti},
keywords = {Artificial intelligence, Academic writing, Critical GAI Literacy, Self-regulated learning, Doctoral education},
abstract = {Generative artificial intelligence (GAI) has revolutionised the landscape of academic writing, presenting both advantages and risks to learning for L2 writers. It is thus imperative that L2 writers, especially at advanced academic levels, develop the critical skills necessary for employing GAI tools ethically and effectively in their writing processes. Our study addressed this need by 1) conceptualising Critical GAI Literacy based on current research and our collected data, and 2) developing a self-regulated learning-based micro-curriculum for L2 doctoral students to cultivate knowledge and skills using GAI for academic writing. We collected interactive and reflective data in an introductory-level academic writing course at a Swedish university enrolled with 60 PhD students from diverse backgrounds and examined their evolving perspectives and strategies for engaging in GAI-mediated writing. Findings show a spectrum of initial attitudes among students and limited knowledge of GAI use. Final reflections illustrate de-enchantment with GAI, recalibrated and enhanced understanding of ethical issues, developed prompting methods, and increased awareness of text ownership through the self-directed learning process. Furthermore, students demonstrated a discerning approach in evaluating GAI-generated suggestions and sociolinguistic impacts, indicating a growing criticality in L2 writing practices.}
}
@article{LIU2025100438,
title = {Designing a generative AI enabled learning environment for mathematics word problem solving in primary schools: Learning performance, attitudes and interaction},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100438},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100438},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000785},
author = {Jingxi Liu and Daner Sun and Jin Sun and Jingyun Wang and Philip Leung Ho Yu},
keywords = {ChatGPT, Generative artificial intelligence, Mathematics word problem solving, Personalized learning, Primary mathematics education},
abstract = {Mathematics word problem solving is a critical component of elementary education, yet many students encounter persistent difficulties in this area due to the combined cognitive demands of linguistic comprehension and mathematical reasoning. While previous studies have explored various pedagogical strategies to enhance problem-solving skills, the integration of generative artificial intelligence (GenAI) in this domain remains underexplored. This study introduces the ChatGPT-supported Mathematics Problem-Solving System (ChatGPT-MPS), a GenAI-enabled learning environment designed to support primary students in developing problem-solving strategies and deepening conceptual understanding. To evaluate its effectiveness, a quasi-experimental design was employed involving 104 fifth-grade students, assigned to an experimental group (using ChatGPT-MPS) and a control group (traditional instruction). Both groups completed a pre- and post-tests of MPS and interests scale to evaluate their word problem-solving proficiency and learning interests. Quantitively data analysis and its results showed that the experimental group exhibited significantly greater improvements in post-test performance compared to the control group. In addition, student feedback revealed increased interest, perceived value, and motivation when engaging with the ChatGPT-MPS learning environment. These findings provide empirical support for the use of GenAI in mathematics education and demonstrate the potential of ChatGPT-MPS to enhance students' mathematical thinking and engagement in problem-solving tasks. The study contributes to the growing body of research on AI-driven personalized learning in primary education, offering insights into the design and implementation of effective GenAI-enabled learning environments.}
}
@article{FANG2025101300,
title = {Generative AI-enhanced human-AI collaborative conceptual design: A systematic literature review},
journal = {Design Studies},
volume = {97},
pages = {101300},
year = {2025},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2025.101300},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X25000122},
author = {Cong Fang and Yujie Zhu and Le Fang and Yonghao Long and Huan Lin and Yangfan Cong and Stephen Jia Wang},
keywords = {Human-AI collaboration, AI-enhanced design, Design methodology, Design process, Conceptual design},
abstract = {Generative Artificial Intelligence (GenAI) has gained increasing attention, enhancing design productivity by elevating creativity within the conceptual design process. Despite these advancements, how GenAI will influence the conceptual design process and methods remains ambiguous, hindering its full potential. This study introduces a systematic literature review to explore GenAI's role in the conceptual design process, emphasizing the GenAI-human interactions and collaborations. We offer a critical evaluation of the current state of GenAI-human collaboration, identifying challenges, opportunities, and future research directions to leverage GenAI's design potential for enhancing creativity in conceptual design practice. Finally, a Generative AI Enhanced Conceptual Design framework was further proposed to clarify the potential collaborative design process, which can serve as a guideline for effective human-AI collaboration in the conceptual design process.}
}
@article{LIMA20251277,
title = {Enhancing Rare Disease Management and Care: Proposal of an Evidence-Based Digital Platform for Second Opinions},
journal = {Procedia Computer Science},
volume = {256},
pages = {1277-1284},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.239},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006003},
author = {Vinícius Lima and Filipe Bernardi and Diego Yamada and Victor Cassão and Francisco Barbosa-Junior and Têmis Félix and Victor Ferraz and Amaury Dal Fabbro and Domingos Alves},
keywords = {rare disease, second opinion, digital health},
abstract = {The management and care of rare diseases pose significant challenges due to limited evidence, scarce specialized resources, and pronounced healthcare disparities, particularly in Brazil. To address these issues, the development of the Rare Disease Second Opinion Platform is presented, an evidence-based digital solution designed to provide comprehensive second opinions for rare disease cases. The primary objectives are to streamline the process of obtaining clinical and non-clinical second opinions, enhance the educational knowledge base for healthcare professionals, and improve patient outcomes. The platform is developed using action research and a sociotechnical approach, ensuring it is user-centric and effective. Business process modeling and platform design will ensure a structured and user-friendly development. Preliminary results highlight the platform’s potential to connect patients, healthcare facilities, and specialists through a centralized web portal. The use of Generative Artificial Intelligence models will accelerate content production and query responses. The platform aims to significantly improve healthcare outcomes for rare disease patients in Brazil by providing timely access to specialist opinions and creating a comprehensive educational database.}
}
@article{QIN2025103769,
title = {EFL learners’ perceptual perezhivaniya and actual writing revision behaviors mediated by GenAI: A sociocultural theory perspective},
journal = {System},
volume = {133},
pages = {103769},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103769},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25001794},
author = {Lili Qin and Jingjing Dong},
abstract = {In recent years, Generative Artificial Intelligence (GenAI) has gained prominence as a valuable tool in enhancing EFL learners’ experiences in Second Language Acquisition (SLA). However, empirical studies specifically investigating on GenAI’s role in mediating the revision stage of EFL learners’ L2 writing processes remain scarce. Notably, research exploring the connection between learners’ perceived perezhivaniya—derived from Vygotskyan theory, denoting an individual’’s subjective lived experiences—and their actual revision behaviors is particularly limited. To address this lacuna, we employed interviews, Q-methodology, and the Translog screen recording tool to investigate the revision processes of nineteen EFL learners at a university in Southern China as they revised L2 continuation writing tasks using GenAI. A key contribution of this study is the development of a novel seven-dimensional L2 writing revision taxonomy (word choice, content, discourse, syntax, errors, alignment, and typographic elements), which guided both the Q-questionnaire design and the Translog data coding. This framework uniquely facilitated a comparison between perceived perezhivaniya and actual revision behaviors by integrating online revision with offline reflective perceptions, thereby capturing an essential dynamic aspect of the concept of perezhivanie. Results indicated a strong consistency between most of the learners’ perceived experiences and their actual revision behaviors, in content, alignment, and typographic elements. However, for some learners, alignment—vital for continuation writing—was frequently overlooked despite its perceptual recognition, highlighting significant pedagogical implications.}
}
@article{GERING2025132,
title = {Strategic organisational responses to generative AI-driven digital transformation in leading higher education institutions},
journal = {International Journal of Organizational Analysis},
volume = {33},
number = {12},
pages = {132-152},
year = {2025},
issn = {1934-8835},
doi = {https://doi.org/10.1108/IJOA-09-2024-4850},
url = {https://www.sciencedirect.com/science/article/pii/S1934883525000163},
author = {Zsuzsanna Gering and Katalin Feher and Vanda Harmat and Reka Tamassy},
keywords = {Generative AI, Higher education, Organisational strategy, Digital transformation, Top universities, Future of higher education},
abstract = {Purpose
This study aims to explore generative artificial intelligence (AI) as a significant milestone and key driver of digital transformation in higher education, emphasising the urgent need for universities and policymakers to adapt strategies to remain effective, competitive and aligned with the rapidly evolving demands of education and research.
Design/methodology/approach
This study used qualitative content analysis to examine publicly available strategic documents and statements related to digital transformation from the top 30 ranked universities in the Times Higher Education 2024 Ranking, producing a data set of 98 strategies covering all key organisational domains.
Findings
The collected documents span eight areas, from teaching-learning strategies to information technology (IT) strategies and committees, with substantial variation among universities in scope, content and strategic combinations. A significant result is that teaching-learning offices and development centres serve as bridges between institutional strategies and grassroots innovation, absorbing top-down and bottom-up knowledge and fostering adaptive responses to generative AI-driven transformation.
Practical implications
By showcasing the best practices, this paper provides practical guidance for proactive institutional development, supporting university leadership in strategy-building and aiding national and international policymakers in shaping forward-looking frameworks.
Originality/value
Understanding and defining generative AI as a milestone in digital transformation is crucial for universities. Proactive adaptation to emerging trends and best practices enables institutions to navigate these challenges effectively.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{SAHEB2024100146,
title = {Convergence of artificial intelligence with social media: A bibliometric & qualitative analysis},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100146},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100146},
url = {https://www.sciencedirect.com/science/article/pii/S277250302400032X},
author = {Tahereh Saheb and Mouwafac Sidaoui and Bill Schmarzo},
keywords = {Social media, Artificial intelligence, Bibliometric analysis, Qualitative research},
abstract = {The integration of artificial intelligence (AI) and social media has provided numerous benefits to businesses, including improved audience analysis and content optimization. However, AI has facilitated the spread of misinformation, emphasizing the importance of taking a balanced approach that considers both the technology's positive applications and its ethical risks. This paper looks at the intersection of AI and social media. The researchers use a mixed-method approach to analyze 1540 scholarly documents, combining bibliometric and systematic literature review techniques. The goal of this research is to identify the most important topics and trends, as well as potential business values and implications, in the AI Social Media domain. The first stage of the research involved a quantitative keyword co-occurrence analysis, which resulted in the identification of ten dominant themes. These include Conversational Agents & User Experience, Human Emotion and Content Recommendation & Moderation, Collective Intelligence in Emergency Management, Algorithmic Activism on social media, Deep Fakes and Fake News, Generative Artificial Intelligence, Algorithmic Bias in Content Moderation Systems, Deep Sentiment Analysis, Metaverse Technologies, and NLP & Mental Health Detection. Each identified theme is then subjected to a qualitative thematic literature review, which provides a more in-depth, context-specific understanding of the associated findings. Because of this comprehensive approach, the study provides a broad overview of the current state of AI social media, shedding light on the potential applications and far-reaching implications of this interdisciplinary nexus. The study's findings have the potential to shape strategic decision-making, policy development, and future research directions in this rapidly changing field.}
}
@article{LEE2025113326,
title = {A structured prompt framework for AI-generated biophilic architectural spaces},
journal = {Journal of Building Engineering},
volume = {111},
pages = {113326},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.113326},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225015633},
author = {Eun Ji Lee and Sung Jun Park},
keywords = {Biophilic design, Generative AI, AI-Assisted visualization, Structured prompt engineering, Architectural space},
abstract = {This study proposes a structured prompt framework to improve the quality and consistency of generative visualizations in biophilic architectural space (BAS) design. Existing generative artificial intelligence (Gen AI)-based visualization approaches often lack alignment with biophilic design principles, resulting in outputs that fail to reflect the restorative qualities of nature-integrated spaces. To address this limitation, the study links generative visualization processes to established biophilic frameworks, thereby enhancing the applicability of Gen AI in sustainable and human-centered architectural practice. The methodology follows a three-stage process: (1) exploration of biophilic visualization requirements through literature review and prompt testing, (2) development of the framework through domain-specific dataset construction, text mining, and prompt curation, and (3) expert evaluation of images generated using the structured prompts. The proposed framework consists of five components—subject, attribute, mood, time and background, and negative prompt—to guide the generation of BAS visualizations systematically. The generated images were assessed based on five criteria: domain fidelity, visual coherence, depth and perspective, spatial integration, and overall biophilic appeal. Results demonstrated substantial improvements—up to 75 % in domain fidelity and over 60 % in spatial integration and biophilic appeal—compared to early-tested prompts. These findings underscore the potential of structured prompts, grounded in biophilic design theory, to enhance the effectiveness of AI visualizations. This study offers a replicable and scalable method for integrating nature-based design principles into early-stage spatial planning. It provides design professionals with a practical tool to visualize restorative environments and promote sustainable architectural practice.}
}
@article{MOORHOUSE2023100151,
title = {Generative AI tools and assessment: Guidelines of the world's top-ranking universities},
journal = {Computers and Education Open},
volume = {5},
pages = {100151},
year = {2023},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2023.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2666557323000290},
author = {Benjamin Luke Moorhouse and Marie Alina Yeo and Yuwei Wan},
keywords = {Generative artificial intelligence, Assessment guidelines, Higher education, ChatGPT, Academic integrity},
abstract = {The public release of generative artificial intelligence (GAI) tools (e.g., ChatGPT) has had a disruptive effect on the assessment practices of higher education institutions (HEIs) worldwide. Concerns have largely been associated with academic integrity, cheating and plagiarism. HEIs have had to develop guidelines in response to GAI. As many of these guidelines were developed in haste and could affect a large number of instructors and students, there is a need to examine their content, coverage and suitability. This review examines the extent to which the world's 50 top-ranking HEIs have developed or modified their assessment guidelines to address GAI use and, where guidelines exist, the primary content and advice given to guide instructors in their GAI assessment design and practices. The findings show that just under half of the institutions have developed publicly available guidelines. The guidelines cover three main areas: academic integrity, advice on assessment design and communicating with students. Amongst the suggestions for teachers on assessment design, two appear particularly pertinent in helping develop effective assessment tasks and developing learners’ AI literacy: first, running assessment tasks through GAI to check the extent to which the tool can accomplish the task and, second, having students use GAI as part of the assessment process. Overall, the review suggests that HEIs have come to accept the use of GAI and drafted assessment guidelines to advise instructors on its use. In the article, we argue that it may be beneficial to embrace GAI as a part of the assessment process since this is the reality of today's educational and job landscape. This will require instructors to develop a new competence - generative artificial intelligence assessment literacy - which is conceptualised in this article.}
}
@article{NAMOUN2024671,
title = {Predicting the usability of mobile applications using AI tools: the rise of large user interface models, opportunities, and challenges},
journal = {Procedia Computer Science},
volume = {238},
pages = {671-682},
year = {2024},
note = {The 15th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) / The 7th International Conference on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024, Hasselt University, Belgium},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.076},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924013127},
author = {Abdallah Namoun and Ahmed Alrehaili and Zaib Un Nisa and Hani Almoamari and Ali Tufail},
keywords = {generative artificial intelligence, LLM, generative UI design, large UI models, mobile apps, usability testing, usability attributes},
abstract = {This article proposes the so-called large user interface models (LUIMs) to enable the generation of user interfaces and prediction of usability using artificial intelligence in the context of mobile applications. To this end, we synergized an integrated framework for the effective testing of the usability of mobile applications following a selective review of the most influential models of mobile usability testing. Next, we identified and analysed 13 recent AI tools that generate user interfaces for mobile apps, and systematically tested these tools to identify their AI capabilities. Our striking findings demonstrate that current generative UI tools fail to address mobile usability attributes, such as efficiency, learnability, effectiveness, satisfaction, and memorability. Our large UI models’ architecture proposes to leverage the capabilities of large language models, large vision models, and large code models to overcome the challenges of AI-driven UI/UX design and front-end implementations. This fascinating UI eco-system must be augmented with sufficient UI data and multi-sensory input regarding user behaviour to train the models. We anticipate LUIMs to create ample opportunities, like expedited frontend software development, enhanced personalised user experience, and wider accessibility of smart technologies. However, the research challenges hindering the UI generation and usability prediction of mobile apps include the seamless integration of complex generative AI models, semantic understanding of non-uniform visual designs, scarcity of UX datasets, and modelling of realistic user interactions.}
}
@article{SEYFI2025101364,
title = {Generational differences in adopting AI-generated travel advice: What drives trust and reduces resistance?},
journal = {Tourism Management Perspectives},
volume = {57},
pages = {101364},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101364},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000297},
author = {Siamak Seyfi and Changkyu Lee and Yunkyoung Jo and Myung Ja Kim},
keywords = {Generative artificial intelligence (GAI), Technology adoption, Generational differences, Innovation resistance theory, Tourism digitalization},
abstract = {The adoption of Generative Artificial Intelligence (GAI) in tourism is expanding, yet significant generational differences remain in its acceptance for travel planning and decision-making. This study, drawing on the theoretical lens of innovation resistance and generation theory, examines how generational attitudes toward technology shape perceptions of barriers to GAI adoption in tourism experiences. Using data from South Korea and the United States, the research employs Structural Equation Modeling (PLS-SEM), multi-group analysis (MGA), and fuzzy-set Qualitative Comparative Analysis (fsQCA) to uncover generational disparities in GAI acceptance. Findings reveal distinct challenges faced by different age groups, emphasizing that trust, usability, and perceived risks influence adoption patterns differently across cohorts. The study contributes to the growing theoretical discourse on GAI adoption in tourism and provides practical insights for tailoring GAI solutions to enhance user acceptance and satisfaction across generations.}
}
@article{RADO2025,
title = {Co-Design of a Health Screening Program Fact Sheet by People Experiencing Homelessness and ChatGPT: Focus Group Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/68316},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25004524},
author = {Nóra Radó and Orsolya Németh and Sándor Békási},
keywords = {digital health, co-design, oral health, focus group, expert by experience, ChatGPT, health information, leaflet, screening, mixed method study, screening programs, oral cancer, vulnerable population, generative AI, co-design, Hungary, homeless, qualitative method, quantitative method, artificial intelligence},
abstract = {Background
People experiencing homelessness have worse oral health outcomes and a notable health informational asymmetry compared to the general population. Screening programs present a viable option for this population; however, barriers to access, such as lower levels of health literacy, lack of information, and mistrust, narrow their chances to participate in such programs.
Objective
The aim of this study is to investigate the applicability of generative artificial intelligence (AI) in designing a homeless health screening program fact sheet with experts by experience using co-design principles.
Methods
Six fact sheet text variants were created by the open-access version of ChatGPT 3.5 for an oral cancer screening program targeting people experiencing homelessness in Budapest, Hungary. Clients of homeless social services (N=23) were invited to a short questionnaire survey and 3 semistructured focus group discussions between May and July 2024. General opinions regarding generative AI technology and direct feedback on the text variants were obtained. Additionally, a standardized readability assessment of the text variants was completed via the Sydney Health Literacy Lab Editor.
Results
Almost two-thirds of participants (17/23) stated that they had previously heard about AI; however, their self-assessment regarding the extent of their knowledge resulted in an average of 2.38 (n=16) on a 5-point Likert scale. During the first focus group discussion, all 6 variants received a high score (between 4.63 and 4.92 on a 5-point Likert scale). In the next sessions, participants remained positive when the pool was narrowed to 4 versions, although they scored the texts lower. During open discussions, text variants were considered understandable, while difficulties with medical expressions, lengthiness of sentences, and references to a stereotypical homeless subgroup (rough sleepers) were also reported. The health literacy editor showed that most AI-generated text variants were difficult to read and too complex for the target group.
Conclusions
The co-design process revealed that focus group participants actively wanted to shape the fact sheet drafts. They shared their insights on how to make the text variants more appealing for the target audience. Moreover, the involvement of generative AI technology revealed that the participants have heard about the concept of AI and text generation as a potential function, and they have not rejected its use in health care settings.}
}
@article{AMANKWAHAMOAH2024102759,
title = {The impending disruption of creative industries by generative AI: Opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {79},
pages = {102759},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102759},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000070},
author = {Joseph Amankwah-Amoah and Samar Abdalla and Emmanuel Mogaji and Amany Elbanna and Yogesh K. Dwivedi},
keywords = {Creative industries, Generative AI, Collaboration, Automation, Transformation},
abstract = {Despite the debate on the potential effects of the adoption of generative artificial intelligence (AI) in modern societies in terms, there needs to be more clarity in the scholarly discourse and directions for the creative industries. In this editorial article, we discuss the potential impact of generative AI adoption on the creative industries and outline future research agendas. We argue that the successful adoption of generative AI in the creative industries lies in finding the delicate balance between maintaining human ingenuity and reaping the benefits of technological innovation. Unlike other industrial sectors, where AI primarily automates repetitive tasks, creative professionals can use generative AI as a collaborative tool to spark new avenues for creativity, streamline workflows, and accelerate creative processes. However, maintaining the human touch and authenticity that define the output of the creative industries remains a challenge for the industry and society. We examine these issues in the paper.}
}
@article{GIORGI2024116058,
title = {Evaluating generative AI responses to real-world drug-related questions},
journal = {Psychiatry Research},
volume = {339},
pages = {116058},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.116058},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124003433},
author = {Salvatore Giorgi and Kelsey Isman and Tingting Liu and Zachary Fried and João Sedoc and Brenda Curtis},
keywords = {Large language models, Generative AI, Substance use, Alcohol, Marijuana, Opioids},
abstract = {Generative Artificial Intelligence (AI) systems such as OpenAI's ChatGPT, capable of an unprecedented ability to generate human-like text and converse in real time, hold potential for large-scale deployment in clinical settings such as substance use treatment. Treatment for substance use disorders (SUDs) is particularly high stakes, requiring evidence-based clinical treatment, mental health expertise, and peer support. Thus, promises of AI systems addressing deficient healthcare resources and structural bias are relevant within this domain, especially in an anonymous setting. This study explores the effectiveness of generative AI in answering real-world substance use and recovery questions. We collect questions from online recovery forums, use ChatGPT and Meta's LLaMA-2 for responses, and have SUD clinicians rate these AI responses. While clinicians rated the AI-generated responses as high quality, we discovered instances of dangerous disinformation, including disregard for suicidal ideation, incorrect emergency helplines, and endorsement of home detox. Moreover, the AI systems produced inconsistent advice depending on question phrasing. These findings indicate a risky mix of seemingly high-quality, accurate responses upon initial inspection that contain inaccurate and potentially deadly medical advice. Consequently, while generative AI shows promise, its real-world application in sensitive healthcare domains necessitates further safeguards and clinical validation.}
}
@article{AMANO2025114600,
title = {Microscopy modality transfer of steel microstructures: Inferring scanning electron micrographs from optical microscopy using generative AI},
journal = {Materials Characterization},
volume = {220},
pages = {114600},
year = {2025},
issn = {1044-5803},
doi = {https://doi.org/10.1016/j.matchar.2024.114600},
url = {https://www.sciencedirect.com/science/article/pii/S1044580324009811},
author = {Nicholas Amano and Bo Lei and Martin Müller and Frank Mücklich and Elizabeth A. Holm},
keywords = {Generative artificial intelligence, Computer vision, Diffusion models, Microstructure, Steel, Modality transfer},
abstract = {Scanning electron microscopy (SEM) is resource intensive, which limits its throughput in some applications. As an alternative, we propose applying computer vision and machine learning to generate high-quality synthetic SEM micrographs from micrographs obtained using light optical microscopy (LOM). Working with a correlated LOM/SEM dataset of dual-phase steel images, we test generative models of various architectures, including encoder-decoder networks, generative adversarial networks (GANs), and diffusion-based models. We find that the diffusion models significantly outperform other methods on both qualitative and quantitative assessments, while preserving key metallurgical meaning. This work establishes diffusion as the state-of-the-art for microscopy modality transfer and demonstrates the potential of AI-powered microscopy to enhance LOM with micron scale structural recreation.}
}
@article{TAI2024105112,
title = {Improving elementary EFL speaking skills with generative AI chatbots: Exploring individual and paired interactions},
journal = {Computers & Education},
volume = {220},
pages = {105112},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105112},
url = {https://www.sciencedirect.com/science/article/pii/S036013152400126X},
author = {Tzu-Yu Tai and Howard Hao-Jan Chen},
keywords = {Generative artificial intelligence (GAI), Chatbots, EFL speaking, Cooperative/collaborative learning, Elementary education},
abstract = {Generative artificial intelligence (GAI) and automatic speech recognition (ASR) have ushered in promising tools for foreign language learning, notably GAI chatbots. This study investigated the impact of GAI chatbots on elementary school English as a foreign language (EFL) learners' speaking skills, focusing on two interaction configurations—individual and paired. Eighty-five elementary school EFL learners participated in a three-week summer program, engaging in daily 45-min interactions with CoolE Bot. The participants were randomly assigned to three groups: (1) individual interaction with CoolE Bot (I-Bot group), (2) paired interaction with CoolE Bot (P-Bot group), and (3) interaction with teachers and peers in a conventional English classroom (No-Bot group). In each class, participants in the Bot group received worksheets with a topic, prompts, and vocabulary to guide their interactions with CoolE Bot, while those in the No-Bot group also received worksheets for comparable activities. Quantitative (English-speaking tests) and qualitative data (semi-structured interviews) were collected and analyzed. Results revealed that the I-Bot and P-Bot groups' post-test speaking skills were significantly higher than those of the No-Bot group. CoolE Bot significantly improved the speaking skills of EFL learners. Both individual and paired interactions with CoolE Bot demonstrated positive effects, with no significant differences between groups. Interviews highlight CoolE Bot's adeptness in coherent interaction, charismatic conversational style with a human-like voice, diverse topic discussions tailored to learners' interests, and supportive functions. The participants found GAI chatbot-assisted EFL speaking enjoyable, motivating, and engaging appreciating its cartoonish, human-like characters, conversational style, and voice. Additionally, CoolE Bot fostered rapport and a supportive environment enhancing learners' confidence and reducing anxiety regarding EFL speaking. Individual interactions encourage personalized engagement and self-directed learning, whereas paired interactions involve social dynamics, shared learning experiences, and mutual resolution of language challenges.}
}
@article{BOUNAB2025107142,
title = {Advancing Direct Tablet Compression with AI: A multi-task framework for quality control, batch acceptance, and causal analysis},
journal = {European Journal of Pharmaceutical Sciences},
volume = {212},
pages = {107142},
year = {2025},
issn = {0928-0987},
doi = {https://doi.org/10.1016/j.ejps.2025.107142},
url = {https://www.sciencedirect.com/science/article/pii/S0928098725001411},
author = {Yazid Bounab and Osmo Antikainen and Mia Sivén and Anne Juppo},
keywords = {Direct Tablet Compression, Tablet quality control, Tabular Data Augmentation, Neural networks, Generative artificial intelligence},
abstract = {Pharmaceutical manufacturing has surged in drug development with the rise of Pharma 4.0, leveraging artificial intelligence (AI) to improve efficiency, optimize resource use, and reduce production times. Direct Tablet Compression (DTC), a key manufacturing technique, depends on the physicochemical properties of active pharmaceutical ingredients (API), excipients, and process parameters. This paper presents a novel multi-task framework combining regression, classification, and text generation to predict tablet properties (friability, hardness, disintegration time, and water absorption ratio), determine batch acceptance, and provide insights for optimizing interactions to improve tablet quality. The framework not only enables real-time monitoring, quality control and regulatory compliance, but also helps to understand the reasons why tablets in the manufacturing batch do not meet quality requirements. Using statistical methods, Neural Networks (NN), Natural Language Processing (NLP), and generative AI (GenAI), it outperforms state-of-the-art methods, achieving 91.8% R2 and 95.5% accuracy for regression and classification, respectively, as demonstrated using the Harvard Dataverse V1 dataset of Fast Disintegrating Tablets (FDTs) non placebo.}
}
@article{URBINA202514,
title = {Disability Ethics and Education in the Age of Artificial Intelligence: Identifying Ability Bias in ChatGPT and Gemini},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {106},
number = {1},
pages = {14-19},
year = {2025},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2024.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0003999324011912},
author = {Jacob T. Urbina and Peter D. Vu and Michael V. Nguyen},
keywords = {Artificial intelligence, Bias, Digital health technology, Disability discrimination, Rehabilitation},
abstract = {Objective
To identify and quantify ability bias in generative artificial intelligence large language model chatbots, specifically OpenAI's ChatGPT and Google's Gemini.
Design
Observational study of language usage in generative artificial intelligence models.
Setting
Investigation-only browser profile restricted to ChatGPT and Gemini.
Participants
Each chatbot generated 60 descriptions of people prompted without specified functional status, 30 descriptions of people with a disability, 30 descriptions of patients with a disability, and 30 descriptions of athletes with a disability (N=300).
Interventions
Not applicable.
Main Outcome Measures
Generated descriptions produced by the models were parsed into words that were linguistically analyzed into favorable qualities or limiting qualities.
Results
Both large language models significantly underestimated disability in a population of people, and linguistic analysis showed that descriptions of people, patients, and athletes with a disability were generated as having significantly fewer favorable qualities and significantly more limitations than people without a disability in both ChatGPT and Gemini.
Conclusions
Generative artificial intelligence chatbots demonstrate quantifiable ability bias and often exclude people with disabilities in their responses. Ethical use of these generative large language model chatbots in medical systems should recognize this limitation, and further consideration should be taken in developing equitable artificial intelligence technologies.}
}
@article{ZHENG2025111,
title = {Detection of Gastrointestinal Bleeding With Large Language Models to Aid Quality Improvement and Appropriate Reimbursement},
journal = {Gastroenterology},
volume = {168},
number = {1},
pages = {111-120.e4},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2024.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0016508524054672},
author = {Neil S. Zheng and Vipina K. Keloth and Kisung You and Daniel Kats and Darrick K. Li and Ohm Deshpande and Hamita Sachar and Hua Xu and Loren Laine and Dennis L. Shung},
keywords = {Generative Artificial Intelligence, Acute Gastrointestinal Bleeding, Large Language Models, Nature Language Processing, Quality Improvement},
abstract = {Background & Aims
Early identification and accurate characterization of overt gastrointestinal bleeding (GIB) enables opportunities to optimize patient management and ensures appropriately risk-adjusted coding for claims-based quality measures and reimbursement. Recent advancements in generative artificial intelligence, particularly large language models (LLMs), create opportunities to support accurate identification of clinical conditions. In this study, we present the first LLM-based pipeline for identification of overt GIB in the electronic health record (EHR). We demonstrate 2 clinically relevant applications: the automated detection of recurrent bleeding and appropriate reimbursement coding for patients with GIB.
Methods
Development of the LLM-based pipeline was performed on 17,712 nursing notes from 1108 patients who were hospitalized with acute GIB and underwent endoscopy in the hospital from 2014 to 2023. The pipeline was used to train an EHR-based machine learning model for detection of recurrent bleeding on 546 patients presenting to 2 hospitals and externally validated on 562 patients presenting to 4 different hospitals. The pipeline was used to develop an algorithm for appropriate reimbursement coding on 7956 patients who underwent endoscopy in the hospital from 2019 to 2023.
Results
The LLM-based pipeline accurately detected melena (positive predictive value, 0.972; sensitivity, 0.900), hematochezia (positive predictive value, 0.900; sensitivity, 0.908), and hematemesis (positive predictive value, 0.859; sensitivity, 0.932). The EHR-based machine learning model identified recurrent bleeding with area under the curve of 0.986, sensitivity of 98.4%, and specificity of 97.5%. The reimbursement coding algorithm resulted in an average per-patient reimbursement increase of $1299 to $3247 with a total difference of $697,460 to $1,743,649.
Conclusions
An LLM-based pipeline can robustly detect overt GIB in the EHR with clinically relevant applications in detection of recurrent bleeding and appropriate reimbursement coding.}
}
@article{JOO2025101571,
title = {Human-AI collaborative reading in academic contexts: An exploratory case study},
journal = {Journal of English for Academic Purposes},
volume = {78},
pages = {101571},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101571},
url = {https://www.sciencedirect.com/science/article/pii/S147515852500102X},
author = {Dayoung Joo and Diane Belcher},
keywords = {Second language reading, Academic literacy, English for academic purposes, Generative AI, The direct and inferential mediation (DIME) model, Sociocultural theory},
abstract = {The increasing prevalence of generative artificial intelligence (GenAI) in education presents new opportunities and challenges for second language (L2) learners' academic literacy development. While tools like ChatGPT can act as virtual experts, offering immediate feedback and engaging learners in reflective dialogues, little is known about how L2 readers interact with them in their academic practices and how their reading processes evolve. Taking a sociocognitive view, grounded in sociocultural theory and interpreted through the heuristic lens of the Direct and Inferential Mediation (DIME) model of reading comprehension, this exploratory case study examined how one international graduate student engages with GenAI to enhance academic reading. Data were collected over six weeks through screen-recordings of reading sessions, chat logs, stimulated recall interviews, and semi-structured interviews. Findings revealed that ChatGPT functioned as a translator, knowledge facilitator, and strategic partner, reducing reading anxiety while supporting comprehension across key components of the DIME model, such as vocabulary knowledge, background knowledge, inference-making, and reading strategies. Notably, the learner demonstrated a shift in reading approach, moving from an initial dependence on translation toward more strategic engagement with academic texts, including the use of summarization and inference. However, perceived AI limitations, such as questionable reliability and excessively detailed responses, occasionally caused fatigue for the learner. By providing an in-depth exploration of human-AI interaction in academic reading, the study contributes to the growing body of literature on GenAI's role in L2 education, laying the groundwork for future studies on its long-term impact on L2 reading.}
}
@article{LEE2025106317,
title = {Generative AI-driven data augmentation for enhanced construction hazard detection},
journal = {Automation in Construction},
volume = {177},
pages = {106317},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106317},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003577},
author = {YeJun Lee and GyeongNam Kang and Jinwoo Kim and Seonghwan Yoon and JungHo Jeon},
keywords = {Construction safety, Computer vision, Object detection, Generative AI, Image augmentation},
abstract = {The construction industry has long struggled with poor safety records. Traditional safety monitoring methods, reliant on manual observations, are often ineffective. To address these limitations, computer vision and generative artificial intelligence (AI) have been explored. While computer vision has shown promise in automating safety monitoring, its effectiveness is often hindered by the challenges of efficiently collecting diverse datasets. Generative AI offers a potential solution by augmenting image datasets, enabling more robust construction hazard detection. This paper investigates the use of generative AI for augmenting image data to improve hazard detection performance. Various combinations of generative AI tools and prompting strategies are tested. The results show that the combination of image-guided structured prompting with Stable Diffusion achieves the highest detection performance (mAP@50 of 92.5 %) using 150 augmented images. This represents a substantial improvement compared to the baseline mAP@50 of 51.6 % achieved with real images alone.}
}
@article{LIU2025,
title = {Generative AI for clinical reasoning: A scoping review},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002410},
author = {Ying-Mei Liu and Chang-Chuan Chou and Tang-Her Jaing and Chizimuzo T.C. Okoli},
keywords = {clinical reasoning, education, generative artificial intelligence, health, simulation},
abstract = {Objectives
To explore how generative artificial intelligence (AI) supports clinical reasoning development through simulation-based teaching in undergraduate health professions education.
Design
Scoping review.
Data Sources
CINAHL, ERIC, PubMed, ScienceDirect, and Web of Science databases.
Review Methods
A systematic search was conducted to identify studies exploring the integration of generative AI in simulation-based learning. Inclusion criteria focused on undergraduate health professions education and clinical reasoning outcomes.
Results
Six studies with a total of 492 participants met the inclusion criteria. Generative AI was used to create simulation scenarios, virtual patients, provide feedback, analyze student performance, and support inquiry-based learning. Four studies reported significantly improved clinical reasoning outcomes with AI-assisted teaching. One study reported the comparability between AI-generated feedback and expert feedback, though expert input remained superior in complex cases.
Conclusions
The integration of generative AI into simulation-based education is in its early stages. Most studies lacked theoretical frameworks and used diverse outcome measures, limiting comparability and generalizability. Future research should adopt theory-driven designs and standardized assessment tools to better evaluate the impact of generative AI on clinical reasoning development.}
}
@article{DAI202384,
title = {Reconceptualizing ChatGPT and generative AI as a student-driven innovation in higher education},
journal = {Procedia CIRP},
volume = {119},
pages = {84-90},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004407},
author = {Yun Dai and Ang Liu and Cher Ping Lim},
keywords = {ChatGPT, generative AI, higher education, learning analytics, personalized learning, engineering education},
abstract = {Higher education is poised at the precipice of the changes and challenges brought about by ChatGPT. This paper addresses some of the most fundamental questions about the role, position, and implications of ChatGPT and generative artificial intelligence (AI) tools amidst the evolving landscape of higher education and modern society. By linking technological affordances with educational needs, we conceptualize ChatGPT as a student-driven innovation with rich potential to empower students and enhance their educational experiences and resources. However, this empowerment comes at a price. It requires collaborative efforts among the stakeholders to address the new and emerging challenges regarding student training, higher education curricula and assessment, and technology development and governance. It also implies new directions for educational research and theories.}
}
@article{BENTZEN2025103798,
title = {Artificial Intelligence in Health Care: A Rallying Cry for Critical Clinical Research and Ethical Thinking},
journal = {Clinical Oncology},
volume = {41},
pages = {103798},
year = {2025},
issn = {0936-6555},
doi = {https://doi.org/10.1016/j.clon.2025.103798},
url = {https://www.sciencedirect.com/science/article/pii/S0936655525000536},
author = {S.M. Bentzen},
abstract = {Artificial intelligence (AI) will impact a large proportion of jobs in the short to medium term, especially in the developed countries. The consequences will be felt across many sectors including health care, a critical sector for implementation of AI tools because glitches in algorithms or biases in training datasets may lead to suboptimal treatment that may negatively affect the health of an individual. The stakes are obviously higher in case of potentially life-threatening diseases such as cancer and therapies with a potential for causing severe or even fatal adverse events. Over the last two decades, much of the research on AI in health care has focussed on diagnostic radiology and digital pathology, but a solid body of research is emerging on AI tools in the radiation oncology workflow. Many of these applications are relatively uncontroversial, although there is still a lack of evidence regarding effectiveness rather than efficiency, and—the ultimate bar—evidence of clinical utility. Proponents of AI will argue that these algorithms should be implemented with robust human supervision. One challenge here is the deskilling effect associated with new technologies. We will become increasingly dependent on the AI tools over time, and we will become less capable of assessing the quality of the AI output. Much of this research appears almost old-fashioned in view of the rapid advances in Generative artificial intelligence (GenAI). GenAI can draw from multiple types of data and produce output that is personalised and appears relevant in the given context. Especially the rapid progress in large language models (LLMs) has opened a wide field of potential applications that were out of bounds just a few years ago. One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made widely accessible to end-users as ChatGPT-4, which passed a rigorous Turing test in a recent study. In this viewpoint, I argue for the necessity of independent academic research to establish evidence-based applications of AI in medicine. Algorithmic medicine is an intervention similar to a new drug or a new medical device. We should be especially concerned about under-represented minorities and rare/atypical clinical cases that may drown in the petabyte-sized training sets. A huge educational push is needed to ensure that the end-users of AI in health care understand the strengths and weaknesses of algorithmic medicine. Finally, we need to address the ethical boundaries for where and when GenAI can replace humans in the relation between patients and healthcare providers.}
}
@article{ARSLAN20245027,
title = {Political Events using RAG with LLMs},
journal = {Procedia Computer Science},
volume = {246},
pages = {5027-5035},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.576},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026267},
author = {Muhammad Arslan and Saba Munawar and Christophe Cruz},
keywords = {Political Analysis, Natural Language Processing (NLP), Large Language Models (LLMs), Retrieval-Augmented Generation (RAG)},
abstract = {In the contemporary digital landscape, media content stands as the foundation for political news analysis, offering invaluable insights sourced from various channels like news articles, social media updates, speeches, and reports. Natural Language Processing (NLP) has revolutionized Political Information Extraction (IE), automating tasks such as Event Extraction (EE) from these diverse media outlets. While traditional NLP methods often necessitate specialized expertise to build rule-based systems or train machine learning models with domain-specific datasets, the emergence of Large Language Models (LLMs) driven by Generative Artificial Intelligence (GenAI) presents a promising alternative. These models offer accessibility, alleviating challenges associated with model construction from scratch and reducing the dependency on extensive datasets during the training phase, thus facilitating rapid implementation. However, challenges persist in handling domain-specific tasks, leading to the development of the Retrieval-Augmented Generation (RAG) framework. RAG enhances LLMs by integrating external data retrieval, enriching their contextual understanding, and expanding their knowledge base beyond pre-existing training data. To illustrate RAG’s efficacy, we introduce the Political EE system, specifically tailored to extract political event information from news articles. Understanding these political insights is essential for remaining informed about the latest political advancements, whether on a national or global scale.}
}
@article{SUBILLAGA2025103566,
title = {Artificial Intelligence-Assisted Narratives: Analysis of Surgical Residency Personal Statements},
journal = {Journal of Surgical Education},
pages = {103566},
year = {2025},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2025.103566},
url = {https://www.sciencedirect.com/science/article/pii/S1931720425001473},
author = {Oswaldo Subillaga and Aixa Pérez Coulter and David Tashjian and Neal Seymour and Daniel Hubbs},
keywords = {artificial intelligence, general surgery residency, personal statements, graduate medical education, NRMP match, interpersonal and communication skills},
abstract = {Objective
Personal statements (PSs) express applicants’ personal characteristics and motivations informing pursuit of a surgical career. Generative artificial intelligence (AI) is a revolutionary technology. There are currently no data to suggest how and to what extent AI is used in surgical residency applications. We examined the prevalence of AI use and applicant pool characteristics in PSs submitted to a surgical residency.
Design
PSs from US MD and DO applicants to an academic general surgery program were collected for both the 2022-23 and 2023-24 NRMP Match cycles. PSs were analyzed using 2 AI-detection tools: GPTZero and Copyleaks. Data were analyzed using T-test and Fisher’s Exact Test.
Setting
UMass Chan Medical School—Baystate general surgery residency program in Springfield, Massachusetts.
Participants
There were 1332 applications during 2022-23 NRMP Match cycle and 1221 for 2023-24. After excluding international medical graduates and incomplete applications, 1490 PSs were analyzed.
Results
1490 PS were included (758 [50.9%] for 2022-23; 732 [49.1%] for 2023-24). Demographic characteristics did not differ between the 2 cycles. GPTZero identified AI use in 77 (10.2%) PSs in 2022-23 and 268 (36.6%) in 2023-24 (p < 0.001). Copyleaks identified AI use in 20 (2.6%) PSs in 2022-23 and 165 (22.5%) in 2023-24 (p < 0.001). Concordance in AI detection with both tools was observed in 13 (1.7% of total PSs) for 2022-23 and 155 (21.2%) for 2023-24 (p < 0.001). Subgroup analysis of concordance in 2023-24 showed increased non-English native language characteristics (38.7% vs 19.6%; p < 0.001), a lower average personal statement word count (597.3 vs 645.9; p < 0.001) and shorter average sentence (10.0 vs 10.4 words; p < 0.001) in the AI group.
Conclusions
Although AI-detection tools are imperfect, demonstration of increased AI use in personal statement preparation is compelling. Implications of AI use in residency applications are unknown, and programs must develop policies anticipating ongoing and potentially increased use of AI in the upcoming application cycles.}
}
@article{CROSTHWAITE2023100066,
title = {Generative AI and the end of corpus-assisted data-driven learning? Not so fast!},
journal = {Applied Corpus Linguistics},
volume = {3},
number = {3},
pages = {100066},
year = {2023},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2666799123000266},
author = {Peter Crosthwaite and Vit Baisa},
keywords = {Data-driven learning, generative AI, ChatGPT, DDL, Corpora},
abstract = {This article explores the potential advantages of corpora over generative artificial intelligence (GenAI) in understanding language patterns and usage, while also acknowledging the potential of GenAI to address some of the main shortcomings of corpus-based data-driven learning (DDL). One of the main advantages of corpora is that we know exactly the domain of texts from which the corpus data is derived, something that we cannot track from current large language models underlying applications like ChatGPT. We know the texts that make up large general corpora such as BNC2014 and BAWE, and can even extract full texts from these corpora if needed. Corpora also allow for more nuanced analysis of language patterns, including the statistics behind multi-word units and collocations, which can be difficult for GenAI to handle. However, it is important to note that GenAI has its own strengths in advancing our understanding of language-in-use that corpora, to date, have struggled with. We therefore argue that by combining corpus and GenAI approaches, language learners can gain a more comprehensive understanding of how language works in different contexts than is currently possible using only a single approach.}
}
@incollection{KHALEEL20262,
title = {Future Proofing the Integrity of Assessments Within Business Management Studies for the Age of Artificial Intelligence},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {2-8},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00330-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013003303},
author = {Fawad Khaleel and Patrick Harte and Alija Avdukic},
keywords = {Academic dishonesty, Academic integrity, Artificial intelligence, Assessment design, Complexity of assessment design, Coursework, Plagiarism, Word count},
abstract = {The content generative artificial intelligence is developing rapidly, and it is challenging the old norms of assessment design within the HEIs. This chapter discusses the impact of AI on the academic integrity, as we argue that with a slight shift within the assessment design, we can address the academic integrity concerns that surfacing within the higher education. This chapter provides practical and useable guidelines that could be used to reduce the breaches of academic integrity within business management programmes at HEIs. These guidelines focus on word count for coursework, complexity of assessment question and social dynamics of assessment design.}
}
@article{DWI2025100136,
title = {Ethical and psychological implications of generative AI in digital afterlife technologies: A systematic literature review on responsible inclusive innovation},
journal = {Journal of Responsible Technology},
volume = {24},
pages = {100136},
year = {2025},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2025.100136},
url = {https://www.sciencedirect.com/science/article/pii/S2666659625000320},
author = {Mariyono Dwi},
keywords = {Generative AI, Digital afterlife, DeathTech, Cultural schemas, Inclusive design, Ethical governance, Grief management, Ritual adaptation},
abstract = {Rapid advances in generative artificial intelligence (GenAI) have given birth to digital afterlife technologies (DeathTech), which enable the preservation of the voices, memories, and personalities of deceased individuals. This study is a systematic review of 45 scientific articles (2020–2025) using a thematic-SWOT analysis approach and the Responsible Inclusive Innovation (RII) framework, to explore how cultural schemas, inclusive design, and governance models influence the acceptance of DeathTech across cultures. Key findings suggest that ritual adaptation and spiritual meanings are critical to the acceptance of this technology. Jewish and Japanese communities show high acceptance through cultural integration, while Hindu and Luhya communities experience ontological dissonance. Design failures such as linguistic exclusion and ritual incongruence impact marginalized groups. In addition, regulatory gaps exist, especially in post-death privacy protection and algorithmic bias. This study proposes a triadic framework for the development of ethical and equitable DeathTech: cultural mediation, inclusive design, and pluralistic governance. This contribution enriches the study of digital thanatology and provides recommendations for culturally and socially sustainable innovation.}
}
@article{ERFANI2026103909,
title = {Applications of multimodal large language models in construction industry},
journal = {Advanced Engineering Informatics},
volume = {69},
pages = {103909},
year = {2026},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103909},
url = {https://www.sciencedirect.com/science/article/pii/S147403462500802X},
author = {Abdolmajid Erfani and Ali Mansouri},
keywords = {Multimodal Language Models, Construction Automation, Generative AI},
abstract = {The advancement of transformer-based models, including multimodal large language models (MLLMs), has led to growing interest in their application across diverse industries, including construction. While a few earlier reviews have explored generative artificial intelligence in the construction sector, they are limited in scope— limited coverage of multimodal models, covering a shorter timeline prior to the expansion of MLLMs research, and offering limited emphasis on practical use cases, adaptation strategies, and integration into construction workflows. This study addresses that gap by reviewing 83 peer-reviewed studies published between January 2020 and February 2025, identified using a structured search process guided by the PRISMA framework and focused on academic literature. By synthesizing these studies, this review highlights trends across application domains, model types, adaptation strategies, technical limitations, and performance evaluation practices—offering a comparative analysis across use cases. It concludes with recommendations for future research, underscoring the need for standardized evaluation frameworks, critical limitations related to technical aspects, ethical risks, and regulatory uncertainty, underscoring the need for responsible development and deployment of MLLMs in construction settings.}
}
@article{ANDRIEUX2024101032,
title = {Ethical considerations of generative AI-enabled human resource management},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101032},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101032},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000056},
author = {Pierre Andrieux and Richard D. Johnson and Jalal Sarabadani and Craig {Van Slyke}},
keywords = {Generative artificial intelligence (GAI), Human resource management (HRM), Affordance, Ethics, Decision-making},
abstract = {This paper examines critical ethical considerations linked to making human resources management (HRM) decisions based on the potential capabilities (affordances) offered by generative artificial intelligence (GAI). We first provide a broad overview of the status quo surrounding the use of GAI in the HRM context. Then, we introduce the concept of “affordance” and explain how it provides a useful perspective for human resource (HR) managers to use when evaluating potential benefits and/or harm resulting from the implementation of a potential GAI-based capability to support HRM processes decisions. We discuss concrete examples of how GAI HRM affordances could be implemented in different HRM functions and the ethical questions that arise from their use. Finally, we present an ethics-based framework, the Two-Rule Method, along with ethics-specific recommendations to guide HR managers through the complex issues that arise because of the use of GAI-enabled HR tools.}
}
@article{DUBEY2024103689,
title = {Benchmarking operations and supply chain management practices using Generative AI: Towards a theoretical framework},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103689},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103689},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002801},
author = {Rameshwar Dubey and Angappa Gunasekaran and Thanos Papadopoulos},
keywords = {Generative Artificial Intelligence (Gen AI), Artificial Intelligence Supply Chain Management, Benchmarking, Organisational Theories},
abstract = {Generative Artificial Intelligence (Gen AI) is an up-and-coming technological innovation that has the potential to revolutionise businesses and create significant value. Despite garnering excitement from some quarters, there are still people who are sceptical about its benefits and even fearful of its impact, particularly in the supply chain context, where it is not yet fully understood. To help academics and practitioners better understand the practical implications of Gen AI in benchmarking supply chain management practices, we propose a theoretical toolbox. This toolbox draws from ten popular organisational theories and provides a comprehensive framework for evaluating the usefulness of Gen AI. By expanding theoretical boundaries, the toolbox provides a deeper understanding of the practical applications of Gen AI for researchers and practitioners in supply chain management.}
}
@article{ALIER2025103940,
title = {LAMB: An open-source software framework to create artificial intelligence assistants deployed and integrated into learning management systems},
journal = {Computer Standards & Interfaces},
volume = {92},
pages = {103940},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001090},
author = {Marc Alier and Juanan Pereira and Francisco José García-Peñalvo and Maria Jose Casañ and Jose Cabré},
keywords = {Generative artificial intelligence, Education domain, Learning assistant, Retrieval-Augmented Generation (RAG), Large language model (LLM), IMS learning tools interoperability (LTI)},
abstract = {This paper presents LAMB (Learning Assistant Manager and Builder), an innovative open-source software framework designed to create AI-powered Learning Assistants tailored for integration into learning management systems. LAMB addresses critical gaps in existing educational AI solutions by providing a framework specifically designed for the unique requirements of the education sector. It introduces novel features, including a modular architecture for seamless integration of AI assistants into existing LMS platforms and an intuitive interface for educators to create custom AI assistants without coding skills. Unlike existing AI tools in education, LAMB provides a comprehensive framework that addresses privacy concerns, ensures alignment with institutional policies, and promotes using authoritative sources. LAMB leverages the capabilities of large language models and associated generative artificial intelligence technologies to create generative intelligent learning assistants that enhance educational experiences by providing personalized learning support based on clear directions and authoritative fonts of information. Key features of LAMB include its modular architecture, which supports prompt engineering, retrieval-augmented generation, and the creation of extensive knowledge bases from diverse educational content, including video sources. The development and deployment of LAMB were iteratively refined using a minimum viable product approach, exemplified by the learning assistant: “Macroeconomics Study Coach,” which effectively integrated lecture transcriptions and other course materials to support student inquiries. Initial validations in various educational settings demonstrate the potential that learning assistants created with LAMB have to enhance teaching methodologies, increase student engagement, and provide personalized learning experiences. The system's usability, scalability, security, and interoperability with existing LMS platforms make it a robust solution for integrating artificial intelligence into educational environments. LAMB's open-source nature encourages collaboration and innovation among educators, researchers, and developers, fostering a community dedicated to advancing the role of artificial intelligence in education. This paper outlines the system architecture, implementation details, use cases, and the significant benefits and challenges encountered, offering valuable insights for future developments in artificial intelligence assistants for any sector.}
}
@article{SUFFOLETTO2024,
title = {Deceptively Simple yet Profoundly Impactful: Text Messaging Interventions to Support Health},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58726},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005235},
author = {Brian Suffoletto},
keywords = {SMS intervention, behavior, intervention, review, text messaging, SMS, interventions, behaviors, behaviour, behaviours, effectiveness, development, impact, narrative review, physical activity, diet, weight loss, mental health, substance use, meta-analysis, chatbot, chatbots, large language model, LLM, large language models, mobile phone},
abstract = {This paper examines the use of text message (SMS) interventions for health-related behavioral support. It first outlines the historical progress in SMS intervention research publications and the variety of funds from US government agencies. A narrative review follows, highlighting the effectiveness of SMS interventions in key health areas, such as physical activity, diet and weight loss, mental health, and substance use, based on published meta-analyses. It then outlines advantages of text messaging compared to other digital modalities, including the real-time capability to collect information and deliver microdoses of intervention support. Crucial design elements are proposed to optimize effectiveness and longitudinal engagement across communication strategies, psychological foundations, and behavior change tactics. We then discuss advanced functionalities, such as the potential for generative artificial intelligence to improve user interaction. Finally, major challenges to implementation are highlighted, including the absence of a dedicated commercial platform, privacy and security concerns with SMS technology, difficulties integrating SMS interventions with medical informatics systems, and concerns about user engagement. Proposed solutions aim to facilitate the broader application and effectiveness of SMS interventions. Our hope is that these insights can assist researchers and practitioners in using SMS interventions to improve health outcomes and reducing disparities.}
}
@article{FURTADO2024100086,
title = {A task-oriented framework for generative AI in design},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100086},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000128},
author = {Lara Sucupira Furtado and Jorge Barbosa Soares and Vasco Furtado},
keywords = {Generative artificial intelligence, Product, Creative computing, Transformational Creativity},
abstract = {The intersection of Artificial Intelligence and Design disciplines such as Architecture, Urban Planning, Engineering and Product Design has been a longstanding pursuit, with Generative AI (GAI) ushering in a new era of possibilities. The research presented here explores how GAI can enhance creativity and assist Design practitioners with tasks to create products such as, but not limited to, renderings, concepts, construction techniques, materials, data analytics or maps. We apply a framework of combinational, exploratory and transformational creativity to organize how recent advancements in GAI can support each creative category. We propose a conceptual framework of GAI towards transformational creativity, and identify real-world examples to demonstrate GAI's impact, such as transforming sketches into detailed renders, facilitating real-time 3D model generation, predicting trends through analytics and creating images or reports via text prompts. Our work envisions a future where GAI becomes a real-time collaborator to complete certain automated tasks while liberating Designers to focus on transformational innovation.}
}
@article{SAGLAM2025104530,
title = {Living with and without AI: A mixed-methods study on AI usage, addiction, and 'AIlessphobia' in nursing students},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104530},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104530},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002872},
author = {Rukiye Kevser Sağlam and Bilge Kalanlar},
keywords = {Artificial intelligence, Nursing students, Addiction, AIlessphobia},
abstract = {Aim
The aim of this study is to examine nursing students' attitudes toward AI use, their patterns of use and levels of AI addiction, as well as to evaluate the impact of emerging fears such as AIlessphobia.
Background
Generative artificial intelligence (AI) is rapidly evolving and is increasingly being used among university students. Concepts such as “AIlessphobia” -the fear of being without AI- highlight the emergence of these issues.
Design
This study used a mixed-methods design.
Methods
The study was carried out during the 2024–2025 Spring Semester with nursing students. Data were collected using the Scale for Dependence on Artificial Intelligence (DAI) and semi-structured interview questions. Qualitative interviews were conducted with students who scored 15 or higher on DAI. The quantitative sample consists of 200 students and the qualitative sample was determined based on quantitative and qualitative data.
Results
Most participants (81.5 %) reported using AI tools, with ChatGPT being the most preferred among them. The interview included 13 questions and the themes emerged during the individual interviews. Thematic analysis highlighted five themes: educational benefits, negative effects, AI addiction, future expectations and AIlessphobia. Students noted that AI eased learning but reduced critical thinking and reported emotional distress when deprived of AI access.
Conclusions
The widespread use of AI tools in education produces both positive and negative effects. It is essential for educators to support students in integrating these tools with critical thinking skills and digital awareness. Such support is crucial for preventing AI addiction and AIlessphobia.}
}
@article{ASAOUER2026104031,
title = {Generative AI-based intrusion detection systems for intra-vehicle networks},
journal = {Ad Hoc Networks},
volume = {180},
pages = {104031},
year = {2026},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2025.104031},
url = {https://www.sciencedirect.com/science/article/pii/S1570870525002793},
author = {Guettouche Asaouer and Djallel Eddine Boubiche},
keywords = {Generative AI, Intrusion detection, In-vehicle networks, Cybersecurity, CAN bus},
abstract = {With the rise of connected and autonomous vehicles, securing Intra-Vehicle Networks against cyber threats has become a critical challenge. The Controller Area Network bus, a widely used communication protocol in modern vehicles, remains highly vulnerable to sophisticated intrusion attacks. Traditional Machine Learning and Deep Learning based Intrusion Detection Systems have demonstrated limitations in adaptability, real-time performance, and handling zero-day attacks. This survey explores the emerging role of Generative Artificial Intelligence in enhancing IVN security. It examines key GenAI—assessing their potential to address the shortcomings of conventional IDS techniques. A comprehensive review of recent literature is conducted, analyzing the effectiveness of generative approaches in intrusion detection compared to deterministic methods. Key aspects such as detection time, adaptability to unknown threats, and real-time processing constraints are evaluated. Additionally, this paper identifies existing research gaps, emphasizing the need for standardized datasets, federated learning strategies, and improved deployment techniques to ensure the practical viability of GenAI-based IDS in real-world vehicular environments. The insights presented aim to guide future research toward more robust and adaptive security solutions for IVNs.}
}
@article{HARRISON2024,
title = {Behavioral Nudging With Generative AI for Content Development in SMS Health Care Interventions: Case Study},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/52974},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000589},
author = {Rachel M Harrison and Ekaterina Lapteva and Anton Bibin},
keywords = {generative artificial intelligence, generative AI, prompt engineering, large language models, GPT, content design, brief message interventions, mHealth, behavior change techniques, medication adherence, type 2 diabetes},
abstract = {Background
Brief message interventions have demonstrated immense promise in health care, yet the development of these messages has suffered from a dearth of transparency and a scarcity of publicly accessible data sets. Moreover, the researcher-driven content creation process has raised resource allocation issues, necessitating a more efficient and transparent approach to content development.
Objective
This research sets out to address the challenges of content development for SMS interventions by showcasing the use of generative artificial intelligence (AI) as a tool for content creation, transparently explaining the prompt design and content generation process, and providing the largest publicly available data set of brief messages and source code for future replication of our process.
Methods
Leveraging the pretrained large language model GPT-3.5 (OpenAI), we generate a collection of messages in the context of medication adherence for individuals with type 2 diabetes using evidence-derived behavior change techniques identified in a prior systematic review. We create an attributed prompt designed to adhere to content (readability and tone) and SMS (character count and encoder type) standards while encouraging message variability to reflect differences in behavior change techniques.
Results
We deliver the most extensive repository of brief messages for a singular health care intervention and the first library of messages crafted with generative AI. In total, our method yields a data set comprising 1150 messages, with 89.91% (n=1034) meeting character length requirements and 80.7% (n=928) meeting readability requirements. Furthermore, our analysis reveals that all messages exhibit diversity comparable to an existing publicly available data set created under the same theoretical framework for a similar setting.
Conclusions
This research provides a novel approach to content creation for health care interventions using state-of-the-art generative AI tools. Future research is needed to assess the generated content for ethical, safety, and research standards, as well as to determine whether the intervention is successful in improving the target behaviors.}
}
@article{HWANG2025101230,
title = {Generative AI is useful for second language writing, but when, why, and for how long do learners use it?},
journal = {Journal of Second Language Writing},
volume = {69},
pages = {101230},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101230},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000554},
author = {Haerim Hwang and Xingyu Chang and Jiaxin Sun},
keywords = {Generative AI, Second language writing, Screen recording, Frequency, Duration, Semantic network analysis},
abstract = {Numerous studies have highlighted the benefits of recent advancements in generative artificial intelligence (AI) technology for second language (L2) writing. However, most of these studies have relied on pretest/posttest designs or interview/questionnaire methods that reflect the researchers’ perspectives. To expand the research on this topic, we take two approaches. Firstly, we investigate how L2 learners of English utilize ChatGPT in a writing task in real time by analyzing recordings of their computer screens collected throughout the writing process. Secondly, we explore how they perceive the usefulness of ChatGPT by analyzing their responses to an open-ended question. Frequency and time-series analyses show that the participants primarily utilized ChatGPT to generate ideas, particularly during the initial stages of writing. They also used it later in the writing process, albeit less frequently and for less time overall, for a word/grammar search/check, polishing, and example generation, alongside idea generation. Semantic network analyses of their responses to the open-ended question further reveal that the participants generally held a positive opinion of ChatGPT, valuing its assistance in content creation and time management, while expressing some concerns. The results emphasize the potential of generative AI in facilitating L2 writing and suggest the importance of digital literacy.}
}
@article{HABER2025100196,
title = {CanvasHero: The role of artificial intelligence in cultivating resilience among children and youth using the 6-part story method in mass war trauma},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100196},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000805},
author = {Yuval Haber and Inbar Levkovich and Iftach Tzafrir and Karny Gigi and Dror Yinon and Dorit Hadar Shoval and Zohar Elyoseph},
keywords = {Resilience, Mass trauma, Displaced population, Children and youth, AI tools, Imagination},
abstract = {Background
The potential of Generative Artificial Intelligence (GenAI) to promote mental health is of great interest. Specifically, there is growing interest in integrating applied GenAI into psychotherapy or into the teacher/parent-child relationship. This paper describes CanvasHero, a GenAI tool that was developed following the devastating attacks on Israel in October 2023. It aims to promote resilience in children and adolescents who were evacuated from their homes due to the war. CanvasHero serves as a proof of concept for integrating GenAI as an additional element that can enrich and deepen interpersonal interaction.
Tool description
CanvasHero utilizes the BASIC Ph model and 6-Part Story Method for assessing and bolstering coping skills, aided by the interactive scaffolding and synthetic abilities of the GenAI. Key stages comprise (1) collaborative narrative construction between child, meaningful adult, and the GAI; (2) analysis of resilience themes; and (3) generative visualization representing the child's story through DALL-E's imaging capabilities.
Implementation protocol
The CanvasHero is optimally designed for children ages 7–16 under adult supervision, with the HEART Checklist developed to structure this process. Sessions typically occur remotely via videoconference, or in person.
Intended outcomes
CanvasHero aims to create a playful space for processing stress and trauma, identifies resilience resources, and strengthens these capabilities. At the same time, risks in GenAI integration are mitigated via human oversight and an ethics-focused design.
Conclusion
CanvasHero exemplifies a GenAI application that can assist during wartime, serving as a psycho-educational mediator and facilitating an imaginative and playful space between children and meaningful adults. Further studies are required to evaluate effectiveness and potential risks.}
}
@article{SAETRA2023102372,
title = {Generative AI: Here to stay, but for good?},
journal = {Technology in Society},
volume = {75},
pages = {102372},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102372},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2300177X},
author = {Henrik Skaug Sætra},
keywords = {Generative AI, Large language models, Generative adversarial networks, Harms, Power, Inequality},
abstract = {Generative AI has taken the world by storm, kicked off for real by ChatGPT and quickly followed by further development and the release of GPT-4 and similar models from OpenAI's competitors. The street has most certainly found its use for generative artificial intelligence (AI), and there is no longer much point in discussing whether generative AI will be influential. It will, and what remains to be discussed it how influential it will be, and what potential harms arise when we use AI to generate text and other forms of content. Technological change entails societal change, and we must always endeavor to ask how new technologies shapes, engenders, or potentially erodes the “good society”. In this sense, Generative AI is another instance of politically and culturally disruptive autonomous technology, and in this short commentary I highlight some of the key questions to be asked regarding consequences on the micro, meso, and macro level.}
}
@article{HAMED2024108782,
title = {Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI},
journal = {iScience},
volume = {27},
number = {2},
pages = {108782},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.108782},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224000038},
author = {Ahmed Abdeen Hamed and Malgorzata Zachara-Szymanska and Xindong Wu},
keywords = {Biocomputational method, Bioinformatics, Biological sciences, Computational bioinformatics, Natural sciences, Neural networks, Artificial intelligence, Artificial intelligence applications},
abstract = {Summary
As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society.}
}
@article{KUO2026108677,
title = {Improvement of an eye disease detection model by using the denoising diffusion implicit model},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108677},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108677},
url = {https://www.sciencedirect.com/science/article/pii/S147692712500338X},
author = {Ping-Huan Kuo and Eirene Du and Chiou-Jye Huang and Wei-Chuan Lan and Shu-Hung Chou and Ting-Chun Yao and Chao-Chung Peng},
keywords = {Eye disease detection, Generative artificial intelligence, Image classification, Denoising diffusion implicit model, Quasi-Monte Carlo sampling},
abstract = {With rapid developments in artificial intelligence (AI), the discussion about and applications of generative AI have increased substantially. Generative AI has extensive and valuable applications in many industrial and medical fields and is a possible solution for industries that struggle to collect large quantities of data. The present study evaluated the use of generative AI in eye disease prediction. Because retinal images are difficult to acquire, this study used a generative AI model [i.e., the denoising diffusion implicit model (DDIM)] to conduct data augmentation, thereby improving the accuracy of a convolutional neural network (CNN) model developed for eye disease detection. This study adopted the DDIM primarily for its high inference speed and ability to consistently generate high-quality samples in a limited number of steps, making it suitable for tasks that require high-quality medical images. With the increasing prevalence of electronic products, the number of patients with retinopathy or optic neuropathy is increasing annually, and patients are experiencing these diseases at increasingly younger ages. Moreover, eye diseases such as glaucoma and macular degeneration are becoming increasingly common in modern society. The developed CNN model exhibited a 3 % higher accuracy when it was trained using the data generated by the DDIM than when it was trained without these data. This CNN model can screen eye disease symptoms early to enable patients to receive timely treatment, thereby mitigating the risk and consequences of eye diseases. The results of this study indicate that the training data generated using the DDIM can enhance the accuracy of early eye disease detection.}
}
@article{ZHANG2025103746,
title = {Becoming a teacher in the era of AI: A multiple-case study of pre-service teachers’ investment in AI-facilitated learning-to-teach practices},
journal = {System},
volume = {133},
pages = {103746},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103746},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25001563},
author = {Yue Zhang and Chun Lai and Michelle Ming Yue Gu},
keywords = {Generative AI, Pre-service teacher, AI literacies, Identity, Teacher candidate, Teacher identity, ChatGPT},
abstract = {Language learning and teaching research explores the affordances and constraints of generative artificial intelligence (GenAI) tools and learners' and teachers' AI literacy. However, little attention has been directed to teachers' use of such tools and their implications for the development of GenAI literacies as diverse, historically, and culturally variable practices involving AI tools, especially pre-service teachers (PSTs) in the second language (L2) context. Based on an exploratory multiple-case study of five undergraduate PSTs in Hong Kong, this paper adopts the model of L2 investment (Darvin & Norton, 2015) to address this need by posing three question: 1. What are the GenAI literacies that PSTs invest in as they learn to teach? 2. What are the perceived affordances and constraints of GenAI tools in their learning-to-teach practices? 3. To what extent do their identity and access to resources shape these literacies? Data was collected from a survey, interviews, and observations of participants' GenAI use, and triangulated using content analysis. Findings reveal how PSTs invest in their English and pedagogy learner, bilingual writer, and teacher identities that intertwine with their identities as users of various GenAI tools in GenAI-empowered spaces as ideological sites that shaped PSTs' dispositions and positioning. Recognizing how PSTs deploy multiple resources to invest in contrasting GenAI literacies, this study underscores the need for the language classroom to integrate GenAI literacies instruction that enables a critical awareness of how GenAI tools operate.}
}