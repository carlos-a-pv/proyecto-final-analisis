@article{SHIRSHAHI20241606,
title = {Identification of propagation path and root cause of faults based on generative adversarial networks in industrial systems},
journal = {Process Safety and Environmental Protection},
volume = {187},
pages = {1606-1617},
year = {2024},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2024.05.143},
url = {https://www.sciencedirect.com/science/article/pii/S0957582024006670},
author = {Amir Shirshahi and Behzad Moshiri and Mahdi Aliyari-Shoorehdeli},
keywords = {Fault propagation, Causality analysis, Machine learning, Latent space, Generative networks},
abstract = {Fault diagnosis and detection (FDD) improves product quality, process safety, and profitability in modern industrial plants. Faults can propagate between different parts of plants due to connections between devices and control loops. As a result, control room operators may receive multiple alarms that distract their attention from addressing the main causes of abnormal situations. Therefore, investigating causal relationships between process variables is essential in determining the root cause of faults. This study proposes a new systematic approach for causality analysis to identify the propagation path and root cause of faults in industrial plants. The research's innovations are categorized into two main parts. Initially, the study utilizes machine learning algorithms to identify causal relationships using probabilistic concepts. Additionally, it introduces a novel architecture by merging the generative adversarial network (GAN) with the variational auto-encoder (VAE). The process variables are mapped to a latent space, where an adversarial generative network will investigate the causal relationship between variables. Finally, the Tennessee Eastman Process simulation and gas turbine industrial data are used to evaluate the proposed algorithm.}
}
@article{PATEL2025104642,
title = {Use of ChatGPT for patient education involving HPV-associated oropharyngeal cancer},
journal = {American Journal of Otolaryngology},
volume = {46},
number = {4},
pages = {104642},
year = {2025},
issn = {0196-0709},
doi = {https://doi.org/10.1016/j.amjoto.2025.104642},
url = {https://www.sciencedirect.com/science/article/pii/S0196070925000456},
author = {Terral A. Patel and Gillian Michaelson and Zoey Morton and Alexandria Harris and Brandon Smith and Richard Bourguillon and Eric Wu and Arturo Eguia and Jessica H. Maxwell},
keywords = {Artificial intelligence, Chatbox, Education, Oropharyngeal cancer, HPV},
abstract = {Objective
This study aims to investigate the ability of ChatGPT to generate reliably accurate responses to patient-based queries specifically regarding oropharyngeal squamous cell carcinoma (OPSCC) of the head and neck.
Study design
Retrospective review of published abstracts.
Setting
Publicly available generative artificial intelligence.
Methods
ChatGPT 3.5 (May 2024) was queried with a set of 30 questions pertaining to HPV-associated oropharyngeal cancer that the average patient may ask. This set of questions was queried a total of four times preceded by a different prompt. The answer prompts for each question set were reviewed and graded on a four-part Likert scale. A Flesch-Kincaid reading level was also calculated for each prompt.
Results
For all answer prompts (n = 120), 6.6 % were graded as mostly inaccurate, 7.5 % were graded as minorly inaccurate, 41.7 % were graded as accurate, and 44.2 % were graded as accurate and helpful. The average Flesch-Kincaid reading grade level was lowest for the responses without any prompt (11.77). Understandably, the highest grade levels were found in the physician-friend prompt (12.97). Of the 30 references, 25 (83.3 %) were found to be authentic published studies. Of the 25 authentic references, the answers accurately cited information found within the original source for 14 of the references (56 %).
Conclusion
ChatGPT was able to produce relatively accurate responses to example patient questions, but there was a high rate of false references. In addition, the reading level of the answer prompts was well above the Centers for Disease Control and Prevention (CDC) recommendations for the average patient.}
}
@article{MING2025109685,
title = {Benchmarking neural radiance fields for autonomous robots: An overview},
journal = {Engineering Applications of Artificial Intelligence},
volume = {140},
pages = {109685},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109685},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624018438},
author = {Yuhang Ming and Xingrui Yang and Weihan Wang and Zheng Chen and Jinglun Feng and Yifan Xing and Guofeng Zhang},
keywords = {Neural radiance fields, Autonomous robots, Robotic perception, Localization, Navigation, Decision-making},
abstract = {Neural Radiance Field (NeRF) has emerged as a powerful paradigm for scene representation, offering high-fidelity renderings and reconstructions from a set of sparse and unstructured sensor data. In the context of autonomous robotics, where perception and understanding of the environment are pivotal, NeRF holds immense promise for improving performance. However, few survey has discussed such a potential. To fill this gap, we have collected over 200 papers since the publication of original NeRF in 2020 and present a thorough analysis of how NeRF can be used to enhance the capabilities of autonomous robots. We especially focus on the perception, localization and navigation, and decision-making modules of autonomous robots and delve into tasks crucial for autonomous operation, including 3-dimensional reconstruction, segmentation, pose estimation, simultaneous localization and mapping, navigation and planning, and interaction. Our survey meticulously benchmarks existing NeRF-based methods, comparing their reported performance, and providing insights into their strengths and limitations. Moreover, we target the existing challenges of applying NeRF in autonomous robots, including real-time processing, sparse input views, and explore promising avenues for future research and development in this domain. We especially discuss potential of integrating advanced deep learning techniques like 3-dimensional Gaussian splatting, large language models, and generative artificial intelligence. This survey serves as a roadmap for researchers seeking to leverage NeRF to empower autonomous robots, paving the way for innovative solutions that can navigate and interact seamlessly in complex environments.}
}
@article{AGUINIS2024101029,
title = {How to use generative AI as a human resource management assistant},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101029},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101029},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000020},
author = {Herman Aguinis and Jose R. Beltran and Amando Cope},
keywords = {Artificial intelligence, Human resource management, Leadership, The future of work, Technology, Talent management},
abstract = {Human resource management (HRM) professionals are often overworked, and their jobs are increasingly complex. Therefore, many suffer from job burnout, and only some can allocate the necessary time to strategic issues. We show how generative artificial intelligence (AI), particularly ChatGPT, can be a helpful HRM assistant for both strategic and operational tasks. But, for this to happen, we demonstrate the need to create valuable prompts that result in specific, helpful, and actionable HRM recommendations. Accordingly, we provide eight guidelines for creating high-quality and effective prompts and illustrate their usefulness in general across eight critical HRM domains and in more depth in the particular areas of workforce diversity and strategic HRM. We also provide recommendations and demonstrate how to implement a critical verification process to check on ChatGPT’s suggestions. We conclude with a list of “dos and don’ts” and that when used by sufficiently trained HRM professionals, it is a very useful tool because it helps complete tasks faster, hopefully reducing their job burnout and allowing them to allocate more time to strategic and long-term issues. In turn, these benefits will likely result in helping achieve the as-of-yet-unrealized aspiration of “having a seat at the table.”}
}
@article{PANAGIOTOU2025106287,
title = {Generative AI-augmented offshore jacket design: Integrated approach for mixed tabular data generation under scarcity and imbalance},
journal = {Automation in Construction},
volume = {177},
pages = {106287},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106287},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003279},
author = {Emmanouil Panagiotou and Han Qian and Steffen Marx and Eirini Ntoutsi},
keywords = {Artificial intelligence, Generative AI, Machine learning, Multi-objective optimization, Mixed tabular data, Data scarcity, Data imbalance, Offshore wind turbines, Industrial design, Offshore jacket substructure},
abstract = {Generative Artificial Intelligence (AI) has found various applications in domains like computer vision and natural language processing. However, limited research exists in the engineering domain, where prevailing challenges involve mixed tabular data, data scarcity, and imbalances. This paper focuses on generating synthetic offshore jacket designs to improve the data quality of a scarce and imbalanced existing dataset. Data quality is quantified by evaluating the machine-learning efficiency of the synthetic data on a domain-specific downstream task. An integrated method is proposed for generating jacket designs, combining modern data-driven techniques with traditional multi-objective-driven approaches. The method addresses challenges related to mixed attributes, data scarcity, and class imbalances. Experimental results demonstrate improved predictive performance on the downstream task when models are trained on synthetic data compared to using only real data. These findings contribute to the advancement of generative AI in offshore engineering and related fields, offering valuable insights and potential applications.}
}
@article{JURGENSMEIER2024468,
title = {Generative AI for scalable feedback to multimodal exercises},
journal = {International Journal of Research in Marketing},
volume = {41},
number = {3},
pages = {468-488},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167811624000430},
author = {Lukas Jürgensmeier and Bernd Skiera},
keywords = {Generative AI, Automated Feedback, Marketing Analytics, Learning, Education},
abstract = {Detailed feedback on exercises helps learners become proficient but is time-consuming for educators and, thus, hardly scalable. This manuscript evaluates how well Generative Artificial Intelligence (AI) provides automated feedback on complex multimodal exercises requiring coding, statistics, and economic reasoning. Besides providing this technology through an easily accessible web application, this article evaluates the technology’s performance by comparing the quantitative feedback (i.e., points achieved) from Generative AI models with human expert feedback for 4,349 solutions to marketing analytics exercises. The results show that automated feedback produced by Generative AI (GPT-4) provides almost unbiased evaluations while correlating highly with (r = 0.94) and deviating only 6 % from human evaluations. GPT-4 performs best among seven Generative AI models, albeit at the highest cost. Comparing the models’ performance with costs shows that GPT-4, Mistral Large, Claude 3 Opus, and Gemini 1.0 Pro dominate three other Generative AI models (Claude 3 Sonnet, GPT-3.5, and Gemini 1.5 Pro). Expert assessment of the qualitative feedback (i.e., the AI’s textual response) indicates that it is mostly correct, sufficient, and appropriate for learners. A survey of marketing analytics learners shows that they highly recommend the app and its Generative AI feedback. An advantage of the app is its subject-agnosticism—it does not require any subject- or exercise-specific training. Thus, it is immediately usable for new exercises in marketing analytics and other subjects.}
}
@article{NEMS2025e01348,
title = {A review of artificial intelligence to thermal energy storage and heat transfer improvement in phase change materials},
journal = {Sustainable Materials and Technologies},
volume = {44},
pages = {e01348},
year = {2025},
issn = {2214-9937},
doi = {https://doi.org/10.1016/j.susmat.2025.e01348},
url = {https://www.sciencedirect.com/science/article/pii/S2214993725001162},
author = {Artur Nemś and Sindu Daniarta and Magdalena Nemś and Piotr Kolasiński and Svetlana Ushak},
keywords = {New material discovery, Machine learning, Figure of merit, Convolutional neural networks, Generative artificial intelligence},
abstract = {This paper examines the applications of artificial intelligence (AI) in predicting and optimizing phase change material (PCM) parameters for heat storage and transport systems. The study reviews research on material parameters, focusing on the role of machine learning (ML) in shaping the characteristics of modified PCMs. It summarizes the input and output parameters, as well as the figures of merit criteria, employed in various PCM-related studies. The paper explores AI's role in enhancing heat transfer and storage in PCMs, highlighting models used to predict the amount of heat stored in PCM-based storage tanks. Also, the application of genetic algorithms (GAs) to optimize the operating parameters of these storage systems is discussed. AI techniques for improving heat transfer processes in PCMs are also reviewed. The prediction quality of different ML methods is analyzed. Other deviations used to evaluate the accuracy of these methods are presented. A third area of focus is the application of AI in systems and energy systems utilizing PCMs. These applications include temperature stabilization in solar systems, maintaining thermal comfort in buildings, ensuring consistent vaccine storage temperatures, and other uses. The study outlines the types of PCMs used in various thermal systems, the AI methods applied, and the criteria for prediction and optimization. Finally, the paper identifies knowledge gaps and research areas requiring further investigation to better understand the potential of ML and GA in optimizing PCM parameters and thermal systems containing PCMs.}
}
@article{MARABELLI2025101921,
title = {Artificial intelligence and the environment: ethical challenges and strategic opportunities for organizations},
journal = {The Journal of Strategic Information Systems},
volume = {34},
number = {3},
pages = {101921},
year = {2025},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2025.101921},
url = {https://www.sciencedirect.com/science/article/pii/S0963868725000368},
author = {Marco Marabelli and Robert M. Davison},
keywords = {Artificial intelligence, GAI and AI strategizing, Global warming, Climate changes, Ethics, Global South, Social justice},
abstract = {In this viewpoint article, our goal is to raise awareness and spark debate in the Information Systems (IS) community regarding a prominent concern that has important strategic and ethical implications: the environmental impact of the increasing use of generative artificial intelligence (GAI). We examine several specific issues, beginning with GAI’s heavy consumption of natural resources and electricity. We then move to assessing how the rich and the Global North gain via GAI, while the poor and the Global South must deal with its adverse effects. We then move to assessing GAI’s impact on underrepresented communities and countries in the Global South; while GAI contributes to global warming, this affects people unevenly, because it is mostly rich people and the Global North that make intensive use of these technologies. After suggesting that more local and global laws are needed to regulate the sustainable use of AI, we report on how organizations can perform AI strategizing, for instance to control emissions in smart cities and improve weather forecasting. We conclude with a research agenda that aims to encourage IS scholars to focus on the environmental impact of AI, its ethical implications for organizations, and how GAI can be used strategically to benefit all.}
}
@article{SARRAF2024114132,
title = {How do system and user characteristics, along with anthropomorphism, impact cognitive absorption of chatbots – Introducing SUCCAST through a mixed methods study},
journal = {Decision Support Systems},
volume = {178},
pages = {114132},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.114132},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623002075},
author = {Shagun Sarraf and Arpan Kumar Kar and Marijn Janssen},
keywords = {Cognitive absorption, Chatbots, Generative artificial intelligence, Anthropomorphism, Qualitative comparative analysis, Artificial intelligence},
abstract = {Chatbots are radically redefining the customer service landscape. With the advent of AI-enabled chatbots, like ChatGPT, organizations are adopting chatbots to provide better customer services; however, the user experience has been given less attention. Building on IS success model and cognitive absorption theory, we posit that system and user characteristics enhance cognitive absorption amongst users, such that the relationship varies between anthropomorphic (e.g., human-like) and non-anthropomorphic chatbots. We undertook a cross-sectional comparative study, which was analyzed using PLS-SEM and fsQCA. Where PLS-SEM provided limited inferential insights about the differences between anthropomorphic and non-anthropomorphic chatbots, the FsQCA analysis resulted in three configurations of attributes for non-anthropomorphic and two configurations for anthropomorphic chatbots, which lead to higher cognitive absorption. The findings extend the existing literature, suggesting that anthropomorphic and non-anthropomorphic chatbots impact cognitive absorption through separate system and user characteristics configurations.}
}
@article{ALMATRAFI2025100404,
title = {Leveraging generative AI for course learning outcome categorization using Bloom's taxonomy},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100404},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100404},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2500044X},
author = {Omaima Almatrafi and Aditya Johri},
keywords = {Large language models (LLMs), Generative artificial intelligence, Learning outcomes, Cognitive level, Bloom's taxonomy, Classification},
abstract = {Learning outcomes are clear and concise statements that describe what students should be able to do or know at the end of a particular course. These statements are crucial in instructional planning, curriculum development, and assessment of student progress and learning. Although there is no universal guidance on how to develop learning outcomes, Bloom's taxonomy is one widely used framework that helps instructors develop outcomes that reflect different levels of thinking, from basic remembering to creative problem-solving. This study investigates the potential of generative AI, specifically GPT-4, in classifying course learning outcomes according to their respective cognitive levels within the revised Bloom's taxonomy. To assess the effectiveness of GenAI, we conducted a comparative study using a dataset of 1000 annotated learning outcomes. We tested multiple prompt engineering strategies, including zero-shot, few-shot, chain-of-thought, rhetorical situation, and multiple binary questions, leveraging GPT-4. Classification performance was evaluated using accuracy, Cohen's κ, and F1-score. The results indicate that the prompt incorporating rhetorical context and domain-specific knowledge achieved the highest classification performance, while the multiple binary question approach underperformed even compared to the zero-shot method. Furthermore, we compared the best-performing prompting strategy with a state-of-the-art classification model, BERT. Although the fine-tuned BERT model showed superior performance, prompt-based classification exhibited moderate to substantial agreement with expert annotations. Overall, this article demonstrates the potential of leveraging large language models to advance both theoretical understanding and practical application within the field of education and natural language processing.}
}
@article{HAYAWI2024101533,
title = {Generative AI and large language models: A new frontier in reverse vaccinology},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101533},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101533},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000893},
author = {Kadhim Hayawi and Sakib Shahriar and Hany Alashwal and Mohamed Adel Serhani},
keywords = {Reverse vaccinology, Large language models (LLMs), AI, Generative AI, Vaccine candidate identification, AI ethics, Vaccines},
abstract = {Reverse vaccinology is an emerging concept in the field of vaccine development as it facilitates the identification of potential vaccine candidates. Biomedical research has been revolutionized with the recent innovations in Generative Artificial Intelligence (AI) and Large Language Models (LLMs). The intersection of these two technologies is explored in this study. In this study, the impact of Generative AI and LLMs in the field of vaccinology is explored. Through a comprehensive analysis of existing research, prospective use cases, and an experimental case study, this research highlights that LLMs and Generative AI have the potential to enhance the efficiency and accuracy of vaccine candidate identification. This work also discusses the ethical and privacy challenges, such as data consent and potential biases, raised by such applications that require careful consideration. This study paves the way for experts, researchers, and policymakers to further investigate the role and impact of Generative AI and LLM in vaccinology and medicine.}
}
@article{JIANG2025134548,
title = {Prompt engineering to inform large language model in automated building energy modeling},
journal = {Energy},
volume = {316},
pages = {134548},
year = {2025},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2025.134548},
url = {https://www.sciencedirect.com/science/article/pii/S0360544225001902},
author = {Gang Jiang and Zhihao Ma and Liang Zhang and Jianli Chen},
keywords = {Prompt engineering, Large language model, Building energy models, Automated building energy modeling, In-context learning, Generative artificial intelligence},
abstract = {Application of large language models (LLMs) to facilitate auto-building energy modeling (ABEM) is complex and resource-intensive. This paper presents practical guidelines for ABEM using prompt engineering with LLMs. Unlike training LLMs for ABEM with fine-tuning (involving model weight adjustment), prompt engineering is to provide specific prompts along with modeling descriptions and demonstrations, informing LLMs to automatically generate building energy models (BEMs) through natural language expression, and enabling users to perform ABEM without specialized building knowledge or software proficiency. In this study, the capabilities of prompt engineering for ABEM using LLMs are investigated. To achieve this, six types of prompts are designed, encompassing two exploratory tasks and one real-world task with a total of 648 case studies. The results from the case studies suggest that prompt engineering is feasible to automatically obtain the desired BEMs using one-shot learning (one demonstration), few-shot learning (few-demonstration), and chain-of-thought strategies (i.e., task explanation and division). Finally, the modeling comparison between the tested lightweighted LLMs with GPT-4o suggests that compact LLMs with an appropriate context window are suitable to be deployed for various building applications. The source codes for prompt engineering are available on GitHub (https://github.com/Gangjiang1/Prompting-for-Auto-building-Modeling.git).}
}
@article{REWTHAMRONGSRIS2025100848,
title = {Image-Based Diagnostic Performance of LLMs vs CNNs for Oral Lichen Planus: Example-Guided and Differential Diagnosis},
journal = {International Dental Journal},
volume = {75},
number = {4},
pages = {100848},
year = {2025},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2025.100848},
url = {https://www.sciencedirect.com/science/article/pii/S0020653925001376},
author = {Paak Rewthamrongsris and Jirayu Burapacheep and Ekarat Phattarataratip and Promphakkon Kulthanaamondhita and Antonin Tichy and Falk Schwendicke and Thanaphum Osathanon and Kraisorn Sappayatosok},
keywords = {Chatbot, Computer-assisted diagnosis, Differential diagnosis, Generative artificial intelligence, Large language model, Oral lichen planus},
abstract = {Introduction and aims
The overlapping characteristics of oral lichen planus (OLP), a chronic oral mucosal inflammatory condition, with those of other oral lesions, present diagnostic challenges. Large language models (LLMs) with integrated computer-vision capabilities and convolutional neural networks (CNNs) constitute an alternative diagnostic modality. We evaluated the ability of seven LLMs, including both proprietary and open-source models, to detect OLP from intraoral images and generate differential diagnoses.
Methods
Using a dataset with 1,142 clinical photographs of histopathologically confirmed OLP, non-OLP lesions, and normal mucosa. The LLMs were tested using three experimental designs: zero-shot recognition, example-guided recognition, and differential diagnosis. Performance was measured using accuracy, precision, recall, F1-score, and discounted cumulative gain (DCG). Furthermore, the performance of LLMs was compared with three previously published CNN-based models for OLP detection on a subset of 110 photographs, which were previously used to test the CNN models.
Results
Gemini 1.5 Pro and Flash demonstrated the highest accuracy (69.69%) in zero-shot recognition, whereas GPT-4o ranked first in the F1 score (76.10%). With example-guided prompts, which improved consistency and reduced refusal rates, Gemini 1.5 Flash achieved the highest accuracy (80.53%) and F1-score (84.54%); however, Claude 3.5 Sonnet achieved the highest DCG score of 0.63. Although the proprietary models generally excelled, the open-source Llama model demonstrated notable strengths in ranking relevant diagnoses despite moderate performance in detection tasks. All LLMs were outperformed by the CNN models.
Conclusion
The seven evaluated LLMs lack sufficient performance for clinical use. CNNs trained to detect OLP outperformed the LLMs tested in this study.}
}
@article{MENG2025933,
title = {“Talk to me, I’m secure”: investigating information disclosure to AI chatbots in the context of privacy calculus},
journal = {Online Information Review},
volume = {49},
number = {5},
pages = {933-954},
year = {2025},
issn = {1468-4527},
doi = {https://doi.org/10.1108/OIR-06-2024-0375},
url = {https://www.sciencedirect.com/science/article/pii/S1468452725000150},
author = {Xiaoxiao Meng and Jiaxin Liu},
keywords = {Privacy calculus, Human–computer interaction, Parasocial interaction, Privacy disclosure, AI chatbots},
abstract = {Purpose
This study aims to explain the privacy paradox, wherein individuals, despite privacy concerns, are willing to share personal information while using AI chatbots. Departing from previous research that primarily viewed AI chatbots from a non-anthropomorphic approach, this paper contends that AI chatbots are taking on an emotional component for humans. This study thus explores this topic by considering both rational and non-rational perspectives, thereby providing a more comprehensive understanding of user behavior in digital environments.
Design/methodology/approach
Employing a questionnaire survey (N = 480), this research focuses on young users who regularly engage with AI chatbots. Drawing upon the parasocial interaction theory and privacy calculus theory, the study elucidates the mechanisms governing users’ willingness to disclose information.
Findings
Findings show that cognitive, emotional and behavioral dimensions all positively influence perceived benefits of using ChatGPT, which in turn enhances privacy disclosure. While cognitive, emotional and behavioral dimensions negatively impact perceived risks, only the emotional and behavioral dimensions significantly affect perceived risk, which in turn negatively influences privacy disclosure. Notably, the cognitive dimension’s lack of significant mediating effect suggests that users’ awareness of privacy risks does not deter disclosure. Instead, emotional factors drive privacy decisions, with users more likely to disclose personal information based on positive experiences and engagement with ChatGPT. This confirms the existence of the privacy paradox.
Research limitations/implications
This study acknowledges several limitations. While the sample was adequately stratified, the focus was primarily on young users in China. Future research should explore broader demographic groups, including elderly users, to understand how different age groups engage with AI chatbots. Additionally, although the study was conducted within the Chinese context, the findings have broader applicability, highlighting the potential for cross-cultural comparisons. Differences in user attitudes toward AI chatbots may arise due to cultural variations, with East Asian cultures typically exhibiting a more positive attitude toward social AI systems compared to Western cultures. This cultural distinction—rooted in Eastern philosophies such as animism in Shintoism and Buddhism—suggests that East Asians are more likely to anthropomorphize technology, unlike their Western counterparts (Yam et al., 2023; Folk et al., 2023).
Practical implications
The findings of this study offer valuable insights for developers, policymakers and educators navigating the rapidly evolving landscape of intelligent technologies. First, regarding technology design, the study suggests that AI chatbot developers should not focus solely on functional aspects but also consider emotional and social dimensions in user interactions. By enhancing emotional connection and ensuring transparent privacy communication, developers can significantly improve user experiences (Meng and Dai, 2021). Second, there is a pressing need for comprehensive user education programs. As users tend to prioritize perceived benefits over risks, it is essential to raise awareness about privacy risks while also emphasizing the positive outcomes of responsible information sharing. This can help foster a more informed and balanced approach to user engagement (Vimalkumar et al., 2021). Third, cultural and ethical considerations must be incorporated into AI chatbot design. In collectivist societies like China, users may prioritize emotional satisfaction and societal harmony over privacy concerns (Trepte, 2017; Johnston, 2009). Developers and policymakers should account for these cultural factors when designing AI systems. Furthermore, AI systems should communicate privacy policies clearly to users, addressing potential vulnerabilities and ensuring that users are aware of the extent to which their data may be exposed (Wu et al., 2024). Lastly, as AI chatbots become deeply integrated into daily life, there is a growing need for societal discussions on privacy norms and trust in AI systems. This research prompts a reflection on the evolving relationship between technology and personal privacy, especially in societies where trust is shaped by cultural and emotional factors. Developing frameworks to ensure responsible AI practices while fostering user trust is crucial for the long-term societal integration of AI technologies (Nah et al., 2023).
Originality/value
The study’s findings not only draw deeper theoretical insights into the role of emotions in generative artificial intelligence (gAI) chatbot engagement, enriching the emotional research orientation and framework concerning chatbots, but they also contribute to the literature on human–computer interaction and technology acceptance within the framework of the privacy calculus theory, providing practical insights for developers, policymakers and educators navigating the evolving landscape of intelligent technologies.}
}
@article{BADINI2025100275,
title = {Enhancing mechanical and bioinspired materials through generative AI approaches},
journal = {Next Materials},
volume = {6},
pages = {100275},
year = {2025},
issn = {2949-8228},
doi = {https://doi.org/10.1016/j.nxmate.2024.100275},
url = {https://www.sciencedirect.com/science/article/pii/S2949822824001722},
author = {Silvia Badini and Stefano Regondi and Raffaele Pugliese},
keywords = {Mechanical materials, Bioinspired materials, Additive manufacturing, Generative AI, Human-machine interaction},
abstract = {The integration of generative artificial intelligence (AI) into the design and additive manufacturing processes of mechanical and bioinspired materials has emerged as a transformative approach in engineering and material science, allowing to explore relationships across different field (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-3D printing). In addition, generative AI techniques, including generative adversarial networks (GAN), genetic algorithms, and large language models (LLMs), offer efficient and tunable solutions for optimizing material properties, reducing production costs, and accelerating the development timelines. In the field of mechanical materials design, generative AI enables the rapid generation of novel structures with enhanced mechanical performance. Instead, bioinspired materials design benefits significantly from the synergy of generative AI with bioinspired concepts and additive manufacturing. By harnessing generative algorithms and topology optimization, researchers can explore complex biological phenomena and translate them into innovative engineering solutions. Lastly, the emergence of LLMs in additive manufacturing optimization demonstrates their potential to optimize printing parameters, debug errors, and enhance productivity. This review highlights the pivotal role of generative AI in advancing materials science and engineering, unlocking new possibilities for innovation, and accelerating the development of efficient material solutions. As generative AI continues to evolve, its integration promises to revolutionize engineering design and drive the field towards unprecedented levels of efficiency, thus turns information into knowledge.}
}
@article{PHAM2025117932,
title = {Segmental retaining wall displacement monitoring using RGB-D image and generative AI approach},
journal = {Measurement},
volume = {254},
pages = {117932},
year = {2025},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2025.117932},
url = {https://www.sciencedirect.com/science/article/pii/S0263224125012916},
author = {Minh-Vuong Pham and Yong-Soo Ha and Thanh-Nhan Nguyen and Yun-Tae Kim},
keywords = {Displacement monitoring, Retaining wall, RGB-D image, Depth estimation model, Generative AI},
abstract = {Using a red green blue (RGB) image obtained from a monocular camera allows measurement of in-plane displacements of segmental retaining walls (SRWs). However, it cannot measure out-of-plane displacements, which are movements perpendicular to the image plane. To address the limitation, this study presents a novel approach for SRW displacement monitoring by using RGB-depth (RGB-D) image. The proposed method used RGB images captured from a single camera and CNN-based depth estimation models to generate a depth map. The depth map was then used for point cloud reconstruction and displacement calculation. Additionally, a generative artificial intelligence (AI)-based enhancement module was implemented to enhance low-quality images captured in low-light or overexposed environments, leading to improved monitoring. The proposed approach was validated through laboratory experiments. The depth estimation models demonstrated high performance, achieving accuracies ranging from 0.896 to 0.957. The generative AI model effectively improved the accuracy of depth map prediction in low-light conditions. The calculated 3D displacement results derived from RGB-D images, with the depth component estimated by the MobileNet depth estimation model, demonstrated the highest accuracy, with errors ranging from 0.0 to 2.6 mm. The proposed method is a reliable, adaptable, and efficient solution for monitoring structural displacement, offering significant potential for real-world applications.}
}
@article{URIBE2024105275,
title = {Estimating the use of ChatGPT in dental research publications},
journal = {Journal of Dentistry},
volume = {149},
pages = {105275},
year = {2024},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2024.105275},
url = {https://www.sciencedirect.com/science/article/pii/S0300571224004445},
author = {Sergio E. Uribe and Ilze Maldupa},
keywords = {Large-language model, Artificial intelligence, Scientific communication, ChatGPT, Dental research},
abstract = {Introduction
Generative artificial intelligence (GenAI) Large-language models such as ChatGPT have become increasingly popular in various fields. However, the impact of ChatGPT on dental research writing has yet to be quantified. This study aimed to assess ChatGPT's usage in dental research writing and discuss potential advantages and challenges.
Methods
Using a bibliometric design, we performed a keyword analysis of specific 'signaling words' indicative of ChatGPT use in the titles/abstracts of 299,695 dental research abstracts indexed PubMed 2018–2024. Statistical comparisons using normalized ratios per 10,000 dental publications compared changes in word frequency before and after the ChatGPT release on November 30, 2022.
Results
Before ChatGPT's release, the frequency of abstracts with signaling words was 47.1 per 10,000 papers. After the release, this increased to 224.2 per 10,000 papers, an increase of 177.2 per 10,000 papers (p = 0.014, 95 % CI 53.5–300.7). The word 'delve' showed the most significant usage increase (increased ratio=17.0).
Conclusions
This study is among the first to systematically assess the use of GenAI, specifically ChatGPT, in dental research. We found evidence of the use and growth of ChatGPT in dental research publications. This trend indicates the widespread adoption of GenAI-assisted writing in scientific communication, consistent with other scientific fields. While GenAI can potentially increase productivity and inclusivity, it raises concerns such as bias, inaccuracy, and distortion of academic incentives. Therefore, our findings support the need for clear AI guidelines and standards for academic publishing to ensure responsible use and maintain scientific integrity.}
}
@incollection{GAUR2026243,
title = {Chapter 14 - Role of governability and generative AI for healthcare},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {243-260},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00004-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000047},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Ethical guidelines, Generative AI, Governability, Healthcare, Regulatory frameworks, Societal values, Stakeholder involvement},
abstract = {This chapter examines the critical role of governability in the context of generative artificial intelligence (AI), particularly within healthcare systems. Governability refers to the ability to regulate, manage, and ensure the ethical operation of AI technologies, which is increasingly essential as these technologies become integrated into healthcare practices. The introduction highlights the need for effective governance frameworks that align AI systems with societal values, ensuring they operate ethically and responsibly. The chapter provides an overview of existing regulations governing AI in healthcare, including global standards and country-specific guidelines. It discusses the unique challenges posed by generative AI technologies, such as accountability, transparency, and compliance, and presents case studies that illustrate various regulatory approaches, their successes, and areas needing improvement. Ensuring the ethical operation of AI systems is paramount. The chapter discusses ethical guidelines that govern AI in healthcare, emphasizing principles like fairness, transparency, and patient safety. It also explores how to balance the push for innovation with adherence to ethical standards, using case studies to illustrate ethical challenges faced in AI-driven healthcare and the governance strategies employed to address them. Effective governance strategies are critical for the successful management of AI in healthcare. Different governance models are explored, highlighting the importance of stakeholder involvement, including healthcare professionals, patients, and policymakers. The chapter examines ongoing monitoring and auditing strategies to ensure AI systems operate in alignment with ethical and regulatory standards. Moreover, aligning AI systems with societal values—such as equity, access, and patient autonomy—is discussed. Strategies for embedding these values into AI design and operation are explored, along with case studies showcasing successful alignment with societal goals. Looking to the future, the chapter discusses the potential evolution of governance standards for AI in healthcare and the role of emerging technologies, such as blockchain and AI, in enhancing governability and transparency. It concludes with recommendations for building a sustainable governance framework for generative AI in healthcare, addressing both challenges and opportunities.}
}
@article{LOMURNO202552,
title = {Synthetic image learning: Preserving performance and preventing Membership Inference Attacks},
journal = {Pattern Recognition Letters},
volume = {190},
pages = {52-58},
year = {2025},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2025.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167865525000388},
author = {Eugenio Lomurno and Matteo Matteucci},
keywords = {Generative deep learning, Dataset generation, Classification Accuracy Score, Privacy, Membership Inference Attack, Generative Knowledge Distillation, Knowledge Recycling},
abstract = {Generative artificial intelligence has transformed the generation of synthetic data, providing innovative solutions to challenges like data scarcity and privacy, which are particularly critical in fields such as medicine. However, the effective use of this synthetic data to train high-performance models remains a significant challenge. This paper addresses this issue by introducing Knowledge Recycling (KR), a pipeline designed to optimise the generation and use of synthetic data for training downstream classifiers. At the heart of this pipeline is Generative Knowledge Distillation, the proposed technique that significantly improves the quality and usefulness of the information provided to classifiers through a synthetic dataset regeneration and soft labelling mechanism. The KR pipeline has been tested on a variety of datasets, with a focus on six highly heterogeneous medical image datasets, ranging from retinal images to organ scans. The results show a significant reduction in the performance gap between models trained on real and synthetic data, with models based on synthetic data outperforming those trained on real data in some cases. Furthermore, the resulting models show almost complete immunity to Membership Inference Attacks, manifesting privacy properties missing in models trained with conventional techniques.}
}
@article{HU2025103376,
title = {Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models},
journal = {Information Fusion},
volume = {124},
pages = {103376},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103376},
url = {https://www.sciencedirect.com/science/article/pii/S156625352500449X},
author = {Man Hu and Yatao Yang and Deng Pan and Zhongliang Guo and Luwei Xiao and Deyu Lin and Shuai Zhao},
keywords = {Generative artificial intelligence, Large language models, Model security, Backdoor attacks, Synthetic data generation, Syntactic structure},
abstract = {Language Models (LMs) have shown significant advancements in various Natural Language Processing (NLP) tasks. However, recent studies indicate that LMs are particularly susceptible to malicious backdoor attacks, where attackers manipulate the models to exhibit specific behaviors when they encounter particular triggers. While existing research has focused on backdoor attacks against English LMs, Chinese LMs remain largely unexplored. Moreover, existing backdoor attacks against Chinese LMs exhibit limited stealthiness. In this paper, we investigate the high detectability of current backdoor attacks against Chinese LMs and propose a more stealthy backdoor attack method based on syntactic paraphrasing. Specifically, we leverage large language models (LLMs) to construct a syntactic paraphrasing mechanism that transforms benign inputs into poisoned samples with predefined syntactic structures. Subsequently, we exploit the syntactic structures of these poisoned samples as triggers to create more stealthy and robust backdoor attacks across various attack strategies. Extensive experiments conducted on three major NLP tasks with various Chinese PLMs and LLMs demonstrate that our method can achieve comparable attack performance (almost 100% success rate). Additionally, the poisoned samples generated by our method show lower perplexity and fewer grammatical errors compared to traditional character-level backdoor attacks. Furthermore, our method exhibits strong resistance against two state-of-the-art backdoor defense mechanisms.}
}
@article{FASANO20251,
title = {The dilemma of accuracy in bankruptcy prediction: a new approach using explainable AI techniques to predict corporate crises},
journal = {European Journal of Innovation Management},
volume = {28},
number = {11},
pages = {1-22},
year = {2025},
issn = {1460-1060},
doi = {https://doi.org/10.1108/EJIM-06-2024-0633},
url = {https://www.sciencedirect.com/science/article/pii/S1460106024000075},
author = {Francesco Fasano and Carlo Adornetto and Iliess Zahid and Maurizio {La Rocca} and Luigi Montaleone and Gianluigi Greco and Alfio Cariola},
keywords = {Bankruptcy prediction, Corporate failure, Generative Artificial Intelligence, Business crisis management, Digital transformation},
abstract = {Purpose
Our aim is to develop a highly precise corporate crisis prediction model that surpasses previous versions, rooted in the forefront of technological advancements.
Design/methodology/approach
Artificial Intelligence (AI) for corporate default prediction with a novel approach based on a mix of techniques, enabling it to achieve a higher accuracy. We investigated models with sequence lengths that were both fixed and variable, and we chose the best variable sequence length model.
Findings
Our findings demonstrate that the artificial techniques implemented lead to very high accuracy in predicting business crises compared to previous research efforts, even those utilising long-time sequences or a high volume of observations.
Research limitations/implications
We highlight the key variables with a higher predictive power that need monitoring to prevent business crises. We also aim to open a new avenue of research that, starting from the use of these techniques and our results, can implement models incorporating non-accounting variables to prevent business crises.
Practical implications
We provide a model/tool that assesses a possible business crisis in advance through a monitoring and alert system. Policymakers can use our research’s output as a tool to combine with current credit-scoring systems and to assess the effectiveness of the new corporate crisis reforms that are upcoming in many European countries. The results of our research can be useful also to banks, public entities, and consulting firms that interact with companies and are interested in the evaluation of a firm’s financial health and stability.
Originality/value
Our innovative work leverages cutting-edge methodologies such as deep Recurrent Neural Networks and explainable AI. This choice is driven by the rapid evolution of AI techniques in practical application.}
}
@article{LI2025100722,
title = {The interaction between emotion dynamics and opinion changes in the era of generative AI},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100722},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100722},
url = {https://www.sciencedirect.com/science/article/pii/S245195882500137X},
author = {Shangqian Li and Shaoyang Fan and Gianluca Demartini},
keywords = {Human computer interaction, Generative Artificial Intelligence, Emotion regulation, Online opinion modelling},
abstract = {Online emotion regulation interventions have experienced huge developments during the last decade due to the expansion of information communication technologies applications. Most existing emotion regulation interventions aim to provide long-term or on-site assistance to help users manage their sentiments to a desired psychological state. Recent advancements have significantly bolstered online emotion regulation interventions, such as AI-driven mindfulness apps that adapt to user feedback. Online-based emotion regulation applications are considered influential on users’ contextual and emotional decision-making processes. However, existing research offers limited observations on (i) how emotion regulation interventions affect people’s opinion changes and (ii) how generative AI could contribute to the development of automatic emotion regulation interventions. Hence, we experimented with 150 participants to close this research gap. We proposed two novel emotion regulation approaches to determine whether users’ opinions and emotional changes differ between ordinary-AI-based and generative-AI-based interventions on emotion regulation tasks. The result revealed that people’s feelings and decisions are highly correlated to their information consumption and perspectives. Furthermore, we found that intervention methods and users’ perceptions of the technology behind that intervention also played a vital role in their user experiences and decision-making processes. This research (i) shows that there exist interactions between emotions and opinion changes, (ii) opens new avenues for leveraging generative AI in emotion regulation applications, and (iii) underscores how divergent attitudes towards AI technology can lead to varied levels of success in the user experience.}
}
@article{DONG2025110789,
title = {Can GPT-4 provide human-level emotion support? Insights from machine learning-based evaluation framework},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110789},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110789},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525011400},
author = {Wanghao Dong and Weijun Wang and Xinheng Han and Junhao Huang and Lie Li and Yinghui Huang},
keywords = {Emotional support, GPT-4, Prompt engineering, Explainable machine learning, Large language models},
abstract = {The global shortage of mental health services has sparked considerable interest in leveraging generative artificial intelligence (AI) to address psychological health challenges. This study systematically evaluates the emotional support capabilities of GPT-4 and explores ways to enhance its performance through targeted prompt engineering. Initially, natural language processing and explainable machine learning were employed to develop a predictive model for evaluating the empathy of GPT-4’s responses. Feature sensitivity analysis identified key linguistic features that significantly influence empathy performance. These insights were then integrated with empathy component theory and helping skills theory to design prompt engineering to enhance GPT-4’s emotional support capabilities. Evaluation results show that while unprompted GPT-4 demonstrates substantial empathy in addressing help-seekers’ needs, it still lags behind human counselors. However, when guided by targeted prompts, GPT-4’s emotional support capabilities improve markedly compared to its zero-prompt version. Notably, in handling emotional issues such as anger, fear, and disgust, prompted GPT-4 performs at a level comparable to human counselors. In summary, this study provides initial evidence of GPT-4’s potential in emotional support and introduces an evaluation framework (initial-Evaluation, Enhancement, and re-Evaluation; EEE) that can be used to assess and optimize LLMs' abilities in mental health applications, offering insights into their role in supporting human mental health services.}
}
@article{GOLDIE2025,
title = {Practitioner Perspectives on the Uses of Generative AI Chatbots in Mental Health Care: Mixed Methods Study},
journal = {JMIR Human Factors},
volume = {12},
year = {2025},
issn = {2292-9495},
doi = {https://doi.org/10.2196/71065},
url = {https://www.sciencedirect.com/science/article/pii/S2292949525002056},
author = {Jessie Goldie and Simon Dennis and Lyndsey Hipgrave and Amanda Coleman},
keywords = {artificial intelligence, ChatGPT, mental health care, practitioner perspectives, mixed methods, digital health},
abstract = {Background
Generative artificial intelligence (AI) chatbots have the potential to improve mental health care for practitioners and clients. Evidence demonstrates that AI chatbots can assist with tasks such as documentation, research, counseling, and therapeutic exercises. However, research examining practitioners’ perspectives is limited.
Objective
This mixed-methods study investigates: (1) practitioners’ perspectives on different uses of generative AI chatbots; (2) their likelihood of recommending chatbots to clients; and (3) whether recommendation likelihood increases after viewing a demonstration.
Methods
Participants were 23 mental health practitioners, including 17 females and 6 males, with a mean age of 39.39 (SD 16.20) years. In 45-minute interviews, participants selected their 3 most helpful uses of chatbots from 11 options and rated their likelihood of recommending chatbots to clients on a Likert scale before and after an 11-minute chatbot demonstration.
Results
Binomial tests found that Generating case notes was selected at greater-than-chance levels ( 15/23, 65%; P=.001), while Support with session planning (P=.86) and Identifying and suggesting literature (P=.10) were not. Although 55% (12/23) were likely to recommend chatbots to clients, a binomial test found no significant difference from the 50% threshold (P=.74). A paired samples t test found that recommendation likelihood increased significantly (19/23, 83%; P=.002) from predemonstration to postdemonstration.
Conclusions
Findings suggest practitioners favor administrative uses of generative AI and are more likely to recommend chatbots to clients after exposure. This study highlights a need for practitioner education and guidelines to support safe and effective AI integration in mental health care.}
}
@article{JIANG2025105365,
title = {A hybrid framework for regional land valuation using generative intelligence and AutoML techniques},
journal = {Landscape and Urban Planning},
volume = {259},
pages = {105365},
year = {2025},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2025.105365},
url = {https://www.sciencedirect.com/science/article/pii/S0169204625000726},
author = {Feifeng Jiang and Jun Ma},
keywords = {Regional land value, Land price, Deep learning, Generative artificial intelligence (generative AI), Sustainable urban development},
abstract = {Land value is a crucial indicator of economic dynamics and regional development, providing essential information for urban planning and policy development. However, most existing studies estimate a singular land value over large areas, lacking the fine-grained details for urban management. This study therefore develops a RAHGV (relative-to-absolute hybrid generative valuation) framework for regional land valuation, which combines a hybrid learning strategy with deep generative modeling to produce high-resolution, spatially continuous land value distribution across extensive urban areas. In a case study of New York City (NYC), the RAHGV model outperforms typical one-step models by differentiating between local land variations and broader regional tendencies. Its bi-attention bottleneck significantly improves model performance, reducing MAE (Mean Absolute Error) by 45.75% and MSE (Mean Squared Error) by 69.86% compared to conventional deep generative methods. Local physical infrastructure and mixed land-use patterns primarily influence micro-scale land values, while community amenities and economic vibrancy drive macro-scale values. The findings highlight the potential of the RAHGV framework as a powerful tool for promoting sustainable urban development by delivering high-resolution, data-driven insights that support informed decision-making in rapidly evolving urban environments.}
}
@article{BISWAS2025450,
title = {Applying the stimulus-organism-behavior-consequence framework to examine the relationship between intention, usage and recommendation of ChatGPT in higher education},
journal = {International Journal of Educational Management},
volume = {39},
number = {2},
pages = {450-468},
year = {2025},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-09-2023-0463},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X25000109},
author = {Mohammad Islam Biswas and Md. Shamim Talukder and Yasheng Chen},
keywords = {Artificial intelligence, Technology adoption, ChatGPT, SOBC framework, Likelihood of recommending, Higher education},
abstract = {Purpose
The adoption and usage of generative artificial intelligence tools like Chat Generative Pre-Trained Transformer (ChatGPT) in academia is the subject of increasing research interest. This study investigates the factors influencing the intention, usage and recommendation of ChatGPT among university students by employing the stimulus-organism-behavior-consequence (SOBC) framework.
Design/methodology/approach
The proposed research model was validated by employing the partial least squares structural equation modeling (PLS-SEM) approach using 249 university students.
Findings
The study revealed that intention to use and usage behavior of ChatGPT among university students are highly influenced by perceived usefulness, initial trust, personal innovativeness and availability of information and support. Similarly, the study found a sequence of significant positive relationships among intention to use, actual use and likelihood of recommending the technology to others. However, the results showed that the impact of perceived ease of use and social influence on behavioral intention was not found to be significant predictors of intention to use ChatGPT in academic settings.
Practical implications
The research findings offer a number of benefits for educational institutions and technology developers regarding students’ perceptions of ChatGPT and its academic applications. Eventually, the findings will encourage AI technology developers to enhance the quality and design of their solutions. Additionally, it helps educators in designing the AI governance framework to promote the ethical and transparent use of AI in academic environments.
Originality/value
This study contributes to the expanding body of technology adoption research and offers an integrated theoretical framework for comprehending the adoption and usage of ChatGPT in academic settings.}
}
@article{MODGIL2025103124,
title = {How could Generative AI support and add value to non-technology companies – A qualitative study},
journal = {Technovation},
volume = {139},
pages = {103124},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103124},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001743},
author = {Sachin Modgil and Shivam Gupta and Arpan Kumar Kar and Tuure Tuunanen},
keywords = {Qualitative study, Generative artificial intelligence, Business value, Business model, Technology appropriation},
abstract = {With the spread of generative AI, non-technology companies are also adopting it at a faster rate. Therefore, this study aims to study the appropriation of Generative AI to create value to non-technology businesses through a knowledge based view of the firm. To achieve this objective, we followed a semi-structured interview schedule, where 98 qualitative data points were collected and analysed. We follow open, axial and selective coding along with Gioia methodology for analysis. Findings indicate that companies employ Generative AI for risk management, where potential threats, impact of possible hazards and degree of uncertainty in the business environment are considered in decision-making. Generative AI also helps in knowledge integration, where assimilation, adaptation, application and implementation are achieved. Findings also suggest that an improved business outlook can be achieved regarding accurate demand forecasting, real-time insights, contextual understanding and alignment to the vision through Generative AI. It is also observed that companies are investing in Generative AI to achieve competitive advantage and greater significance. The contribution of this study lies in the development of four propositions and a framework for generative AI-driven value for non-technology companies. The framework also uncovers the internal flow among key elements from risk identification to integration to developing the outlook and driving utility.}
}
@article{LI2025110672,
title = {SafetyGPT: An autonomous agent of electrical safety risks for monitoring workers’ unsafe behaviors},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {168},
pages = {110672},
year = {2025},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2025.110672},
url = {https://www.sciencedirect.com/science/article/pii/S0142061525002236},
author = {Wei Li and Fuqi Ma and Zhiyuan Zuo and Rong Jia and Bo Wang and Abdullah M Alharbi},
keywords = {Generative artificial intelligence, Risk identification, Electric power production, Multi-modal large language model, Unsafe behaviors},
abstract = {Workers’ unsafe behavior is one of the major causes of accidents in electric power production. Intelligent monitoring of workers’ unsafe behaviors can effectively prevent the expansion of safety risks, thereby blocking the development process of risks to accidents. Electric power production processes are diverse in nature and require the frequent switching of operating scenarios. This makes it difficult to identify what is “unsafe” since worker behaviors within the given electrical context also exhibit variability and diversity. Existing methods have insufficient generalization and adaptability, which makes them inadequate for the case of electric power production. Therefore, this paper proposes Safety Generative Pre-trained Transformers (SafetyGPT), an autonomous agent of safety risk based on a multi-modal large language model, which incorporates a human–machine collaborative monitoring mode for unsafe behaviors of workers. SafetyGPT loads the electric power production video, and the backend supervisors set instructions for SafetyGPT based on task requirements. The model encodes visual and textual features into corresponding tokens, realizes multi-modal feature alignment and fusion through the cross-attention mechanism, and then generates targeted responses through the large language model. Next, the proposed method is applied to real production site data to confirm the effectiveness and superiority through comparison with other methods designed to identify unsafe behaviors. Experimental results show that the accuracy of the proposed method for the identification of unsafe behaviors in complex environments is 96.5%, and that it can generate reasonable recommended plan based on the identification results, assist backend supervisors in making decisions, and effectively improve the safety level of power production.}
}
@article{ALANISRUIZ2025112856,
title = {A deep convolutional generative adversarial network (DCGAN) for the fast estimation of pollutant dispersion fields in indoor environments},
journal = {Building and Environment},
volume = {276},
pages = {112856},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112856},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325003385},
author = {Claudio {Alanis Ruiz} and Marcel Loomans and Twan {van Hooff}},
keywords = {Generative adversarial networks (GANs), Convolutional neural networks (CNNs), Generative artificial intelligence (GenAI), Pollutant dispersion, Indoor air quality, Computational fluid dynamics (CFD)},
abstract = {This paper presents a generative AI approach using a conditional deep convolutional generative adversarial network (cDCGAN) to rapidly predict pollutant concentration fields in indoor environments. The cDCGAN model is applied to a case study of a generic classroom with multiple heat and pollution sources and two distinct ventilation system configurations. It predicts pollutant dispersion at the breathing plane under simultaneous variations in ventilation rates and air supply temperatures. The model was trained and validated using high-quality computational fluid dynamics (CFD) simulation data. Results show that the cDCGAN can generate rapid predictions within seconds, providing reasonable accuracy in capturing the overall distribution and concentration levels of pollutants, with a mean absolute percentage error ranging from 13 % to 15 % when compared to CFD simulations. Despite some limitations in reproducing small-scale flow features, the model's ability to handle multiple system parameters and efficiently predict complex flow phenomena with limited training data highlights its value and potential. The methodology is adaptable to a range of indoor and outdoor environments and can be extended to estimate other flow variables and incorporate additional system parameters, making it a promising tool for applications requiring speed and efficiency when analyzing a large number of flow and dispersion scenarios.}
}
@article{SASIWAT2024100532,
title = {Implementation and test of a Device-Free localization system with a modified desync network protocol and a weighted k-nearest neighbor algorithm},
journal = {Egyptian Informatics Journal},
volume = {27},
pages = {100532},
year = {2024},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2024.100532},
url = {https://www.sciencedirect.com/science/article/pii/S1110866524000951},
author = {Yoschanin Sasiwat and Dujdow Buranapanichkit and Apidet Booranawong},
keywords = {Device-free localization, Desync protocols, RSSI, Fingerprinting, Weighted k-nearest neighbors},
abstract = {A device-free localization system is a technology for tracking targets or individuals without requiring them to carry any electronic devices. The system works by monitoring and processing changes in the received signal strength to detect changes in the environment. However, due to unreliable wireless communications and radio-based tracking solutions, an efficient system concerning both wireless communication and tracking performance should be developed. This paper presents a study of the 2.4 GHz IEEE 802.15.4 device-free localization system, focusing on the effectiveness of wireless network protocols and the accuracy of localization algorithms. The novelty and contribution of our work is that we develop a modified desync protocol for network synchronization and the weighted k-nearest neighbor algorithm for location tracking. The study provides both simulation and experimental evaluations, considering hardware configurations such as the CC2538 + CC2592 device. Results demonstrate that the modified desync protocol can effectively operate in real-world environments. The network’s performance is evaluated through the packet delivery ratios for different network sizes and the convergence time, which refers to the ability to restore synchronization among network nodes. In our experiment case, the packet delivery ratio and the convergence time for a twenty-node network size are 97.98 % and 6.976 s, respectively. In addition, the weighted k-nearest neighbor algorithm with an additional solution provides a high estimation accuracy of 99.93 % as accessed from various fixed human locations. Results also indicate that our algorithm can track the locations of a movement person, achieving an average accuracy of 85.75 % for different movement patterns. Finally, we suggest that the effect of new generative artificial intelligence approaches in this field should be investigated.}
}
@article{WANG2025112115,
title = {A multi-view new energy vehicle form generation design method combining Kansei imagery and deep learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112115},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112115},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625021232},
author = {Zihao Wang and Le Xi and Yifan Ding and Wenjie Fang and Kaiming Wang and Hongliang Zuo},
keywords = {Vehicle appearance design, Design decision evaluation, Residual networks, Kernels network, Multi-view fusion},
abstract = {In the competitive landscape of new energy vehicles, exterior design has become a crucial differentiator amid functional homogenization. User preferences are central to shaping vehicle appearance, yet most perceptual design methods rely on a single viewpoint, limiting insights into complex preference patterns. This study proposes a multi-perspective mapping approach that integrates Kansei engineering with deep learning. Firstly, user core imagery is collected and mined through big data. Secondly, Kernels Network (KNet) semantic segmentation model, Residual Networks (ResNet) tri-view (front/side/rear) score prediction model and fully connected network (FCN) feature fusion model are integrated to construct a multi-view feature mapping system. Finally, the optimal combination of morphological elements is explored based on the Elite Genetic Algorithm (EGA), and the scheme is validated through generative artificial intelligence (AI) workflow. The experimental results demonstrate that, employing “Cool” as a case study, the three-view scheme and the combination scheme devised by this research process exhibit substantial superiority over the majority of the samples. Under identical parameters, the scheme with decision constraints surpasses the randomly generated scheme in terms of perceptual scores and stability. The performance of the test set and the experimental results collectively substantiate the model’s validity. This workflow—covering preference extraction, morphological decomposition, AI-driven generation, and validation—provides a scalable framework for new energy vehicle exterior design. It also demonstrates novel applications of Kansei engineering in multi-view fusion and generative form design.}
}
@article{MUTIN2025,
title = {Extraction de données d’articles scientifiques pharmaceutiques par intelligence artificielle : évaluation de la conformité des réponses de ChatGPT 4.0 avec l’extraction humaine},
journal = {Le Pharmacien Clinicien},
year = {2025},
issn = {2772-9532},
doi = {https://doi.org/10.1016/j.phacli.2025.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S2772953225000863},
author = {Juliette Mutin and Marie-Lili Hafizin and Victor El-Jammal and Célia Morel and Lisa Leca and Maxime Bergeron and Jean-François Bussières},
keywords = {Agents conversationnels, Extraction données, Intelligence artificielle, Pharmacie, Conversational agents, Data extraction, Generative artificial intelligence, Pharmacy},
abstract = {Résumé
Introduction
L’intelligence artificielle (IA) est notamment utilisée pour automatiser l’extraction de données, avec l’aide d’agents conversationnels tels que ChatGPT. Il reste à évaluer si ces outils peuvent extraire des données d’articles scientifiques avec une précision comparable à celle des humains dans le domaine pharmaceutique. L’objectif est d’évaluer la conformité des données extraites par ChatGPT 4.0 en comparaison avec celles extraites par des étudiants en pharmacie, dans le cadre de la mise à jour de la plateforme impactpharmacie.org.
Matériel et méthodes
Cent articles pharmaceutiques ont été analysés. ChatGPT 4.0 a été programmé par un prompt et a été interrogé par 18 questions pour chaque article afin d’en extraire les données ciblées. Elles ont ensuite été comparées à celles préalablement validées et intégrées dans la plateforme par cinq étudiants en pharmacie. La conformité a été évaluée sur 23 critères incluant la description du type d’étude, les limites, l’intervention pharmaceutique et ce selon trois niveaux : conforme, partiellement conforme et non conforme. Le nombre et la nature des hallucinations ont également été relevés.
Résultats
La conformité des données extraites par ChatGPT comparées à celles des étudiants a atteint 77±19 % en moyenne. Cependant, des hallucinations d’IA ont été relevées dans 23 des 100 articles, et 30 % des paramètres (outcomes) (n=138/449) étaient absents de l’extraction. Une analyse complémentaire a été effectuée pour six revues systématiques et cinq méta-analyses.
Discussion
ChatGPT 4.0 est un outil prometteur pour extraire des données de la littérature scientifique pharmaceutique, mais une validation humaine reste nécessaire.
Summary
Introduction
Generative Artificial Intelligence (AI), particularly conversational agents like ChatGPT, can be used to automate data extraction. However, it remains to be determined if these tools can extract scientific data with accuracy comparable to humans, especially in the field of pharmacy. Objective was to assess the compliance rate of data extracted by ChatGPT 4.0 compared to Impact Pharmacie entries.
Materials and methods
This is a descriptive comparative study. A random selection of 100 articles entered on Impact Pharmacie in 2024 was identified. ChatGPT 4.0 was programmed with a prompt and queried with 18 questions per article to extract targeted data. The responses were compared to data previously entered into the Impact Pharmacie platform by pharmacy students following a standardized operating procedure. Compliance was assessed across 23 criteria (e.g., study type description, pharmaceutical intervention description, limitations) and categorized into three levels: compliant, partially compliant, and non-compliant. The number and nature of AI hallucinations were also recorded.
Results
The compliance rate of data extracted by ChatGPT compared to student-entered data averaged 77±19%. However, AI hallucinations were observed in 23 out of 100 articles, and 30% of parameters (n=138/449) were missing from the extraction.
Discussion
ChatGPT 4.0 is a promising tool to support data extraction from pharmaceutical scientific literature, but human validation remains essential to ensure the accuracy of the information.}
}
@article{MEJIASALGADO2025102509,
title = {Diagnostic accuracy in dry eye: Insights into clinical and artificial intelligence limitations: Limitations of diagnostic accuracy in dry eye},
journal = {Contact Lens and Anterior Eye},
pages = {102509},
year = {2025},
issn = {1367-0484},
doi = {https://doi.org/10.1016/j.clae.2025.102509},
url = {https://www.sciencedirect.com/science/article/pii/S1367048425001432},
author = {Germán Mejía-Salgado and William Rojas-Carabali and Carlos Cifuentes-González and María Andrea Bernal-Valencia and Paola Saboya-Galindo and Jaime Soto-Ariño and Valentina Dumar-Kerguelen and Guillermo Marroquín-Gómez and Martha Lucía Moreno-Pardo and Juliana Tirado-Ángel and Anat Galor and Alejandra de-la-Torre},
keywords = {Dry eye disease, Diagnosis, Large language models, Generative artificial intelligence},
abstract = {Purpose
To evaluate the agreement and performance of four large language models (LLMs)—ChatGPT-3.5, ChatGPT-4.0, Leny-ai, and MediSearch—in diagnosing and classifying Dry Eye Disease (DED), compared to clinician judgment and Dry Eye Workshop-II (DEWS-II) criteria.
Methods
A standardized prompt incorporating retrospective clinical and symptomatic data from patients with suspected DED referred to a dry eye clinic was developed. LLMs were evaluated for diagnosis (DED vs. no DED) and classification (aqueous-deficient, evaporative, mixed-component). Agreement was assessed using Cohen’s-kappa (Cκ) and Fleiss’-kappa (Fκ). Balanced accuracy, sensitivity, specificity, and F1 score were calculated.
Results
Among 338 patients (78.6 % female, mean age 53.2 years), clinicians diagnosed DED in 300, and DEWS-II criteria identified 234. LLMs showed high agreement with clinicians for DED diagnosis (93 %–99 %, Cκ: 0.81–0.86). Subtype agreement was lower (aqueous-deficient: 0 %–18 %, evaporative: 4 %–80 %, mixed-component: 22 %–92 %; Fκ: −0.20 to −0.10). Diagnostic balanced accuracy was 48 %–56 %, with high sensitivity (93 %–99 %) but low specificity (0 %–16 %). Subtype balanced accuracy and F1 score ranged from 33 %-81 % 0 %–71 %, respectively. Compared to DEWS-II, agreement for DED diagnosis remained high (96 %–99 %) but with weaker Cκ (0.52–0.58). Subtype agreement was again low (aqueous-deficient: 0 %–20 %, evaporative: 9 %–68 %, mixed-component: 16 %–75 %; Fκ: −0.09 to −0.02). Diagnostic balanced accuracy was 49 %–56 %, sensitivity 97 %–99 %, and specificity 5 %–16 %. Subtype balanced accuracy ranged from 43 % to 56 %, F1 score 0–68.
Conclusion
LLMs showed strong agreement and high sensitivity for DED diagnosis but limited specificity and poor subtype classification, mirroring clinical challenges and highlighting risks of overdiagnosis.}
}
@article{DUONG2023100883,
title = {Applying a modified technology acceptance model to explain higher education students’ usage of ChatGPT: A serial multiple mediation model with knowledge sharing as a moderator},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100883},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100883},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723001210},
author = {Cong Doanh Duong and Trong Nghia Vu and Thi Viet Nga Ngo},
keywords = {Technology acceptance model, Behavior intention to use ChatGPT, Actual use of ChatGPT, Knowledge sharing},
abstract = {Generative artificial intelligence (AI), such as ChatGPT, has taken the world by storm, especially in the education sector, because of its capacity to produce responses that are contextually relevant and appear to imitate human language. This has increased concerns from both scholars and practitioners regarding the potential impacts of ChatGPT on students' learning. However, research on higher education students' adoption of ChatGPT is still scant. Drawing on the modified technology acceptance model (TAM) and a sample of 1389 higher education students recruited in 11 universities in Vietnam with a stratified random sampling approach, the findings of this study indicated that effort expectancy not only directly affected students' actual usage of ChatGPT, but also serially indirectly increased their actual use of ChatGPT through performance expectancy and intentions to use ChatGPT. Additionally, knowledge sharing was found to significantly increase higher education students’ transformation from having the intention to use ChatGPT to actual users of ChatGPT. The theoretical and managerial implications of this are discussed in this paper in order to gain benefits and manage the potential threats from this new technology.}
}
@article{DAI2025100019,
title = {Why students use or not use generative AI: Student conceptions, concerns, and implications for engineering education},
journal = {Digital Engineering},
volume = {4},
pages = {100019},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100019},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000190},
author = {Yun Dai},
keywords = {Artificial intelligence, generative AI, engineering education, student concern, barrier, technology integration, higher education},
abstract = {Generative artificial intelligence (GenAI) technologies are believed to transform engineering education. However, it remains underexamined how engineering students choose to use GenAI or not, along with the reasons behind their choices. To fill this research gap, this study presents a natural experiment that examines student use or non-use of GenAI tools in engineering design tasks in an undergraduate course. In this experiment, the participants (n = 403) were provided with unconstrained access to a GPT 4.0-empowered chatbot and were allowed to use it for their design projects voluntarily. Overall, 59.80 % of the students reported substantial use of GenAI in their design projects, and 40.20 % showed limited or no use. Those adopters used GenAI to aid idea generation and brainstorming, mediate discussions with instructors/TA, overcome non-technical expertise gaps, and optimize their design solutions. Conversely, non-adopters attributed their reluctance and rejection to inherent limitations in GenAI outputs, misalignment between GenAI functionalities and project needs, a lack of adaptation and prompt skills, and unclear benefits of GenAI use for personal growth. This study challenges the popular assumption of naturally active GenAI adoption among university students. It identifies three major factors—task characteristics, decision-maker characteristics, and context characteristics—that shape students' adoption of and interaction with GenAI. The findings highlight the need of establishing a consensus across various stakeholders (i.e., students, instructors, curriculum developers, policymakers, and others), while calling for adaptation and evidence-based decision-making in integrating GenAI tools into engineering education.}
}
@article{TRIANTAFYLLOPOULOS2025101802,
title = {Vishing: Detecting social engineering in spoken communication — A first survey & urgent roadmap to address an emerging societal challenge},
journal = {Computer Speech & Language},
volume = {94},
pages = {101802},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2025.101802},
url = {https://www.sciencedirect.com/science/article/pii/S0885230825000270},
author = {Andreas Triantafyllopoulos and Anika A. Spiesberger and Iosif Tsangko and Xin Jing and Verena Distler and Felix Dietz and Florian Alt and Björn W. Schuller},
keywords = {Vishing, Social engineering, Human–computer interaction, Computational paralinguistics},
abstract = {Vishing – the use of voice calls for phishing – is a form of Social Engineering (SE) attacks. The latter have become a pervasive challenge in modern societies, with over 300,000 yearly victims in the US alone. An increasing number of those attacks is conducted via voice communication, be it through machine-generated ‘robocalls’ or human actors. The goals of ‘social engineers’ can be manifold, from outright fraud to more subtle forms of persuasion. Accordingly, social engineers adopt multi-faceted strategies for voice-based attacks, utilising a variety of ‘tricks’ to exert influence and achieve their goals. Importantly, while organisations have set in place a series of guardrails against other types of SE attacks, voice calls still remain ‘open ground’ for potential bad actors. In the present contribution, we provide an overview of the existing speech technology subfields that need to coalesce into a protective net against one of the major challenges to societies worldwide. Given the dearth of speech science and technology works targeting this issue, we have opted for a narrative review that bridges the gap between the existing psychological literature on the topic and research that has been pursued in parallel by the speech community on some of the constituent constructs. Our review reveals that very little literature exists on addressing this very important topic from a speech technology perspective, an omission further exacerbated by the lack of available data. Thus, our main goal is to highlight this gap and sketch out a roadmap to mitigate it, beginning with the psychological underpinnings of vishing, which primarily include deception and persuasion strategies, continuing with the speech-based approaches that can be used to detect those, as well as the generation and detection of AI-based vishing attempts, and close with a discussion of ethical and legal considerations.}
}
@article{KWOK20243254,
title = {Utilizing large language models in infectious disease transmission modelling for public health preparedness},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {3254-3257},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024002654},
author = {Kin On Kwok and Tom Huynh and Wan In Wei and Samuel Y.S. Wong and Steven Riley and Arthur Tang},
keywords = {Large language model, Generative artificial intelligence, Infectious diseases, Mathematical transmission modelling, Simulation and modelling},
abstract = {Introduction
OpenAI's ChatGPT, a Large Language Model (LLM), is a powerful tool across domains, designed for text and code generation, fostering collaboration, especially in public health. Investigating the role of this advanced LLM chatbot in assisting public health practitioners in shaping disease transmission models to inform infection control strategies, marks a new era in infectious disease epidemiology research. This study used a case study to illustrate how ChatGPT collaborates with a public health practitioner in co-designing a mathematical transmission model.
Methods
Using natural conversation, the practitioner initiated a dialogue involving an iterative process of code generation, refinement, and debugging with ChatGPT to develop a model to fit 10 days of prevalence data to estimate two key epidemiological parameters: i) basic reproductive number (Ro) and ii) final epidemic size. Verification and validation processes are conducted to ensure the accuracy and functionality of the final model.
Results
ChatGPT developed a validated transmission model which replicated the epidemic curve and gave estimates of Ro of 4.19 (95 % CI: 4.13- 4.26) and a final epidemic size of 98.3 % of the population within 60 days. It highlighted the advantages of using maximum likelihood estimation with Poisson distribution over least squares method.
Conclusion
Integration of LLM in medical research accelerates model development, reducing technical barriers for health practitioners, democratizing access to advanced modeling and potentially enhancing pandemic preparedness globally, particularly in resource-constrained populations.}
}
@article{LI2025150926,
title = {Artificial Intelligence and Machine Learning in Transfusion Practice: An Analytical Assessment},
journal = {Transfusion Medicine Reviews},
volume = {39},
number = {4},
pages = {150926},
year = {2025},
note = {Horizons in Transfusion Medicine: Perspectives after the first quarter of the 21st century},
issn = {0887-7963},
doi = {https://doi.org/10.1016/j.tmrv.2025.150926},
url = {https://www.sciencedirect.com/science/article/pii/S0887796325000513},
author = {Na Li and Ruchika Goel and Sheharyar Raza and Kiarash Riazi and Jie Pan and Huong Quynh Nguyen and Andrew W. Shih and Adam D’Souza and Rounak Dubey and Aaron A.R. Tobian and Donald M. Arnold},
keywords = {Transfusion medicine, Artificial intelligence, Clinical decision support, Supervised learning, Unsupervised learning, Reinforcement learning, Generative artificial intelligence},
abstract = {Transfusion medicine is vital to healthcare and affects clinical outcomes, patient safety, and system resilience while addressing challenges such as blood shortages, donor variability, and rising costs. The integration of artificial intelligence (AI) and machine learning (ML) presents new opportunities to improve clinical decision-making and operational effectiveness in this field. This structured narrative review identified and evaluated studies applying AI and ML in transfusion medicine. A search of PubMed and Scopus for articles published between January 2018 and April 2025 yielded 565 publications. Studies were included if they applied AI or ML techniques, focused on transfusion management or decision support, and were evaluated using electronic health records or expert review. Four exemplar studies were selected, each representing a distinct AI paradigm: supervised, unsupervised, reinforcement, and generative learning. These studies were critically appraised for methodological rigor, clinical relevance, and potential for implementation in practice. The reviewed studies reflected a clear shift from traditional analytic methods toward more advanced computational approaches to improve prediction accuracy, optimize resource allocation, and support clinical decision-making. Three overarching themes emerged: the need to balance model complexity with interpretability and clinical feasibility; the impact of data quality and preprocessing on model performance and fairness; and the barriers to broader applicability and cross-institutional deployment. As technological barriers continue to decline, future challenges will increasingly center on privacy regulations, infrastructure constraints, and aligning model complexity with practical utility. Thoughtful integration of these considerations through scalable, clinical-grade, and transparent solutions will be critical in realizing the full potential of AI and ML in transfusion medicine.}
}
@incollection{NAYYAR2025161,
title = {Chapter 7 - Tools and platforms for prompt engineering},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {161-210},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000082},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {FlowGPT, GIMP, GPT-Neo, Jasper AI, Prompt engineering, PromptBase},
abstract = {Prompt engineering has surfaced as a crucial strategy in how we interact with language models while using generative artificial intelligence (AI) over the last years. This chapter aims to introduce the range of tools and platforms fielded for prompt engineering, offering an exhaustive survey of resources that can be leveraged in order to shape more sophisticated prompts on various applications. Starting with prompt engineering tools, we are going to analyze the software/platforms that have been built specifically for trying out prompt generation across many different types of AI models. The tools provide certain features, such as prompt refinement, integration with AT models, and evaluation of results, that can help a wide variety of users, from novices to experts, in designing prompts. The chapter also touches on online resources to create powerful prompts, providing details about sites where you can learn about creating prompts, download prompt examples, and interactively fine-tune input from the user to obtain the desired output from AI systems. Then we are presented with a big picture of online resources for image generation, which are web interfaces made to convert textual prompts into sample images through advanced generative models. The Online Resources for Video Generation section is most exciting in considering tools designed around prompts to make and edit video content — a far more dynamic world full of possibilities. This chapter also offers a comprehensive resource for those interested in working with generative AI to be able to tap into such power across domains.}
}
@article{NGUYEN2024100899,
title = {Detecting and assessing AI-generated and human-produced texts: The case of second language writing teachers},
journal = {Assessing Writing},
volume = {62},
pages = {100899},
year = {2024},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2024.100899},
url = {https://www.sciencedirect.com/science/article/pii/S1075293524000928},
author = {Loc Nguyen and Jessie S. Barrot},
keywords = {ChatGPT, Computer-assisted language learning, Generative artificial intelligence, Second language writing, Writing assessment},
abstract = {Artificial intelligence (AI) technologies have recently attracted the attention of second language (L2) writing scholars and practitioners. While they recognize the tool’s viability, they also raised the potential adverse effects of these tools on accurately reflecting students’ actual level of writing performance. It is, therefore, crucial for teachers to discern AI-generated essays from human-produced work for more accurate assessment. However, limited information is available about how they assess and distinguish between essays produced by AI and human authors. Thus, this study analyzed the scores and comments teachers gave and looked into their strategies for identifying the source of the essays. Findings showed that essays by a native English-speaking (NS) lecturer and ChatGPT were rated highly. Meanwhile, essays by an NS college student, non-native English-speaking (NNS) college student, and NNS lecturer scored lower, which made them distinguishable from an AI-generated text. The study also revealed that teachers could not consistently identify the AI-generated text, particularly those written by an NS professional. These findings were attributed to teachers’ past engagement with AI writing tools, familiarity with common L2 learner errors, and exposure to native and non-native English writing. From these results, implications for L2 writing instruction and future research are discussed.}
}
@article{KOMPLEUKKUNEN2024103382,
title = {How ChatGPT shapes the future labour market situation of software engineers: A Finnish Delphi study},
journal = {Futures},
volume = {160},
pages = {103382},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103382},
url = {https://www.sciencedirect.com/science/article/pii/S001632872400065X},
author = {Kathrin Komp-Leukkunen},
keywords = {Artificial Intelligence, Large Language Models, Software architects, Scenarios, Possible futures, Probable futures},
abstract = {ChatGPT is changing our working lives, conjuring visions of revolutionary shifts ahead. ChatGPT is a chatbot based on generative artificial intelligence, which can, e.g., write computer code. This article explores how it might shape the future labour market situation of software engineers. A Delphi study with 14 experts was conducted in Finland. The first round identified possible futures, and the second round assessed their probabilities. Five scenarios prevailed: the unlikely scenario that the status quo persists; the ambivalent scenario that ChatGPT can replace software engineers to a large extent; the likely scenario that computer departments in startups embrace ChatGPT; the likely scenario that ChatGPT use proliferates among software engineers to increase productivity; and the highly likely scenario that ChatGPT makes computer programming accessible to the masses. Findings contradict previous discussions that technological advancements might take over especially routine tasks. ChatGPT can also take over non-routine tasks. Moreover, findings underline that digitalisation does not only bring about a choice between upskilling and employability loss, but also a democratisation of knowledge and expertise. Software engineers and companies might use the findings as an impetus for upskilling, while universities might feel nudged to incorporate ChatGPT more strongly into their curricula.}
}
@article{ZHAO2025100497,
title = {Large-scale pretrained frame generative model enables real-time low-dose DSA imaging: An AI system development and multi-center validation study},
journal = {Med},
volume = {6},
number = {1},
pages = {100497},
year = {2025},
issn = {2666-6340},
doi = {https://doi.org/10.1016/j.medj.2024.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S2666634024003076},
author = {Huangxuan Zhao and Ziyang Xu and Lei Chen and Linxia Wu and Ziwei Cui and Jinqiang Ma and Tao Sun and Yu Lei and Nan Wang and Hongyao Hu and Yiqing Tan and Wei Lu and Wenzhong Yang and Kaibing Liao and Gaojun Teng and Xiaoyun Liang and Yi Li and Congcong Feng and Tong Nie and Xiaoyu Han and Dongqiao Xiang and Charles B.L.M. Majoie and Wim H. {van Zwam} and Aad {van der Lugt} and P. Matthijs {van der Sluijs} and Theo {van Walsum} and Yun Feng and Guoli Liu and Yan Huang and Wenyu Liu and Xuefeng Kan and Ruisheng Su and Weihua Zhang and Xinggang Wang and Chuansheng Zheng},
keywords = {generative artificial intelligence, GenAI, GenDSA, large-scale pretrained model, deep learning, multi-center clinical study},
abstract = {Summary
Background
Digital subtraction angiography (DSA) devices are commonly used in numerous interventional procedures across various parts of the body, necessitating multiple scans per procedure, which results in significant radiation exposure for both doctors and patients. Inspired by generative artificial intelligence techniques, this study proposes GenDSA, a large-scale pretrained multi-frame generative model-based real-time and low-dose DSA imaging system.
Methods
GenDSA was developed to generate 1-, 2-, and 3-frame sequences following each real frame. A large-scale dataset comprising ∼3 million DSA images from 27,117 patients across 10 hospitals was constructed to pretrain, fine-tune, and validate GenDSA. Two other datasets from 25 hospitals were used for evaluation. Objective evaluations included SSIM and PSNR. Five interventional radiologists independently assessed the quality of the generated frames using the Likert scale and visual Turing test. Scoring consistency among the radiologists was measured using the Kendall coefficient of concordance (W). The Fleiss’ kappa values were used for inter-rater agreement analysis for visual Turing tests.
Findings
Using only one-third of the clinical radiation dose, videos generated by GenDSA were perfectly consistent with real videos. Objective evaluations demonstrated that GenDSA’s performance (PSNR = 36.83, SSIM = 0.911, generation time = 0.07 s/frame) surpassed state-of-the-art algorithms. Subjective ratings and statistical results from five doctors indicated no significant difference between real and generated videos. Furthermore, the generated videos were comparable to real videos in overall quality (4.905 vs. 4.935) and lesion assessment (4.825 vs. 4.860).
Conclusions
With clear clinical and translational values, the developed GenDSA can significantly reduce radiation damage to both doctors and patients during DSA-guided procedures.
Funding
This study was supported by the National Key R&D Program and the National Natural Science Foundation of China.}
}
@article{LIAO2025120662,
title = {Intelligent zoning design of concrete-faced rockfill dams using image-parameter fusion enhanced generative adversarial networks},
journal = {Engineering Structures},
volume = {339},
pages = {120662},
year = {2025},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2025.120662},
url = {https://www.sciencedirect.com/science/article/pii/S0141029625010533},
author = {Wenjie Liao and Zongliang Zhang and Biao Liu and Xinzheng Lu and Difu Liu and Qiang Liu and Zhijie Duan and Chao Liu},
keywords = {Intelligent zoning design of rockfill dams, Image-parameter feature fusion, Generative adversarial network, Parametric-generated data augmentation, Image pixel vectorization},
abstract = {The design of concrete-face rockfill dams (CFRDs) is gradually evolving from digitization to intelligent design, primarily driven by advanced technologies such as generative artificial intelligence (AI). Generative AI offers powerful capabilities for extracting and mining data features and generating new design solutions efficiently through inference. These strengths provide critical technical support for intelligent CFRD design, facilitating the full utilization of design data, and significantly improving design efficiency and quality. However, CFRD design is a highly specialized and complex task, and conventional generative AI techniques often fail to produce professional-grade designs. In response to this challenge, this study explored generative intelligent design methods specifically for the critical task of CFRD profile design. An intelligent design method based on feature-fusion generative adversarial networks (GANs) for CFRD profile solutions is proposed. This approach enables the dense representation and augmentation of design data, GAN model training, and automated evaluation, thereby addressing the key challenge of fusing small-sample multimodal image-parameter data. The effectiveness of the intelligent design method for CFRD profiles was validated through algorithm analysis and case studies. The design efficiency was nearly 10 times higher than that of traditional engineer-driven designs, reducing the time required from 1–2 h to approximately 6 min. The proposed intelligent design approach has great potential and provides valuable insights for the further development of intelligent design of rockfill dams.}
}
@incollection{GAUR2026211,
title = {Chapter 12 - Lawfulness and generative AI},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {211-226},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00011-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000114},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Data privacy, Ethical principles, Generative AI, Healthcare law, Medical regulations, Patient rights, Transparency},
abstract = {This chapter explores the legal landscape surrounding generative artificial intelligence (AI) in healthcare, emphasizing the need for a comprehensive legal and ethical framework to govern its use. Generative AI, which encompasses technologies that can create content, analyze data, and support clinical decision-making, has numerous applications in healthcare, including diagnostics, treatment planning, and patient management. However, the integration of AI technologies raises significant legal and ethical considerations that must be navigated to ensure patient rights and safety. The chapter begins by defining generative AI and examining its applications within the medical field. It discusses existing medical regulations that govern practice, including licensing, malpractice laws, and clinical guidelines, while exploring how the adoption of AI is reshaping these frameworks. Through case studies, it highlights the legal challenges and compliance issues encountered in AI-driven medical practice, focusing on liability and regulatory adherence. Patient rights and data privacy are crucial themes, with a review of the legal frameworks protecting patient autonomy and confidentiality. Key data privacy laws, such as General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA), are discussed in relation to generative AI, along with best practices for compliance. Transparency and fairness in AI systems are emphasized, detailing the legal and ethical imperatives for clear decision-making processes and the avoidance of biases in AI applications. The chapter outlines key ethical principles governing the use of AI in healthcare, such as autonomy, beneficence, and justice, and the importance of integrating these principles into AI development. The chapter concludes with case studies demonstrating successful legal and ethical practices in AI healthcare solutions and discusses future directions for evolving legal standards and ethical frameworks. Recommendations for building a robust legal and ethical framework are provided, ensuring that generative AI contributes positively to healthcare while addressing the challenges it presents.}
}
@article{CHEN2026103765,
title = {MALM-CLIP: A generative multi-agent framework for multimodal fusion in few-shot industrial anomaly detection},
journal = {Information Fusion},
volume = {127},
pages = {103765},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103765},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008279},
author = {Hanzhi Chen and Jingbin Que and Kexin Zhu and Zhide Chen and Fei Zhu and Wencheng Yang and Xu Yang and Xuechao Yang},
keywords = {CLIP, Few-shot learning, Industrial anomaly detection, Multi-agent systems, GenAI},
abstract = {The Contrastive Language-Image Pre-training (CLIP) model has significantly improved few-shot industrial anomaly detection. However, existing approaches often rely on manually crafted visual description texts, which lack robustness and generalizability in real-world production settings. This limitation is evident as these methods struggle to adapt to new or evolving anomalies, where original prompts fail to generalize beyond their initial design. This paper proposes a novel method, Multi-agent Language Models with CLIP (MALM-CLIP), which integrates the generative capabilities of large language models (LLMs) with CLIP within a multi-agent framework. In this system, specialized agents handle different subtasks such as prompt generation and model evaluation, enabling automated and context-aware multimodal information fusion. By eliminating manual prompt engineering, MALM-CLIP enhances both the accuracy and efficiency of anomaly detection. Experimental results on standard datasets such as MVTec and VisA demonstrate that our approach outperforms existing methods in detecting image-level anomalies with minimal training data. This work highlights the potential of combining Generative Artificial Intelligence (GenAI) and multi-agent systems for robust few-shot industrial anomaly detection.}
}
@article{SANDRINI2023111317,
title = {Generative AI and deceptive news consumption},
journal = {Economics Letters},
volume = {232},
pages = {111317},
year = {2023},
issn = {0165-1765},
doi = {https://doi.org/10.1016/j.econlet.2023.111317},
url = {https://www.sciencedirect.com/science/article/pii/S0165176523003427},
author = {Luca Sandrini and Robert Somogyi},
keywords = {Generative AI, News media market, Online advertising, Clickbait, Fake news},
abstract = {In this paper, we analyze the effects of advancements in generative Artificial Intelligence (GenAI) on the news media market. We model a representative consumer who allocates their time between reading news and deceptive articles. We find that GenAI may induce consumers to inefficiently reallocate their time and increase the consumption of the lower value good, i.e. deceptive content (clickbait articles or fake news). Therefore, early-stage GenAI distorts the incentives of consumers and reduces their welfare. After GenAI technology reaches a certain threshold, however, consumers start benefiting from its advancements. Finally, we find that the negative effects of early-stage GenAI are exacerbated as they induce a lower level of investment in news production.}
}
@article{BUNDUCHI2025124095,
title = {A legitimacy-based explanation for user acceptance of controversial technologies: The case of Generative AI},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124095},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124095},
url = {https://www.sciencedirect.com/science/article/pii/S004016252500126X},
author = {Raluca Bunduchi and Dan-Andrei Sitar-Tăut and Daniel Mican},
keywords = {Technology acceptance, Legitimacy, Technology uncertainty, Technology variation},
abstract = {Controversial technologies are technologies where social concerns play a disproportionate role in shaping the public attitudes to their adoption. An example of such controversial technologies is Generative Artificial Intelligence (GenAI), whose rapid diffusion is fuelled by expectations for significant performance improvements, while also facing concerns at individual (trust in technology), technology (accuracy and quality), and institutional (cultural, ethical and regulatory) level. Individual and technology factors are well accounted for by rational choice-based models which underpin most technology acceptance research. Such models are less suited to explore the role of institutional factors in shaping technology acceptance. Drawing from legitimacy and technology lifecycle research, we develop a legitimacy-based model of GenAI adoption which accounts for the institutional context in which technology use happens, and for technology characteristics, namely its maturity, in shaping users' acceptance. Surveying 483 information systems students who are GenAI users, we find that users' perceptions of technology uncertainty and variation positively affect their technology legitimacy evaluations and that their pragmatic and cognitive legitimacy evaluations, but not moral, affect their intention to use. We answer recent calls to examine alternative theoretical predictors of technology acceptance, and to consider the role of context in examining the acceptance of controversial technologies.}
}
@article{WANG2025112481,
title = {A graph-enabled parametric modeling approach for façade layout generative design},
journal = {Journal of Building Engineering},
volume = {105},
pages = {112481},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112481},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225007181},
author = {Bolun Wang and Weisheng Lu and Yi Zhang},
keywords = {Graph, Generative design, Multi-objective optimization, Façade layout, Residential buildings},
abstract = {Façade layout is a crucial design element that has significantly benefited from the advancements in generative artificial intelligence. However, current generative methods such as procedural modeling and parametric modeling exhibit two primary limitations. Firstly, they rely on drawings or images instead of more flexible and structured data inputs. Secondly, they often neglect the spatial sequence of the façade in the optimization process. This paper introduces a graph-enabled parametric modeling approach (GEPMA) for façade layout generation. The approach utilizes graphs to represent structural data inputs and incorporates spatial sequence-aware optimization for the output. The process begins by decoding a hierarchical attributed graph (HAG) to extract essential façade information and define key modeling parameters. Facades are then generated and simulated based on two predefined objectives: energy use intensity (EUI) and spatial daylight autonomy (sDA). Subsequently, the façade variants are optimized under four different spatial sequences using a non-dominated sorting genetic algorithm II (NSGA-II). GEPMA was evaluated through a case study of a residential building in China. The optimal solutions improved sDA by an average of 7.71 % (up to 12.02 %) and reduced EUI by an average of 0.40 % (up to 0.62 %) compared to the baseline façade. This study contributes to the field of generative design by presenting a flexible and editable methodology and providing practical insights for façade design.}
}
@article{CHERREZOJEDA2025101071,
title = {How accurate are ChatGPT-4 responses in chronic urticaria? A critical analysis with information quality metrics},
journal = {World Allergy Organization Journal},
volume = {18},
number = {7},
pages = {101071},
year = {2025},
issn = {1939-4551},
doi = {https://doi.org/10.1016/j.waojou.2025.101071},
url = {https://www.sciencedirect.com/science/article/pii/S1939455125000481},
author = {Ivan Cherrez-Ojeda and Marco Faytong-Haro and Patricio Alvarez-Muñoz and José Ignacio Larco and Erika {de Arruda Chaves} and Isabel Rojo and Carol Vivian Moncayo and German D. Ramon and Gabriela Rodas-Valero and Emek Kocatürk and Giselle S. Mosnaim and Karla Robles-Velasco},
keywords = {Artificial intelligence, Generative artificial intelligence, Chronic urticaria},
abstract = {Background
The increasing use of artificial intelligence (AI) in healthcare, especially in delivering medical information, prompts concerns over the reliability and accuracy of AI-generated responses. This study evaluates the quality, reliability, and readability of ChatGPT-4 responses for chronic urticaria (CU) care, considering the potential implications of inaccurate medical information.
Objective
The goal of the study was to assess the quality, reliability, and readability of ChatGPT-4 responses to inquiries on CU management in accordance with international guidelines, utilizing validated metrics to evaluate the effectiveness of ChatGPT-4 as a resource for medical information acquisition.
Methods
Twenty-four questions were derived from the EAACI/GA2LEN/EuroGuiDerm/APAAACI recommendations and utilized as prompts for ChatGPT-4 to obtain responses in individual chats for each question. The inquiries were categorized into 3 groups: A.) Classification and Diagnosis, B.) Assessment and Monitoring, and C.) Treatment and Management Recommendations. The responses were separately evaluated by allergy specialists utilizing the DISCERN instrument for quality assessment, Journal of the American Medical Association (JAMA) benchmark criteria for reliability evaluation, and Flesch scores for readability analysis. The scores were further examined by median calculations and Intraclass Correlation Coefficient assessments.
Results
Categories A and C exhibited insufficient reliability according to JAMA, with median scores of 1 and 0, respectively. Category B exhibited a low reliability score (median 2, interquartile range 2). The information quality from category C questions was satisfactory (median 51.5, IQR 12.5). All 3 groups exhibited confusing readability levels according to the Flesch assessment.
Limitations
The study's limitations encompass the emphasis on CU, possible bias in question selection, the use of particular instruments such as DISCERN, JAMA, and Flesch, as well as reliance on expert opinion for assessment.
Conclusion
ChatGPT-4 demonstrates potential for producing medical content; nonetheless, its reliability is shaky underscoring the necessity for caution and confirmation when employing AI-generated medical information, especially in the management of CU.}
}
@article{VAUGHN2024101487,
title = {Enhancing Healthcare Education: Leveraging ChatGPT for Innovative Simulation Scenarios},
journal = {Clinical Simulation in Nursing},
volume = {87},
pages = {101487},
year = {2024},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2023.101487},
url = {https://www.sciencedirect.com/science/article/pii/S1876139923001019},
author = {Jacqueline Vaughn and Shannon H. Ford and Melissa Scott and Carolyn Jones and Allison Lewinski},
keywords = {generative artificial intelligence, ChatGPT, simulation, Scenario Design},
abstract = {Background
Developing simulation scenarios for implementation in nursing programs is labor intensive and time consuming. The purpose of this study was to determine if ChatGPT could create accurate and realistic simulation scenarios efficiently to assist faculty in healthcare education.
Methods
ChatGPT was used to create five healthcare simulations. The scenarios were sent to 18 peer reviewers who evaluated them using a 25-question Likert scale survey, which also included opportunities to provide qualitative feedback.
Results
Data analysis revealed that scenarios varied in terms of realism regarding patient profile, history, present illness and the way the scenario unfolded. Also noted was that pertinent information was missing in all scenarios however, the information generated was accurate. Most of the reviewer comments were positive and many were surprised at the amount of overall information included in each scenario.
Conclusions
ChatGPT is a powerful AI tool that has the potential to help simulation educators develop simulation scenarios. However, at present, caution needs to be employed, considering its current limitations.}
}
@article{SACHER2024,
title = {Impact of a Health Coach–Led, Text-Based Digital Behavior Change Intervention on Weight Loss and Psychological Well-Being in Patients Receiving a Procedureless Intragastric Balloon Program: Prospective Single-Arm Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/54723},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24004207},
author = {Paul M Sacher and Emily Fulton and Victoria Rogers and Julia Wilson and Marco Gramatica and Jennifer E Dent and Edo O Aarts and David Eccleston and Jan Willem Greve and Inge Palm-Meinders and Ram Chuttani},
keywords = {intragastric balloon, obesity, behavior change, health coaching, digital health, weight management, well-being, mobile phone},
abstract = {Background
Digital health interventions show promise for weight management. However, few text-based behavior change interventions have been designed to support patients receiving intragastric balloons, and none have simultaneously evaluated weight loss, psychological well-being, and behavior change despite the crucial interplay of these factors in weight management.
Objective
This study aims to assess whether a health coach–led, asynchronous, text-based digital behavior change coaching intervention (DBCCI) delivered to participants receiving an intragastric balloon and its aftercare program was feasible and acceptable to participants and supported improved outcomes, including weight loss, psychological well-being, and lifestyle behavior change conducive to weight loss maintenance.
Methods
This 12-month, single-arm prospective study enrolled adults aged 21 to 65 years with BMI ≥27 kg/m2 receiving a procedureless intragastric balloon (PIGB) at 5 bariatric clinics in the United Kingdom and the Netherlands. Participants received the DBCCI and the clinic-led PIGB aftercare program (remotely delivered) for 6 months after PIGB placement and then no intervention for an additional 6 months. The DBCCI was an evidence-based, personalized intervention wherein health coaches supported participants via exchanged asynchronous in-app text-based messages. Over the 12-month study, we assessed percentage of total body weight loss and psychological well-being via self-administered validated questionnaires (Warwick-Edinburgh Mental Wellbeing Scale, Generalized Anxiety Disorder Scale, Impact of Weight on Quality of Life–Lite–Clinical Trials Version, Loss of Control Over Eating Scale–Brief, Weight Efficacy Lifestyle Questionnaire–Short Form, and Barriers to Being Active Quiz). Participant engagement with and acceptability of the intervention were assessed via self-reported surveys.
Results
Overall, 107 participants (n=96, 89.7% female; mean baseline BMI 35.4, SD 5.4 kg/m2) were included in the analysis. Mean total body weight loss was 13.5% (SEM 2.3%) at the end of the DBCCI and 11.22% (SEM 2.3%) at the 12-month follow-up (P<.001). Improvements were observed for all psychological well-being measures throughout the 12 months except for the Generalized Anxiety Disorder Scale (improvement at month 1) and Barriers to Being Active Quiz (improvements at months 3 and 6). Surveys showed high levels of engagement with and acceptability of the DBCCI.
Conclusions
This study provides evidence that the health coach–led, asynchronous, text-based DBCCI was engaging and acceptable to participants with overweight and obesity. The DBCCI, delivered alongside the PIGB and its aftercare program, supported improved weight loss outcomes and psychological well-being versus baseline and was associated with lifestyle behavior changes known to help achieve and maintain long-term weight loss and improved health outcomes. Follow-up findings suggest a potential need for longer-term, more intense coaching to focus on weight loss maintenance and support ongoing self-coaching. This could be achieved by leveraging generative artificial intelligence to provide ongoing automated behavior change coaching support to augment human-led care.
Trial Registration
ClinicalTrials.gov NCT05884606; https://clinicaltrials.gov/study/NCT05884606}
}
@article{DAS2025100213,
title = {Generative AI for drug discovery and protein design: the next frontier in AI-driven molecular science},
journal = {Medicine in Drug Discovery},
volume = {27},
pages = {100213},
year = {2025},
issn = {2590-0986},
doi = {https://doi.org/10.1016/j.medidd.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2590098625000107},
author = {Uddalak Das},
keywords = {Generative AI, Molecular design, Protein engineering, Diffusion models, Drug discovery},
abstract = {Generative artificial intelligence (AI) has emerged as a disruptive paradigm in molecular science, enabling algorithmic navigation and construction of chemical and proteomic spaces through data-driven modeling. This review systematically delineates the theoretical underpinnings, algorithmic architectures, and translational applications of deep generative models—including variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive transformers, and score-based denoising diffusion probabilistic models (DDPMs)—in the rational design of bioactive small molecules and functional proteins. We examine the role of latent space learning, probabilistic manifold exploration, and reinforcement learning in inverse molecular design, focusing on optimization of pharmacologically relevant objectives such as ADMET profiles, synthetic accessibility, and target affinity. Furthermore, we survey advancements in graph-based molecular generative frameworks, LLM-guided protein sequence modeling, and diffusion-based structural prediction pipelines (e.g., RFdiffusion, FrameDiff), which have demonstrated state-of-the-art performance in de novo protein engineering and conformational sampling. Generative AI is also catalyzing a paradigm shift in structure-based drug discovery via AI-augmented molecular docking (e.g., DiffDock), end-to-end binding affinity prediction, and quantum chemistry-informed neural potentials. We explore the convergence of generative models with Bayesian retrosynthesis planners, self-supervised pretraining on ultra-large chemical corpora, and multimodal integration of omics-derived features for precision therapeutics. Finally, we discuss translational milestones wherein AI-designed ligands and proteins have progressed to preclinical and clinical validation, and speculate on the synthesis of generative AI, closed-loop automation, and quantum computing in future autonomous molecular design ecosystems.}
}
@article{SAQIB20241430,
title = {Evaluation of AI content generation tools for verification of academic integrity in higher education},
journal = {Journal of Applied Research in Higher Education},
volume = {17},
number = {4},
pages = {1430-1440},
year = {2024},
issn = {2050-7003},
doi = {https://doi.org/10.1108/JARHE-10-2023-0470},
url = {https://www.sciencedirect.com/science/article/pii/S205070032400007X},
author = {Muhammad Bilal Saqib and Saba Zia},
keywords = {Chatbot, Generative AI, ChatGPT, LLM, AI content detectors, AI writing},
abstract = {Purpose
The notion of using a generative artificial intelligence (AI) engine for text composition has gained excessive popularity among students, educators and researchers, following the introduction of ChatGPT. However, this has added another dimension to the daunting task of verifying originality in academic writing. Consequently, the market for detecting artificially generated content has seen a mushroom growth of tools that claim to be more than 90% accurate in sensing artificially written content.
Design/methodology/approach
This research evaluates the capabilities of some highly mentioned AI detection tools to separate reality from their hyperbolic claims. For this purpose, eight AI engines have been tested on four different types of data, which cover the different ways of using ChatGPT. These types are Original, Paraphrased by AI, 100% AI generated and 100% AI generated with Contextual Information. The AI index recorded by these tools against the datasets was evaluated as an indicator of their performance.
Findings
The resulting figures of cumulative mean validate that these tools excel at identifying human generated content (1.71% AI content) and perform reasonably well in labelling AI generated content (76.85% AI content). However, they are perplexed by the scenarios where the content is either paraphrased by the AI (39.42% AI content) or generated by giving a precise context for the output (60.1% AI content).
Originality/value
This paper evaluates different services for the detection of AI-generated content to verify academic integrity in research work and higher education and provides new insights into their performance.}
}
@article{MASROURI2024102230,
title = {Generative AI model trained by molecular dynamics for rapid mechanical design of architected graphene},
journal = {Extreme Mechanics Letters},
volume = {72},
pages = {102230},
year = {2024},
issn = {2352-4316},
doi = {https://doi.org/10.1016/j.eml.2024.102230},
url = {https://www.sciencedirect.com/science/article/pii/S235243162400110X},
author = {Milad Masrouri and Kamalendu Paul and Zhao Qin},
keywords = {Architected graphene, Molecular dynamics, Stable Diffusion, Low Rank Adaptation, Von Mises stress field},
abstract = {Generative artificial intelligence (AI) is shown to be a useful tool to automatically learn from existing information and generate new information based on their connections, but its usage for quantitative mechanical research is less understood. Here, we focus on the structure-mechanics relationship of architected graphene as graphene with void defects of specific patterns. We use Molecular Dynamics (MD) to simulate uniaxial tension on architected graphene, extract the von Mises stress field in mechanical loading, and use the results to train a fine-tuned generative AI model through a Low-Rank Adaptation method. This model enables the freely designed architected graphene structures and predicts its associated stress field in uniaxial tension loading through simple descriptive language. We demonstrate that the fine-tuned model can be established with a few training images and can quantitatively predict the stress field for graphene with various defect geometries and distributions not included in the training set. We validate the accuracy of the stress field with MD simulations. Moreover, we illustrate that our generative AI model can predict the stress field from a schematic drawing of the architected graphene through image-to-image generation. These features underscore the promising future for employing advanced generative AI models in end-to-end advanced nanomaterial design and characterization, enabling the creation of functional, structural materials without using complex numerical modeling and data processing.}
}
@article{HAWASHIN2025100754,
title = {Using GenAI and blockchain for enhanced user experience in Metaverse-based therapy sessions},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100754},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100754},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001691},
author = {Diana Hawashin and Khaled Salah and Raja Jayaraman and Samer Ellaham and Ibrar Yaqoob},
keywords = {Therapy sessions, Metaverse, GenAI, LLM, Blockchain, Virtual healthcare},
abstract = {As awareness of mental health issues rises, the demand for accessible and effective therapy becomes more urgent. However, existing digital therapy platforms fall short of providing personalization and real-time interaction, often leading to generic and ineffective responses that fail to meet individual psychological needs. These platforms rely on costly therapists or inadequately trained assistants, which limits their effectiveness. Additionally, the centralized systems used to manage therapy sessions lack adequate traceability, trust, and security, which are critical for users’ confidence in the process. In this paper, we present a blockchain-based solution integrated with Generative Artificial Intelligence (GenAI) to deliver superior Metaverse-based therapy sessions that are decentralized, traceable, trustworthy, secure, and access-controlled. We fine-tune a Generative Pre-trained Transformer (GPT)-3.5 model to provide personalized and context-aware responses in real time, enhancing user experience and engagement. The proposed system achieves a ROUGE-1 score of 0.5147 and a ROUGE-L score of 0.4048, demonstrating its effectiveness in generating relevant responses. A cost analysis reveals that user access control operations incur the highest gas costs, while simpler operations remain cost-efficient. Compared to existing digital mental health platforms, our system offers superior access control, automation, security, and user interaction through the integration of blockchain, NFTs, and decentralized storage. These features, combined with GenAI for real-time interaction, have the potential to significantly improve user experience and engagement in Metaverse-based therapy sessions}
}
@article{ARSLAN2025106793,
title = {Empowering SMEs with SustainWater Bot to advance urban water sustainability},
journal = {Sustainable Cities and Society},
volume = {132},
pages = {106793},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106793},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725006675},
author = {Muhammad Arslan and Saba Munawar and Zainab Riaz},
keywords = {Urban water decision-making, Sustainable transitions, Small and medium-sized enterprises (SMEs), Large language models (LLMs), Retrieval-augmented generation (RAG)},
abstract = {Climate change, population growth, and resource constraints are intensifying pressure on urban water systems (UWSs), prompting a shift toward integrated information management. Due to their agility and reach, small- and medium-sized enterprises (SMEs) are central to this transition. However, many SMEs lack access to robust information systems (ISs) that consolidate government initiatives, industry trends, and broader water-related data, impeding sustainable adoption. This study introduces SustainWater Bot, a chatbot driven by generative artificial Intelligence (GenAI), including large language models (LLMs) and retrieval-augmented generation (RAG). Designed to fill this information gap, SustainWater Bot addresses the shortcomings of conventional LLMs, such as information misalignment, over-complexity, and information deficiencies. RAG enables semantic consolidation of various sources, such as news, government reports, industry insights, academic research, and social media, into an integrated IS. The evaluation results showed that RAG with LLM-based methods outperformed traditional information retrieval (IR) techniques, with Llama3.2:3b achieving top scores in precision (95 %), completeness (95 %), and exact match (90 %). Traditional IR techniques such as term frequency-inverse document frequency (TF-IDF) and best matching 25 (BM25) performed lower but offered quicker responses. SustainWater Bot supports informed decision-making through a question-answering (QA) framework that delivers relevant insights on sustainable urban water initiatives (SUWIs). It is built on open-source technologies and offers SMEs a cost-effective, scalable, and sustainable solution to enhance eco-friendly water practices and operational efficiency.}
}
@article{KUMAR2025102993,
title = {Advances in DeepFake detection algorithms: Exploring fusion techniques in single and multi-modal approach},
journal = {Information Fusion},
volume = {118},
pages = {102993},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102993},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000661},
author = {Ashish Kumar and Divya Singh and Rachna Jain and Deepak Kumar Jain and Chenquan Gan and Xudong Zhao},
keywords = {DeepFake, Artificial intelligence, Generative adversarial network, Fusion algorithms, Transformer, Detection},
abstract = {In recent years, generative artificial intelligence has gained momentum and created extremely realistic synthetic multimedia content that can spread misinformation and mislead society. Deepfake detection is a technique consisting of frameworks, algorithms and approaches to predict manipulated contents namely, image, audio and video. To this end, we have analyzed and explored various deepfake detection frameworks by categorizing them as single-modal or multi-modal approaches. To provide better understanding and clarity, single-modal approaches are further categorized as conventional and advanced techniques. Conventional techniques extract complementary handcrafted features and classify them using machine-learning-based algorithms. On the other hand, advanced techniques adopt deep learning and hybrid algorithms to detect deepfakes. Multi-modal techniques utilize a mixture of two or more modalities for feature extraction and fuse them to obtain the final classification scores. These techniques are also categorized either as deep learning or hybrid techniques. The complementary features, multiple modalities, and deep learning models are fused adaptively using score-level or feature-level fusion. The advantages, features, practical applications, and limitations under each category are highlighted to address the challenges and determine future trends to counter deepfakes. In addition, recommendations are also elaborated to evaluate the potential of artificial intelligence in deepfake detection for providing a safer and more reliable digital world.}
}
@article{RUIZ2025104293,
title = {Artificial intelligence-created personal statements compared with applicant-written personal statements: a survey of obstetric anesthesia fellowship program directors in the United States},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104293},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003054},
author = {A.M. Ruiz and M.B. Kraus and K.W. Arendt and D.R. Schroeder and E.E. Sharpe},
keywords = {Artificial intelligence, Generative AI, Medical education, Obstetric anesthesia, Personal statements, Fellowship},
abstract = {Background
A personal statement is a common requirement in medical residency and fellowship applications. Generative artificial intelligence may be used to create a personal statement for these applications.
Methods
Two personal statements were created using OpenAI’s Chat Generative Pre-trained Transformer (ChatGPT) and two applicant-written statements were collected. A survey was sent to obstetric anesthesia fellowship program directors in the United States to assess the perceived readability, authenticity, and originality of the four personal statements. In addition, the survey assessed perceptions of applicants who use artificial intelligence to write a personal statement, including their integrity, work ethic, reliability, intelligence, and English proficiency.
Results
Surveyed fellowship directors could not accurately discern whether statements were applicant-written or artificial intelligence-generated. The artificial intelligence-generated personal statements were rated as more readable and original than the applicant-written statements. Most program directors were moderately or extremely concerned about the applicant’s integrity, work ethic, and reliability if they suspected the applicant utilized ChatGPT.
Conclusions
Program directors could not accurately discern if the statements were written by a person or artificial intelligence and would have concerns about an applicant suspected of using artificial intelligence. Medical training programs may benefit from outlining their expectations regarding applicants’ use of artificial intelligence.}
}
@article{BELANCHE2025102954,
title = {Customer reactions to generative AI vs. real images in high-involvement and hedonic services},
journal = {International Journal of Information Management},
volume = {85},
pages = {102954},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102954},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000866},
author = {Daniel Belanche and Sergio Ibáñez-Sánchez and Pau Jordán and Sergio Matas},
keywords = {Generative artificial intelligence, AI-generated images, Hedonic services, Utilitarian services, Consumer involvement level, ChatGPT, Midjourney},
abstract = {Given the emerging opportunities of generative AI for business and marketing, many companies are wondering whether they should use images created through generative AI for commercial purposes. Prior research on hospitality communication has not solved this issue, as AI-generated images are occasionally promoted as effective marketing tools across various service contexts, while other scholars caution against their use due to the significant concerns they may trigger among consumers. Following a mixed-methods approach to find boundary conditions, our research reveals that consumers prefer hospitality services advertised with real images, rather than those featuring AI-generated images. Nevertheless, this effect is moderated by two key factors. In particular, the research reveals that the negative influence of using generative AI images on intentions to use and recommend the service are strengthened for hedonic rather than utilitarian services, and for highly rather than lowly involved customers. A qualitative study further explores the reasons behind this rejection, highlighting that customers perceive companies using AI-generated images as impersonal, less professional, lacking credibility, and potentially misleading, as they impede customers’ ability to envision the actual experience. Implications for management suggest that, while generative AI holds promise for enhancing communication, companies should use AI-generated images with caution. The discussion also proposes future research directions to explore the broader implications of AI use in marketing.}
}
@article{CHIU2024100197,
title = {Future research recommendations for transforming higher education with generative AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100197},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100197},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000760},
author = {Thomas K.F. Chiu},
keywords = {Generative artificial intelligence, ChatGPT, Learning outcomes, AI literacy, Assessment},
abstract = {Higher education is crucial for producing ethical citizens and professionals globally. The introduction of generative AI (GenAI), such as ChatGPT, has posed opportunities and challenges to the traditional model of education. However, the current conversations primarily focus on policy development and assessment, with limited research on the future of higher education. GenAI's impact on learning outcomes, pedagogy, and assessment is crucial for reforming and advancing the workforce. This qualitative study aims to investigate student perspectives on GenAI's impact on higher education. The study uses an initial conceptual framework driven by a systematic literature review to investigate the opportunities and challenges of AI in education. This framework serves as an initial data collection and analysis framework. A sample of 51 students from three research-intensive universities was selected for this study. Thematic analysis identified three themes and 10 subthemes. The findings suggest that future higher education should be transformed to train students to be future-ready for employment in a society powered by GenAI. They suggest new learning outcomes—skills in learning and teaching with GenAI, AI literacy—and emphasize the significance of interdisciplinarity and maker learning, with assessment focusing on in-class and hands-on activities. They recommend six future research directions – competence for future workforce and its self-assessment measures, AI literacy or competency measures, new literacies and their relationships, interdisciplinary teaching, Innovative pedagogies and their evaluation, new assessment and its acceptance.}
}
@article{RAY2024174,
title = {Large language models in laparoscopic surgery: A transformative opportunity},
journal = {Laparoscopic, Endoscopic and Robotic Surgery},
volume = {7},
number = {4},
pages = {174-180},
year = {2024},
issn = {2468-9009},
doi = {https://doi.org/10.1016/j.lers.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468900924000483},
author = {Partha Pratim Ray},
keywords = {Large language model, Artificial intelligence, Generative artificial intelligence, Laparoscopy, Surgery},
abstract = {This opinion paper explores the transformative potential of large language models (LLMs) in laparoscopic surgery and argues for their integration to enhance surgical education, decision support, reporting, and patient care. LLMs can revolutionize surgical education by providing personalized learning experiences and accelerating skill acquisition. Intelligent decision support systems powered by LLMs can assist surgeons in making complex decisions, optimizing surgical workflows, and improving patient outcomes. Moreover, LLMs can automate surgical reporting and generate personalized patient education materials, streamlining documentation and improving patient engagement. However, challenges such as data scarcity, surgical semantic capture, real-time inference, and integration with existing systems need to be addressed for successful LLM integration. The future of laparoscopic surgery lies in the seamless integration of LLMs, enabling autonomous robotic surgery, predictive surgical planning, intraoperative decision support, virtual surgical assistants, and continuous learning. By harnessing the power of LLMs, laparoscopic surgery can be transformed, empowering surgeons and ultimately benefiting patients.}
}
@article{ZHOU2025110090,
title = {Forward and inverse adversarial model applying to well-logging},
journal = {Engineering Applications of Artificial Intelligence},
volume = {144},
pages = {110090},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110090},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625000909},
author = {Jun Zhou and Juan Zhang and Rongbo Shao and Lizhi Xiao and Guangzhi Liao},
keywords = {Generative artificial intelligence, Well logging, Forward model, Inverse model, Machine learning},
abstract = {Geophysical logging is critical for reservoir characterization but is limited by the small sample problem in machine learning. To address this, we propose the Forward and Inverse Adversarial Model (FIAM), which borrows the training method from generative adversarial networks and applies to geophysical logging. The FIAM includes a forward model for generating synthetic logging data and an inverse model for predicting reservoir parameters. These models are trained using an adversarial process, enabling continuous improvement without large labeled datasets. In the case study with exploration logging data, the FIAM enhances reservoir parameter prediction effect and maps the relationship between logging curves and reservoir parameters by pure data-driven training. The inverse model is pre-trained by measured data and then guides the forward model to generate logging data based on virtual reservoir parameters. Both models are trained alternately until no further improvement is achieved. Experimental results on oilfield datasets show that the FIAM improves reservoir parameter predictions by more than 30% when facing the small sample problem. The FIAM demonstrates significant potential for improving reservoir parameters prediction with small sample dataset, advancing both artificial intelligence methodologies and practical engineering applications.}
}
@article{CAI2025103373,
title = {Differentially private synthetic data generation for robust information fusion},
journal = {Information Fusion},
volume = {124},
pages = {103373},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103373},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004464},
author = {Xiaohong Cai and Yi Sun and Zhaowen Lin and Ripeng Li and Tianwei Cai},
keywords = {Generative artificial intelligence, Fusion, Differential privacy, Fine-tuning},
abstract = {Synthetic data is crucial in information fusion in term of enhancing data representation and improving system robustness. Among all synthesis methods, deep generative models exhibit excellent performance. However, recent studies have shown that the generation process faces privacy challenges due to the memorization of training instances by generative models. To maximize the benefits of synthesis data while ensuring data security, we propose a novel framework for the generation and utilization of private synthetic data in information fusion processes. Furthermore, we present differential private adaptive fine-tuning (DP-AdaFit), a method for private parameter efficient fine-tuning that applies differential privacy only to the singular values of the incremental updates. In details, DP-AdaFit adaptively adjusts the rank of the low-rank weight increment matrices according to their importance score, and allows us to achieve an equivalent privacy policy by only injecting noise into gradient of the corresponding singular values. Such a novel approach essentially reduces their parameter budget but avoids too much noise introduced by the singular value decomposition. We decrease the cost on memory and computation nearly half of the SOTA, and achieve the FID of 19.2 on CIFAR10. Our results demonstrate that trading off weights contained in the differential privacy fine-tuning parameters can improve model performance, even achieving generation quality competitive with differential privacy full fine-tuning diffusion model. Our code is available at DP-AdaFit.}
}
@article{CELIKTEN20243351,
title = {HybridGAD: Identification of AI-Generated Radiology Abstracts Based on a Novel Hybrid Model with Attention Mechanism},
journal = {Computers, Materials and Continua},
volume = {80},
number = {2},
pages = {3351-3377},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.051574},
url = {https://www.sciencedirect.com/science/article/pii/S154622182400537X},
author = {Tuğba Çelikten and Aytuğ Onan},
keywords = {Generative artificial intelligence, AI-generated text detection, attention mechanism, hybrid model for text classification},
abstract = {The purpose of this study is to develop a reliable method for distinguishing between AI-generated, paraphrased, and human-written texts, which is crucial for maintaining the integrity of research and ensuring accurate information flow in critical fields such as healthcare. To achieve this, we propose HybridGAD, a novel hybrid model that combines Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM), and Bidirectional Gated Recurrent Unit (Bi-GRU) architectures with an attention mechanism. Our methodology involves training this hybrid model on a dataset of radiology abstracts, encompassing texts generated by AI, paraphrased by AI, and written by humans. The major findings of our analysis indicate that HybridGAD achieves a high accuracy of 98%, significantly outperforming existing state-of-the-art models. This high performance is attributed to the model’s ability to effectively capture the contextual nuances and structural differences between AI-generated and human-written texts. In conclusion, HybridGAD not only enhances the accuracy of text classification in the field of radiology but also paves the way for more advanced medical diagnostic processes by ensuring the authenticity of textual information. Future research will focus on integrating textual and visual data for comprehensive radiology assessments and improving model generalization with partially labeled data. This study underscores the potential of HybridGAD in transforming medical text classification and highlights its applicability in ensuring the integrity and reliability of research in healthcare and beyond.}
}
@article{RACHANAHARISH2025103366,
title = {Collaborative garment design through group chatting with generative industrial large models},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103366},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103366},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625002599},
author = {Arjun {Rachana Harish} and Zhaolin Yuan and Ming Li and Hongxia Yang and George Q. Huang},
keywords = {Collaborative Garment Design, Industrial Large Model, Generative Artificial Intelligence, Group Chat, Transformer},
abstract = {The collaborative garment designing lifecycle involves stages such as designing, styling, and patterning. Some of these stages can be partially or fully automated using industrial large models (LMs), such as generative and large language models. The key to quick and cost-effective order fulfillment is the orchestration of group interactions, or a group chat, between the stakeholders and LMs in garment design. However, certain unaddressed aspects, such as knowledge retention, generalization, and complexity of group interaction, are critical to realizing group chat for garment design. This study proposes a framework called ChatFashion for group chat in garment design. Transformer, a core construct of the proposed framework, orchestrates interaction among stakeholders and industrial LMs. It undergoes an evolution with the intelligence it picks up from its interaction with diverse stakeholders and industrial LMs, allowing it to act as a one-stop solution for multidisciplinary design needs. This study contributes to theory in the following aspects. First, it proposes transformers to eliminate concerns about knowledge retention by industrial LMs. Second, while other studies focus on the benefits of industrial LMs to simplify individual stages in garment design, this study introduces the design and demonstration of a ChatFashion framework for collaborative garment designing using industrial LMs. Finally, this study advances the literature on prompt engineering of industrial LMs by utilizing collaborative learning (or models learning from each other) to capture and orchestrate the group chat among stakeholders, signifying its practicality and value for research in garment design.}
}
@article{DENHOLM2025100842,
title = {Virtual Histological Staining as a Tool for Extending Renal Segmentation Across Stains},
journal = {Modern Pathology},
volume = {38},
number = {12},
pages = {100842},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2025.100842},
url = {https://www.sciencedirect.com/science/article/pii/S0893395225001395},
author = {James Denholm and Azam Hamidinekoo and Nikolay Burlutskiy and Laura C. Setyo and Irina Zhang and Fariba Yousefi and Jack Mortimer and Joana Palés Huix and Christopher Bagnall and Arthur Lewis and Heather E. Hulme and Robert Unwin and Simon T. Barry and Richard J.A. Goodwin and Ferdia A. Gallagher and Magnus Söderberg and Talha Qaiser},
keywords = {chronic kidney disease, computational pathology, generative artificial intelligence, National Unified Renal Translational Research Enterprise, renal pathology, virtual staining},
abstract = {In renal histopathology, the routine clinical use of several histological stains presents challenges for the direct application of stain-specific deep learning–based analysis tools to whole-slide images. We present an approach to the in silico histological staining of kidney tissue where samples stained with hematoxylin and eosin (H&E) are virtually restained with periodic acid-Schiff (PAS). Our approach is underpinned by cycle-consistent generative adversarial neural networks trained on the National Unified Renal Translational Research Enterprise data set—the first UK-wide Biobank for chronic kidney disease—which features diverse data from 16 nephrology centers. Our work is divided into the following 4 main components: (1) we developed a virtual staining model, which infers PAS staining from H&E; (2) 2 board-certified pathologists assessed the virtual staining by attempting to distinguish it from real examples; (3) we trained a glomerular segmentation model using 3 independent renal segmentation data sets (Kidney Precision Medicine Project, Human BioMolecular Atlas Program [Kidney], and data by Jayapandian et al); and (4) we demonstrated the utility of virtual staining by inferring PAS staining from previously unseen H&E test images and applying our PAS-specific glomerular segmentation model. Each pathologist was able to identify 52.5% and 75.8% of the virtually stained images, respectively, showing an overlap in the variability of the authentic and synthetic staining. We discussed the utility of virtual staining in digital pathology, the need for pathology-specific testing with respect to chronic damage, and minimal changes and steps for incorporating more stains. Furthermore, alongside this article, we included complete glomerular annotations for 20 Kidney Precision Medicine Project H&E-stained slides.}
}
@article{STEVENS2025100831,
title = {A Comparison of Artificial Intelligence Platforms in the Utility of Answering Frequently Asked Questions About Carpal Tunnel Syndrome: A Cross-Sectional Study},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100831},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100831},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001513},
author = {Calista Stevens and Mehreen Pasha and Dashun Liu and Andrew Block and Anthony Parrino and Craig Rodner},
keywords = {Carpal tunnel syndrome, Generative artificial intelligence, Hand, Orthopedic surgery},
abstract = {Purpose
The rise of artificial intelligence (AI) in health care comes with increasing concerns about the use and integrity of the information it generates. Chat Generative Pre-Trained Transformer (ChatGPT) 3.5, Google Gemini, and Bing Copilot are free AI chatbot platforms that may be used for answering medical questions and disseminating medical information. Given that carpal tunnel syndrome accounts for 90% of all neuropathies, it is important to understand the accuracy of the information patients may be receiving. The purpose of this study is to determine the use and accuracy of responses generated by ChatGPT, Google Gemini, and Bing Copilot in answering frequently asked questions about carpal tunnel syndrome.
Methods
Two independent authors scored responses using the DISCERN tool. DISCERN consists of 15 questions assessing health information on a five-point scale, with total scores ranging from 15 to 75 points. Then, a two-factor analysis of variance was conducted, with scorer and chatbot type as the factors.
Results
One-way analysis of variance revealed no significant difference in DISCERN scores among the three chatbots. The chatbots each scored in the “fair” range, with means of 45 for ChatGPT, 48 for Bing Copilot, and 46 for Google Gemini. The average Journal of the American Medical Association score for ChatGPT and Google Gemini surpassed that of Bing Copilot, with averages of 2.3, 2.3, and 1.8, respectively.
Conclusions
ChatGPT, Google Gemini, and Bing Copilot platforms generated relatively reliable answers for potential patient questions about carpal tunnel syndrome. However, users should continue to be aware of the shortcomings of the information provided, given the lack of citations, potential for misconstrued information, and perpetuated biases that inherently come with using such platforms. Future studies should explore the response quality for less common orthopedic pathologies and assess patient perceptions of response readability to determine the value of AI as a patient resource across the medical field.
Type of study/level of evidence
Cross-sectional study V}
}
@article{HU2025100979,
title = {Enhancing student engagement in online collaborative writing through a generative AI-based conversational agent},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100979},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2024.100979},
url = {https://www.sciencedirect.com/science/article/pii/S1096751624000411},
author = {Wanqing Hu and Jirong Tian and Yanyan Li},
keywords = {Student engagement, Online collaborative writing, Conversational agents, Generative artificial intelligence, Retrieval-augmented generation},
abstract = {Promoting student engagement in online collaborative writing (OCW) activities has been a critical concern for educators. Previous research has attempted to design conversational agents (CAs) utilizing retrieval-based models to engage students in collaborative learning. However, few studies have yet explored the design of CAs for OCW based on generative AI (GAI) models. Researchers are calling for investigations into how GAI technology can be better utilized to support learning. Addressing this gap, this study integrates advanced AI technologies (i.e. the retrieval-based model, GAI model, and retrieval-augmented generation) to develop a CA aimed at enhancing students' engagement in OCW activities. Furthermore, a quasi-experiment involving 78 undergraduate students was conducted to explore the effects of this CA on students' engagement (including behavioral, cognitive, and emotional engagement) and group writing performance. The results indicate that the CA did not significantly impact behavioral engagement, emotional engagement, or group writing performance. However, it was found to significantly enhance students' cognitive engagement, particularly by supporting students in sharing opinions, explaining concepts, and engaging in analysis. This research offers both theoretical and practical implications for better utilizing GAI technology to facilitate OCW activities.}
}
@article{ZENG2025120578,
title = {Data-driven structural generative design based on diffusion model for flexible support of optical mirror},
journal = {Engineering Structures},
volume = {338},
pages = {120578},
year = {2025},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2025.120578},
url = {https://www.sciencedirect.com/science/article/pii/S0141029625009691},
author = {Chaoqun Zeng and Jiaying Wang and Wei Wang and Kuo Hai and Shaoxing Ma and Lei Wei},
keywords = {Airborne optical system, Flexible support, Data-driven generative design, Diffusion model, Performance-guided sketch generation},
abstract = {Generative artificial intelligence has enabled new structural design methods, allowing for rapid generation of complex designs. High-end equipment in aerospace, electronics, information, and other fields operates under demanding conditions with stringent performance requirements, making the initial design phase challenging. An example is the design of mirror flexible supports, a critical component in the optical systems of unmanned aerial vehicles that determines their optical precision. Empirical design processes are increasingly inadequate for meeting high-performance and rapid designing for flexible supports under varying conditions. This study proposes a generative structural design approach based on diffusion model to establish the relationship between structural performance and existing sketches. A dataset of flexible support structures is prepared using a maze path-planning algorithm. The method can automatically generate initial feasible design solutions rapidly. A case study involving a 400 millimeter (mm) aperture reflector shows that the designed support achieves a surface shape accuracy of approximately 15 nanometer (nm) at room temperature and under 40 nm at −20 degrees Celsius (℃). Compared to conventional methods, the proposed approach significantly improves design quality and significantly shortens the design cycle. This work contributes to the application of diffusion models in structural designs.}
}
@article{SUN2025103037,
title = {Multi-objective math problem generation using large language model through an adaptive multi-level retrieval augmentation framework},
journal = {Information Fusion},
volume = {119},
pages = {103037},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103037},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525001101},
author = {Jianwen Sun and Wangzi Shi and Xiaoxuan Shen and Shengyingjie Liu and Luona Wei and Qian Wan},
keywords = {Math problem generation, Large language model, Retrieval-augmented generation, Educational application, Generative artificial intelligence},
abstract = {Math problems are an important knowledge carrier and evaluation means in personalized teaching. Their high cost of manual compilation promotes the research of math problem generation. Many previous studies have focused on the generation of math word problems, which are difficult to meet the real teaching needs due to the single task-objective orientation and small differences in generation results. By fusing external knowledge through retrieval-augmented generation (RAG), large language model (LLM) can generate a variety of math problems, but the generated results still have limitations such as poor knowledge consistency, uncontrollability, and high computational cost. In this paper, we propose the task of multi-objective math problem generation (MMPG). This task introduces the triple objectives of generation including “question type, knowledge point and difficulty” in respond to teaching needs in real scene. To the best of our knowledge, this is the first study considering multiple objectives on the process of math problem generation. Based on this, we further design an adaptive multi-level retrieval augmentation framework (AMRAF) for LLM to generate multi-objective math problems. This plug-and-play framework can effectively improve the generation performance without parameter tuning of the target model due to the fine-grained information retrieval and fusion. To verify the effectiveness of the proposed framework and provide a benchmark for subsequent research, we construct an MMPG dataset containing 9,000 samples. Experimental results demonstrate the superiority and effectiveness of our framework.}
}
@incollection{NAYYAR2025241,
title = {Chapter 9 - Prompt engineering: Ethical considerations and challenges},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {241-264},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00002-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000021},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {Biasing, Cyber-attacks, Generative AI, Intellectual property},
abstract = {Generative artificial intelligence (AI) stands at the forefront of technological innovation, yet it remains an evolving domain where prompt engineering plays a pivotal role in shaping the quality and accuracy of model outputs. This chapter serves as both an introduction and an explainer, emphasizing the critical need to address ethical considerations surrounding AI performance, especially as these technologies permeate diverse sectors. The chapter delves into pressing issues of bias and fairness, highlighting how historical biases in training data can lead to discriminatory outcomes in AI applications. This necessitates vigilant monitoring to mitigate such risks effectively. Furthermore, the discussion encompasses privacy and security concerns related to data handling, underscoring the importance of user confidentiality. Central themes of transparency and accountability emerge, advocating for clear communication regarding the capabilities and limitations of AI systems. We propose the establishment of moral standards that unite AI developers and users in a shared commitment to responsible practices. When AI predictions are made, accountability must be ensured through transparent logic that is open to scrutiny, fostering ethical norms within organizations. The chapter also addresses the unique challenges faced by small and medium-sized enterprises (SMEs) in adopting generative AI, offering insights into the specific risks they may encounter. By maintaining a focus on ethical considerations, this chapter aims to provide practitioners in prompt engineering with a comprehensive understanding of the implications of their work. Ultimately, it calls for collaborative efforts to define and uphold clear ethical standards that will facilitate the responsible development and application of generative AI technologies, enabling progress that benefits all stakeholders.}
}
@article{HUETTEMANN2025102901,
title = {Designing ontology-based search systems for research articles},
journal = {International Journal of Information Management},
volume = {83},
pages = {102901},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102901},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000337},
author = {Sebastian Huettemann and Roland M. Mueller and Barbara Dinter},
keywords = {Search engines, Ontologies, Domain ontologies, Large language models, Knowledge extraction, Design science research, Literature review},
abstract = {The process of conducting scientific literature reviews is becoming increasingly complex and time-consuming due to the rapid expansion of available research. Popular academic search engines offer limited filtering capabilities and suffer from low precision. Machine learning-enhanced approaches tend to target rather specific areas, and novel approaches based on generative artificial intelligence suffer from hallucinations. Drawing on information foraging theory, this article presents a design science research project aimed at generating design knowledge for developing domain-specific search systems for research articles. Our contributions include: (1) integrating domain ontologies with large language models to design ontology-based search systems, (2) generating descriptive design knowledge by exploring the problem space, (3) generating prescriptive design knowledge for developing domain-specific search systems, and (4) presenting an ontology-based search engine prototype. Our results indicate that the proposed solution supports researchers in conducting literature reviews by increasing information gain while reducing interaction costs.}
}
@article{HERCKIS2025,
title = {AI-enabled fraud detection, prevention, and perpetration in nursing credential evaluation: A scoping study},
journal = {Journal of Nursing Regulation},
year = {2025},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000973},
author = {Lauren Herckis and Emily Tse},
keywords = {Scoping review, Fraud, Credential evaluation, Artificial intelligence},
abstract = {Background
Credential fraud among healthcare professionals is a global, significant, and ever-evolving challenge. Technological innovations, such as digital imaging and generative artificial intelligence (AI) that make it easier to fabricate documents, have changed the credential evaluation and verification landscape. A global health worker shortage compounds the critical need to maintain integrity, reliability, and rigor in credential verification of healthcare professionals.
Purpose
To identify evidence-based best practices for combatting nursing credential fraud in the context of AI.
Methods
This research effort entailed a scoping review following Arskey and O'Malley's methodological framework to identify scholarly research related to AI and nursing credential fraud. After the scoping review, an environmental scan of grey literature and professional guidance was performed. Integrated analysis of the findings was used to develop themes and recommendations to guide future work.
Results
Four articles, all published between 2020 and 2025, were subjected to full-text review. Of these four articles, none directly addressed AI in perpetrating or combatting nursing credential fraud. The environmental scan revealed practices documented by professional associations and regulatory bodies as well as emerging trends. Five areas of future research are recommended based on these findings: (1) translate existing research, (2) collaborate in cross-functional teams; (3) engage in experimental software development; (4) generate evidence-based guidance; and (5) participate in ongoing evaluation processes.
Conclusions
This study found emerging practices but no empirical research or evidence-based guidance on the use of AI in combatting or perpetuating nursing credential fraud. Literature addressing employment fraud, AI and nursing regulation, and AI in credential evaluation reveal that nursing credential fraud leveraging AI tools requires urgent attention from regulators, credential evaluators, employers, and researchers.}
}
@incollection{GAUR2026227,
title = {Chapter 13 - Empathy and generative AI: Role and ethical challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {227-242},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000011},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Emotional intelligence, Empathy, Ethical challenges, Generative AI, Human-AI interactions, Transparency, User autonomy},
abstract = {This chapter delves into the concept of empathy in the context of generative artificial intelligence (AI), examining its significance in enhancing human-AI interactions while addressing the ethical challenges that arise. Empathy, defined as the ability to understand and share the feelings of another, is crucial for creating AI systems that foster meaningful and socially intelligent interactions. By embedding empathetic responses into AI design, developers can improve user experiences and engagement, making technology more relatable and effective. The chapter discusses various strategies for incorporating empathy into AI systems, such as leveraging natural language processing, affective computing, and emotional intelligence models. Through illustrative case studies, it highlights successful applications of empathetic AI, showcasing how they enhance user satisfaction. However, designing empathetic AI is fraught with challenges, including technical limitations and the complexity of accurately understanding emotional nuances. Ethical considerations surrounding empathetic AI are a major focus. The potential for emotional manipulation poses significant risks, necessitating discussions about authenticity and transparency. The chapter explores how empathetic interactions can respect user autonomy, ensuring that AI does not undermine decision-making abilities. Through case studies, the ethical dilemmas faced by emotional AI assistants and health-related AI systems are examined, illustrating the complexities of managing empathy in practice. Developing ethical guidelines for empathetic AI is essential, and the chapter advocates for the involvement of diverse stakeholders in the design process to address ethical concerns effectively. Looking to the future, the chapter discusses innovations in empathetic AI technologies and the need to anticipate emerging ethical challenges. It concludes with recommendations for building a robust framework that supports ethical empathy in AI, aiming to create systems that are both effective and aligned with ethical principles.}
}
@article{YIN2024,
title = {Consumer Attitudes Towards GenAI Advertisements:},
journal = {Journal of Cases on Information Technology},
volume = {26},
number = {1},
year = {2024},
issn = {1548-7717},
doi = {https://doi.org/10.4018/JCIT.356502},
url = {https://www.sciencedirect.com/science/article/pii/S1548771724000836},
author = {Mengjiao Yin and Biao Ma and Xianyu Pan},
keywords = {Advertisement, Consumer Attitude, Gen AI, IKEA Effect, In-group Bias, Perceived Authenticity, Social Identity Theory},
abstract = {ABSTRACT
This research focuses on the attitudes of potential consumers towards generative artificial intelligence (GenAI) advertisements, employing a multi-experimental approach based on engagement to shed light on how e-marketers should leverage novel technological tools in the age of human-AI co-creation to enhance brand favorability. The experimental findings indicate the continued adaptiveness of concepts such as in-group bias, IKEA effect, and social identity theory in the GenAI era, demonstrating that (a) consumers' awareness of AI authorship (b) their level of participation in the co-creative process and (c) their perceived authenticity, significantly influence their attitudes. This study expands the boundaries of theories previously confined to human populations and provides pioneering practical guidance for AI co-creation in the realm of electronic commerce.}
}
@article{LIU2025103797,
title = {Critical digital literacies, agentic practices, and AI-mediated informal digital learning of English},
journal = {System},
volume = {134},
pages = {103797},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103797},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002076},
author = {Guangxiang Leon Liu and Ju Seong Lee and Xian Zhao},
keywords = {Critical digital literacies, Generative AI, Agency, AI-mediated informal digital learning of English (AI-IDLE)},
abstract = {Building upon Darvin and Norton's (2015) model of investment, this paper presents a case study of eight Chinese university EFL learners who have developed creative and productive informal language learning experiences using generative artificial intelligence (AI) tools. It aims to examine how these students invest in critical digital literacies (CDL) that empower them to navigate invisible power relations of AI platforms and enact agentic language learning practices. Data was collected through an adapted questionnaire, semi-structured interviews, digital artifacts (e.g., screenshots of interactions with AI), and reflective journals. Using NVivo 12, an inductive thematic analysis approach (Braun & Clarke, 2021) was adopted to code data and generate the primary themes. The analysis revealed that participants' investment in CDL manifested through multiple interconnected dimensions. These participants invested in CDL by first establishing dispositional stances and mobilizing capital to demystify the black box of AI tools and developing critical awareness about power relations embedded in AI platforms. Participants also negotiated varying levels of agency in their AI-mediated informal digital learning of English (AI-IDLE), ranging from basic content consumption to sophisticated co-creative partnerships. By shedding light on the components of CDL that AI-IDLE learners need to develop, this paper provides implications for language educators and policymakers to design pedagogies of critical AI literacies and promote equitable and agentic AI-supported language learning practices outside of the classroom.}
}
@article{BALKI2023,
title = {Use and Acceptance of Digital Communication Technology by Older Adults for Social Connectedness During the COVID-19 Pandemic: Mixed Methods Study},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/41535},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123005861},
author = {Eric Balki and Carol Holland and Niall Hayes},
keywords = {aging in place, technology acceptance, technology adoption, information and communication technologies, qualitative research, COVID-19 pandemic, Facebook, Meta, WhatsApp, Zoom, generative artificial intelligence, AI},
abstract = {Background
Older adults are at higher risk for health issues, including mental health problems. This was especially apparent during the COVID-19 pandemic, where older adults were simultaneously more vulnerable to the disease and the mental health concerns created by social distancing. Subsequently, the use of digital communication technology (DCT) became a critical option for maintaining social connectedness in older adults. Prior to the pandemic, the low uptake and use of technology by older adults was an established problem, known as the digital divide. However, not much is known about how this may have changed as a result of the pandemic.
Objective
This study aims to explore how older adults maintained social connectedness through DCT during the pandemic and to understand factors influencing the use and acceptance of DCT.
Methods
A mixed methods explorative field study was set up, involving surveys and interviews of 25 community-dwelling older adults (65-88 years old) living in the United Kingdom. The surveys included the internet acceptance questionnaire (based on the Technology Acceptance Model [TAM]); COVID-19 dysfunctional anxiety was captured using the COVID-19 Anxiety Scale (CAS). Background information (demographics, use of technology) was gathered before conducting semistructured interviews. We hypothesized that CAS would affect constructs of TAM and that predictive constructs of TAM would have remained valid during the pandemic. We also posited that there would be unidentified themes outside TAM that impacted the acceptance and use of DCT. We used the quantitative data to guide the semistructured interviews, which were then analyzed through thematic analysis to identify additional themes.
Results
Correlational analysis showed that CAS influences all constructs of TAM. We also saw that the predictive constructs of TAM, especially the perceived ease of use (PEU) and perceived usefulness (PU), remained valid during the pandemic. Common acceptance-influencing themes were encountered in both quantitative and qualitative analyses, with 3 matching the known constructs of TAM (PU, PEU, and behavioral intention). We identified 2 additional themes affecting acceptance, namely influence of the pandemic (situational context) and privacy and security concerns. DCT use (especially email and videoconferencing use) increased during the pandemic, but the results related to social networking sites were mixed.
Conclusions
The COVID-19 pandemic impacted technology acceptance and use by older adults, encouraging their use of certain DCT apps (email and videoconferencing apps, such as WhatsApp). These apps helped insulate them from adverse effects (social isolation and loneliness). Other social networking apps, however, exerted a negative influence, increasing anxiety and a general feeling of negativity. Future studies should maximize older adult agency related to design, privacy, security, and user requirements for development. We also recommend that when studying DCT acceptance for older adults, our additional identified themes should be considered alongside the existing TAM constructs.}
}
@article{ALLI2024,
title = {The Potential of Artificial Intelligence Tools for Reducing Uncertainty in Medicine and Directions for Medical Education},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/51446},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224001314},
author = {Sauliha Rabia Alli and Soaad Qahhār Hossain and Sunit Das and Ross Upshur},
keywords = {artificial intelligence, machine learning, uncertainty, clinical decision-making, medical education, generative AI, generative artificial intelligence},
abstract = {In the field of medicine, uncertainty is inherent. Physicians are asked to make decisions on a daily basis without complete certainty, whether it is in understanding the patient’s problem, performing the physical examination, interpreting the findings of diagnostic tests, or proposing a management plan. The reasons for this uncertainty are widespread, including the lack of knowledge about the patient, individual physician limitations, and the limited predictive power of objective diagnostic tools. This uncertainty poses significant problems in providing competent patient care. Research efforts and teaching are attempts to reduce uncertainty that have now become inherent to medicine. Despite this, uncertainty is rampant. Artificial intelligence (AI) tools, which are being rapidly developed and integrated into practice, may change the way we navigate uncertainty. In their strongest forms, AI tools may have the ability to improve data collection on diseases, patient beliefs, values, and preferences, thereby allowing more time for physician-patient communication. By using methods not previously considered, these tools hold the potential to reduce the uncertainty in medicine, such as those arising due to the lack of clinical information and provider skill and bias. Despite this possibility, there has been considerable resistance to the implementation of AI tools in medical practice. In this viewpoint article, we discuss the impact of AI on medical uncertainty and discuss practical approaches to teaching the use of AI tools in medical schools and residency training programs, including AI ethics, real-world skills, and technological aptitude.}
}
@article{KUMAR2024100005,
title = {A market management approach to transformative business operations},
journal = {Marketing Strategy Journal},
volume = {1},
pages = {100005},
year = {2024},
issn = {2950-3086},
doi = {https://doi.org/10.1016/j.msj.2025.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2950308625000055},
author = {V. Kumar and Philip Kotler},
keywords = {New-age technologies, Market management approach, Transformative business operations, Research agenda, Artificial intelligence, Generative artificial intelligence, The metaverse, Cloud computing, IoT, Robotics, Drones, And blockchain},
abstract = {How are new-age technologies transforming business operations? Why does it matter? The article suggests that a market management approach is conducive to understanding how new-age technologies can transform business operations. In this regard, the article defines market management approach as a holistic framework for managing transformative business operations that emphasizes the integration of emerging technologies with an organization’s operational processes. In this regard, the concept of transformative business operations is introduced and defined as the transformation of organizational systems, resources, and processes using new-age technologies to improve business functions that can generate superior value offerings to all stakeholders. The proposed transformative business operations approach identifies three triggers—the tension of uncertainty, adaptive capabilities, and operational elasticity—that drive the unique and synergistic impacts of these technologies. These triggers result in transformative changes through (a) foundational shifts in organizations, (b) strategy design, execution, and optimization, (c) unified ecosystem creation, and (d) pioneering business operations solutions. The actual transformation is observed in hyper-automation, augmented decision-making, and decentralized supply chains. The article also highlights barriers to adopting these technologies - cultural and workforce adjustments, data security and privacy concerns, and interoperability issues -, which moderate their potential impact, and guide organizations navigating these challenges. Finally, it outlines a market management agenda for exploring the implications of these developments.}
}
@article{MUNIR2025102370,
title = {Taking the plunge together: A student-led faculty learning seminar series on artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {8},
pages = {102370},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102370},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000917},
author = {Faria Munir and Elma Abdulbaki and Zeba Saiyad and Heather Ipema},
keywords = {Artificial intelligence, Drug information, Higher education, Pharmacy, Faculty, Pharmacy students, Learning series},
abstract = {Objective
This pilot study explored the effectiveness of a student-led faculty development series by evaluating two key outcomes: the capacity of students to deliver meaningful professional development sessions to faculty and the impact of these sessions on faculty perceptions of generative artificial intelligence (AI).
Methods
In a flipped classroom model, two pharmacy students and 12 faculty members engaged in a semester-long learning series on AI. Each week, students presented on a selected topic followed by discussions that facilitated self-directed learning, including decision-making and project management. Faculty perceptions of AI were evaluated before and after the series using an anonymous survey tool (Technology Acceptance Model Edited to Assess ChatGPT Adoption, TAME-ChatGPT). Respondents created a self-chosen code to link their responses. Additionally, students completed a questionnaire to gauge their reflective thinking after the series.
Results
Faculty participation averaged 7 members per session. Twelve faculty completed the pre-survey, while 8 faculty completed the post-survey. Among those who had used ChatGPT (n = 4 pre [33 %], n = 2 post [25 %]), scores for usefulness increased, while concerns about risks decreased. In contrast, faculty who had not used ChatGPT (n = 8 pre [67 %], n = 6 post [75 %]) reported unchanged or improved scores for ease of use and reduced anxiety. Both students responded positively to the reflective thinking questionnaire.
Conclusion
This pilot study demonstrated that a student-led faculty learning series effectively fostered mutual collaborative learning, benefiting both faculty and students. Pharmacy students, often an underutilized resource, can play a valuable role in faculty development. Colleges of pharmacy may enhance faculty engagement by integrating student-led initiatives into their programs.}
}
@incollection{CHEN202537,
title = {Chapter Two - Game changer: Navigating between challenges and hopes in geropharmacology},
editor = {Mehmet Can Atayik and Ufuk Çakatay},
series = {Advances in Pharmacology},
publisher = {Academic Press},
volume = {104},
pages = {37-85},
year = {2025},
booktitle = {Theoretical and Clinical Geropharmacology},
issn = {1054-3589},
doi = {https://doi.org/10.1016/bs.apha.2025.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1054358925000481},
author = {Qian Chen and Reid Hartman and Lidia Dankiv and Emily Yan and Lindon Young and Robert Barsotti},
keywords = {Geropharmacology, Aging, Heterogeneity, Plasticity, Aging-associated diseases, Inflammation, Cell senescence, Stem cell, Mitochondrial dysfunction, Nicotinamide adenine dinucleotide, Metformin, Rapamycin, Senolytics, Incretin mimetics, Artificial intelligence},
abstract = {The aging population is expanding rapidly to reshape the social and economic structures. Aging signifies the close to the end of life and threatens health because it features unavoidable compression of body reserve and gradual suppression of organ function. Tremendous research has established twelve essential aging hallmarks that shed light on mitigation frameworks. Interestingly, aging harbors inherent heterogeneity and plasticity, reflecting its multifaceted nature. Additionally, age-related diseases, such as cardiovascular and neurodegenerative diseases, often undergo the exact mechanisms with more devastating damage and speed. Therefore, interventions to promote healthy aging improve life quality and delay the disease’s prevalence to later age. Clinical studies in humans have demonstrated the potential of several interventions, including lifestyle modifications, NAD+ supplementation, gut microbiota modulation, antidiabetic drugs (e.g., metformin), rapamycin, and senolytics, to mitigate the aging process and delay the onset of age-related diseases. Remarkably, clinical trials exhibit heterogeneity by showing substantial inter-individual differences in response to the interventions. It is often attributed to basal health status, tissue senescent burden, and immunity level. Continuous research would validate these correlations and solidify the personalized approaches. Lastly, generative artificial intelligence can pave a promising avenue to revolutionize anti-aging research and tailor aging management to promote healthy aging and extend health span.}
}
@article{IGNACZ2023100040,
title = {Data-driven future for nanofiltration: Escaping linearity},
journal = {Journal of Membrane Science Letters},
volume = {3},
number = {1},
pages = {100040},
year = {2023},
issn = {2772-4212},
doi = {https://doi.org/10.1016/j.memlet.2023.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2772421223000041},
author = {Gergo Ignacz and Aron K. Beke and Gyorgy Szekely},
keywords = {Machine learning, Big data, Inverse design, Data science, Process analytical technologies},
abstract = {Compared with traditional membrane separation methods such as distillation and chromatography, nanofiltration (NF) affords decreased waste generation and energy consumption. Despite the multiple advantages of NF and materials available for NF membranes, the industrial applicability of this process requires improvement. To address these challenges, we propose four important pillars for the future of membrane materials and process development. These four pillars are digitalization, structure–property analysis, miniaturization, and automation. We fill gaps in the development of NF membranes and processes by fostering the most promising contemporary technologies, e.g., the integration of process analytical technologies and the development of a parallel artificial nanofiltration permeability assay (PANPA) or large online databases. Moreover, we propose the extensive use of density functional theory-aided structure–property relationship methods to understand solute transport process at a molecular level. Realizing an inverse design would allow researchers and industrial scientists to develop custom membranes for specific applications using optimized properties.}
}
@article{WORKUM2026155262,
title = {AI in critical care: A roadmap to the future},
journal = {Journal of Critical Care},
volume = {91},
pages = {155262},
year = {2026},
issn = {0883-9441},
doi = {https://doi.org/10.1016/j.jcrc.2025.155262},
url = {https://www.sciencedirect.com/science/article/pii/S0883944125002497},
author = {J.D. Workum and G. Meyfroidt and J. Bakker and C. Jung and J.M. Tobin and D. Gommers and P.W.G. Elbers and J.G. {van der Hoeven} and M.E. {Van Genderen}},
keywords = {Large language models, Generative artificial intelligence, AI readiness, Implementation},
abstract = {Artificial intelligence (AI) has the potential to revolutionize critical care medicine by enhancing patient care, improving resource allocation and reducing clinician workload. Despite this promise, many AI applications remain confined to scientific research rather than being integrated into everyday clinical practice. This manuscript aims to help intensivists prepare themselves and their intensive care units (ICUs) for AI implementation. It provides a comprehensive yet practical roadmap, detailing AI methods, applications, responsible AI principles, common roadblocks and implementation strategies. We propose a three-tiered risk-based approach to AI implementation, starting with low-risk low-complexity administrative AI, progressing to logistical AI, and finally integrating medical AI as clinical decision support systems. This ensures a gradual build-up of AI skills, technical AI readiness of the ICU, incremental value demonstration and alignment with evolving regulatory standards. For each AI project, responsible AI principles should be incorporated and adequately addressed throughout the entire AI lifecycle, from development to validation to implementation and scaling. Common roadblocks for AI implementation including technical issues (such as data quality and interoperability issues), organizational challenges (such as lack of a clear vision and strategy), and clinical concerns (such as limited AI literacy among staff), should be addressed proactively. By following this roadmap, ICUs can achieve sustainable AI integration, ultimately improving patient outcomes and clinician experience. The future of critical care lies in the responsible and strategic adoption of AI, with intensivists playing a central role in shaping its implementation.}
}
@article{ODU2025112353,
title = {Automatic instantiation of assurance cases from patterns using large language models},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112353},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112353},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000214},
author = {Oluwafemi Odu and Alvine B. Belle and Song Wang and Segla Kpodjedo and Timothy C. Lethbridge and Hadi Hemmati},
keywords = {Requirement engineering, Assurance cases, Assurance case patterns, Pattern formalization, Generative artificial intelligence, Large language models, GPT},
abstract = {An assurance case is a structured set of arguments supported by evidence, demonstrating that a system’s non-functional requirements (e.g., safety, security, reliability) have been correctly implemented. Assurance case patterns serve as templates derived from previous successful assurance cases, aimed at facilitating the creation of new assurance cases. Despite using these patterns to generate assurance cases, their instantiation remains a largely manual and error-prone process that heavily relies on domain expertise. Thus, exploring techniques to support their automatic instantiation becomes crucial. This study aims to investigate the potential of Large Language Models (LLMs) in automating the generation of assurance cases that comply with specific patterns. Specifically, we formalize assurance case patterns using predicate-based rules and then utilize LLMs, i.e., GPT-4o and GPT-4 Turbo, to automatically instantiate assurance cases from these formalized patterns. Our findings suggest that LLMs can generate assurance cases that comply with the given patterns. However, this study also highlights that LLMs may struggle with understanding some nuances related to pattern-specific relationships. While LLMs exhibit potential in the automatic generation of assurance cases, their capabilities still fall short compared to human experts. Therefore, a semi-automatic approach to instantiating assurance cases may be more practical at this time.}
}
@article{FLECKENSTEIN2024100209,
title = {Do teachers spot AI? Evaluating the detectability of AI-generated texts among student essays},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100209},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100209},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000109},
author = {Johanna Fleckenstein and Jennifer Meyer and Thorben Jansen and Stefan D. Keller and Olaf Köller and Jens Möller},
keywords = {Generative AI, Writing assessment, Teachers, Essay writing, ChatGPT},
abstract = {The potential application of generative artificial intelligence (AI) in schools and universities poses great challenges, especially for the assessment of students’ texts. Previous research has shown that people generally have difficulty distinguishing AI-generated from human-written texts; however, the ability of teachers to identify an AI-generated text among student essays has not yet been investigated. Here we show in two experimental studies that novice (N = 89) and experienced teachers (N = 200) could not identify texts generated by ChatGPT among student-written texts. However, there are some indications that more experienced teachers made more differentiated and more accurate judgments. Furthermore, both groups were overconfident in their judgments. Effects of real and assumed source on quality assessment were heterogeneous. Our findings demonstrate that with relatively little prompting, current AI can generate texts that are not detectable for teachers, which poses a challenge to schools and universities in grading student essays. Our study provides empirical evidence for the current debate regarding exam strategies in schools and universities in light of the latest technological developments.}
}
@article{LIAO2024105187,
title = {Generative AI design for building structures},
journal = {Automation in Construction},
volume = {157},
pages = {105187},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105187},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523004478},
author = {Wenjie Liao and Xinzheng Lu and Yifan Fei and Yi Gu and Yuli Huang},
keywords = {Building structural design, Data feature representation, Generative AI algorithm, Design evaluation, Intelligent optimization},
abstract = {Designing building structures presents various challenges, including inefficient design processes, limited data reuse, and the underutilization of previous design experience. Generative artificial intelligence (AI) has emerged as a powerful tool for learning and creatively using existing data to generate new design ideas. Learning from past experiences, this technique can analyze complex structural drawings, combine requirement texts, integrate mechanical and empirical knowledge, and create fresh designs. In this paper, a comprehensive review of recent research and applications of generative AI in building structural design is provided. The focus is on how data is represented, how intelligent generation algorithms are constructed, methods for evaluating designs, and the integration of generation and optimization. This review reveals the significant progress generative AI has made in building structural design, while also highlighting the key challenges and prospects. The goal is to provide a reference that can help guide the transition towards more intelligent design processes.}
}
@article{CHOWDHURY2025112827,
title = {R-VQA: A robust visual question answering model},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112827},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112827},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124014618},
author = {Souvik Chowdhury and Badal Soni},
keywords = {Visual question answering, Large language model, In-context learning, Computer vision, Natural language processing, Generative artificial intelligence},
abstract = {Visual Question Answering (VQA) involves generating answers to questions about visual content, such as images. VQA models process an image and a question to produce an answer. One major challenge in this domain is robustness, as current VQA models often operate within a fixed answer space and struggle with issues related to language prior (favoring frequent answers) and compositional reasoning (difficulty with complex object relationships). While existing research addresses these challenges separately, no work has tackled both language prior and compositional reasoning simultaneously. This paper presents three key contributions: the development of a dataset specifically designed to address language prior and compositional reasoning issues, the creation of a unified model capable of addressing both problems in a single inference, and the ability to generate answers beyond a predefined answer space. Our proposed model, R-VQA, demonstrates superior performance compared to state-of-the-art (SOTA) models across various VQA datasets.}
}
@article{AGARWAL2025100214,
title = {Beyond boundaries: Charting the frontier of healthcare with big data and ai advancements in pharmacovigilance},
journal = {Health Sciences Review},
volume = {14},
pages = {100214},
year = {2025},
issn = {2772-6320},
doi = {https://doi.org/10.1016/j.hsr.2025.100214},
url = {https://www.sciencedirect.com/science/article/pii/S2772632025000066},
author = {Arohi Agarwal and Gagan Singh and Samyak Jain and Piyush Mittal},
keywords = {Big data, Big data analytics, Genomics, Structured data, Unstructured data, Semi-structured data, Descriptive analytics, Exploratory or discovery analytics, Predictive analytics, Pharmacovigilance (Pv), Artificial intelligence (AI), Generative adversarial networks, Variational autoencoders, Transformer-based models},
abstract = {The healthcare sector is intricate, generating vast amounts of data from various sources at an accelerated pace. The contemporary trend of Big Data Analytics is pivotal, impacting not only the pharmaceutical industry but also transforming healthcare, contributing to personalized treatment, aiding in preventive healthcare, managing electronic health records, facilitating adverse drug reporting, and incorporating consumer reviews. This article provides an overview of the inevitable influence of big data and the utilization of artificial intelligence in revolutionizing both healthcare and the pharmaceutical sector. It delves into the notable benefits and challenges encountered in advancing data analytics of the early 21st century.In many countries, Post-marketing surveillance of drug safety relinquishes on a systematic analysis of spontaneous using Generative artificial intelligence (AI) to overcome gaps in the present PV ecosystem is critical to maintaining an uninterrupted record of security and effectiveness within healthcare analytics, data mining techniques, predictive analytics, and the emergence of scientific fields like bioinformatics and health informatics are empowered by Big Data. Nevertheless, the integration of AI in healthcare, especially in pharmacovigilance, aligns with the evolving landscape of electronic health information technology. In conclusion, review highlights the transformative impact of Big Data and AI in healthcare, emphasizing their applications in pharmacovigilance and pharmacoepidemiology. The continuous evolution of these technologies holds promise for improving patient safety, personalized medicine, and overall healthcare outcomes.}
}
@article{XIAO2024114691,
title = {Exploring automated energy optimization with unstructured building data: A multi-agent based framework leveraging large language models},
journal = {Energy and Buildings},
volume = {322},
pages = {114691},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114691},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824008077},
author = {Tong Xiao and Peng Xu},
keywords = {Automated energy optimization, Unstructured data, Generative Artificial Intelligence, Energy audit, Energy efficiency diagnosis},
abstract = {The building sector is a significant energy consumer, making building energy optimization crucial for reducing energy demand. Automating energy optimization tasks eases the workload on engineers and hastens energy savings. More than 85% of building data is unstructured and diverse, concealing energy insights that demand laborious extraction. We propose an LLM-based multi-agent framework to explore automated tasks using these data. The framework includes three stages: building information processing, performance diagnosis, and retrofit recommendation, where LLMs injected with domain expertise act as agents for the roles of planner, researcher and advisor. We develop knowledge databases with retriever tools to inject knowledge and validate through experiments. In case studies, our framework delivered reliable results with only $5.15, effectively handling diverse inputs and tasks across cases. This demonstrates its potential to significantly reduce repetitive human labor and costs. We also discuss the potential of LLM-based multi-agent systems as trustworthy, generalized automated task solvers.}
}
@article{GUPTA2024103997,
title = {Exploring the generative AI adoption in service industry: A mixed-method analysis},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {103997},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103997},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924002935},
author = {Rohit Gupta and Bhawana Rathore},
keywords = {Generative AI, Service industry, Text mining, Topic modelling, FDM, Fuzzy AHP, Fuzzy DEMATEL},
abstract = {In the last few years, many service organisations have been exploring the use of Generative Artificial Intelligence (GAI) tools for their businesses and upgrading their existing processes. These tools have the potential and capability to transform the business world in various aspects. However, serval service organisations are facing many challenges while adopting the GAI tools in their organisations. In a similar context, this study explores the adoption of GAI barriers through two studies by a mixed-method approach. The first study is based on YouTube datasets of selected videos where GAI adoption challenges, problems, and barriers were discussed. Further, these YouTube datasets were analysed through text mining and empirical modelling techniques. In the second study, an extensive literature review was done and critical barriers to GAI adoption were identified based on the extensive literature review. Further, these barriers were analysed through three theoretical lenses and a hybrid fuzzy multicriteria decision-making approach. In addition, the results from the first study were further matched and verified with our second study. This establishes the relevance of adopting a mixed-method approach. Our major findings are: (i) trust, anticipation, and surprise emerged as the strongest emotions of the viewers who posted their comments on the YouTube videos; (ii) Five major barriers are revealed through topic analysis of YouTube transcripts and these are ethical, technological, regulations & policies, cost, and human resources; (iii) Six major barriers are identified through second study are privacy & security, return on investment, running cost, misuse, over-reliance, and Lack of digital infrastructure.}
}
@article{ISSA2024e38759,
title = {A teamwork framework for preventing breaches of academic integrity and improving students’ collaborative skills in the AI era},
journal = {Heliyon},
volume = {10},
number = {19},
pages = {e38759},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e38759},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024147901},
author = {Tomayess Issa and Mahnaz Hall},
keywords = {Teamwork assessment, Self/peer evaluation, Teamwork framework, AI, Academic integrity},
abstract = {Generative artificial intelligence (AI) tools have become a major challenge in the education sector in terms of the way that students use and manage them. This study examines the development, implementation, and evaluation of a teamwork framework by using academic integrity standards and formative feedback to minimise the use of generative AI tools in the Business Project Management (BPM) unit and promote students' learning skills through teamwork and self/peer evaluation. This teamwork assessment was designed to transform students into independent learners by improving their cultural awareness, self-confidence, teamwork, communication, leadership, as well as personal and interpersonal skills. The study's objectives are to determine whether a teamwork framework can help to maintain academic integrity and transform BPM students into independent learners and leaders in the era of generative AI, and to determine whether lecturers' formative feedback enhances students' skills in teamwork assessment. This research comprises an empirical study of 408 local and international BPM students from different cultural backgrounds. A mixed-methods approach was used to collect data and achieve a broader perspective of the research topic. BPM students reported their satisfaction with this type of assessment since it helped them acquire skills such as intercultural effectiveness and teamwork. Following the implementation of the teamwork framework, the number of instances of academic misconduct and requests for extensions have decreased dramatically, while the assessment's average marks increased by 10 %. A set of recommendations is offered that will ensure the successful implementation of the proposed framework for teamwork assessment and self/peer evaluation. This study was limited to the Business Project Management unit, but in 2024, the same study will be conducted involving other postgraduate units at Curtin University with a future rollout in other universities to compare how students perceive teamwork assessment.}
}
@article{FLEURENCE2025,
title = {ELEVATE-GenAI: Reporting Guidelines for the Use of Large Language Models in Health Economics and Outcomes Research: An ISPOR Working Group Report},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525024556},
author = {Rachael L. Fleurence and Dalia Dawoud and Jiang Bian and Mitchell K. Higashi and Xiaoyan Wang and Hua Xu and Jagpreet Chhatwal and Turgay Ayer},
keywords = {artificial intelligence, generative AI, large language model, reporting guidelines},
abstract = {Objectives
Generative artificial intelligence (AI), particularly large language models (LLMs), holds significant promise for health economics and outcomes research (HEOR). However, standardized reporting guidance for LLM-assisted research is lacking. This article introduces the ELEVATE-GenAI framework and checklist—reporting guidelines specifically designed for HEOR studies involving LLMs.
Methods
The framework was developed through a targeted literature review of existing reporting guidelines, AI evaluation frameworks, and expert input from the ISPOR Working Group on Generative AI. It comprises 10 domains—including model characteristics, accuracy, reproducibility, and fairness and bias. The accompanying checklist translates the framework into actionable reporting items. To illustrate its use, the framework was applied to 2 published HEOR studies: one focused on a systematic literature review tasks and the other on economic modeling.
Results
The ELEVATE-GenAI framework offers a comprehensive structure for reporting LLM-assisted HEOR research, while the checklist facilitates practical implementation. Its application to the 2 case studies demonstrates its relevance and usability across different HEOR contexts.
Conclusions
Although the framework provides robust reporting guidance, further empirical testing is needed to assess its validity, completeness, usability, and generalizability across diverse HEOR use cases. The ELEVATE-GenAI framework and checklist address a critical gap by offering structured guidance for transparent, accurate, and reproducible reporting of LLM-assisted HEOR research. Future work will focus on extensive testing and validation to support broader adoption and refinement.}
}
@article{AHLGREN2025107832,
title = {Assisting early-stage software startups with LLMs: Effective prompt engineering and system instruction design},
journal = {Information and Software Technology},
volume = {187},
pages = {107832},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107832},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001715},
author = {Thea Lovise Ahlgren and Helene Fønstelien Sunde and Kai-Kristian Kemell and Anh Nguyen-Duc},
keywords = {Generative Artificial Intelligence, GenAI, ChatGPT, StartupGPT, Software engineering, Software startup, Software development, Design Science Research},
abstract = {Context:
Early-stage software startups, despite their strong innovative potential, experience high failure rates due to factors such as inexperience, limited resources, and market uncertainty. Generative AI technologies, particularly Large Language Models (LLMs), offer promising support opportunities; however, effective strategies for their integration into startup practices remain underexplored.
Objective:
This study investigates how prompt engineering and system instruction design can enhance the utility of LLMs in addressing the specific needs and challenges faced by early-stage software startups.
Methods:
A Design Science Research (DSR) methodology was adopted, structured into three iterative cycles. In the first cycle, use cases for LLM adoption within the startup context were identified. The second cycle experimented with various prompt patterns to optimize LLM responses for the defined use cases. The third cycle developed “StartupGPT”, an LLM-based assistant tailored for startups, exploring system instruction designs. The solution was evaluated with 25 startup practitioners through a combination of qualitative feedback and quantitative metrics.
Results:
The findings show that tailored prompt patterns and system instructions significantly enhance user perceptions of LLM support in real-world startup scenarios. StartupGPT received strong evaluation scores across key dimensions: satisfaction (93.33%), effectiveness (80%), efficiency (80%), and reliability (86.67%). Nonetheless, areas for improvement were identified, particularly in context retention, personalization of suggestions, communication tone, and sourcing external references.
Conclusion:
This study empirically validates the applicability of LLMs in early-stage software startups. It offers actionable guidelines for prompt and system instruction design and contributes both theoretical insights and a practical artifact — StartupGPT — that supports startup operations without necessitating costly LLM retraining.}
}
@article{YAN2025620,
title = {Real-time detection of road surface friction coefficient: A new framework integrating diffusion model and Transformer in Transformer algorithms},
journal = {Alexandria Engineering Journal},
volume = {113},
pages = {620-632},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824014170},
author = {Zhangcun Yan and Lishengsa Yue and Wang Luo and Jian Sun},
keywords = {Road engineering, Road surface friction coefficient detection, Image classification, Data augmentation, Diffusion model, Transform in transform},
abstract = {The real-time road surface friction coefficient (RSFC) is a critical parameter for evaluating skid resistance and making safe driving decisions in driver assistance systems and autonomous vehicles, especially under adverse weather conditions. RSFC estimation depends on the interaction between the road surface and tires. However, accurate estimation is challenging due to varying road environments and sensor errors that can cause significant distortions. To obtain high-accuracy RSFC, this study proposes a novel real-time RSFC detection method that integrates a diffusion model with the Transformer-in-Transformer(TNT) model to detect RSFC from vehicle video pictures. The method consists of three steps. First, we created labeled friction coefficient image datasets representing asphalt concrete surfaces under four moisture conditions. Second, we used a diffusion model to enhance the dataset, increasing sample diversity. Finally, we trained a TNT model on the extended dataset to recognize friction coefficients. The approach was tested across various datasets and compared to four state-of-the-art (SOTA) methods. The results show that the proposed method significantly improves accuracy, achieving a 22.89% increase compared to the unenhanced dataset and a 5.59% improvement over SOTA methods. The primary contribution of this study is the integration of generative artificial intelligence and computer vision algorithms to enhance RSFC recognition accuracy. Furthermore, the recognition method meets the real-time performance requirements, processing frames in just two milliseconds. This method can be an effective tool for perceiving road surface environmental parameters and holds significant value in improving driving safety under adverse weather conditions.}
}
@article{CANOORTIZ2024102745,
title = {Enhancing pavement crack segmentation via semantic diffusion synthesis model for strategic road assessment},
journal = {Results in Engineering},
volume = {23},
pages = {102745},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102745},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024010004},
author = {Saúl Cano-Ortiz and Eugenio Sainz-Ortiz and Lara {Lloret Iglesias} and Pablo {Martínez Ruiz del Árbol} and Daniel Castro-Fresno},
keywords = {Pavement crack segmentation, Generative artificial intelligence, Semantic diffusion synthesis, Road maintenance, Deep learning},
abstract = {Computer-aided deep learning has significantly advanced road crack segmentation. However, supervised models face challenges due to limited annotated images. There is also a lack of emphasis on deriving pavement condition indices from predicted masks. This article introduces a novel semantic diffusion synthesis model that creates synthetic crack images from segmentation masks. The model is optimized in terms of architectural complexity, noise schedules, and condition scaling. The optimal architecture outperforms state-of-the-art semantic synthesis models across multiple benchmark datasets, demonstrating superior image quality assessment metrics. The synthetic frames augment these datasets, resulting in segmentation models with significantly improved efficiency. This approach enhances results without extensive data collection or annotation, addressing a key challenge in engineering. Finally, a refined pavement condition index has been developed for automated end-to-end defect detection systems, promoting more effective maintenance planning.}
}
@article{GANGA2024127932,
title = {Object detection and crowd analysis using deep learning techniques: Comprehensive review and future directions},
journal = {Neurocomputing},
volume = {597},
pages = {127932},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127932},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224007033},
author = {B. Ganga and Lata B.T. and Venugopal K.R.},
keywords = {Deep learning, Generative Artificial Intelligence (GAI), Generative Adversarial Network (GAN), Object detection, Object localization, Convolutional Neural Network (CNN)},
abstract = {Object detection using deep learning has attracted considerable interest from researchers because of its competency in performing state-of-the-art tasks, including detection, observation, and action recognition. Deep Learning (DL)-based object detection models extract features directly from data, which is more efficient and effective than traditional methods requiring handcrafted features. Further, DL also effectively tackles spatiotemporal challenges by leveraging techniques; hence, researchers can develop better object detection models and implement more efficient strategies for object recognition. Moreover, optimizing these models improves performance and recognizes objects within videos or images. This survey comprises of an overview of related review papers and DL-based Object Detection (OD) algorithms. Object detection algorithms are presented as two classifications, namely Two-stage and One-stage methods, with Convolutional Neural Network (CNN) as the backbone. OD’s applications are examined here, and crowd analysis has been extensively studied and researched for potential applications. Most of the papers in object detection rely on Convolutional Neural Networks (CNNs) (28%), whereas crowd analysis papers are distributed as follows: 24% in counting, 25% in categorizing, and 25% in analyzing individual behaviors, and 27% in others. In recent years, deep learning has significantly advanced object detection capabilities to provide effective solutions for various applications, including crowd analysis.}
}
@article{ZHENG2024100271,
title = {The effects of chatbot use on foreign language reading anxiety and reading performance among Chinese secondary school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100271},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100271},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000742},
author = {Shuyan Zheng},
keywords = {Chatot-assisted language learning (BALL), Foreign language reading anxiety (FLRA), Foreign language reading performance (FLRP), Chinese L1 secondary school students, Generative artificial intelligence (GenAI)},
abstract = {The present study investigates the effectiveness of a GenAI-based chatbot, “Reading Bot,” in reducing foreign language reading anxiety (FLRA) and improving foreign language reading performance (FLRP) among Chinese secondary school students learning English as a foreign language (EFL). To do so, a mixed-methods quasi-experimental pre-test/post-test design with qualitative interviews was employed. After ensuring homogeneity between the two groups, one class was designated as the experimental group (n = 42), utilizing a chatbot as a treatment, while the other class served as the comparison group (n = 42), receiving traditional teacher support. Both groups participated in five 45-min reading practice sessions. The results indicated that the chatbot intervention significantly reduced the participants' FLRA within the experimental group when comparing pre- and post-test scores. However, no significant differences were found between the two groups after the treatment, either in FLRA or FLRP. The qualitative analysis of semi-structured interviews suggested that the chatbot provided technological, pedagogical, linguistic, and affective affordances to assist reading. Nevertheless, the analysis also revealed some potential drawbacks and challenges to a GenAI-enhanced approach to reading instruction that may have influenced FLRA and FLRP. The theoretical and pedagogical implications of these findings are discussed, along with potential directions for future research.}
}
@article{BAYRAM2025107850,
title = {Nutritional analysis of AI-generated diet plans based on popular online diet trends},
journal = {Journal of Food Composition and Analysis},
volume = {145},
pages = {107850},
year = {2025},
issn = {0889-1575},
doi = {https://doi.org/10.1016/j.jfca.2025.107850},
url = {https://www.sciencedirect.com/science/article/pii/S0889157525006659},
author = {Hatice Merve Bayram and Sedat Arslan},
keywords = {Artificial intelligence, Diet analysis, Popular diets, The Mediterranean diet, Raw diet, Vegetarian diet, Low sodium diet, High protein diet},
abstract = {This study aimed to evaluate the nutritional composition and consistency of 1500 kcal daily diet plans generated by four generative Artificial Intelligence (AI) tools (ChatGPT-4, ChatGPT-4o, Mistral, and Claude) based on five popular diet types identified via Google Trends (keto, paleo, Mediterranean, intermittent fasting, and raw). Each AI model was prompted with standardized requests, and the resulting menus were analyzed using Nutrition Information System (BeBIS) (version 9.0) to determine energy, macronutrient, and micronutrient content. Nutrient composition differences across AI tools were statistically assessed using SPSS 24.0 (ANOVA, p < 0.05). Results showed significant variations between AI outputs, with energy values ranging from 1357 kcal to 2273 kcal and protein intake varying by up to 65 g across models. Notable inconsistencies were also found in micronutrients such as calcium, iron, and vitamin D. AI models often failed to meet targeted caloric levels and showed inconsistent adherence to diet-specific nutrient profiles. These discrepancies suggest limitations not only in the AI tools’ capabilities but also in their interpretation of user prompts. The findings highlight the need for improved prompt design, database integration, and AI training for safe and reliable use in personalized nutrition.}
}
@article{GOH2025113968,
title = {Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture},
journal = {Applied Soft Computing},
volume = {185},
pages = {113968},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113968},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625012815},
author = {Kam Meng Goh and Usman Ullah Sheikh and Jun Kit Chaw and Weng Kin Lai and Weng Chun Tan and Santhi Krishnamoorthy},
keywords = {Agriculture, Disease, Few-Shot learning, Transfer learning},
abstract = {Deep learning has demonstrated considerable success in agricultural applications. However, its conventional implementations heavily depend on large-scale labelled datasets—a requirement that is often impractical in agriculture due to data scarcity, high annotation costs, or environmental variability. While insufficient training data can significantly limit the performance of standard deep learning models, Few-Shot Learning (FSL) has emerged as a transformative paradigm, enabling robust model training with minimal labelled samples by utilising limited data for training instead. Despite its potential, a critical review assessing how FSL addresses expert system challenges in agriculture remains notably absent. This paper attempts to fill this void by presenting an updated comprehensive review of FSL's applications in agriculture. We categorise FSL methodologies into two primary approaches: data processing-driven and model learning-driven. Data processing–driven approaches address data scarcity by enriching representational diversity through synthetic samples generated with models such as generative adversarial networks, or by transferring knowledge from related domains to improve generalisation. In contrast, model learning–driven strategies confront the same challenge through specialised architectures and optimisation techniques that enable effective generalisation from limited samples. Within this taxonomy, data processing–driven paradigms include transfer learning and generative artificial intelligence, while model learning–driven paradigms cover metric learning methods such as Siamese or prototypical networks, together with model-based and optimisation approaches designed for efficient generalisation. Our analysis pinpoints cutting-edge technologies within each sector, shedding light on overlooked areas and opportunities where FSL can harness limited data to yield promising outcomes when used to solve problems in agriculture.}
}
@article{SINGH2024103021,
title = {Applications of generative AI and future organizational performance: The mediating role of explorative and exploitative innovation and the moderating role of ethical dilemmas and environmental dynamism},
journal = {Technovation},
volume = {133},
pages = {103021},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224000713},
author = {Kuldeep Singh and Sheshadri Chatterjee and Marcello Mariani},
keywords = {Generative AI, Organization future performance, Exploratory and exploitative innovation, Environmental dynamism, Ethics},
abstract = {Generative Artificial Intelligence (GenAI) is one of the popular AI technologies which can produce multiple kinds of contents including music, text, image, as well as synthetic data. As GenAI technology can produce various forms of contents, organizations must face ethical dilemmas as to where this technology is likely to be used. Organizations do not want to compromise their ethical standards and compliance policies. Against this backdrop, the aim of this study is to examine if GenAI technology could improve the future performance of the organizations. This study deployed ethical dilemmas and environmental dynamism as two moderators acting on different linkages between adoption of GenAI and organizational future performance. With the help of literature review and theories, a theoretical model has been developed conceptually which was validated using PLS-SEM technique with the feedback of 326 responses from different types of organizations. This study found that the adoption of GenAI could improve exploratory and exploitative innovation under the moderating effects of environmental dynamism and ethical dilemmas. Moreover, it highlighted that the application of GenAI could improve organizational performance.}
}