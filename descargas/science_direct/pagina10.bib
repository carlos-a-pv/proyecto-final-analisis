@article{SIMEONE202537,
title = {Conceptualisation of a multimodal, non-intrusive, generative AI-based assistive system for assembly},
journal = {CIRP Annals},
volume = {74},
number = {1},
pages = {37-41},
year = {2025},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2025.04.061},
url = {https://www.sciencedirect.com/science/article/pii/S0007850625001088},
author = {Alessandro Simeone and Yuchen Fan and Dario Antonelli and Paolo C. Priarone and Luca Settineri},
keywords = {Generative artificial intelligence, Assembly, Multimodal assistance},
abstract = {The transition to Industry 5.0 highlights the necessity for human-centric and adaptive manufacturing systems. This study conceptualises a multimodal, generative AI-based assistive system for assembly designed to deliver real-time error detection and adaptive guidance tailored to diverse operator profiles. The system improves human-machine interaction by issuing preventive warnings to the operator prior to critical tasks, detecting assembly errors, providing multimodal corrective instructions during operations, and deploying robotic interventions when operator-driven corrections prove inadequate. Preliminary laboratory-scale implementation results show the system capability in mitigating assembly errors through dynamic assistive technology selection and iterative feedback learning.}
}
@article{HUDON2024,
title = {Using ChatGPT in Psychiatry to Design Script Concordance Tests in Undergraduate Medical Education: Mixed Methods Study},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/54067},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000400},
author = {Alexandre Hudon and Barnabé Kiepura and Myriam Pelletier and Véronique Phan},
keywords = {psychiatry, artificial intelligence, medical education, concordance scripts, machine learning, ChatGPT, evaluation, education, medical learners, learning, teaching, design, support, tool, validation, educational, accuracy, clinical questions, educators},
abstract = {Background
Undergraduate medical studies represent a wide range of learning opportunities served in the form of various teaching-learning modalities for medical learners. A clinical scenario is frequently used as a modality, followed by multiple-choice and open-ended questions among other learning and teaching methods. As such, script concordance tests (SCTs) can be used to promote a higher level of clinical reasoning. Recent technological developments have made generative artificial intelligence (AI)–based systems such as ChatGPT (OpenAI) available to assist clinician-educators in creating instructional materials.
Objective
The main objective of this project is to explore how SCTs generated by ChatGPT compared to SCTs produced by clinical experts on 3 major elements: the scenario (stem), clinical questions, and expert opinion.
Methods
This mixed method study evaluated 3 ChatGPT-generated SCTs with 3 expert-created SCTs using a predefined framework. Clinician-educators as well as resident doctors in psychiatry involved in undergraduate medical education in Quebec, Canada, evaluated via a web-based survey the 6 SCTs on 3 criteria: the scenario, clinical questions, and expert opinion. They were also asked to describe the strengths and weaknesses of the SCTs.
Results
A total of 102 respondents assessed the SCTs. There were no significant distinctions between the 2 types of SCTs concerning the scenario (P=.84), clinical questions (P=.99), and expert opinion (P=.07), as interpretated by the respondents. Indeed, respondents struggled to differentiate between ChatGPT- and expert-generated SCTs. ChatGPT showcased promise in expediting SCT design, aligning well with Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition criteria, albeit with a tendency toward caricatured scenarios and simplistic content.
Conclusions
This study is the first to concentrate on the design of SCTs supported by AI in a period where medicine is changing swiftly and where technologies generated from AI are expanding much faster. This study suggests that ChatGPT can be a valuable tool in creating educational materials, and further validation is essential to ensure educational efficacy and accuracy.}
}
@article{LEVIN2024105566,
title = {Evaluating GenAI systems to combat mental health issues in healthcare workers: An integrative literature review},
journal = {International Journal of Medical Informatics},
volume = {191},
pages = {105566},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105566},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624002296},
author = {C. Levin and E. Naimi and M. Saban},
keywords = {Machine learning, Mental health, Burnout, Healthcare professionals, Generative AI},
abstract = {Background
Mental health issues among healthcare workers remain a serious problem globally. Recent surveys continue to report high levels of depression, anxiety, burnout and other conditions amongst various occupational groups. Novel approaches are needed to support clinician well-being.
Objective
This integrative literature review aims to explore the current state of research examining the use of generative artificial intelligence (GenAI) and machine learning (ML) systems to predict mental health issues and identify associated risk factors amongst healthcare professionals.
Methods
A literature search of databases was conducted in Medline then adapted as necessary to Scopus, Web of Science, Google Scholar, PubMed and CINAHL with Full Text. Eleven studies met the inclusion criteria for the review.
Results
Nine studies employed various machine learning techniques to predict different mental health outcomes among healthcare workers. Models showed good predictive performance, with AUCs ranging from 0.82 to 0.904 for outcomes such as depression, anxiety and safety perceptions. Key risk factors identified included fatigue, stress, burnout, workload, sleep issues and lack of support. Two studies explored the potential of sensor-based technologies and GenAI analysis of physiological data. None of the included studies focused on the use of GenAI systems specifically for providing mental health support to healthcare workers.
Conclusion
Preliminary research demonstrates that AI/ML models can effectively predict mental health issues. However, more work is needed to evaluate the real-world integration and impact of these tools, including GenAI systems, in identifying clinician distress and supporting well-being over time. Further research should aim to explore how GenAI may be developed and applied to provide mental health support for healthcare workers.}
}
@article{HYNEK2025100782,
title = {Risks and benefits of artificial intelligence deepfakes: Systematic review and comparison of public attitudes in seven European Countries},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100782},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100782},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001271},
author = {Nik Hynek and Beata Gavurova and Matus Kubak},
keywords = {Generative artificial intelligence, Deepfakes, AI-Generated hyper-realistic audio-visual digital content, SWOT/Risks and benefits, Cross-National survey, Public opinion},
abstract = {This study provides an evidence-based integrated appraisal of artificial intelligence (AI)-generated deepfakes by integrating a cross-disciplinary literature synthesis with original opinion-poll evidence from seven European countries. A SWOT matrix distils convergent concerns—weaponised disinformation, privacy erosion, and the detection arms race—alongside under-explored opportunities in education, therapy, and creative industries. To test whether these scholarly themes resonate with citizens, a computer-assisted web survey (N = 7,083) measured perceived risks and benefits across 10 specific scenarios for each theme. Correspondence analysis and Bonferroni-adjusted means reveal a pronounced age gradient for benefits, whereas risk perceptions vary by country—younger cohorts are noticeably less alarmed only in Sweden, France, and Czechia. Geographically, Dutch, German, British, and Italian publics prove the most enthusiastic: the United Kingdom (UK) couples similar enthusiasm with markedly higher risk vigilance, whereas Czech and Swedish respondents remain consistently sceptical, underscoring a broad, though imperfect, west/south versus central/north divide. The Netherlands, Germany, the UK, and Italy value pro-social applications (i.e., realistic crisis drills, public-interest campaigns, and therapeutic ‘mental-health’ avatars), with the Netherlands topping four benefit items and Italy favouring commercial/entertainment uses such as virtual brand ambassadors. By contrast, Czech and Swedish respondents assign uniformly low benefit scores. Juxtaposed with risk perceptions, the UK and Czechia register the greatest vigilance, Sweden the most relaxed, and others intermediate. Divergence seems associated with digital literacy levels and regulatory maturity. The survey reveals a statistically and practically significant gap between perceived risks and benefits: across all seven countries, respondents, on average, rate risks higher than advantages. Regression estimates indicate that advancing age, lower household income, and gender (woman) enlarge this gap—primarily by undermining perceived benefits—whereas tertiary education and residence in certain western or southern European countries—notably, Germany and Italy—are associated with more balanced appraisals. This study concludes that layered governance, interoperable detection standards, and targeted literacy programmes are urgently required.}
}
@article{SONG2026104368,
title = {Defining the problem: The impact of OCR quality on retrieval-augmented generation performance and strategies for improvement},
journal = {Information Processing & Management},
volume = {63},
number = {1},
pages = {104368},
year = {2026},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104368},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325003097},
author = {Minchae Song},
keywords = {Document information extraction, Generative artificial intelligence, Optical character recognition, Factoid question-answering, Retrieval-augmented generation, Word error rate},
abstract = {Despite considerable progress in Retrieval-Augmented Generation (RAG) and Optical Character Recognition (OCR) technologies, only a limited amount of research has examined how OCR-derived data influences RAG performance. Thus, this study presents a document-based question-answering dataset derived from unstructured image documents across financial domains and investigates the impact of OCR-generated data on RAG outcomes. Although high OCR accuracy was achieved, especially for handwritten content, using raw OCR outputs directly in the RAG substantially increased the error rates. To address this, we propose a simple yet effective method of transforming OCR outputs into a structured tabular format, with the results showing a marked improvement in RAG performance without altering the OCR quality. The approach proved robust in correcting OCR errors, representing data in structured formats, and integrating alternative retriever and reranker techniques, and highlighted that RAG performance is more sensitive to the structure of input data than to OCR accuracy alone. This study presents a practical solution for optimizing RAG systems by utilizing structured representations of OCR-extracted data, thereby providing new insights for integrating OCR and RAG.}
}
@article{LIU2025101211,
title = {RePower: An LLM-driven autonomous platform for power system data-guided research},
journal = {Patterns},
volume = {6},
number = {4},
pages = {101211},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101211},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925000595},
author = {Yu-Xiao Liu and Mengshuo Jia and Yong-Xin Zhang and Jianxiao Wang and Guannan He and Shao-Long Zhong and Zhi-Min Dang},
keywords = {algorithm evolution, autonomous research, data-driven tasks, large language models, power systems, research assistant},
abstract = {Summary
Large language models (LLMs) have shown strong capabilities across disciplines such as chemistry, mathematics, and medicine, yet their application in power system research remains limited, and most studies still focus on supporting specific tasks under human supervision. Here, we introduce Revive Power Systems (RePower), an autonomous LLM-driven research platform that uses a reflection-evolution strategy to independently conduct complex research in power systems. RePower assists researchers by controlling devices, acquiring data, designing methods, and evolving algorithms to address problems that are difficult to solve but easy to evaluate. Validated on three critical data-driven tasks in power systems—parameter prediction, power optimization, and state estimation—RePower outperformed traditional methods. Consistent performance improvements were observed across multiple tasks, with an average error reduction of 29.07%. For example, in the power optimization task, the error decreased from 0.00137 to 0.000825, a reduction of 39.78%. This framework facilitates autonomous discoveries, promoting innovation in power systems research.}
}
@article{RACHANAHARISH2025104269,
title = {Blockchain For Logistics 4.0: A Systematic Review and Prospects},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {201},
pages = {104269},
year = {2025},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2025.104269},
url = {https://www.sciencedirect.com/science/article/pii/S1366554525003102},
author = {Arjun {Rachana Harish} and Xinlai Liu and Xin Wang and Shenle Pan and Hong-Ning Dai and Ming Li and George Q. Huang},
keywords = {Logistics 4.0, Blockchain, Decentralized ledger, Smart contract, Systematic Literature Review (SLR)},
abstract = {Logistics 4.0, with its supporting technologies, is gaining popularity with researchers and practitioners as a way to navigate the dynamic and demanding logistics environment. Blockchain technology is such a topical technology in logistics. The logistics industry benefits from blockchain as it enhances communication and collaboration among stakeholders through applications such as information sharing, goods monitoring and tracing, and executing financing and payments. However, the perceived lack of clarity on the adoption benefits has increased decision-maker’s hesitation to adopt and utilize blockchain technology in the logistics industry. To fully understand blockchain applications in the context of logistics, this paper conducts a systematic literature review (SLR) on blockchain research in logistics. A selection of 113 articles undergoes review based on a two-axis framework. The first axis lists the core blockchain technologies, such as decentralized ledger, consensus mechanism, and smart contract. It comprehensively reviews their interplay with the foundational logistics requirements, such as agility, collaboration, and resilience. The second axis reviews domains such as e-commerce logistics, business logistics, green logistics, and logistics financing, which are key avenues for blockchain applications. The key themes arising from the review are a precursor to deriving avenues for future research. Finally, we present Web 4.0 in logistics, the new wave of generative artificial intelligence (AI)-empowered blockchain innovation that can shape future logistics. More specifically, we explore the role of modern AI agents in driving future research for seamless blockchain integration to logistics, enabling logistics ESG (Environmental, Social, and Governance) and organizational adoption. Besides addressing a gap in existing literature, the concepts discussed in this study allow for a comprehensive understanding of blockchain adoption in logistics, thus encouraging wider practical application of novel technology. From a theoretical lens, this study helps comprehend blockchain technology and its significance to logistics research.}
}
@article{TONG2025,
title = {Effectiveness of Topic-Based Chatbots on Mental Health Self-Care and Mental Well-Being: Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70436},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125006260},
author = {Alan C Y Tong and Kent T Y Wong and Wing W T Chung and Winnie W S Mak},
keywords = {chatbot intervention, mental health literacy, self-care, randomized controlled trial, digital health, mental well-being, artificial intelligence},
abstract = {Background
The global surge in mental health challenges has placed unprecedented strain on health care systems, highlighting the need for scalable interventions to promote mental health self-care. Chatbots have emerged as promising tools by providing accessible, evidence-based support. While chatbots have shown promise in delivering mental health interventions, most studies have only focused on clinical populations and symptom reduction, leaving a critical gap in understanding their preventive potential for self-care and mental health literacy in the general population.
Objective
This study evaluated the effectiveness of a rule-based, topic-specific chatbot intervention in improving self-care efficacy, mental health literacy, self-care intention, self-care behaviors, and mental well-being immediately after 10 days and 1 month of its use.
Methods
A 2-arm, assessor-blinded randomized controlled trial was conducted. A total of 285 participants were randomly assigned to the chatbot intervention group (n=140) and a waitlist control group (n=145). The chatbot intervention consisted of 10 topic-specific sessions targeting stress management, emotion regulation, and value clarification, delivered over 10 days with a 7-day free-access period. Primary outcomes included self-care self-efficacy, behavioral intentions, self-care behaviors, and mental health literacy. Secondary outcomes included depressive symptoms, anxiety symptoms, and mental well-being. Assessments were self-administered on the web at baseline, 10 days after the intervention, and at a 1-month follow-up. All outcomes were analyzed using linear mixed models with an intention-to-treat approach, and effect sizes were calculated using Cohen d.
Results
Participants in the chatbot group demonstrated significantly greater improvements in behavioral intentions (F2,379.74=15.02; P<.001) and mental health literacy (F2,423.57=4.27; P=.02) compared to the control group. The chatbots were also able to bring significant improvement in self-care behaviors (Cohen d=0.36, 95% CI 0.08-0.30; P<.001), mindfulness (Cohen d=0.37, 95% CI 0.14-0.38; P<.001), depressive symptoms (Cohen d=–0.26, 95% CI –1.77 to –0.26; P=.004), overall well-being (Cohen d=0.22, 95% CI 0.02-0.42; P=.02), and positive emotions (Cohen d=0.28, 95% CI 0.08-0.54; P=.004) after 10 days. However, these improvements did not differ significantly at 1 month when compared to the waitlist control group. Adherence was higher among participants who received push notifications (t138=–4.91; P<.001).
Conclusions
This study highlights the potential of rule-based chatbots in promoting mental health literacy and fostering short-term self-care intentions. However, the lack of sustained effects points to the necessary improvements required in chatbot design, including greater personalization and interactive features to enhance self-efficacy and long-term mental health outcomes. Future research should explore hybrid approaches that combine rule-based and generative artificial intelligence systems to optimize intervention effectiveness.
Trial Registration
ClinicalTrials.gov NCT05694507; https://clinicaltrials.gov/ct2/show/NCT05694507}
}
@article{KIM2026129086,
title = {Multi-modal recommender system using text-to-image generative models and adaptive learning},
journal = {Expert Systems with Applications},
volume = {296},
pages = {129086},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129086},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425027034},
author = {Seongmin Kim and Seona Moon and Yeongseo Lim and Sang-Min Choi and Sang-Ki Ko},
keywords = {Recommender systems, Multi-modal data, Adaptive learning, Generative artificial intelligence},
abstract = {Recently, various successful approaches have been developed to enhance the performance of recommender systems by incorporating multi-modal data, such as item images and textual descriptions. However, adopting these algorithms in real-world scenarios is challenging, as images or textual descriptions are often unavailable. Moreover, in some cases, the provided images or descriptions may not accurately represent the item. We refer to such situations as missing data. In the fashion domain, visual information is crucial, as people are unlikely to buy clothing without seeing its design and appearance. Thus, we propose employing a text-to-image Generative Adversarial Network (GAN) to generate missing visual data from available textual descriptions, enabling a multi-modal recommender system that leverages both visual and textual information. We also introduce an adaptive feature importance learning mechanism to dynamically determine the weight of each multi-modal feature when calculating the preference score. We demonstrate the effectiveness of the proposed algorithm through extensive experiments on the publicly available Amazon review dataset.}
}
@article{YU2025100172,
title = {Modular AI agents for transportation surveys and interviews: Advancing engagement, transparency, and cost efficiency},
journal = {Communications in Transportation Research},
volume = {5},
pages = {100172},
year = {2025},
issn = {2772-4247},
doi = {https://doi.org/10.1016/j.commtr.2025.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2772424725000125},
author = {Jiangbo Yu and Jinhua Zhao and Luis Miranda-Moreno and Matthew Korp},
keywords = {Travel survey, Preference elicitation, Large language model, Natural language processing, Human-computer interaction, Artificial intelligence (AI), Public consultation},
abstract = {Surveys and interviews—structured, semi-structured, or unstructured—are widely used for collecting insights on emerging or hypothetical scenarios. Traditional human-led methods often face challenges related to cost, scalability, and consistency. For example, distributed questionnaires lack the ability to provide real-time guidance and request immediate clarifications. Recently, various domains have begun to explore the use of conversational agents (chatbots) powered by generative artificial intelligence (AI) technologies. However, considering decisions in transportation investments and policies often carry significant socioeconomic and environmental consequences, surveys and interviews face unique challenges in integrating AI agents. This issue underscors the need for a rigorous, explainable, and resource-efficient approach that enhances participant engagement and ensures privacy. This paper bridges this gap by introducing a modular approach accompanied by a parameterized process for designing and deploying AI agents for surveys and interviews, thereby supporting decision-makings in high-stakes contexts. We detail the system architecture, integrating engineered prompts, specialized knowledge bases, and customizable, goal-oriented conversational logic. We demonstrate the adaptability, generalizability, and efficacy of our modular approach through three empirical studies: (1) travel preference surveys, highlighting conditional logic and multimodal (voice, text, and image generation) capabilities; (2) public opinion elicitation on a newly constructed, novel infrastructure project, showcasing question customization and multilingual (English and French) capabilities; and (3) expert consultations about the impact of technologies on future transportation systems, highlighting real-time, clarification request capabilities for open-ended questions, resilience in handling erratic inputs, and efficient transcript postprocessing. The results suggest that the AI agent increases completion rates and response quality. Furthermore, the modular approach demonstrates controllability, flexibility, and robustness while addressing key ethical, privacy, security, and token consumption concerns. We believe this work lays the foundation for next-generation surveys and interviews in transportation research.}
}
@article{MARTINS2024105640,
title = {A conversational agent for enhanced Self-Management after cardiothoracic surgery},
journal = {International Journal of Medical Informatics},
volume = {192},
pages = {105640},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105640},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624003034},
author = {Ana Martins and Luís {Velez Lapão} and Isabel L. Nunes and Ana {Paula Giordano} and Helena Semedo and Clara Vital and Raquel Silva and Pedro Coelho and Ana Londral},
keywords = {Co-design, Conversational Agents, Personalization, Self-management, Cardiothoracic Surgery, Health},
abstract = {Background
Enhanced self-management is crucial for long-term survival following cardiothoracic surgery.
Objectives
This study aimed to develop a conversational agent to enhance patient self-management after cardiothoracic surgery.
Methodology
The solution was designed and implemented following the Design Science Research Methodology. A pilot study was conducted at the hospital to assess the feasibility, usability, and perceived effectiveness of the solution. Feedback was gathered to inform further interactions. Additionally, a focus group with clinicians was conducted to evaluate the acceptability of the solution, integrating insights from the pilot study.
Results
The conversational agent, implemented using a rule-based model, was successfully tested with patients in the cardiothoracic surgery unit (n = 4). Patients received one month of text messages reinforcing clinical team recommendations on a healthy diet and regular physical activity. The system received a high usability score, and two patients suggested adding a feature to answer user prompts for future improvements. The focus group feedback indicated that while the solution met the initial requirements, further testing with a larger patient cohort is necessary to establish personalized profiles. Moreover, clinicians recommended that future iterations prioritize enhanced personalization and interoperability with other hospital platforms. Additionally, while the use of artificial generative intelligence was seen as relevant for content personalization, clinicians expressed concerns regarding content safety, highlighting the necessity for rigorous testing.
Conclusions
This study marks a significant step towards enhancing post-cardiothoracic surgery care through conversational agents. The integration of a diversity of stakeholder knowledge enriches the solution, grants ownership and ensures its sustainability. Future research should focus on automating message generation and delivery based on patient data and environmental factors. While the integration of artificial generative intelligence holds promise for enhancing patient interaction, ensuring the safety of its content is essential.}
}
@article{ALSHAIKH2024e25361,
title = {The implementation of the cognitive theory of multimedia learning in the design and evaluation of an AI educational video assistant utilizing large language models},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e25361},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e25361},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024013926},
author = {Rana AlShaikh and Norah Al-Malki and Maida Almasre},
keywords = {Large language models, Cognitive theory of multimedia learning, Educational video, ASR, Google's bard},
abstract = {The integration of Artificial Intelligence (AI) holds immense potential for revolutionizing education; especially, in contexts where multimodal learning experiences are designed. This paper investigated the potential benefits of Generative Artificial Intelligence (AI) in education, concentrating on the design and evaluation of an AI Educational Video Assistant tailored for multimodal learning experiences. The tool, utilizing the principles of the Cognitive Theory of Multimedia Learning (CTML), comprises three modules: Transcription, Engagement, and Reinforcement, each focusing on distinct aspects of the learning process. It Integraties Automatic Speech Recognition (ASR) using OpenAI's Whisper and Google's Large Language Model (LLM) Bard. Our twofold objective includes both the development of this AI assistant tool and the assessment of its effect on improving the learning experiences. For the evaluation, a mixed methods approach was adopted, combining human evaluation by nine educational experts with automatic metrics. Participants provided their perceptions on the tool's effectiveness in terms of engagement, content organization, clarity, and usability. Additionally, automatic metrics including Content Distinctiveness and Readability scores were computed. The results from the human evaluation suggest positive impacts across all assessed domains. The automatic metrics further proved the tool's ability in content generation and readability. Collectively, these preliminary results highlight the tool's potential to revolutionize educational design and provide personalized and engaging learning experiences.}
}
@article{CESCO2024105015,
title = {Smart management of emergencies in the agricultural, forestry, and animal production domain: Tackling evolving risks in the climate change era},
journal = {International Journal of Disaster Risk Reduction},
volume = {114},
pages = {105015},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.105015},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924007775},
author = {Stefano Cesco and Davide Ascoli and Lucia Bailoni and Gian Battista Bischetti and Pietro Buzzini and Monica Cairoli and Luisella Celi and Giuseppe Corti and Marco Marchetti and Giacomo Scarascia Mugnozza and Simone Orlandini and Andrea Porceddu and Giovanni Gigliotti and Fabrizio Mazzetto},
keywords = {Climate change, Sustainability, Emergency, Agriculture, Forestry, Livestock},
abstract = {The agricultural, forestry, and animal production domain (AFA domain) plays an essential role in meeting global needs and supporting livelihoods while facing escalating challenges from climate change-induced impacts and extreme natural events. This perspective advocates for urgent strategies to enhance resilience through effective emergency management and prevention measures tailored to this critical domain. The analysis here exposed, which includes elements of ontology and the conceptual approach of an emergency management system encompassing both restoration and prevention aspects, entails three case studies across the AFA domain. Each case study, described by location, timing, nature, and consequences, critically evaluates the implemented risk prevention measures, details the emergency and recovery actions, and highlights shortcomings in response efforts. The analysis, incorporating a retrospective comparative component based on the proposed conceptual model, highlights the importance of identifying lessons learned and potential future applications. It emphasizes the urgent need for a well-structured emergency management strategy that integrates risk mapping and advanced technology to ensure timely and effective responses. The active engagement of domain professionals (agronomists, foresters, animal production doctors) and scholars of AFA domain sciences, as either farm owners or technical advisors, is crucial to optimize intervention strategies. This engagement is especially important for enhancing resilience during recovery phases, aligning with the best international practices such as making use of local knowledge and citizen engagement strategies. Comprehensive training initiatives, also adopting innovative formats and tools including micro-credentials, e-learning platforms, and the applications of generative Artificial Intelligence for learning assistance, as well as new research insights are strategic for coordinated and effective emergency responses across all stakeholders. Collaboration between the different production systems and areas of expertise, raising awareness of the distinction between Civil Protection and Production Protection and fostering their close interconnection, is essential for effective emergency response and long-term resilience.}
}
@article{YIN2024108417,
title = {Unleashing pre-service language teachers’ productivity with generative AI: Emotions, appraisal and coping strategies},
journal = {Computers in Human Behavior},
volume = {161},
pages = {108417},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108417},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002851},
author = {Hongbiao Yin and Chan Wang and Zhijun Liu},
keywords = {Emotions, Appraisal, Approach-oriented coping, Avoidance-oriented coping, AI-enabled productivity, Pre-service language teachers},
abstract = {The potential of Generative Artificial Intelligence (AI) in language education has been widely recognized. However, there has been limited attention given to the emotional experiences of language teachers using AI and its relationship with AI-enabled productivity. By investigating 1,683 pre-service language teachers’ experiences of using generative AI in their teaching practicum or learning, this study explored how teachers’ emotional responses to AI use in teaching and learning are related to their AI-enabled productivity through the mediation of appraisal and coping. We uncovered several key findings: (1) achievement, challenge, and loss emotions were directly and/or indirectly related to AI-enabled productivity, while deterrence emotions were not; (2) achievement and challenge emotions were positively correlated with challenge appraisal and negatively correlated with hindrance appraisal, whereas loss and deterrence emotions showed the opposite pattern of correlation; (3) challenge emotions were positively related to approach-oriented coping, while loss and deterrence emotions were positively associated with avoidance-oriented coping; (4) among the coping strategies, only positive reinterpretation was positively associated with AI-enabled productivity; and (5) challenge appraisal and positive reinterpretation were significant mediators in the relationships between emotions and AI-enabled productivity, either separately or sequentially. These findings provide valuable insights for future research and practice, aiming to support the application of generative AI in the context of language education.}
}
@article{HABICHT2025,
title = {Generative AI–Enabled Therapy Support Tool for Improved Clinical Outcomes and Patient Engagement in Group Therapy: Real-World Observational Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60435},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003425},
author = {Johanna Habicht and Larisa-Maria Dina and Jessica McFadyen and Mona Stylianou and Ross Harper and Tobias U Hauser and Max Rollwage},
keywords = {artificial intelligence, National Health Service, NHS Talking Therapies, mental health, therapy support tool, cognitive behavioral therapy, CBT, chatbot, conversational agent, clinical, patient engagement, therapist, treatment, medication, depression, anxiety disorder, exercise, observational study, control group, patient adherence},
abstract = {Background
Cognitive behavioral therapy (CBT) is a highly effective treatment for depression and anxiety disorders. Nonetheless, a substantial proportion of patients do not respond to treatment. The lack of engagement with therapeutic materials and exercises between sessions, a necessary component of CBT, is a key determinant of unsuccessful treatment.
Objective
The objective of this study was to test whether the deployment of a generative artificial intelligence (AI)–enabled therapy support tool, which helps patients to engage with therapeutic materials and exercises in between sessions, leads to improved treatment success and patient treatment adherence compared with the standard delivery of CBT exercises through static workbooks.
Methods
We conducted a real-world observational study of 244 patients receiving group-based CBT in 5 of the United Kingdom’s National Health Service Talking Therapies services, comparing 150 (61.5%) patients who used the AI-enabled therapy support tool to 94 (38.5%) patients who used the standard delivery of CBT exercises. The groups were equivalent with respect to the content of the CBT materials and the human-led therapy sessions; however, the intervention group received support from the AI-enabled therapy support tool in conducting CBT exercises.
Results
Patients using the AI-enabled therapy support tool exhibited greater attendance at therapy sessions and fewer dropouts from treatment. Furthermore, these patients demonstrated higher reliable improvement, recovery, and reliable recovery rates when compared to the control group, which was related to the degree of use of the AI-enabled therapy support tool. Moreover, we found that engagement with AI-supported CBT interventions, relative to psychoeducational materials, predicted better treatment adherence and treatment success, highlighting the role of personalization in the intervention’s effectiveness. To investigate the mechanisms of these effects further, we conducted a separate qualitative experiment in a nonclinical sample of users (n=113). Results indicated that users perceived the AI-enabled therapy support tool as most useful for discussing their problems to gain awareness and clarity of their situation as well as learning how to apply coping skills and CBT techniques in their daily lives.
Conclusions
Our results show that an AI-enabled, personalized therapy support tool in combination with human-led group therapy is a promising avenue to improve the efficacy of and adherence to mental health care.}
}
@article{NIELSEN2025,
title = {Investigating the Classification of Living Kidney Donation Experiences on Reddit and Understanding the Sensitivity of ChatGPT to Prompt Engineering: Content Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/57319},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000067},
author = {Joshua Nielsen and Xiaoyu Chen and LaShara Davis and Amy Waterman and Monica Gentili},
keywords = {prompt engineering, generative artificial intelligence, kidney donation, transplant, living donor},
abstract = {Background
Living kidney donation (LKD), where individuals donate one kidney while alive, plays a critical role in increasing the number of kidneys available for those experiencing kidney failure. Previous studies show that many generous people are interested in becoming living donors; however, a huge gap exists between the number of patients on the waiting list and the number of living donors yearly.
Objective
To bridge this gap, we aimed to investigate how to identify potential living donors from discussions on public social media forums so that educational interventions could later be directed to them.
Methods
Using Reddit forums as an example, this study described the classification of Reddit content shared about LKD into three classes: (1) present (presently dealing with LKD personally), (2) past (dealt with LKD personally in the past), and (3) other (LKD general comments). An evaluation was conducted comparing a fine-tuned distilled version of the Bidirectional Encoder Representations from Transformers (BERT) model with inference using GPT-3.5 (ChatGPT). To systematically evaluate ChatGPT’s sensitivity to distinguishing between the 3 prompt categories, we used a comprehensive prompt engineering strategy encompassing a full factorial analysis in 48 runs. A novel prompt engineering approach, dialogue until classification consensus, was introduced to simulate a deliberation between 2 domain experts until a consensus on classification was achieved.
Results
BERT and GPT-3.5 exhibited classification accuracies of approximately 75% and 78%, respectively. Recognizing the inherent ambiguity between classes, a post hoc analysis of incorrect predictions revealed sensible reasoning and acceptable errors in the predictive models. Considering these acceptable mismatched predictions, the accuracy improved to 89.3% for BERT and 90.7% for GPT-3.5.
Conclusions
Large language models, such as GPT-3.5, are highly capable of detecting and categorizing LKD-targeted content on social media forums. They are sensitive to instructions, and the introduced dialogue until classification consensus method exhibited superior performance over stand-alone reasoning, highlighting the merit in advancing prompt engineering methodologies. The models can produce appropriate contextual reasoning, even when final conclusions differ from their human counterparts.}
}
@article{BELKINA2025100407,
title = {Implementing generative AI (GenAI) in higher education: A systematic review of case studies},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100407},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100407},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000475},
author = {Marina Belkina and Scott Daniel and Sasha Nikolic and Rezwanul Haque and Sarah Lyden and Peter Neal and Sarah Grundy and Ghulam M. Hassan},
keywords = {Generative AI, Education, GenAI, Case study, University, Implementation},
abstract = {The introduction of Generative Artificial Intelligence (GenAI) tools, like ChatGPT, into higher education heralds a transformative era, reshaping instructional methods, enhancing student support systems, and redefining the educational landscape. Recent literature reviews on GenAI highlight a lack of focus on how these tools are being practically implemented in educational settings. Addressing this gap, the present study systematically examines empirical case studies that demonstrate the integration of GenAI into teaching and learning in higher education, offering actionable insights and guidance for academic practice. We conducted a search of relevant databases and identified 21 empirical studies that met our inclusion criteria. The selected studies cover a diverse range of disciplines, locations, types of participants (from first-year students to postgraduates and academics), and a variety of methodologies. We classified the selected publications based on the pedagogic theory of Laurillard's Conversational Framework (LCF) and the Substitution, Augmentation, Modification, and Redefinition (SAMR) framework. We also synthesized definitions from selected empirical studies and recent research exploring Technological Pedagogical Content Knowledge (TPACK) in the age of GenAI, providing a comprehensive understanding of GenAI-TPACK factors. Limitations and future research opportunities are also discussed. The paper concludes by providing a GenAI-TPACK diagram to guide educators in effectively incorporating GenAI tools into their teaching practices, ensuring responsible and impactful use in higher education.}
}
@article{HIRN2024102826,
title = {Transfer learning of species co-occurrence patterns between plant communities},
journal = {Ecological Informatics},
volume = {83},
pages = {102826},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102826},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124003686},
author = {Johannes Hirn and Verónica Sanz and José Enrique García and Marta Goberna and Alicia Montesinos-Navarro and José Antonio Navarro-Cano and Ricardo Sánchez-Martín and Alfonso Valiente-Banuet and Miguel Verdú},
keywords = {Generative artificial intelligence, Patchy vegetation, Plant communities, Restoration ecology, Species co-occurrence, Variational autoencoders},
abstract = {Aim
The use of neural networks (NNs) is spreading to all areas of life, and Ecology is no exception. However, the data-hungry nature of NNs can leave out many small, valuable datasets. Here we show how to apply transfer learning to rescue small datasets that can be invaluable in understanding patterns of species co-occurrence.
Location
Semiarid plant communities in Spain and México.
Time period
2016–2022.
Major taxa studied
Angiosperms.
Methods
Based on a large sample of plant species co-occurrence in vegetation patches in a semi-arid area of eastern Spain, we fit a generative artificial intelligence (AI) model that correctly reproduces which species live with which in these patches. Subsequently, we train the same type of model on two communities for which we only have smaller datasets (another semi-arid community in eastern Spain, and a tropical community in Mexico).
Results
When we transfer the knowledge learnt from the large dataset directly to the other two, the predictions improve for the community more similar to our reference one. As for the more dissimilar community, improving the accuracy of the transfer requires a further tuning of the model to the local data. In particular, the knowledge transferred relates primarily to species frequency and, to a lesser extent, to their phylogenetic relationships, which are known to be determinants of species interaction patterns.
Main conclusions
This AI-based approach can be performed for communities similar or not so similar to the reference community, opening the door to systematic transfer learning for accurate predictions on small datasets. Interestingly, this transfer operates by matching unrelated species between the origin and target datasets, implying that arbitrary datasets can then be transferred to, or even combined in order to augment each other, irrespective of the species involved, potentially allowing such models to be applied to a wide range of plant communities in different climates.}
}
@article{MA2024123801,
title = {How AI use in organizations contributes to employee competitive advantage: The moderating role of perceived organization support},
journal = {Technological Forecasting and Social Change},
volume = {209},
pages = {123801},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123801},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524005997},
author = {Liang Ma and Peng Yu and Xin Zhang and Gaoshan Wang and Feifei Hao},
keywords = {Work-related generative AI use, Employee competitive advantage, Employee boundary spanning, Employee agility, Resource base view model},
abstract = {Although the use of generative artificial intelligence (AI) within organizations is becoming increasingly common, research on how to enhance employees' competitive advantage through generative AI use within organizations is very limited. Using a resource-based view model, this study investigates the relationship between generative AI use and employees' competitive advantage, as well as the moderating role of perceived organization support. From an analysis of data from 264 employees from 200 organizations, it is found that work-related generative AI use has a positive effect on employee boundary spanning, which contributes to employee competitive advantage. Secondly, work-related generative AI use also has a positive effect on employee agility, including employee resilience and employee adaptability, which further contributes to employee competitive advantage. However, work-related generative AI use has a positive effect on employee proactivity, while the effect of employee proactivity on employee competitive advantage is not significant. Thirdly, perceived organizational support can enhance the effect between employee boundary spanning and employee competitive advantage. However, it is interesting to observe that perceived organizational support enhances the effect between employee adaptability and employee competitive advantage, while weakening the effect between employee proactivity and employee competitive advantage. It does not exert a moderating effect between employee resilience and employee competitive advantage. These findings can help deepen the current understanding of the relationship between generative AI use in the organization and employee competitive advantage, and provide suggestions for business managers on how to use generative AI to improve employee competitive advantage.}
}
@article{SUAREZ2025102997,
title = {On the verge of a digital divide in the use of generative AI?},
journal = {Telecommunications Policy},
volume = {49},
number = {7},
pages = {102997},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.102997},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125000941},
author = {David Suárez and Begoña García-Mariñoso},
keywords = {Artificial intelligence (AI), Generative AI, Digital divide, Chatbots, Gender imbalance, Digital inclusion},
abstract = {The launch of ChatGPT in late 2022 has generalized the availability of chatbots with generative artificial intelligence capabilities for end users. From here, the question is whether this technology is being used equally by all user groups or rather whether we may be at the beginning of a new digital divide. The present study addresses this question by using a well-designed, nationwide survey with data on AI chatbot use. Binary and ordered logit regression models are estimated for the actual AI chatbot use. The results show that the older, the less educated and women lag behind in the use of this new technology. In addition, users who make greater use of other digital technologies are also more likely to use generative AI. Although generative AI is a new technology, its pattern of use among individuals seems to follow the path of previous digital divides. The implications of these findings are discussed.}
}
@article{PINTO2024102920,
title = {Assessing information, media and data literacy in academic libraries: Approaches and challenges in the research literature on the topic},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {5},
pages = {102920},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102920},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000818},
author = {Maria Pinto and Javier Garcia-Marco and David Caballero and Ramón Manso and Alejandro Uribe and Carmen Gomez},
keywords = {Information literacy, Media literacy, Academic literacy, Multiliteracies, Academic libraries, Assessment, Systematic literature reviews},
abstract = {A review of the research literature on the assessment of information, media, and data literacy in academic libraries has been carried out with the intention of learning about the main approaches taken; the assessment tools, criteria, and indicators used; and the main challenges for the future. To this end, 60 relevant records were retrieved from the Web of Science Core Collection and Scopus after being filtered according to the Preferred Reporting Items for Systematic review and Meta-Analysis (PRISMA) model. A content analysis of the articles was then carried out using a detailed form based on the objectives, methodology, results, conclusions, and recommendations model in relation to the current aims. Literacy assessment has been conducted primarily in information literacy. Research in anglophone countries and Spain stands out. Much of it relates to academic libraries as a whole, although there are also numerous studies focused on a field of use, primarily health, STEM, and social sciences. Among the most commonly used methods of analysis, case studies stand out, followed by descriptive, exploratory, experimental, and comparative studies; literature reviews; and content analysis. The results are positive, and assessment helps improve programs and demonstrate libraries' impact on student learning. Despite its importance, media literacy assessment is still an emerging field, and data literacy assessment is still largely a work in progress. Academic libraries need to integrate new types of literacy and emerging challenges such as open data, open science, and generative artificial intelligence into the comprehensive framework of information literacy and conduct a systematic assessment of their training programs and activities.}
}
@article{LIU2025103097,
title = {Hierarchical multi-source cues fusion for mono-to-binaural based Audio Deepfake Detection},
journal = {Information Fusion},
volume = {120},
pages = {103097},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103097},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525001708},
author = {Rui Liu and Jinhua Zhang and Haizhou Li},
keywords = {Audio Deepfake Detection, Mono-to-binaural, Multi-source cues fusion},
abstract = {Audio Deepfake Detection (ADD) targets identifying forgery cues in audio generated by text-to-speech (TTS), voice conversion (VC), voice editing, etc. With the advancement of generative artificial intelligence(AI), ADD has gained increasing attention. In recent years, mono-to-binaural (M2B) conversion has been explored in ADD to uncover forgery cues from a novel perspective. However, M2B-based methods may weaken or overlook unique forgery cues specific to mono, limiting detection performance. To this end, this paper proposes a Hierarchical Multi-Source Cues Fusion network for more accurate ADD (HMSCF-ADD). This approach leverages mono alongside binaural left and right channels as three distinct sources for hierarchical information fusion, it distinguishes common and binaural-specific features while removing redundant information for more effective detection. Specifically, binaural-specific and common features are first extracted and fused as binaural information, followed by dynamic fusion of mono and binaural information to achieve hierarchical fusion. Experiments on ASVspoof2019-LA and ASVspoof2021-PA datasets demonstrate that HMSCF-ADD outperforms all mono-input and M2B-based baselines. Detailed comparisons on fusion strategies and M2B conversion further validate the framework’s effectiveness. The codes are available at: https://github.com/AI-S2-Lab/HMSCF-ADD.}
}
@article{KIM2025115498,
title = {From visuals to value: leveraging generative AI to explore the economic implications of movie poster},
journal = {Journal of Business Research},
volume = {198},
pages = {115498},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115498},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325003212},
author = {Youngjun Kim and Hye-Jin Kim and Keeyeon Ki-cheon Park},
keywords = {Movie poster, Mood, Generative artificial intelligence, Film industry, Expectancy violations theory},
abstract = {This study introduces a novel exploration into the impact of visual elements on consumer behavior in the film industry, utilizing generative AI. By employing expectancy violations theory, this study examines how the mood and tone suggested by movie posters—a key visual advertising tool—contrast with the actual content of the films, revealing a significant influence on consumer decisions. Through feature extraction from movie posters using generative AI and regression model analysis, this study demonstrates that deviations from audience expectations, as suggested by movie posters, positively affect box office performance. However, this impact varies depending on whether the movie is produced by major or non-major studios, with major studio productions benefiting more from mood and tone congruence. This study extends existing literature by highlighting the role of visual cues in movie posters and offers practical insights for movie marketers using expectancy violations to enhance audience engagement and box office performance.}
}
@article{LI2025621,
title = {A large manufacturing decision model for human-centric decision-making},
journal = {CIRP Annals},
volume = {74},
number = {1},
pages = {621-625},
year = {2025},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2025.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0007850625000654},
author = {Xingyu Li and Aydin Nassehi and S. Jack Hu and Byung Gun Joung and Robert X. Gao},
keywords = {Manufacturing system, Generative artificial intelligence, Digital twin},
abstract = {To adapt to changing demands and disruptions, manufacturing systems necessitate dynamic reconfiguration, facilitated by growing digitalization, modularity, and autonomy. Such reconfiguration, however, heightens decision-making complexity and the need for human supervision. While Generative AI (GenAI), particularly large language models (LLMs), fosters natural human-resource interactions, existing methods lack manufacturing-specific context. This paper introduces a Large Manufacturing Decision Model (LMDM) leveraging image generative models to precisely represent and generate manufacturing-specific reconfiguration decisions using a digital twin, minimizing data requirements and reducing hallucination risks. Simulation results showcase LMDM's ability to refine system configurations through human guidance, transforming digital twins into human-centric decision-making tools.}
}
@article{CANILLASDELREY202538,
title = {Explorando el potencial de la inteligencia artificial en traumatología: respuestas conversacionales a preguntas específicas},
journal = {Revista Española de Cirugía Ortopédica y Traumatología},
volume = {69},
number = {1},
pages = {38-46},
year = {2025},
issn = {1888-4415},
doi = {https://doi.org/10.1016/j.recot.2024.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1888441524000869},
author = {F. {Canillas del Rey} and M. {Canillas Arias}},
keywords = {Inteligencia artificial generativa, Robot conversacional, Respuesta a preguntas de opción múltiple, ChatGPT, Bard, Perplexity, Generative Artificial Intelligence, Chatbot, Multi-choice question answering, ChatGPT, Bard, Perplexity},
abstract = {Resumen
Antecedentes y objetivo
La inteligencia artificial generativa es una tecnología que ofrece su mayor conectividad con las personas gracias a los bots conversacionales («chatbot»). Estos pueden mantener un diálogo con un lenguaje natural indistinguible del humano y son una fuente potencial de información para los pacientes. El objetivo de este trabajo es estudiar el rendimiento de estos bots en la resolución de cuestiones específicas de cirugía ortopédica y traumatología empleando las preguntas del examen MIR español entre 2008 y 2023.
Material y métodos
Se analizaron 3 modelos de «chatbots» (ChatGPT, Bard y Perplexity) respondiendo a 114 preguntas del MIR. Se compararon aciertos, se valoró la legibilidad de las respuestas y se examinó su dependencia con el razonamiento lógico y la información interna y externa. En los fallos también se evaluó el tipo de error.
Resultados
ChatGPT obtuvo un 72,81% de aciertos, seguido por Perplexity (67,54%) y Bard (60,53%). Las respuestas más legibles y completas las ofrece Bard. Las respuestas demostraron un razonamiento lógico y el uso de información interna de los enunciados de preguntas. En 16 preguntas (14%) las 3 aplicaciones fallaron simultáneamente. Se identificaron errores, que incluían fallos lógicos y de información.
Conclusiones
Aunque los bots conversacionales pueden ser útiles en la resolución de preguntas médicas, se señala la necesidad de precaución debido a la posibilidad de errores. Actualmente deben considerarse como una herramienta en desarrollo y la opinión humana debe prevalecer sobre la inteligencia artificial generativa.
Introduction
Generative Artificial Intelligence is a technology that provides greater connectivity with people through conversational bots («chatbots»). These bots can engage in dialogue using natural language indistinguishable from humans and are a potential source of information for patients.The aim of this study is to examine the performance of these bots in solving specific issues related to orthopedic surgery and traumatology using questions from the Spanish MIR exam between 2008 and 2023.
Material and methods
Three «chatbot» models (ChatGPT, Bard and Perplexity) were analyzed by answering 114 questions from the MIR. Their accuracy was compared, the readability of their responses was evaluated, and their dependence on logical reasoning and internal and external information was examined. The type of error was also evaluated in the failures.
Results
ChatGPT obtained 72.81% correct answers, followed by Perplexity (67.54%) and Bard (60.53%).Bard provides the most readable and comprehensive responses. The responses demonstrated logical reasoning and the use of internal information from the question prompts. In 16 questions (14%), all 3 applications failed simultaneously. Errors were identified, including logical and information failures.
Conclusions
While conversational bots can be useful in resolving medical questions, caution is advised due to the possibility of errors. Currently, they should be considered as a developing tool, and human opinion should prevail over Generative Artificial Intelligence.}
}
@article{ESTEVEZ2025100796,
title = {Market research and knowledge using Generative AI: the power of Large Language Models},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100796},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100796},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001416},
author = {Macarena Estevez and María Teresa Ballestar and Jorge Sainz},
keywords = {Generative AI, Marketing, Market research, LLMs},
abstract = {Generative artificial intelligence (GAI) is rapidly transforming the marketing industry with its capabilities in data analysis, personalisation, strategic optimisation, and content generation, providing powerful tools for businesses aiming to establish or maintain a strong brand position. This research examines the application of Large Language Models (LLMs) for market research, enabling marketers to create insights that capture the complexities of market behaviour and customer psychology, helping them to connect with their target audiences more meaningfully and effectively. Particularly, it aims to evaluate the extent to which GAI can replicate traditional market research. We conducted a comprehensive survey on beer consumption in Spain, covering all conversion funnel stages, from Brand Awareness to Purchase. The study was replicated using four prominent LLMs: ChatGPT (OpenAI), Gemini (Google), Claude (Anthropic) and LlaMa (Meta), and the results of these LLMs were compared with those of the traditional survey using a collection of statistical methods. Our results show that LLMs are valuable for market research, offering significant insights as reliable proxies. This represents a competitive advantage by making studies of this kind more accessible and cost-effective, benefitting companies of all sizes. However, LLMs cannot fully replicate traditional methods and present result variability, introducing risks in decision-making because of potential errors in data generation that are complex to estimate without benchmarking.}
}
@article{TALAEIKHOEI2024102975,
title = {How does incorporating ChatGPT within a firm reinforce agility-mediated performance? The moderating role of innovation infusion and firms’ ethical identity},
journal = {Technovation},
volume = {132},
pages = {102975},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.102975},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224000257},
author = {Amir Talaei-Khoei and Alan T. Yang and Masialeti Masialeti},
keywords = {ChatGPT, Operational agility, Market agility, Ethical identity, Performance.},
abstract = {The expansion of ChatGPT has sparked substantial discussions on the capabilities of generative artificial intelligence AI to profoundly reshape the business environment. However, empirical data on ChatGPT and its effects on firm performance are still lacking. In accordance with relevant literature, this study investigates the influence of ChatGPT-enabled agility, encompassing both operational and market facets, on firm performance. This work studies the moderating roles of innovative infusion of ChatGPT and ethical identity in the association between incorporating ChatGPT into standard processes with operational and market agilities. Data from a survey of IT executives were analyzed to validate our proposed hypotheses. We found that while the infusion of ChatGPT in an organization moderates the relationship between ChatGPT incorporation and operational agility, infusion does not significantly impact market agilities. In addition, we found that a firm's ethical identity moderates ChatGPT-enabled market agilities but not operational agility. We also found that both types of agility play mediating roles in improving firm performance. This study adds to the growing body of literature on dynamic capabilities by presenting and testing a theory on the influence of a firm's capability to incorporate ChatGPT on agility, firm performance, and the role of ChatGPT infusion and firm ethical identity.}
}
@article{KIM2024665,
title = {ChatGPT vs. sleep disorder specialist responses to common sleep queries: Ratings by experts and laypeople},
journal = {Sleep Health},
volume = {10},
number = {6},
pages = {665-670},
year = {2024},
issn = {2352-7218},
doi = {https://doi.org/10.1016/j.sleh.2024.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S2352721824001876},
author = {Jiyoung Kim and Seo-Young Lee and Jee Hyun Kim and Dong-Hyeon Shin and Eun Hye Oh and Jin A Kim and Jae Wook Cho},
keywords = {Sleep disorders, Artificial intelligence, Health information seeking behavior, Medical informatics, Patient education as topic},
abstract = {Background
Many individuals use the Internet, including generative artificial intelligence like ChatGPT, for sleep-related information before consulting medical professionals. This study compared responses from sleep disorder specialists and ChatGPT to common sleep queries, with experts and laypersons evaluating the responses' accuracy and clarity.
Methods
We assessed responses from sleep medicine specialists and ChatGPT-4 to 140 sleep-related questions from the Korean Sleep Research Society's website. In a blinded study design, sleep disorder experts and laypersons rated the medical helpfulness, emotional supportiveness, and sentence comprehensibility of the responses on a 1-5 scale.
Results
Laypersons rated ChatGPT higher for medical helpfulness (3.79 ± 0.90 vs. 3.44 ± 0.99, p < .001), emotional supportiveness (3.48 ± 0.79 vs. 3.12 ± 0.98, p < .001), and sentence comprehensibility (4.24 ± 0.79 vs. 4.14 ± 0.96, p = .028). Experts also rated ChatGPT higher for emotional supportiveness (3.33 ± 0.62 vs. 3.01 ± 0.67, p < .001) but preferred specialists' responses for sentence comprehensibility (4.15 ± 0.74 vs. 3.94 ± 0.90, p < .001). When it comes to medical helpfulness, the experts rated the specialists' answers slightly higher than the laypersons did (3.70 ± 0.84 vs. 3.63 ± 0.87, p = .109). Experts slightly preferred specialist responses overall (56.0%), while laypersons favored ChatGPT (54.3%; p < .001). ChatGPT's responses were significantly longer (186.76 ± 39.04 vs. 113.16 ± 95.77 words, p < .001).
Discussion
Generative artificial intelligence like ChatGPT may help disseminate sleep-related medical information online. Laypersons appear to prefer ChatGPT's detailed, emotionally supportive responses over those from sleep disorder specialists.}
}
@article{TANG2025128644,
title = {ChatSOS: Vector database augmented generative question answering assistant in safety engineering},
journal = {Expert Systems with Applications},
volume = {294},
pages = {128644},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128644},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425022638},
author = {Haiyang Tang and Dongping Chen and Qingzhao Chu and Zhenyi Liu},
keywords = {Large language models, Vector database, Prompt engineering, Safety engineering, Accident analysis},
abstract = {With the rapid advancement of natural language processing technologies, generative artificial intelligence techniques, represented by large language models (LLMs), are gaining increasing prominence and demonstrating significant potential for applications in safety engineering. However, foundational LLMs face constraints such as limited training data coverage and unreliable responses. This study develops a vector database from 117 explosion accident reports in China spanning 2013 to 2023, employing techniques such as corpus segmenting and vector embedding. By utilizing the vector database, which outperforms the relational database in information retrieval quality, we provide LLMs with richer, more relevant knowledge. Comparative analysis of LLMs demonstrates that ChatSOS significantly enhances reliability, accuracy, and comprehensiveness, improves adaptability and clarification of responses. These results illustrate the effectiveness of supplementing LLMs with an external database, highlighting their potential to handle professional queries in safety engineering and laying a foundation for broader applications.}
}
@article{TAKAGI2024,
title = {The Performance of ChatGPT-4V in Interpreting Images and Tables in the Japanese Medical Licensing Exam},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/54283},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000588},
author = {Soshi Takagi and Masahide Koda and Takashi Watari},
keywords = {ChatGPT, medical licensing examination, generative artificial intelligence, medical education, large language model, images, tables, artificial intelligence, AI, Japanese, reliability, medical application, medical applications, diagnostic, diagnostics, online data, web-based data}
}
@article{LERMANNHENESTROSA2025100142,
title = {“Always check important information!” - The role of disclaimers in the perception of AI-generated content},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100142},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100142},
url = {https://www.sciencedirect.com/science/article/pii/S294988212500026X},
author = {Angelica {Lermann Henestrosa} and Joachim Kimmerle},
keywords = {Disclaimer, System transparency, Explainable AI (XAI), Generative artificial intelligence, Credibility perceptions, Science communication},
abstract = {Generative AI, and large language models (LLMs) in particular, have become a prevalent source of digital content. Despite their widespread availability, these models come with critical weaknesses, such as a lack of factual accuracy. Being informed about the advantages and disadvantages of these tools is essential for using AI safely and adequately, yet not everyone is aware of them. Therefore, we explored in three experimental studies how disclaimers affect people's perceptions of AI-authorship and AI-generated content on scientific topics. Additionally, we investigated the impact of information presentation and authorship attributions—whether content is authored solely by AI or co-authored with humans. Across the experiments, no effects of disclaimer type on text perceptions and only minor effects on authorship perceptions were found. In Study 1, an evaluative (vs. neutral) information presentation decreased credibility perceptions, while informing about AI's strengths vs. limitations did not. In addition, we found participants to believe in the machine heuristic, that is, to attribute more accuracy and less bias to AI than to human authors. Study 2 revealed interaction effects between authorship and disclaimer type, providing insights into possible balancing effects of human-AI co-authorship. In Study 3, both strengths and limitations disclaimers induced higher credibility ratings than basic disclaimers. This research suggests that disclaimers fail to univocally influence the perception of AI-generated output. Further interventions should be developed to raise awareness of the capabilities and limitations of LLMs and to advocate for ethical practices in handling AI-generated content, especially regarding factual information.}
}
@article{GAO2024100958,
title = {Enhancing academic performance of business students using generative AI: An interactive-constructive-active-passive (ICAP) self-determination perspective},
journal = {The International Journal of Management Education},
volume = {22},
number = {2},
pages = {100958},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.100958},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724000296},
author = {Ziyi Gao and Jun-Hwa Cheah and Xin-Jean Lim and Xi Luo},
keywords = {ChatGPT, Technology integration, ICAP framework, Self-determination theory, Academic performance, Epistemic curiosity},
abstract = {Generative artificial intelligence (GAI) tools, such as ChatGPT, have emerged as valuable assets in higher education. Despite their potential benefits in academic support, questions persist about the concrete advantages of integrating this technology into learning processes and its impact on academic outcomes. This research addresses this gap by investigating the influence of technology integration on academic performance, employing the Interactive-Constructive-Active-Passive (ICAP) framework and self-determination theory. The empirical findings from Chinese business students using Wenjuanxing platform reveal a positive impact of technology integration on business students' motivation, encompassing their learning desires, self-efficacy, and future beliefs, ultimately leading to enhanced academic performance. Notably, while epistemic curiosity augments the effects of technology integration on learning desires and future beliefs, its influence on self-efficacy is not significant. This suggests that curiosity alone might not be enough to alter deeply ingrained beliefs about one’s capabilities. In conclusion, this study underscores the academic significance of these findings and their practical implications for educators and business students in optimizing ChatGPT’s potential for academic success.}
}
@article{OMALLEY2024,
title = {Ensuring Appropriate Representation in Artificial Intelligence–Generated Medical Imagery: Protocol for a Methodological Approach to Address Skin Tone Bias},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/58275},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000656},
author = {Andrew O'Malley and Miriam Veenhuizen and Ayla Ahmed},
keywords = {artificial intelligence, generative AI, AI images, dermatology, anatomy, medical education, medical imaging, skin, skin tone, United States, educational material, psoriasis, digital imagery},
abstract = {Background
In medical education, particularly in anatomy and dermatology, generative artificial intelligence (AI) can be used to create customized illustrations. However, the underrepresentation of darker skin tones in medical textbooks and elsewhere, which serve as training data for AI, poses a significant challenge in ensuring diverse and inclusive educational materials.
Objective
This study aims to evaluate the extent of skin tone diversity in AI-generated medical images and to test whether the representation of skin tones can be improved by modifying AI prompts to better reflect the demographic makeup of the US population.
Methods
In total, 2 standard AI models (Dall-E [OpenAI] and Midjourney [Midjourney Inc]) each generated 100 images of people with psoriasis. In addition, a custom model was developed that incorporated a prompt injection aimed at “forcing” the AI (Dall-E 3) to reflect the skin tone distribution of the US population according to the 2012 American National Election Survey. This custom model generated another set of 100 images. The skin tones in these images were assessed by 3 researchers using the New Immigrant Survey skin tone scale, with the median value representing each image. A chi-square goodness of fit analysis compared the skin tone distributions from each set of images to that of the US population.
Results
The standard AI models (Dalle-3 and Midjourney) demonstrated a significant difference between the expected skin tones of the US population and the observed tones in the generated images (P<.001). Both standard AI models overrepresented lighter skin. Conversely, the custom model with the modified prompt yielded a distribution of skin tones that closely matched the expected demographic representation, showing no significant difference (P=.04).
Conclusions
This study reveals a notable bias in AI-generated medical images, predominantly underrepresenting darker skin tones. This bias can be effectively addressed by modifying AI prompts to incorporate real-life demographic distributions. The findings emphasize the need for conscious efforts in AI development to ensure diverse and representative outputs, particularly in educational and medical contexts. Users of generative AI tools should be aware that these biases exist, and that similar tendencies may also exist in other types of generative AI (eg, large language models) and in other characteristics (eg, sex, gender, culture, and ethnicity). Injecting demographic data into AI prompts may effectively counteract these biases, ensuring a more accurate representation of the general population.}
}
@article{PARVIZ2025,
title = {AI Anxiety in English Language Education:},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.386135},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000155},
author = {Muhammed Parviz and Francis Arthur},
keywords = {Artificial Intelligence, Anxiety, English Language Education, Field of Study, Teaching Experience},
abstract = {ABSTRACT
Generative Artificial Intelligence (GenAI) is increasingly recognized as a transformative force in education, offering innovative ways to improve teaching and learning. However, integrating these technologies into educational settings poses significant challenges. Teachers often express skepticism and anxiety about implementing GenAI tools due to various factors (e.g., lack of familiarity and concerns about job displacement). This study aimed to investigate the level of AI anxiety (AIA) among Iranian English as a Foreign Language (EFL) teachers, focusing on their perceptions of GenAI tools such as ChatGPT in language teaching. In addition, the research examined differences in AI anxiety based on demographic variables such as age, gender, teaching experience, field of study, and educational level. A total of 444 Iranian EFL teachers from different language education institutions participated in the study, with data collected through an online questionnaire. The results revealed moderate level of AIA among EFL teachers. The study also showed that there were no statistically significant differences in AIA based on the gender, age, field of study, and highest level of education. However, significant difference in AIA among EFL teachers based on their teaching experience was revealed. Specifically, EFL teachers with fewer years of teaching experience (1-3 years) tended to have significantly lower AIA compared to those with moderate teaching experience (4-20 years). To address AIA among EFL teachers, targeted professional development programs should be implemented to enhance teachers’ AI literacy and confidence. Additionally, educational institutions should ensure that AI implementation is accompanied by clear guidelines and pedagogical frameworks to alleviate concerns about job security and teaching autonomy.}
}
@article{CARPO2024100001,
title = {Perspectives in computational design: A brief assessment of today's socio-technical context, promises, and challenges},
journal = {Perspectives in Architecture and Urbanism},
volume = {1},
number = {1},
pages = {100001},
year = {2024},
issn = {2950-2675},
doi = {https://doi.org/10.1016/j.pau.2024.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2950267524000010},
author = {Mario Carpo},
keywords = {Computational design, Digital fabrication, Mass-customization, Robotic automation, Virtual reality, Generative artificial intelligence},
abstract = {Overwhelming factual evidence proves that digital technologies are much better suited to fixing at least some of today's socio-technical problems than the obsolete mechanical technologies we inherited from the twentieth century and which we are, at long last, phasing out. Everyone knows that digital mass-customization is cheaper, faster, smarter, and more environmentally sustainable, than the mechanical mass-production of standardized industrial goods; and everyone knows that the electronic transmission of information is cheaper, faster, smarter, and more environmentally sustainable, than the mechanical transportation of people and goods. Why then are so many neo-Luddite arguments being so vociferously and influentially evoked at all times and in all contexts to the detriment of sheer common sense? In short, why do digital technologies today—in computational design, and in general—have such a bad press?}
}
@article{ALMAZEEDI2025102161,
title = {237 - ChatGPT Follows Standardized Terminology & Practices on Urodynamics’ Interpretation: The New Virtual Functional Urologist},
journal = {Continence},
volume = {15},
pages = {102161},
year = {2025},
note = {ICS-EUS 2025 Abu Dhabi Abstracts},
issn = {2772-9737},
doi = {https://doi.org/10.1016/j.cont.2025.102161},
url = {https://www.sciencedirect.com/science/article/pii/S2772973725007787},
author = {A Almazeedi and N AlBoloushi and A Abdullah and A Almarzouq and T AL-shaiji and S Yaiesh},
abstract = {Hypothesis / aims of study
Since its availability for public usage, ChatGPT and other generative artificial intelligence (gAI) and large language model services have been tested for their ability and utilization in a number of medical diagnostic procedures and surgical education. Over time, ChatGPT’s ability to provide concise assessments and evaluations has improved so has its ability to learn and research true resources and references, while previous concerns about its shortcomings with regard to hallucinations and fallacy, among other issues, are easing. Urodynamic studies’ good practices and terminology have been described and published by the International Continence Society (ICS) and are recommended for practitioners 1, 3. We report on ChatGPTs ability to analyze urodynamic traces correctly before and after teaching it the ICS best practices and terms for urodynamics, cystometry and pressure-flow studies.
Study design, materials and methods
We chose at random urodynamic traces including cystometries and pressure-flow studies conducted at our institution by a single functional urology expert. The traces were then reassessed by another expert, and agreement in the assessments was noted. Any disagreement was resolved by a third expert. ChatGPT 4o was used, and it was asked to analyze the same traces twice: first batch without instruction to use certain resources or teaching, and the second batch after it was taught and instructed to use the ICS standards 1, 3. Parameters analyzed include components of the urodynamics traces as well as select nomograms, overall diagnosis and devising a management plan accordingly. Concordance with expert opinion before and after teaching ChatGPT was calculated and statistical significance of the teaching was calculated using McNemar’s test. Institutional board review approval was obtained.
Results
We analyzed a total of 100 urodynamic traces of different etiologies, of which 75% were of female patients. The most common presenting complaint was mixed urinary incontinence, while the most common diagnosis was non-neurogenic dry detrusor overactivity. With regards to assessments of filling cystometry results, ChatGPT did not exhibit any improvement or regression in its ability to correctly diagnose dysfunctions in sensation (p=1), cystometric capacity (p=0.1336), bladder compliance (p=0.4795), urinary incontinence (p=0.3711), and electromyography (EMG) synergy or dyssynergia (p=0.7728). The only parameter that reached some statistical significance was ChatGPTs ability to identify uninhibited detrusor contractions after teaching it (p=0.07). In a similar manner, ChatGPT’s ability to assess voided volume, detrusor pressure at maximal flow (Pdet@Qmax), maximum urinary flow rate (Qmax), and identify after contractions remained unchanged after instruction and teaching (p>0.1), as well as its ability to calculate the bladder contractility index (p=0.25), provide an overall diagnosis (p=1) and formulate an appropriate management plan (p=0.13).
Interpretation of results
This study demonstrates that ChatGPT-4o has a consistent baseline ability to interpret urodynamic traces irrespective of formal instruction. Notably, its capacity to identify uninhibited detrusor contractions improved following exposure to ICS terminology and standards (p = 0.07), suggesting promise for refinement with targeted training.
Concluding message
Our findings underscore ChatGPT’s emerging utility in functional urology as a consistent, adaptable tool with the potential to support clinical education and decision-making. To enhance ChatGPT’s accuracy in interpreting urodynamic studies, future development should focus on multimodal fine-tuning using annotated trace-image datasets aligned with ICS standards, and gAI may eventually play a valuable role in standardizing and scaling access to urodynamic interpretation expertise. Funding none Clinical Trial No Subjects Human Ethics Committee IRB jaber alahmed hospital Helsinki Yes Informed Consent Yes}
}
@article{SIKSTROM2024105140,
title = {Pedagogical agents communicating and scaffolding students' learning: High school teachers' and students' perspectives},
journal = {Computers & Education},
volume = {222},
pages = {105140},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105140},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524001544},
author = {Pieta Sikström and Chiara Valentini and Anu Sivunen and Tommi Kärkkäinen},
keywords = {Pedagogical agent, Secondary education, User-centered design, Human–machine communication (HMC), Human-to-human communication script},
abstract = {Pedagogical agents (PAs) communicate verbally and non-verbally with students in digital and virtual reality/augmented reality learning environments. PAs have been shown to be beneficial for learning, and generative artificial intelligence, such as large language models, can improve PAs' communication abilities significantly. K-12 education is underrepresented in learning technology research and teachers' and students' insights have not been considered when developing PA communication. The current study addresses this research gap by conducting and analyzing semi-structured, in-depth interviews with eleven high school teachers and sixteen high school students about their expectations for PAs' communication capabilities. The interviewees identified relational and task-related communication capabilities that a PA should perform to communicate effectively with students and scaffold their learning. PA communication that is simultaneously affirmative and relational can induce immediacy, foster the relationship and engagement with a PA, and support students' learning management. Additionally, the teachers and students described the activities and technological aspects that should be considered when designing conversational PAs. The study showed that teachers and students applied human-to-human communication scripts when outlining their desired PA communication characteristics. The study offers novel insights and recommendations to researchers and developers on the communicational, pedagogical, and technological aspects that must be considered when designing communicative PAs that scaffold students’ learning, and discusses the contributions on human–machine communication in education.}
}
@article{BOFFA202541,
title = {L’intelligence artificielle en santé},
journal = {Actualités Pharmaceutiques},
volume = {64},
number = {649},
pages = {41-44},
year = {2025},
issn = {0515-3700},
doi = {https://doi.org/10.1016/j.actpha.2025.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0515370025003386},
author = {Aymeric Boffa and Pierre Renaudin},
keywords = {intelligence artificielle, intelligence artificielle générative, intelligence artificielle symbolique, machine learning, santé, soin pharmaceutique, artificial intelligence, generative artificial intelligence, health, machine learning, pharmaceutical care, symbolic artificial intelligence},
abstract = {L’intelligence artificielle (IA) en santé regroupe l’IA symbolique, utilisée dans les systèmes d’aide à la décision pharmaceutique, et l’IA générative, fondée sur l’apprentissage machine. La première est fiable et explicable mais limitée par la structuration des données. La seconde, plus récente, permet des usages comme la retranscription d’ordonnances ou d’entretiens pharmaceutiques, bien que ses performances soient encore perfectibles. L’IA reste un outil au service du pharmacien, nécessitant rigueur et esprit critique.
Artificial intelligence in healthcare
Artificial intelligence (AI) in healthcare encompasses symbolic AI, used in pharmaceutical decision support systems, and generative AI, based on machine learning. The former is reliable and explainable, but limited by data structuring. The latter is more recent, and can be used to transcribe prescriptions or pharmaceutical interviews, although its performance can still be perfected. AI remains a tool at the pharmacist’s service, requiring rigor and critical thinking.}
}
@article{CANILLASDELREY2025T38,
title = {[Translated article] Exploring the potential of artificial intelligence in traumatology: Conversational answers to specific questions},
journal = {Revista Española de Cirugía Ortopédica y Traumatología},
volume = {69},
number = {1},
pages = {T38-T46},
year = {2025},
issn = {1888-4415},
doi = {https://doi.org/10.1016/j.recot.2024.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1888441524001802},
author = {F. {Canillas del Rey} and M. {Canillas Arias}},
keywords = {Generative artificial intelligence, Chatbot, Multi-choice question answering, ChatGPT, Bard, Perplexity, Inteligencia artificial generativa, Robot conversacional, Respuesta a preguntas de opción múltiple, ChatGPT, Bard, Perplexity},
abstract = {Background and objective
Generative artificial intelligence is a technology that provides greater connectivity with people through conversational bots (“chatbots”). These bots can engage in dialogue using natural language indistinguishable from humans and are a potential source of information for patients. The aim of this study is to examine the performance of these bots in solving specific issues related to orthopedic surgery and traumatology using questions from the Spanish MIR exam between 2008 and 2023.
Material and methods
Three “chatbot” models (ChatGPT, Bard and Perplexity) were analyzed by answering 114 questions from the MIR. Their accuracy was compared, the readability of their responses was evaluated, and their dependence on logical reasoning and internal and external information was examined. The type of error was also evaluated in the failures.
Results
ChatGPT obtained 72.81% correct answers, followed by Perplexity (67.54%) and Bard (60.53%). Bard provides the most readable and comprehensive responses. The responses demonstrated logical reasoning and the use of internal information from the question prompts. In 16 questions (14%), all three applications failed simultaneously. Errors were identified, including logical and information failures.
Conclusions
While conversational bots can be useful in resolving medical questions, caution is advised due to the possibility of errors. Currently, they should be considered as a developing tool, and human opinion should prevail over generative artificial intelligence.
Resumen
Antecedentes y objetivo
La inteligencia artificial generativa es una tecnología que ofrece su mayor conectividad con las personas gracias a los bots conversacionales («chatbot»). Estos pueden mantener un diálogo con un lenguaje natural indistinguible del humano y son una fuente potencial de información para los pacientes. El objetivo de este trabajo es estudiar el rendimiento de estos bots en la resolución de cuestiones específicas de cirugía ortopédica y traumatología empleando las preguntas del examen MIR español entre 2008 y 2023.
Material y métodos
Se analizaron 3 modelos de «chatbots» (ChatGPT, Bard y Perplexity) respondiendo a 114 preguntas del MIR. Se compararon aciertos, se valoró la legibilidad de las respuestas y se examinó su dependencia con el razonamiento lógico y la información interna y externa. En los fallos también se evaluó el tipo de error.
Resultados
ChatGPT obtuvo un 72,81% de aciertos, seguido por Perplexity (67,54%) y Bard (60,53%). Las respuestas más legibles y completas las ofrece Bard. Las respuestas demostraron un razonamiento lógico y el uso de información interna de los enunciados de preguntas. En 16 preguntas (14%) las 3 aplicaciones fallaron simultáneamente. Se identificaron errores, que incluían fallos lógicos y de información.
Conclusiones
Aunque los bots conversacionales pueden ser útiles en la resolución de preguntas médicas, se señala la necesidad de precaución debido a la posibilidad de errores. Actualmente deben considerarse como una herramienta en desarrollo, y la opinión humana debe prevalecer sobre la inteligencia artificial generativa.}
}
@article{WU20243481,
title = {Towards generative digital twins in biomedical research},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {3481-3488},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024003192},
author = {Jiqing Wu and Viktor H. Koelzer},
keywords = {Generative AI, Spatial omics, Multiplexed imaging, Digital twin},
abstract = {Digital twins in biomedical research, i.e. virtual replicas of biological entities such as cells, organs, or entire organisms, hold great potential to advance personalized healthcare. As all biological processes happen in space, there is a growing interest in modeling biological entities within their native context. Leveraging generative artificial intelligence (AI) and high-volume biomedical data profiled with spatial technologies, researchers can recreate spatially-resolved digital representations of a physical entity with high fidelity. In application to biomedical fields such as computational pathology, oncology, and cardiology, these generative digital twins (GDT) thus enable compelling in silico modeling for simulated interventions, facilitating the exploration of ‘what if’ causal scenarios for clinical diagnostics and treatments tailored to individual patients. Here, we outline recent advancements in this novel field and discuss the challenges and future research directions.}
}
@article{KO2025,
title = {Users’ Needs for Mental Health Apps: Quality Evaluation Using the User Version of the Mobile Application Rating Scale},
journal = {JMIR mHealth and uHealth},
volume = {13},
year = {2025},
issn = {2291-5222},
doi = {https://doi.org/10.2196/64622},
url = {https://www.sciencedirect.com/science/article/pii/S2291522225000981},
author = {Siyeon Ko and Hyekyung Woo},
keywords = {app user perspective, user evaluation, mental health care, digital health, mobile app, mHealth, mental health, app, evaluation study, mobile health, quality, user, user perspective, Google Play Store, correlation analysis, regression analysis, technology, generative AI, app quality, smartphone},
abstract = {Background
Mental health is an essential element of life. However, existing mental health services face challenges in utilization due to issues such as societal prejudices and a shortage of counselors. Mobile health is gaining attention as an alternative approach to improving mental health by addressing the shortcomings of traditional services. As a result, various mental health apps are being developed, but there is a lack of evaluation research on whether these apps meet users’ needs.
Objective
This study aims to evaluate the content and quality of mental health apps from the user’s perspective and identify the content features that influence evaluation scores. We also aim to guide future updates and improvements in mental health apps to deliver high-quality solutions to users.
Methods
We searched the Google Play Store and iOS App Store using Korean keywords “mental health,” “mental health care,” “depression,” and “stress.” Apps meeting the following criteria were selected for the study: relevance to the topic, written in Korean, more than 700 reviews (Android) or more than 200 reviews (iOS), updated within the past 365 days, available for free, nonduplicate, and currently operational. After identifying and defining the primary contents of the apps, 7 users evaluated their quality using the user version of the Mobile Application Rating Scale (uMARS). Correlation analysis was performed to examine the relationships among app content, uMARS scores, star ratings, and the number of reviews. Multiple regression analysis was conducted to identify the factors influencing uMARS scores and each evaluation item.
Results
The analysis included a total of 41 mental health apps. Content analysis revealed that reminders (n=29, 71%), recording and statistics features (n=29, 71%), and diaries (n=24, 59%) were the most common app components. The top-rated apps, as determined by uMARS evaluations, consistently provided information about counselors and counseling agencies, and included counseling services. uMARS scores were significantly correlated with the presence of health care provider information (r=0.53; P<.001) and counseling/question and answer services (r=0.55; P<.001). Multiple regression analysis indicated that providing more relevant information was associated with higher uMARS scores (β=.361; P=.02).
Conclusions
The quality of mental health apps was evaluated from the user’s perspective using a validated scale. To deliver a high-quality mental health app, it is essential to incorporate app technologies such as generative artificial intelligence during development and to continuously monitor app quality from the user’s perspective.}
}
@incollection{GAUR202657,
title = {Chapter 4 - Explainability in generative AI and large language models},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {57-74},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00002-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000023},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Black box models, Ethical AI, Interpretability, Model accountability, Model explainability, Transparency, Trustworthiness},
abstract = {Explainability is critical in the context of generative artificial intelligence (AI) models, including large language models (LLMs), which are increasingly used in high-impact areas such as personalized recommendations and automated decision-making. Without a clear understanding of how these models arrive at their conclusions, there is a risk of unintentional consequences and ethical concerns. Furthermore, the lack of explainability in AI models can delay their adoption and public trust, as users may be hesitant to rely on systems they cannot fully understand or verify. The balance between explainability and performance in AI models is a complex and ongoing challenge. As the field of AI continues to evolve, researchers and practitioners must find ways to maintain transparency and accountability while still leveraging the power of advanced machine learning techniques to push the boundaries of what is possible. The chapter will delve into explainability techniques for generative AI and LLMs. Also, case studies demonstrate the importance of explainability in healthcare decision-making.}
}
@article{TENG2025103848,
title = {Understanding EFL Student Writers’ Metacognitive awareness in utilizing ChatGPT},
journal = {System},
pages = {103848},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103848},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002581},
author = {Mark Feng Teng},
keywords = {ChatGPT, academic writing, metacognitive awareness, digital education},
abstract = {Understanding metacognition in using generative artificial intelligence (GenAI) for academic writing is a research gap. This mixed-method study of combining survey data with interview insights aims to bridge this gap of understanding EFL learners’ metacognitive awareness in utilizing ChatGPT for EFL academic writing feedback and their metacognitive practices and experiences in using ChatGPT to obtain feedback for writing. The research involved 452 EFL undergraduate students enrolled in a semester-long writing course. The quantitative analysis confirmed the validity of the metacognitive awareness scale, providing a robust measure for assessing learners’ awareness in using ChatGPT for writing. Complementing these findings, the qualitative analysis of interview data offered a detailed understanding of students’ metacognitive awareness. The results revealed varied levels of metacognitive awareness in GenAI use, ranging from simply copying words generated by ChatGPT to effectively leveraging the tool for writing feedback and improvement. These findings underscore the complex interplay between ChatGPT and human writers, emphasizing the need for ethical considerations in its use. The study highlights a need to foster metacognitive awareness to ensure students’ engagement with ChatGPT responsibly, using it as a tool for writing rather than as a substitute for genuine effort.}
}
@article{FARBER2024,
title = {Physicians’ and Patients’ Expectations From Digital Agents for Consultations: Interview Study Among Physicians and Patients},
journal = {JMIR Human Factors},
volume = {11},
year = {2024},
issn = {2292-9495},
doi = {https://doi.org/10.2196/49647},
url = {https://www.sciencedirect.com/science/article/pii/S2292949524000737},
author = {Andri Färber and Christiane Schwabe and Philipp H Stalder and Mateusz Dolata and Gerhard Schwabe},
keywords = {adherence to treatment, digital agents, eHealth, electronic medical records, health literacy, mobile health, mHealth, mobile phone},
abstract = {Background
Physicians are currently overwhelmed by administrative tasks and spend very little time in consultations with patients, which hampers health literacy, shared decision-making, and treatment adherence.
Objective
This study aims to examine whether digital agents constructed using fast-evolving generative artificial intelligence, such as ChatGPT, have the potential to improve consultations, adherence to treatment, and health literacy. We interviewed patients and physicians to obtain their opinions about 3 digital agents—a silent digital expert, a communicative digital expert, and a digital companion (DC).
Methods
We conducted in-depth interviews with 25 patients and 22 physicians from a purposeful sample, with the patients having a wide age range and coming from different educational backgrounds and the physicians having different medical specialties. Transcripts of the interviews were deductively coded using MAXQDA (VERBI Software GmbH) and then summarized according to code and interview before being clustered for interpretation.
Results
Statements from patients and physicians were categorized according to three consultation phases: (1) silent and communicative digital experts that are part of the consultation, (2) digital experts that hand over to a DC, and (3) DCs that support patients in the period between consultations. Overall, patients and physicians were open to these forms of digital support but had reservations about all 3 agents.
Conclusions
Ultimately, we derived 9 requirements for designing digital agents to support consultations, treatment adherence, and health literacy based on the literature and our qualitative findings.}
}
@article{LEE2026103059,
title = {Development and validation of Generative AI Competence Scale (GenAIComp) among university students},
journal = {Technology in Society},
volume = {84},
pages = {103059},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103059},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002490},
author = {Seul Chan Lee and Tiju Baby and Rattawut Vongvit and Jieun Lee and Young Woo Kim and Min Chul Cha and Sol Hee Yoon},
keywords = {Generative AI, AI competence, Digital literacy, GenAIComp},
abstract = {The rapid development of Generative Artificial Intelligence (Generative AI) across several sectors underscores the need for a systematic tool to evaluate AI competence. Current digital literacy frameworks lack AI-specific competencies, resulting in inconsistencies in the assessment of AI competence. This study aims to establish a standardized assessment framework for Generative AI competence by identifying key skill factors and empirically validating a structured evaluation tool called the Generative AI Competence Scale (GenAIComp). The proposed GenAIComp has five essential factors: Information and Data Literacy, Communication and Collaboration, Digital Content Creation, Safety and Ethics, and Problem-Solving. A quantitative approach was employed, incorporating expert validation, pilot testing, and extensive empirical evaluation involving 1000 participants, principally university students. The factor analysis confirmed a robust 5-factor structure with strong psychometric properties. The final model demonstrated excellent fit indices, confirming its reliability and validity in assessing Generative AI competence across the five key factors. Research demonstrates that educational background considerably impacts AI competence, with individuals from technical disciplines showing a greater aptitude for problem-solving and content generation. Gender-based disparities were noted, with males achieving marginally higher scores in several factors, but with minimal effect sizes. Correlation analysis indicated that perceived AI expertise and frequency of AI utilization significantly influenced competence, especially in data literacy and problem-solving, and exhibited less correlation with ethical awareness. GenAIComp provides a reliable tool for assessing AI competence, helping educators, industry experts, and policymakers to design AI training programs and integrate AI literacy into curricula and thereby AI technology advancement in society. Future research should explore its applicability across cultures and include performance-based assessments to enhance AI competence.}
}
@article{SEE2025111919,
title = {New directions in mapping the Earth’s surface with citizen science and generative AI},
journal = {iScience},
volume = {28},
number = {3},
pages = {111919},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.111919},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225001798},
author = {Linda See and Qingqing Chen and Andrew Crooks and Juan Carlos {Laso Bayas} and Dilek Fraisl and Steffen Fritz and Ivelina Georgieva and Gerid Hager and Martin Hofer and Myroslava Lesiv and Žiga Malek and Milutin Milenković and Inian Moorthy and Fernando Orduña-Cabrera and Katya Pérez-Guzmán and Dmitry Schepaschenko and Maria Shchepashchenko and Jan Steinhauser and Ian McCallum},
keywords = {Earth sciences, Environmental science, Remote sensing, Cartography},
abstract = {Summary
As more satellite imagery has become openly available, efforts in mapping the Earth’s surface have accelerated. Yet the accuracy of these maps is still limited by the lack of in situ data needed to train machine learning algorithms. Citizen science has proven to be a valuable approach for collecting in situ data through applications like Geo-Wiki and Picture Pile, but better approaches for optimizing volunteer time are still required. Although machine learning is being used in some citizen science projects, advances in generative artificial intelligence (AI) are yet to be fully exploited. This paper discusses how generative AI could be harnessed for land cover/land use mapping by enhancing citizen science approaches with multi-modal large language models (MLLMs), including improvements to the spatial awareness of AI.}
}
@article{WANG2025112626,
title = {Air quality index prediction through TimeGAN data recovery and PSO-optimized VMD-deep learning framework},
journal = {Applied Soft Computing},
volume = {170},
pages = {112626},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112626},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624014005},
author = {Kenan Wang and Tianning Yang and Shanshan Kong and Mingduo Li},
keywords = {Time Generative Adversarial Network, Air Quality Index Prediction, Deep learning model, Optimization algorithm, Variational Mode Decomposition},
abstract = {With the rapid development of the economy, air pollution has become increasingly severe. Accurate prediction of the Air Quality Index (AQI) is crucial for safeguarding public health and the environment. However, AQI time series exhibit strong randomness and volatility, posing challenges for traditional forecasting methods to achieve precise AQI predictions. Therefore, we propose a new AQI hybrid prediction model, TG-Hybrid model, which integrates generative artificial intelligence, signal decomposition techniques, artificial intelligence methods, and optimization algorithms. In the proposed model, missing values in the data are handled using generative adversarial networks, effectively addressing the issue of a large number of missing values in time series data. Autoregressive integrated moving average is employed to forecast the linear components of the data, while variational mode decomposition decomposes AQI into multiple modes. Particle swarm optimization is used to combine the prediction results of convolutional neural network combined with bidirectional long short-term memory and extreme gradient boosting. Additionally, AQI prediction experiments were conducted using air pollution data from Tangshan and Beijing, and compared with fifteen other models. The results indicate that the root mean square error for Tangshan and Beijing are 6.407 and 7.485, respectively, significantly outperforming other baseline models.}
}
@article{CHAN2025100344,
title = {Automatic item generation in various STEM subjects using large language model prompting},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100344},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100344},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001474},
author = {Kuang Wen Chan and Farhan Ali and Joonhyeong Park and Kah Shen Brandon Sham and Erdalyn Yeh Thong Tan and Francis Woon Chien Chong and Kun Qian and Guan Kheng Sze},
keywords = {Generative artificial intelligence, Large language model, Automatic item generation, STEM education, Assessment},
abstract = {Large language models (LLMs) that power chatbots such as ChatGPT have capabilities across numerous domains. Teachers and students have been increasingly using chatbots in science, technology, engineering, and mathematics (STEM) subjects in various ways, including for assessment purposes. However, there has been a lack of systematic investigation into LLMs’ capabilities and limitations in automatically generating items for STEM subject assessments, especially given that LLMs can hallucinate and may risk promoting misconceptions and hindering conceptual understanding. To address this, we systematically investigated LLMs' conceptual understanding and quality of working in generating question and answer pairs across various STEM subjects. We used prompt engineering on GPT-3.5 and GPT-4 with three different approaches: standard prompting, standard prompting with added chain-of-thought prompting using worked examples with steps, and the chain-of-thought prompting with coding language. The questions and answer pairs were generated at the pre-university level in the three STEM subjects of chemistry, physics, and mathematics and evaluated by subject-matter experts. We found that LLMs generated quality questions when using the chain-of-thought prompting for both GPT-3.5 and GPT-4 and when using the chain-of-thought prompting with coding language for GPT-4 overall. However, there were varying patterns in generating multistep answers, with differences in final answer and intermediate step accuracy. An interesting finding was that the chain-of-thought prompting with coding language for GPT-4 significantly outperformed the other approaches in generating correct final answers while demonstrating moderate accuracy in generating multistep answers correctly. In addition, through qualitative analysis, we identified domain-specific prompting patterns across the three STEM subjects. We then discussed how our findings aligned with, contradicted, and contributed to the current body of knowledge on automatic item generation research using LLMs, and the implications for teachers using LLMs to generate STEM assessment items.}
}
@article{MERONOPENUELA2025100847,
title = {KG.GOV: Knowledge graphs as the backbone of data governance in AI},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100847},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100847},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000337},
author = {Albert Meroño-Peñuela and Elena Simperl and Anelia Kurteva and Ioannis Reklos},
keywords = {Knowledge graphs, AI, Governance},
abstract = {As (generative) Artificial Intelligence continues to evolve, so do the challenges associated with governing the data that powers it. Ensuring data quality, privacy, security, and ethical use become more and more challenging due to the increasing volume and variety of the data, the complexity of AI models, and the rapid pace of technological advancement. Knowledge graphs have the potential to play a significant role in enabling data governance in AI, as we move beyond their traditional use as data organisational systems. To address this, we present KG.gov, a framework that positions KGs at a higher abstraction level within AI workflows, and enables them as a backbone of AI data governance. We illustrate the three dimensions of KG.gov: modelling data, alternative representations, and describing behaviour; and describe the insights and challenges of three use cases implementing them: Croissant, a vocabulary to model and document ML datasets; WikiPrompts, a collaborative KG of prompts and prompt workflows to study their behaviour at scale; and Multimodal transformations, an approach for multimodal KGs harmonisation and completion aiming at broadening access to knowledge.}
}
@article{DIRO2025103960,
title = {Workplace security and privacy implications in the GenAI age: A survey},
journal = {Journal of Information Security and Applications},
volume = {89},
pages = {103960},
year = {2025},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103960},
url = {https://www.sciencedirect.com/science/article/pii/S221421262400262X},
author = {Abebe Diro and Shahriar Kaisar and Akanksha Saini and Samar Fatima and Pham Cong Hiep and Fikadu Erba},
keywords = {Cybersecurity, Generative AI, ChatGPT, Bard, Privacy, Security, Ethics},
abstract = {Generative Artificial Intelligence (GenAI) is transforming the workplace, but its adoption introduces significant risks to data security and privacy. Recent incidents underscore the urgency of addressing these issues. This comprehensive survey investigates the implications of GenAI integration in workplaces, focusing on its impact on organizational operations and security. We analyze vulnerabilities within GenAI systems, threats they face, and repercussions of AI-driven workplace monitoring. By examining diverse attack vectors like model attacks and automated cyberattacks, we expose their potential to undermine data integrity and privacy. Unlike previous works, this survey specifically focuses on the security and privacy implications of GenAI within workplace settings, addressing issues like employee monitoring, deepfakes, and regulatory compliance. We delve into emerging threats during model training and usage phases, proposing countermeasures such as differential privacy for training data and robust authentication for access control. Additionally, we provide a comprehensive analysis of evolving regulatory frameworks governing AI tools globally. Based on our comprehensive analysis, we propose targeted recommendations for future research and policy-making to promote responsible and secure adoption of GenAI in the workplace, such as incentivizing the development of explainable AI (XAI) and establishing clear guidelines for ethical data usage. This survey equips stakeholders with a comprehensive understanding of GenAI’s complex workplace landscape, empowering them to harness its benefits responsibly while mitigating risks.}
}
@article{GIUNTI2024,
title = {Cocreating an Automated mHealth Apps Systematic Review Process With Generative AI: Design Science Research Approach},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48949},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000205},
author = {Guido Giunti and Colin P Doherty},
keywords = {generative artificial intelligence, mHealth, ChatGPT, evidence-base, apps, qualitative study, design science research, eHealth, mobile device, AI, language model, mHealth intervention, generative AI, AI tool, software code, systematic review, language model},
abstract = {Background
The use of mobile devices for delivering health-related services (mobile health [mHealth]) has rapidly increased, leading to a demand for summarizing the state of the art and practice through systematic reviews. However, the systematic review process is a resource-intensive and time-consuming process. Generative artificial intelligence (AI) has emerged as a potential solution to automate tedious tasks.
Objective
This study aimed to explore the feasibility of using generative AI tools to automate time-consuming and resource-intensive tasks in a systematic review process and assess the scope and limitations of using such tools.
Methods
We used the design science research methodology. The solution proposed is to use cocreation with a generative AI, such as ChatGPT, to produce software code that automates the process of conducting systematic reviews.
Results
A triggering prompt was generated, and assistance from the generative AI was used to guide the steps toward developing, executing, and debugging a Python script. Errors in code were solved through conversational exchange with ChatGPT, and a tentative script was created. The code pulled the mHealth solutions from the Google Play Store and searched their descriptions for keywords that hinted toward evidence base. The results were exported to a CSV file, which was compared to the initial outputs of other similar systematic review processes.
Conclusions
This study demonstrates the potential of using generative AI to automate the time-consuming process of conducting systematic reviews of mHealth apps. This approach could be particularly useful for researchers with limited coding skills. However, the study has limitations related to the design science research methodology, subjectivity bias, and the quality of the search results used to train the language model.}
}
@article{LI2025,
title = {The Agentic-AI Core: An AI-Empowered, Mission-Oriented Core Network for Next-Generation Mobile Telecommunications},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S209580992500325X},
author = {Xu Li and Weisen Shi and Hang Zhang and Chenghui Peng and Shaoyun Wu and Wen Tong},
keywords = {6G, Core network, Generative artificial intelligence, Artificial intelligence agent},
abstract = {While the complexity of fifth-generation wireless networks is being widely commented upon, there is great anticipation for the arrival of the sixth generation (6G), with its enriched capabilities and features. It can easily be imagined that, without proper design, the enrichment of 6G will further increase system complexity. To address this issue, we propose the Agentic-AI Core (A-Core), an artificial intelligence (AI)-empowered, mission-oriented core network architecture for next-generation mobile telecommunications. In A-Core, network capabilities can be added and updated on the fly and further programmed into missions for enabling and offering diverse services to customers. These missions are created and executed by autonomous network agents according to the customer’s intent, which may be expressed in natural language. The agents resolve intents from customers into workflows of network capabilities by leveraging a large-scale network AI model and follow the workflows to execute the mission. As an open, agile system architecture, A-Core holds promise for accelerating innovation and greatly reducing standard release times. The advantages of A-Core are demonstrated through two use cases.}
}
@article{WANG2026103581,
title = {Entropy-regulated cross-modal generative fusion for multimodal network intrusion detection},
journal = {Information Fusion},
volume = {126},
pages = {103581},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103581},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525006530},
author = {Xiangbin Wang and Qingjun Yuan and Wentao Yu and Qianwei Meng and Siqi Lu and Wenqi He and Chunxiang Gu and Yongjuan Wang},
keywords = {Generative artificial intelligence, Intrusion detection system, Multimodal fusion, Diffusion model, Cross-modal representation, Differential entropy},
abstract = {With the increasing popularity of network encryption protocols, analyzing encrypted traffic has become a significant challenge for network security. In this context, deep learning methods have been widely applied to intrusion detection and traffic classification tasks due to their powerful feature extraction capabilities. However, these methods still face two main limitations: relying on unimodal feature extraction, which ignores the multimodal characteristics of network traffic, or adopting simple static fusion strategies, which may fail to capture the complex semantic associations between different modalities. These limitations make it challenging for models to detect sophisticated attacks concealed within otherwise normal encrypted traffic. To address this challenge, this paper introduces an Entropy-Regulated Cross-Modal Generative Framework for Intrusion Detection (ER-CMGI), which combines the generative power of diffusion models with dynamic information-theoretic optimization techniques. The framework integrates variational autoencoders(VAEs) with a lightweight diffusion model for multimodal feature extraction and generation. It implements an adaptive fusion mechanism using a hybrid entropy-based approach that combines both traditional low-entropy priority and inverse entropy weighting through learnable mixing coefficients. The cross-modal generation consistency is achieved through a lightweight diffusion model, which enables self-supervised learning via direct cross-modal generation and comparison. This design enhances semantic alignment across heterogeneous modalities through cross-modal generative learning. Experimental results show that the proposed model achieves F1 scores of 99.12% and 97.81% on two datasets, respectively. This study presents a dynamically adaptive and entropy-guided framework for intrusion detection in network environments, which shows effectiveness in capturing complex attack patterns. By integrating dynamic feature fusion with cross-modal semantic modeling, the framework enhances detection accuracy and interpretability, offering a promising approach for improving network security under evolving threat scenarios.}
}
@article{LIU2024108362,
title = {Unpacking the role of motivation and enjoyment in AI-mediated informal digital learning of English (AI-IDLE): A mixed-method investigation in the Chinese context},
journal = {Computers in Human Behavior},
volume = {160},
pages = {108362},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108362},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002309},
author = {Guangxiang Leon Liu and Ron Darvin and Chaojun Ma},
keywords = {Motivation, Enjoyment, Informal digital learning of English, AI-Mediated informal language learning, Language learning beyond the classroom},
abstract = {This paper examines how Chinese university students negotiate their second language (L2) motivational dynamics, including their ideal and ought-to L2 selves, to participate in informal digital learning of English (IDLE) mediated by generative artificial intelligence (AI). It demonstrates the extent to which enjoyment, the most observable positive emotion in L2 learning, influences their involvement in AI-mediated IDLE (AI-IDLE) activities. Employing an explanatory sequential mixed-method design, this study surveyed 690 Chinese undergraduate students and conducted 12 post-survey interviews. Using a structural equation modeling approach, the quantitative analysis reveals that participants’ ideal L2 self can significantly predict both their sense of enjoyment and AI-IDLE, while the ought-to L2 self is only able to directly predict enjoyment. The quantitative results also demonstrate that enjoyment can partially mediate the relationship between the ideal L2 self and AI-IDLE and simultaneously fully channel the indirect impact of the ought-to L2 self on AI-IDLE. Supplementing these quantitative findings, the interview data provides a nuanced understanding of how motivation and enjoyment shift and interact with learning contexts as participants engage in AI-IDLE. Drawing on these quantitative and qualitative insights, this study identifies implications for pedagogy, particularly in terms of motivating Chinese university students to engage in IDLE while maintaining emotional well-being in the age of generative AI.}
}
@article{BERTOMEU2025101782,
title = {The impact of generative AI on information processing: Evidence from the ban of ChatGPT in Italy},
journal = {Journal of Accounting and Economics},
volume = {80},
number = {1},
pages = {101782},
year = {2025},
issn = {0165-4101},
doi = {https://doi.org/10.1016/j.jacceco.2025.101782},
url = {https://www.sciencedirect.com/science/article/pii/S0165410125000187},
author = {Jeremy Bertomeu and Yupeng Lin and Yibin Liu and Zhenghui Ni},
keywords = {Generative AI, ChatGPT, Analyst, Information processing, Market efficiency},
abstract = {This paper explores how the emergence of generative artificial intelligence is reshaping the information environment in capital markets. Leveraging an unexpected ban on ChatGPT in Italy, we examine its impact on the information processing capabilities of market participants. We employ metrics for AI-generated text detection to show that the ban coincides with decreased AI usage by domestic financial analysts and fewer earnings forecasts issued relative to foreign analysts covering the same firm. The negative effects are more pronounced among analysts whose pre-ban reports are more consistent with AI use or analysts with a technical background. The ban also diminishes forecast accuracy, increases reliance on industry-specific information, and reduces information efficiency. Furthermore, investor reactions to earnings announcements become more pronounced, and bid–ask spreads widen, reflecting lower market efficiency.}
}
@article{BIRKHOLZ2025102520,
title = {Navigating artificial intelligence in nursing: An ethical exploration of benefits, risks, and educational shifts},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102520},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102520},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001733},
author = {Lorri Birkholz and Michael Martin and Brenda Barnum and Linda Breslin and Shika Kalevor},
keywords = {Artificial intelligence, Nursing, Nursing ethics, Nursing care, Academic integrity},
abstract = {A significant challenge of generative artificial intelligence (AI) is the gap between technological advancements and policies to guide their ethical use. The integration of AI in all aspects of nursing is poised to revolutionize the delivery of nursing care to patients. As such, nursing practice and educational programs will be required to adapt to these advancing technologies while maintaining the core tenets and ethical values inherent in the profession. Schools, colleges, and universities will be called upon to act to safeguard the value of education and the sanctity of the nursing profession Ultimately, it will be the responsibility of nurses to make sure technological advances, including AI, do not compromise learning or the human interactions and relationships that are essential to providing patient-centered care. The purpose of this article is to explore the ethical implications for the nursing profession of these advances as currently known and understood.}
}
@article{HUANG2025100275,
title = {The chain mediating effect of academic anxiety and performance expectations between academic self-efficacy and generative AI reliance},
journal = {Computers and Education Open},
volume = {9},
pages = {100275},
year = {2025},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2025.100275},
url = {https://www.sciencedirect.com/science/article/pii/S2666557325000345},
author = {Ting Huang and Chenze Wu},
keywords = {Generative AI reliance, Academic self-efficacy, Academic anxiety, Performance expectations},
abstract = {While Generative Artificial Intelligence (GenAI) tools have been used by an increasing number of students, many teachers and researchers recognized that excessive use of these tools may have adverse impacts on students’ academic development. However, the underlying mechanisms driving GenAI reliance and its consequences remain underexplored. This study aimed to address these gaps by investigating the relationships among academic self-efficacy, academic anxiety, performance expectations, and GenAI reliance, as well as examining the consequences of GenAI reliance and coping strategies to mitigate these issues. Data were collected from 337 university students in a Chinese university and analyzed using Pearson correlation, chain mediation effect, and thematic analysis. The results indicated no significant direct relationship between academic self-efficacy and GenAI reliance. However, academic anxiety and performance expectations were found to mediate this relationship. The most salient consequences of GenAI reliance were decreased independent thinking ability, reduced innovative thinking ability, restricted self-reflection, and limited critical thinking ability. Additionally, students’ self-initiated and expected teacher-initiated strategies to alleviate these consequences were recognized. This study contributes to the limited understanding of GenAI reliance and provides valuable insights for educators and academic institutions in directing students toward the appropriate and critical utilization of GenAI tools.}
}
@article{RAMAN2024e27026,
title = {Evaluating human resources management literacy: A performance analysis of ChatGPT and bard},
journal = {Heliyon},
volume = {10},
number = {5},
pages = {e27026},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e27026},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024030573},
author = {Raghu Raman and Murale Venugopalan and Anju Kamal},
keywords = {Human resource management, LLM, Generative AI, Text mining, HR policy, Hiring, Ethics, Managerial decisions},
abstract = {This study presents a comprehensive analysis comparing the literacy levels of two Generative Artificial Intelligence (GAI) tools, ChatGPT and Bard, using a dataset of 134 questions from the Human Resources (HR) domain. The generated responses are evaluated for accuracy, relevance, and clarity. We find that ChatGPT outperforms Bard in overall accuracy (84.3% vs. 82.8%). This difference in performance suggests that ChatGPT could serve as a robotic advisor in transactional HR roles. In contrast, Bard may possess additional safeguards against misuse in the HR function, making it less capable of generating responses to certain types of questions. Statistical tests reveal that although the two systems differ in their mean accuracy, relevance, and clarity of the responses, the observed differences are not always statistically significant, implying that both tools may be more complementary than competitive. The Pearson correlation coefficients further support this by showing weak to non-existent relationships in performance metrics between the two tools. Confirmation queries don't improve ChatGPT or Bard's response accuracy. The study thus contributes to emerging research on the utility of GAI tools in Human Resources Management and suggests that involving certified HR professionals in the design phase could enhance underlying language model performance.}
}
@article{DACUNHA2025149623,
title = {Bridging BioSciences and technology: The impact of AI & GenAI in life sciences and agribusiness},
journal = {Gene},
volume = {964},
pages = {149623},
year = {2025},
issn = {0378-1119},
doi = {https://doi.org/10.1016/j.gene.2025.149623},
url = {https://www.sciencedirect.com/science/article/pii/S0378111925004123},
author = {Nicolau Brito {da Cunha} and Fabiano Cavalcanti Fernandes and Abel Gil-Ley and Octavio L. Franco and Naagma Timakondu and Fabricio F. Costa},
keywords = {GenAI, LLMs, Biotechnology, Life sciences, Agribusiness, Drug discovery, Synthetic biology, Personalized medicine, Precision agriculture, Ethics in GenAI},
abstract = {The intersection of biosciences and technology has yielded transformative advancements, and Generative Artificial Intelligence (GenAI) started to stand at the forefront of this synergy. In the field of life sciences, GenAI is emerging as a catalyst, accelerating drug discovery by swiftly generating and predicting novel molecules. This expedites the identification of potential drug candidates, significantly reducing time and costs compared to traditional methods. Beyond drug discovery, GenAI contributes to protein folding predictions, genomics research, disease diagnosis and biomarker identification, enhancing our understanding of diseases and health conditions, fostering the development of personalized medicine. In agribusiness, GenAI proves instrumental in optimizing crop breeding and improving agricultural productivity. It can generate new crop varieties with desired traits by analyzing vast datasets comprising genomic and ecological information, addressing challenges such as disease resistance, improved yield, and enhanced nutritional content. Moreover, GenAI transcends traditional applications and extends its influence on synthetic biology, contributing to the design of novel enzymes and pathways. This opens avenues for bio-based manufacturing, renewable energy production, and environmental remediation. By harnessing the power of GenAI, the synergies between biosciences and technology accelerate innovation, improve efficiency, decrease costs, and address critical challenges. Conversely, the ethical considerations surrounding GenAI, especially Large Language Model (LLM) utilization in life sciences and agribusiness, such as data privacy, algorithmic bias, and the equitable distribution of benefits, must be addressed to ensure responsible and fair implementation, especially environment sustainability when utilizing this technology. This review article discusses the multifaceted impact of GenAI in a new era of advancements in life sciences and agribusiness.}
}
@article{LI2025112605,
title = {Betting on success: Unveiling the role of innovation and financing capability on funding decisions by human versus AI evaluators},
journal = {Economics Letters},
volume = {256},
pages = {112605},
year = {2025},
issn = {0165-1765},
doi = {https://doi.org/10.1016/j.econlet.2025.112605},
url = {https://www.sciencedirect.com/science/article/pii/S0165176525004422},
author = {Lun Li and Yanbo Peng and Guanlin Shao and Huiyang Dai},
keywords = {Funding decisions, Generative artificial intelligence (GenAI), Human, Innovation capability, Financing capability},
abstract = {This study compares preferences of AI and human evaluators in startup funding, finding that humans prioritize startups with higher innovation capabilities whereas AI favors superior financing capabilities. External certifications can substitute for these internal capabilities, thereby weakening their predictive power.}
}
@article{SON2025110622,
title = {A DID-based one-time session key authentication mechanism for secure human-AI chatbot communication},
journal = {Computers and Electrical Engineering},
volume = {127},
pages = {110622},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2025.110622},
url = {https://www.sciencedirect.com/science/article/pii/S0045790625005658},
author = {Wooyoung Son and Soonhong Kwon and Jong-Hyouk Lee},
keywords = {AI chatbot, RPA system, DID, Session key},
abstract = {As generative Artificial Intelligence (AI) technology has recently gained popularity, society is undergoing a full-scale transformation centered around AI. This technology is attracting attention across various fields, particularly as it meets the growing demand for ‘24/7 availability’. Among these applications, AI chatbot-based Robotic Process Automation (RPA) systems have demonstrated the ability to automate tasks, and with the integration of generative AI, they can now handle more advanced operations such as sending emails and managing complex workflows. However, because AI chatbot-based RPA systems are required to perform sensitive and high-level tasks, secure identity authentication is essential. Traditional Public Key Infrastructure (PKI)-based authentication mechanisms pose risks, as they often require storing personal information within the AI chatbot system—potentially increasing the damage in the event of a security breach. To address this issue, this paper proposes an authentication mechanism that uses a Decentralized Identity (DID)-based one-time session key. By leveraging DID technology, the proposed mechanism ensures self-sovereignty and privacy. Furthermore, the use of a one-time session key guarantees session independence, non-reusability, and untraceability. A performance comparison with PKI-based mechanisms shows that when more than five authentications are performed, the proposed mechanism achieves higher time efficiency, highlighting its advantages in both security and effectiveness. Additionally, potential security threats in each step of the proposed system are analyzed probabilistically. A mathematical formula is presented to demonstrate that the likelihood of such threats occurring is very low. By performing partial differentiation on the attack success probability with respect to representative variables at each step, the analysis identifies which authentication process most significantly influences overall system security. This provides clear insights for designing secure authentication systems based on the proposed approach.}
}
@article{LIN2025124485,
title = {How does the explosive growth of AI affect China's power supply and demand: A scenario simulation based on the LEAP model},
journal = {Renewable Energy},
pages = {124485},
year = {2025},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2025.124485},
url = {https://www.sciencedirect.com/science/article/pii/S0960148125021494},
author = {Boqiang Lin and Dengli Zhou},
keywords = {Artificial intelligence, LEAP model, Power demand, Power supply, Renewable energy},
abstract = {Generative artificial intelligence (AI) has created a new wave of AI around the world. However, the huge potential power demand from the widespread application of AI may challenge the carrying capacity of the power system. This paper uses the Low Emission Analysis Platform (LEAP) to study the impact of the explosive growth of AI on China’s power demand and supply structure. The exponential growth of AI computing power will drive a rapid increase in China’s power demand, and data centers are expected to become the third largest power-using sector in addition to the industry and residential sector. The explosive growth of AI will likely accelerate the growth of coal power generation, while slowing down the decline of the share of coal power, and further highlighting the attributes of coal power to maintain supply. Increasing the installed capacity of renewable energy can mitigate the negative impact of AI growth on the cleaner power supply transformation. The research results in this paper put forward targeted policy recommendations in terms of regulating power consumption in data centers, accelerating the growth of renewable energy installed capacity, and cautiously withdrawing from coal power in phases.}
}
@article{HASHMI2024607,
title = {Generative AI in higher education and beyond},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {607-614},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S000768132400065X},
author = {Nada Hashmi and Anjali S. Bal},
keywords = {Generative AI, Higher education, Typography, ChatGPT, Artificial intelligence},
abstract = {Generative artificial intelligence (GenAI) is a method of machine learning that uses algorithms to create new content such as images, text, and video. In the last year, the popularity of GenAI has exploded. Websites like ChatGPT and DALL-E have become ubiquitous in everything from logo and NFT creation to social media content and artistic verse construction. While the popularity of GenAI is undeniable, the adoption of these technological tools has been splintered in higher education. This conceptual study examines the relationship between transparency and responsibility in the usage of GenAI. We go further, examining the relationship between training and application of skills within higher education. Finally, we propose a framework for how higher education can engage with GenAI to better prepare students to use it outside of school.}
}
@article{ZHU2025,
title = {Current Landscape and Future Directions Regarding Generative Large Language Models in Stroke Care: Scoping Review},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/76636},
url = {https://www.sciencedirect.com/science/article/pii/S2291969425001577},
author = {XingCe Zhu and Wei Dai and Richard Evans and Xueyu Geng and Aruhan Mu and Zhiyong Liu},
keywords = {large language model, stroke, generative artificial intelligence, health care, artificial intelligence, AI},
abstract = {Background
Stroke has a major impact on global health, causing long-term disability and straining health care resources. Generative large language models (gLLMs) have emerged as promising tools to help address these challenges, but their applications and reported performance in stroke care require comprehensive mapping and synthesis.
Objective
The aim of this scoping review was to consolidate a fragmented evidence base and examine the current landscape, shortcomings, and future directions in the design, reporting, and evaluation of gLLM-based interventions in stroke care.
Methods
In this scoping review, which adhered to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines and the Population, Concept, and Context (PCC) framework, we searched 6 major scientific databases in December 2024 for gLLM-based interventions across the stroke care pathway, mapping their key characteristics and outcomes.
Results
A total of 25 studies met the predefined eligibility criteria and were included for analysis. Retrospective designs predominated (n=16, 64%). Key applications of gLLMs included clinical decision-making support (n=10, 40%), administrative assistance (n=9, 36%), direct patient interaction (n=5, 20%), and automated literature review (n=1, 4%). Implementations mainly used generative pretrained transformer models accessed through task-prompted chat interfaces. In total, 5 key challenges were identified from the included studies during the implementation of gLLM-based interventions: ensuring factual alignment, maintaining system robustness, enhancing interpretability, optimizing efficiency, and facilitating clinical adoption.
Conclusions
The application of gLLMs in stroke care, while promising, remains relatively new, with most interventions reflecting early-stage or relatively simple implementations. Against this backdrop, critical gaps in research and clinical translation persist. To support the development of clinically impactful and trustworthy applications, we propose an actionable framework that prioritizes real-world evidence, mandates transparent technical reporting, broadens evaluation beyond output accuracy, strengthens validation of advanced task adaptation strategies, and investigates mechanisms for safe and effective human-gLLM interaction.}
}
@article{MISIEJUK2024100216,
title = {Augmenting assessment with AI coding of online student discourse: A question of reliability},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100216},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100216},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000171},
author = {Kamila Misiejuk and Rogers Kaliisa and Jennifer Scianna},
keywords = {Artificial intelligence, Data coding, ChatGPT, Large language models, Learning analytics, AI-driven assessment},
abstract = {Currently, many generative Artificial Intelligence (AI) tools are being integrated into the educational technology landscape for instructors. Our paper examines the potential and challenges of using Large Language Models (LLMs) to code student-generated content in online discussions based on intended learning outcomes and how instructors could use this to assess the intended and enacted learning design. If instructors were to rely on LLMs as a means of assessment, the reliability of these models to code the data accurately is crucial. Employing a diverse set of LLMs from the GPT family and prompting techniques on an asynchronous online discussion dataset from a blended-learning bachelor-level course, our research examines the reliability of AI-supported coding in educational research. Findings reveal that while AI-supported coding demonstrates efficiency, achieving substantial, moderate agreement with human coding for specific nuanced and context-dependent codes is challenging. Moreover, the high cost, token limits, and the advanced necessary skills needed to write API scripts might limit the usability of AI-driven coding. Finally, implementation would require specific parameterization techniques based on the class and may not be feasible for widespread implementation. Our study underscores the importance of transparency in AI coding methodologies and the need for a hybrid approach that integrates human judgement to ensure data accuracy and interpretability. In addition, it contributes to the knowledge base about the reliability of LLMs to code real, small datasets using complex codes that are common in the instructor's practice and explores the potential and challenges of using these models for assessment purposes.}
}
@article{ZHANG2025104413,
title = {Unraveling the potential of diffusion models in small-molecule generation},
journal = {Drug Discovery Today},
volume = {30},
number = {7},
pages = {104413},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2025.104413},
url = {https://www.sciencedirect.com/science/article/pii/S1359644625001266},
author = {Peining Zhang and Daniel Baker and Minghu Song and Jinbo Bi},
abstract = {Generative artificial intelligence (AI) presents chemists with novel ideas for drug design and facilitates the exploration of vast chemical spaces. As an emerging tool, diffusion models (DMs) have recently attracted great attention in drug research and development (R&D). Here, we comprehensively review the latest advances in, and applications of, DMs in molecular generation. We introduce the theoretical principles of DMs and then categorize various DM-based molecular generation methods according to their mathematical and chemical applications. We also examine the performance of these models on benchmark datasets, with a particular focus on comparing the generation performance of existing 3D methods. Finally, we conclude by emphasizing current challenges and suggesting future research directions to fully exploit the potential of DMs in drug discovery.}
}
@incollection{GAUR202675,
title = {Chapter 5 - Ethical considerations in generative AI development and usage},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {75-90},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00012-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000126},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {AI governance, Bias mitigation, Data privacy, Ethics, Ethical AI development, Generative AI, Transparency},
abstract = {The development and usage of generative artificial intelligence (AI) raise critical ethical considerations that demand a comprehensive understanding. This chapter explores the ethical landscape of generative AI by first defining ethics within this technological context and emphasizing the importance of responsible development. From a developer's perspective, navigating ethical challenges involves ensuring transparency, sourcing data ethically, and obtaining user consent. The presence of biases in AI systems, how they arise, and strategies for mitigating these biases are analyzed, supported by case studies that demonstrate real-world impacts. Additionally, the chapter addresses implications for users, including the need for user education, privacy concerns in data collection, and transparency in AI interactions. Ethical dilemmas surrounding AI creativity, and its societal impacts are explored, with a focus on governance and regulation. The chapter concludes by proposing future directions, such as the creation of ethical guidelines, fostering collaboration among stakeholders, and envisioning a future where generative AI operates within an ethical framework that promotes trust and accountability.}
}
@article{BERTHON2024461,
title = {Trajectories of AI technologies: Insights for managers},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {461-470},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000284},
author = {Pierre Berthon and Taylan Yalcin and Ekin Pehlivan and Tamara Rabinovich},
keywords = {Trajectories of technology, Generative AI, Chatbots, ChatGPT, Large language models, Social media},
abstract = {Generative artificial intelligence (GenAI) has long been considered a technology for the future. With the release of the chatbot ChatGPT 4, many now feel the future has arrived. Long in gestation, this new technology promises many benefits to humankind, but worries persist that as AI technology scales and comes to rival or exceed human intelligence, the servant may become the master. Amid such hyperbole, the more nuanced trajectories of this technology have been neglected. In this article, we use the Trajectories of Technology (ToT) framework developed by Berthon and colleagues to explore the disparate paths that AI has taken and will take in the coming years, especially in the form of chatbots. This framework provides managers with a conceptual tool to strategically plan for the enormous promises and perils of AI in general and of chatbots specifically.}
}
@article{MORAVEC2025100691,
title = {Environmental footprint of GenAI – Changing technological future or planet climate?},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {3},
pages = {100691},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100691},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000411},
author = {Vaclav Moravec and Beata Gavurova and Viliam Kovac},
keywords = {Generative artificial intelligence, ChatGPT, DeepSeek, Artificial intelligence literacy, Climate change, Data centre, Czechia},
abstract = {The beginnings of generative artificial intelligence (GenAI), led by Chat Generative Pre-Trained Transformer (ChatGPT), not only change the behaviour of digital media ecosystem users but also increase the energy consumption of enterprises working with GenAI, which presents them with a fundamental challenge in the era of climate change. This study aims to examine the relationships between the selected aspects of the use of GenAI tools and the environmental perception and behaviour of their users to understand the population's current environmental attitudes towards environmental risks and environmental sustainability. The survey was conducted in October 2024 on a sample of 1,268 respondents of the Czech Republic population. To process the data set, a logistic regression analysis, chi-squared test, Akaike information criterion, and Bayesian information criterion are employed. The results show that the more often people use GenAI tools, the more distant they consider the effects of climate change in time. The low frequency of use of ChatGPT may influence a higher willingness to change popular GenAI tools that are not maintained by environmentally friendly data centres. The frequency of ChatGPT use influences individuals’ perception of the importance of climate-change solving. The more frequently the respondents use artificial intelligence (AI) systems, they less perceive climate change as important. The low frequency of ChatGPT usage is associated with lower willingness to change email provider, transfer own data, leave social networks, stop using a favourite streaming platform and stop using a favourite GenAI platform. The respondents’ attitudes show a visible behavioural change. Internal personal motivation and self-confidence in learning, interest in career and self-confidence when using AI, the behavioural aspects, and the cognitive aspects are altered considerably. Based on the outcomes of the population survey, the study concludes that the issue of environmental friendliness of AI tools should become part of AI literacy that could strengthen population's willingness to use more energy-efficient GenAI platforms. The listed challenges are important in the perspective of the latest technological development, as shown by the discussion on the energy and computational demands of the GenAI platform DeepSeek, which is also discussed in the study.}
}
@article{SATO2025,
title = {Performance Evaluation of 18 Generative AI Models (ChatGPT, Gemini, Claude, and Perplexity) in 2024 Japanese Pharmacist Licensing Examination: Comparative Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/76925},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001217},
author = {Hiroyasu Sato and Katsuhiko Ogasawara and Hidehiko Sakurai},
keywords = {generative AI, artificial intelligence, ChatGPT, Gemini, pharmacist, National License Examination},
abstract = {Background
Generative artificial intelligence (AI) has shown rapid advancements and increasing applications in various domains, including health care. Previous studies have evaluated AI performance on medical license examinations, primarily focusing on ChatGPT. However, the availability of new online chat-based large language models (OC-LLMs) and their potential utility in pharmacy licensing examinations remain underexplored. Considering that pharmacists require a broad range of expertise in physics, chemistry, biology, and pharmacology, verifying the knowledge base and problem-solving abilities of these new models in Japanese pharmacy examinations is necessary.
Objective
This study aimed to assess the performance of 18 OC-LLMs released in 2024 in the 107th Japanese National License Examination for Pharmacists (JNLEP). Specifically, the study compared their accuracy and identified areas of improvement relative to earlier models.
Methods
The 107th JNLEP, comprising 345 questions in Japanese, was used as a benchmark. Each OC-LLM was prompted by the original text-based questions, and images were uploaded where permitted. No additional prompt engineering or English translation was performed. For questions that included diagrams or chemical structures, the models incapable of image input were considered incorrect. The model outputs were compared with publicly available correct answers. The overall accuracy rates were calculated based on subject area (pharmacology and chemistry) and question type (text-only, diagram-based, calculation, and chemical structure). Fleiss’ κ was used to measure answer consistency among the top-performing models.
Results
Four flagship models—ChatGPT o1, Gemini 2.0 Flash, Claude 3.5 Sonnet (new), and Perplexity Pro—achieved 80% accuracy, surpassing the official passing threshold and average examinee score. A significant improvement in the overall accuracy was observed between the early and the latest 2024 models. Marked improvements were noted in text-only and diagram-based questions compared with those of earlier versions. However, the accuracy of chemistry-related and chemical structure questions remains relatively low. Fleiss’ κ among the 4 flagship models was 0.334, which suggests moderate consistency but highlights variability in more complex questions.
Conclusions
OC-LLMs have substantially improved their capacity to handle Japanese pharmacists’ examination content, with several newer models achieving accuracy rates of >80%. Despite these advancements, even the best-performing models exhibit an error rate exceeding 10%, underscoring the ongoing need for careful human oversight in clinical settings. Overall, the 107th JNLEP will serve as a valuable benchmark for current and future generative AI evaluations in pharmacy licensing examinations.}
}
@article{FOSSOWAMBA2023109015,
title = {Are both generative AI and ChatGPT game changers for 21st-Century operations and supply chain excellence?},
journal = {International Journal of Production Economics},
volume = {265},
pages = {109015},
year = {2023},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2023.109015},
url = {https://www.sciencedirect.com/science/article/pii/S0925527323002475},
author = {Samuel {Fosso Wamba} and Maciel M. Queiroz and Charbel Jose {Chiappetta Jabbour} and Chunming (Victor) Shi},
keywords = {ChatGPT, Generative artificial intelligence, Operations and supply chain management, Disruptive technology, Emerging technologies, Organizational learning},
abstract = {The remarkable growth of ChatGPT, a Generative Artificial Intelligence (Gen-AI), has triggered a significant debate in society. It has the potential to radically transform the business landscape, with consequences for operations and supply chain management (O&SCM). However, empirical evidence on Gen-AI's effects in O&SCM remains limited. This study investigates the benefits, challenges, and trends associated with Gen-AI/ChatGPT in O&SCM. We collected data from O&SCM practitioners in the UK (N = 154) and the USA (N = 161). As we used the organizational learning theory for the research, our findings reveal increased efficiency as a significant benefit for both adopters and non-adopters in both countries, while indicating security, risks, and ethical as prominent concerns. In particular, it appeared that the integration of Gen-AI/ChatGPT leads to the enhancement of the overall supply chain performance. Moreover, organizational learning can speed up the results of Gen-AI/ChatGPT in O&SCM. No wonders that adopters express their satisfaction about the post-implementation benefits of the technology, which include reduced perceived challenges for pre-implementation, and greater optimism about future Gen-AI/ChatGPT utilization compared to non-adopters. Adopters also display diverse behavioral patterns toward efficiency, agility, responsiveness, etc. This study provides valuable insights for scholars, practitioners, and policymakers interested in comprehending Gen-AI/ChatGPT's implications in O&SCM for both adopters and non-adopters. Additionally, it underscores the importance of organizational learning processes in facilitating successful Gen-AI/ChatGPT adoption in O&SCM.}
}
@article{CHEN2025105198,
title = {Unpacking help-seeking process through multimodal learning analytics: A comparative study of ChatGPT vs Human expert},
journal = {Computers & Education},
volume = {226},
pages = {105198},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105198},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524002124},
author = {Angxuan Chen and Mengtong Xiang and Junyi Zhou and Jiyou Jia and Junjie Shang and Xinyu Li and Dragan Gašević and Yizhou Fan},
keywords = {Data science applications in education, Human-computer interface, 21st century abilities, Information literacy, Human-AI interaction},
abstract = {Help-seeking is an active learning strategy tied to self-regulated learning (SRL), where learners seek assistance when facing challenges. They may seek help from teachers, peers, intelligent tu-tor systems, and more recently, generative artificial intelligence (AI). However, there is limited empirical research on how learners’ help-seeking process differs between generative AI and hu-man experts. To address this, we conducted a lab experiment with 38 university students tasked with essay writing and revising. The students were randomly divided into two groups: one seeking help from ChatGPT (AI Group) and the other from an experienced teacher (HE Group). To examine their help-seeking processes, we used a combination of statistical testing and process mining methods, analyzing multimodal data (e.g., trace data, eye-tracking data, and conversa-tional data). Our results indicated that the AI Group exhibited a nonlinear help-seeking process, such as skipping evaluation, differing significantly from the linear model observed in the HE Group which also aligned with classic help-seeking theory. Detailed analysis revealed that the AI Group asked more operational questions, showing pragmatic help-seeking activities, whereas the HE Group was more proactive in evaluating and processing received feedback. We discussed factors such as social pressure, metacognitive off-loading, and over-reliance on AI in these different help-seeking scenarios. More importantly, this study offers innovative insights and evidence, based on multimodal data, to better understand and scaffold learners learning with generative AI.}
}
@article{BRAGAZZI2024,
title = {Toward Clinical Generative AI: Conceptual Framework},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/55957},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000322},
author = {Nicola Luigi Bragazzi and Sergio Garbarino},
keywords = {clinical intelligence, artificial intelligence, iterative process, abduction, benchmarking, verification paradigms},
abstract = {Clinical decision-making is a crucial aspect of health care, involving the balanced integration of scientific evidence, clinical judgment, ethical considerations, and patient involvement. This process is dynamic and multifaceted, relying on clinicians’ knowledge, experience, and intuitive understanding to achieve optimal patient outcomes through informed, evidence-based choices. The advent of generative artificial intelligence (AI) presents a revolutionary opportunity in clinical decision-making. AI’s advanced data analysis and pattern recognition capabilities can significantly enhance the diagnosis and treatment of diseases, processing vast medical data to identify patterns, tailor treatments, predict disease progression, and aid in proactive patient management. However, the incorporation of AI into clinical decision-making raises concerns regarding the reliability and accuracy of AI-generated insights. To address these concerns, 11 “verification paradigms” are proposed in this paper, with each paradigm being a unique method to verify the evidence-based nature of AI in clinical decision-making. This paper also frames the concept of “clinically explainable, fair, and responsible, clinician-, expert-, and patient-in-the-loop AI.” This model focuses on ensuring AI’s comprehensibility, collaborative nature, and ethical grounding, advocating for AI to serve as an augmentative tool, with its decision-making processes being transparent and understandable to clinicians and patients. The integration of AI should enhance, not replace, the clinician’s judgment and should involve continuous learning and adaptation based on real-world outcomes and ethical and legal compliance. In conclusion, while generative AI holds immense promise in enhancing clinical decision-making, it is essential to ensure that it produces evidence-based, reliable, and impactful knowledge. Using the outlined paradigms and approaches can help the medical and patient communities harness AI’s potential while maintaining high patient care standards.}
}
@article{LIU2025112278,
title = {Agent design pattern catalogue: A collection of architectural patterns for foundation model based agents},
journal = {Journal of Systems and Software},
volume = {220},
pages = {112278},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112278},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003224},
author = {Yue Liu and Sin Kit Lo and Qinghua Lu and Liming Zhu and Dehai Zhao and Xiwei Xu and Stefan Harrer and Jon Whittle},
keywords = {Agent, Foundation model, Large language model, Pattern, Software engineering, Responsible AI},
abstract = {Foundation model-enabled generative artificial intelligence facilitates the development and implementation of agents, which can leverage distinguished reasoning and language processing capabilities to takes a proactive, autonomous role to pursue users’ goals. Nevertheless, there is a lack of systematic knowledge to guide practitioners in designing the agents considering challenges of goal-seeking (including generating instrumental goals and plans), such as hallucinations inherent in foundation models, explainability of reasoning process, complex accountability, etc. To address this issue, we have performed a systematic literature review to understand the state-of-the-art foundation model-based agents and the broader ecosystem. In this paper, we present a pattern catalogue consisting of 18 architectural patterns with analyses of the context, forces, and trade-offs as the outcomes from the previous literature review. We propose a decision model for selecting the patterns. The proposed catalogue can provide holistic guidance for the effective use of patterns, and support the architecture design of foundation model-based agents by facilitating goal-seeking and plan generation.}
}
@article{DEAZEVEDO2025128414,
title = {Comprehensive application of denoising diffusion probabilistic models towards the automation of analog integrated circuit sizing},
journal = {Expert Systems with Applications},
volume = {290},
pages = {128414},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128414},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425020330},
author = {Filipe Parrado {de Azevedo} and Nuno Calado {Correia Lourenço} and Ricardo Miguel {Ferreira Martins}},
keywords = {Analog integrated circuits, Artificial neural networks, Diffusion models, Electronic design automation, Generative artificial intelligence, Inverse sizing problem, Sizing automation},
abstract = {In the past few decades, the problem of automating the sizing task of analog integrated circuit (IC) design has been a popular topic of research in the electronic design automation community. Traditionally, metaheuristics and optimization-based approaches have been explored to address this challenge, but each method has its own drawbacks and/or yield inefficient results’ production. Alternatively, recent advances in machine learning have also brought new perspectives at solving this particular problem. Particularly, artificial neural networks have been used in some works, but there is the common hurdle of small sizing datasets available to train the models in a supervised manner, and the fact that these models lack the ability to generalize beyond/outside their training data, as well as their tendency to fall into mode collapse. Therefore, to overcome these issues, in this paper, the focus is given on using denoising diffusion probabilistic models (DDPMs), a category of state-of-the-art diffusion models, to tackle the inverse problem of analog IC sizing. These models are trained to automatically determine the sizing of an analog IC when given only the set of constraints for its performance metrics. Several DDPM architectures are trained to gradually learn to remove noise, meaning that after training, they can produce new data from random noise samples. While previous work has shown that even a simple DDPM can sample promising sizing solutions in a small amount of time, this work takes one step further by employing a transformer architecture as the backbone of the model, learning a velocity equation of how the data changes between the noise addition steps. 100 sampled points are generated under 1 s, while revealing improved functional performance over other points generated by state-of-the-art approaches. These points can then be utilized as a starting point for further simulation-based optimizations until non-dominated optimal solutions are found. The use of these starting points saves, in some cases, more than 20,000 simulations when compared with randomized starting points, proving the model and pipeline’s efficiency. This work presents the first extensive study in the literature on the use of diffusion models to tackle the inverse problem of analog IC sizing, targeting multiple circuit topologies and integration technologies.}
}
@article{HARRER2023104512,
title = {Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine},
journal = {eBioMedicine},
volume = {90},
pages = {104512},
year = {2023},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2023.104512},
url = {https://www.sciencedirect.com/science/article/pii/S2352396423000774},
author = {Stefan Harrer},
keywords = {Generative artificial intelligence, Large language models, Foundation models, AI ethics, Augmented human intelligence, Information management, AI trustworthiness},
abstract = {Summary
Large Language Models (LLMs) are a key component of generative artificial intelligence (AI) applications for creating new content including text, imagery, audio, code, and videos in response to textual instructions. Without human oversight, guidance and responsible design and operation, such generative AI applications will remain a party trick with substantial potential for creating and spreading misinformation or harmful and inaccurate content at unprecedented scale. However, if positioned and developed responsibly as companions to humans augmenting but not replacing their role in decision making, knowledge retrieval and other cognitive processes, they could evolve into highly efficient, trustworthy, assistive tools for information management. This perspective describes how such tools could transform data management workflows in healthcare and medicine, explains how the underlying technology works, provides an assessment of risks and limitations, and proposes an ethical, technical, and cultural framework for responsible design, development, and deployment. It seeks to incentivise users, developers, providers, and regulators of generative AI that utilises LLMs to collectively prepare for the transformational role this technology could play in evidence-based sectors.}
}
@article{SCHOLZ2025,
title = {EPIC visuals: An integrated framework to operationalize archetypes for visual storytelling},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001399},
author = {Joachim Scholz},
keywords = {storytelling, visual content, branding, archetypes, social media},
abstract = {Compelling visuals are vitally important for successful brand storytelling. Yet even though the importance of visual content has exploded in recent years – driven by the ease through which consumers, influencers, and managers can create and share brand-related visuals thanks to social media and now generative artificial intelligence – comprehensive advice on how brand strategies can be visually executed has remained scarce. This article introduces the EPIC framework for translating nuanced brand meanings into concrete visual content. Integrating the literatures on visual storytelling, archetypes, and critical visual analysis, the framework details four interlocked steps to operationalize archetypes for visual storytelling: Defining the essence of the brand, personifying the brand essence into suitable archetypes, inflecting archetypes towards the brand via themes, and cataloguing visual elements into a SMART instrument to guide visual content creation in a bottom-up process. Brands that employ the EPIC framework can bridge the strategy-execution gap in visual storytelling and unlock two particular benefits: (1) a more consistently enacted archetypal gestalt, and (2) differentiation through more distinct and clearly composed images.}
}
@article{BERLANGALLAVORI2025100663,
title = {Del Ars Magna a la inteligencia artificial generativa},
journal = {Revista de Senología y Patología Mamaria},
volume = {38},
number = {3},
pages = {100663},
year = {2025},
issn = {0214-1582},
doi = {https://doi.org/10.1016/j.senol.2024.100663},
url = {https://www.sciencedirect.com/science/article/pii/S0214158224000914},
author = {Rafael {Berlanga Llavori}},
keywords = {Inteligencia artificial generativa, Evolución de la inteligencia artificial, Aplicaciones de la inteligencia artificial a la medicina, Generative artificial intelligence, Evolution of artificial intelligence, Artificial intelligence applications to medicine},
abstract = {Resumen
Con este artículo se pretende dar a conocer los elementos clave en la evolución de la inteligencia artificial (IA) en los últimos años, especialmente la inteligencia artificial generativa. Así como la IA predictiva o discriminativa ha tenido un impacto notable en la medicina en las últimas 2 décadas, especialmente en el diagnóstico de enfermedades a partir de datos clínicos, la IA generativa nos conduce a nuevos retos y oportunidades en numerosos campos, como son el tratamiento personalizado, la prevención, la proacción, nuevas técnicas terapéuticas y, en general, la ampliación de los horizontes de la investigación clínica y biomédica. Para este trabajo hemos realizado un estudio bibliográfico y organizado en las principales ideas de aplicación de la IA generativa a la medicina. El principal resultado de este estudio es un conjunto de aplicaciones potenciales de la IA generativa que se están iniciando en diversas áreas de la medicina y que pueden suponer una revolución de la misma a corto o medio plazo. No obstante, hay obstáculos muy importantes que superar, principalmente los referentes a la calidad y precisión de estos sistemas, así como las barreras de privacidad y cuestiones éticas que deben ser respetadas por los sistemas digitales de salud.
This article aims to present the key elements in the evolution of Artificial Intelligence (AI) in recent years, especially Generative Artificial Intelligence. Predictive or discriminative AI has had a notable impact on medicine in the last two decades, especially in the diagnosis of pathologies based on clinical data. Now, generative AI leads us to new challenges and opportunities in numerous fields such as personalised treatment, prevention, pro-action, new therapeutic techniques and, in general, the broadening of the horizons of clinical and biomedical research. For this work, we have carried out a bibliographic study and organised it into the main ideas for the application of generative AI to medicine. The main result of this study is a set of potential applications of generative AI that are being initiated in several areas of medicine and that may lead to a revolution in medicine in the short to mid-term. However, there are major hurdles to overcome, mainly those concerning the quality and accuracy of these systems, as well as the privacy and ethical barriers that must be respected by the new automated healthcare systems.}
}
@article{LI2025132,
title = {Data and AI-driven synthetic binding protein discovery},
journal = {Trends in Pharmacological Sciences},
volume = {46},
number = {2},
pages = {132-144},
year = {2025},
issn = {0165-6147},
doi = {https://doi.org/10.1016/j.tips.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165614724002682},
author = {Yanlin Li and Zixin Duan and Zhenwen Li and Weiwei Xue},
keywords = {synthetic binding proteins, protein design, bioinformatics database, molecular modeling, artificial intelligence},
abstract = {Synthetic binding proteins (SBPs) are a class of protein binders that are artificially created and do not exist naturally. Their broad applications in tackling challenges of research, diagnostics, and therapeutics have garnered significant interest. Traditional protein engineering is pivotal to the discovery of SBPs. Recently, this discovery has been significantly accelerated by computational approaches, such as molecular modeling and artificial intelligence (AI). Furthermore, while numerous bioinformatics databases offer a wealth of resources that fuel SBP discovery, the full potential of these data has not yet been fully exploited. In this review, we present a comprehensive overview of SBP data ecosystem and methodologies in SBP discovery, highlighting the critical role of high-quality data and AI technologies in accelerating the discovery of innovative SBPs with promising applications in pharmacological sciences.}
}
@article{ALSAAD2024,
title = {Multimodal Large Language Models in Health Care: Applications, Challenges, and Future Outlook},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/59505},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005983},
author = {Rawan AlSaad and Alaa Abd-alrazaq and Sabri Boughorbel and Arfan Ahmed and Max-Antoine Renault and Rafat Damseh and Javaid Sheikh},
keywords = {artificial intelligence, large language models, multimodal large language models, multimodality, multimodal generative artificial intelligence, multimodal generative AI, generative artificial intelligence, generative AI, health care},
abstract = {In the complex and multidimensional field of medicine, multimodal data are prevalent and crucial for informed clinical decisions. Multimodal data span a broad spectrum of data types, including medical images (eg, MRI and CT scans), time-series data (eg, sensor data from wearable devices and electronic health records), audio recordings (eg, heart and respiratory sounds and patient interviews), text (eg, clinical notes and research articles), videos (eg, surgical procedures), and omics data (eg, genomics and proteomics). While advancements in large language models (LLMs) have enabled new applications for knowledge retrieval and processing in the medical field, most LLMs remain limited to processing unimodal data, typically text-based content, and often overlook the importance of integrating the diverse data modalities encountered in clinical practice. This paper aims to present a detailed, practical, and solution-oriented perspective on the use of multimodal LLMs (M-LLMs) in the medical field. Our investigation spanned M-LLM foundational principles, current and potential applications, technical and ethical challenges, and future research directions. By connecting these elements, we aimed to provide a comprehensive framework that links diverse aspects of M-LLMs, offering a unified vision for their future in health care. This approach aims to guide both future research and practical implementations of M-LLMs in health care, positioning them as a paradigm shift toward integrated, multimodal data–driven medical practice. We anticipate that this work will spark further discussion and inspire the development of innovative approaches in the next generation of medical M-LLM systems.}
}
@article{CASTELLANO2025111,
title = {Clinical trial screening in gynecologic oncology: Defining the need and identifying best practices},
journal = {Gynecologic Oncology},
volume = {192},
pages = {111-119},
year = {2025},
issn = {0090-8258},
doi = {https://doi.org/10.1016/j.ygyno.2024.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0090825824012150},
author = {T. Castellano and O.D. Lara and C. McCormick and D. Chase and V. BaeJump and A.L. Jackson and J.T. Peppin and S. Ghamande and K.N. Moore and B. Pothuri and T.J. Herzog and T. Myers},
keywords = {Clinical trial screening, Artificial intelligence in clinical trial screening, Best practices for clinical trial screening, Clinical trial equity, Clinical trial screening survey in gynecologic oncology},
abstract = {Background
Evidence is limited in gynecologic cancers on best practices for clinical trial screening, but the risk of ineffective screening processes and subsequent under-enrollment introduces significant cost to patient, healthcare systems, and scientific advancement. Absence of a defined screening process makes determination of who and when to screen potential patients inconsistent allowing inefficiency and potential introduction of biases. This is especially germane as generative artificial intelligence (AI), and electronic health record (EHR) integration is applied to trial screening. Though often a requirement of cooperative groups such as the Cancer therapy Evaluation Program (CTEP), and/or the Commission on Cancer (CoC), there are no standard practice guidelines on best practices regarding screening and how best to track screening data.
Development of manuscript
The authors provided a review of current clinical trial screening practices and the effect on enrollment and trial activation across a variety of disease and practice sites. Established clinical trial screening practices and evidence supporting emerging strategies were reviewed and reported. Due to lack of published literature in gynecologic oncology, authors sought to survey the members of current rostered GOG sites to provide perspectives on clinical trial screening practices. Survey results showed a variety of screening practices. Most respondents participate in some type of manual screening process, where approximately 13 % also report incorporating AI or EHR integration. Over half (60 %) of sites track screening data to use for feasibility when opening new trials. The rapid increase in generative AI, EHR integration, and site agnostic screening initiatives could provide a significant opportunity to improve screening efficiency, translating to improved enrollment, but limitations and barriers remain.}
}
@article{XIAO2025105414,
title = {Using ChatGPT to bring non-player characters to life: Effects on students’ storyline-driven game-based writing learning},
journal = {Computers & Education},
volume = {238},
pages = {105414},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105414},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001824},
author = {Ya Xiao and Danling Li and Kai Guo},
keywords = {Storyline, ChatGPT, Non-player characters, Game-based learning, EFL writing},
abstract = {This study introduces a novel design approach to game-based learning by integrating ChatGPT into the development of non-player characters (NPCs) within storylines. This integration seeks to enhance interactivity with student players and foster an immersive, dynamic learning environment. We applied this approach in English as a Foreign Language (EFL) writing classrooms to examine its impact on both the affective and cognitive aspects of student writing learning, as well as their writing performance. Utilizing a quasi-experimental design, the study involved two classes of Chinese undergraduate students. One class (n = 42) engaged with ChatGPT-powered NPCs, while the other class (n = 43) interacted with conventional NPCs in a storyline-based game designed to enhance argumentative writing skills. Quantitative data were collected through questionnaires assessing students' intrinsic motivation, situational interest, cognitive load, and effort regulation. Additionally, student essays were evaluated to compare writing performance across the two conditions. Qualitative data, including students' chat histories with ChatGPT-powered NPCs, were gathered to investigate their interactions. The results indicated that engaging with ChatGPT-enhanced NPCs positively influenced students' intrinsic motivation and situational interest, leading them to invest greater effort in completing learning tasks. Notably, interactions with ChatGPT-enhanced NPCs did not increase students’ cognitive load during the learning process. Moreover, students who interacted with ChatGPT-powered NPCs exhibited superior writing performance, producing essays that were significantly clearer, more elaborated, and more persuasive, while also more effectively addressing opposing viewpoints. Additionally, students employed various conversational strategies while interacting with these NPCs. This study not only advances our understanding of the role of generative artificial intelligence in educational contexts but also provides valuable insights for educators seeking to enhance student engagement and learning outcomes through innovative instructional strategies.}
}
@article{CHEESE2025,
title = {Using Natural Language Processing to Explore Patient Perspectives on AI Avatars in Support Materials for Patients With Breast Cancer: Survey Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70971},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500857X},
author = {Eleanor Cheese and Raouef Ahmed Bichoo and Kartikae Grover and Dorin Dumitru and Alexandros Zenonos and Joanne Groark and Douglas Gibson and Rebecca Pope},
keywords = {educational videos, breast cancer, natural language processing, avatars, patient feedback, artificial intelligence, AI},
abstract = {Background
Having well-informed patients is crucial to enhancing patient satisfaction, quality of life, and health outcomes, which in turn optimizes health care use. Traditional methods of delivering information, such as booklets and leaflets, are often ineffective and can overwhelm patients. Educational videos represent a promising alternative; however, their production typically requires significant time and financial resources. Video production using generative artificial intelligence (AI) technology may provide a solution to this problem.
Objective
This study aimed to use natural language processing (NLP) to understand free-text patient feedback on 1 of 7 AI-generated patient educational videos created in collaboration with Roche UK and the Hull University Teaching Hospitals NHS Trust breast cancer team, titled “Breast Cancer Follow Up Programme.”
Methods
A survey was sent to 400 patients who had completed the breast cancer treatment pathway, and 98 (24.5%) free-text responses were received for the question “Any comments or suggestions to improve its [the video’s] contents?” We applied and evaluated different NLP machine learning techniques to draw insights from these unstructured data, namely sentiment analysis, topic modeling, summarization, and term frequency–inverse document frequency word clouds.
Results
Sentiment analysis showed that 81% (79/98) of the responses were positive or neutral, while negative comments were predominantly related to the AI avatar. Topic modeling using BERTopic with k-means clustering was found to be the most effective model and identified 4 key topics: the breast cancer treatment pathway, video content, the digital avatar or narrator, and short responses with little or no content. The term frequency–inverse document frequency word clouds indicated positive sentiment about the treatment pathway (eg, “reassured” and “faultless”) and video content (eg, “informative” and “clear”), whereas the AI avatar was often described negatively (eg, “impersonal”). Summarization using the text-to-text transfer transformer model effectively created summaries of the responses by topic.
Conclusions
This study demonstrates the success of NLP techniques in efficiently generating insights into patient feedback related to generative AI educational content. Combining NLP methods resulted in clear visuals and insights, enhancing the understanding of patient feedback. Analysis of free-text responses provided clinicians at Hull University Teaching Hospitals NHS Trust with deeper insights than those obtained from quantitative Likert scale responses alone. Importantly, the results validate the use of generative AI in creating patient educational videos, highlighting its potential to address the challenges of costly video production and the limitations of traditional, often overwhelming educational leaflets. Despite the positive overall feedback, negative comments focused on the technical aspects of the AI avatar, indicating areas for improvement. We advocate that patients who receive AI avatar explanations are counseled that this technology is intended to supplement, not replace, human health care interactions. Future investigations are needed to confirm the ongoing effectiveness of these educational tools.}
}
@article{JIANG2024114688,
title = {Women entrepreneurship in China: A bibliometric literature review and future research agenda},
journal = {Journal of Business Research},
volume = {179},
pages = {114688},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114688},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324001929},
author = {Yiqi Jiang and Zhou Jiang and Zhijun Chen},
keywords = {Women entrepreneurship, Female entrepreneur, Gender, China, Bibliometric literature review, Bibliographic analysis},
abstract = {Women entrepreneurship in China plays a pivotal role in social and economic advancement. Over recent decades, Chinese female entrepreneurs have significantly impacted national and global economies. However, despite increasing research efforts, our understanding of this domain remains fragmented. To offer a comprehensive overview, we conducted a bibliometric review of 85 primary articles and 5,010 secondary documents, unveiling the intellectual landscape of research in Chinese women entrepreneurship. Employing document co-citation and bibliographic coupling analyses, we delve into intellectual traditions/foundations and emerging research areas. By synthesizing these findings, the article outlines a research agenda aimed at advancing our scholarly knowledge of women entrepreneurship in China. We highlight that future women entrepreneurship research can delve deeper into theoretical roots in the Chinese context, effects of cultural values, intranational disparities, multi-level entrepreneurial barriers, digital entrepreneurship, gender differences in entrepreneurial self-efficacy and intention, and the roles of generative artificial intelligence (AI).}
}
@article{TALYSHINSKII202451,
title = {ChatGPT as a Clinical Decision Maker for Urolithiasis: Compliance with the Current European Association of Urology Guidelines},
journal = {European Urology Open Science},
volume = {69},
pages = {51-62},
year = {2024},
issn = {2666-1683},
doi = {https://doi.org/10.1016/j.euros.2024.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S2666168324006530},
author = {Ali Talyshinskii and Patrick Juliebø-Jones and B.M. {Zeeshan Hameed} and Nithesh Naik and Kinju Adhikari and Ulanbek Zhanbyrbekuly and Lazaros Tzelves and Bhaskar Kumar Somani},
keywords = {Generative pretrained transformer, Urolithiasis, Diagnosis, Treatment, Clinical decision},
abstract = {Background and objective
Generative artificial intelligence models are among the most promising and widely used tools used in health care. This review investigates GPT-4 answers to decision-making questions regarding the diagnosis and treatment of urolithiasis across several clinical settings and their correspondence to the current European Association of Urology (EAU) guidelines.
Methods
In March 2024, the GPT-4 model was asked 11 questions, containing a brief description of a patient with urolithiasis. All questions were grouped according to urolithiasis care step: diagnosis, urgent care, scheduled intervention, and metaphylaxis. When responses were received, compliance with the current EAU guidelines was assessed by experienced urologists.
Key findings and limitations
Although all responses were provided with information that corresponded to EAU guidelines, six of the 11 answers were associated with missed guideline–provided parts, and incorrect data were given in eight of the 11 answers. GPT-4 is relatively safe in the initial diagnostic flow of patients suspected of having stones within the urinary tract and during treatment planning; however, its understanding of all the nuances of metaphylaxis leaves much to be desired and is far from the dogma given in the EAU guidelines. Moreover, GPT-4 knowledge of strategy and algorithm is not always aligned with the EAU guidelines.
Conclusions and clinical implications
Despite the fact that from the perspective of patients with urolithiasis, GPT-4 is capable of answering their questions well, the specificity of questions from urologists is labor intensive for its current version, and necessitates the ability to interpret it correctly and further attempts to improve it. While some aspects of diagnostics are more accurate, these struggle with surgical planning and algorithms in line with the EAU guidelines.
Patient summary
The generative artificial intelligence (AI) model GPT-4 is capable of answering urology-related questions, but lacks detailed responses. Although some aspects of the diagnostics are accurate, knowledge of surgical planning is not in line with the European Association of Urology guidelines. Future improvements should focus on efforts to enhance the accuracy, reliability, and clinical relevance of AI tools in urology.}
}
@article{CHOUDHURY2025,
title = {User Intent to Use DeepSeek for Health Care Purposes and Their Trust in the Large Language Model: Multinational Survey Study},
journal = {JMIR Human Factors},
volume = {12},
year = {2025},
issn = {2292-9495},
doi = {https://doi.org/10.2196/72867},
url = {https://www.sciencedirect.com/science/article/pii/S2292949525001233},
author = {Avishek Choudhury and Yeganeh Shahsavar and Hamid Shamszare},
keywords = {artificial intelligence, data privacy, health informatics, human factors engineering, ChatGPT, risk assessment, technology acceptance, trust, user adoption},
abstract = {Background
Generative artificial intelligence (AI)—particularly large language models (LLMs)—has generated unprecedented interest in applications ranging from everyday questions and answers to health-related inquiries. However, little is known about how everyday users decide whether to trust and adopt these technologies in high-stakes contexts such as personal health.
Objectives
This study examines how ease of use, perceived usefulness, and risk perception interact to shape user trust in and intentions to adopt DeepSeek, an emerging LLM-based platform, for health care purposes.
Methods
We adapted survey items from validated technology acceptance scales to assess user perception of DeepSeek. A 12-item Likert scale questionnaire was developed and pilot-tested (n=20). It was then distributed on the web to users in India, the United Kingdom, and the United States who had used DeepSeek within the past 2 weeks. Data analysis involved descriptive frequency assessments and Partial Least Squares Structural Equation Modeling. The model assessed direct and indirect effects, including potential quadratic relationships.
Results
A total of 556 complete responses were collected, with respondents almost evenly split across India (n=184), the United Kingdom (n=185), and the United States (n=187). Regarding AI in health care, when asked whether they were comfortable with their health care provider using AI tools, 59.3% (n=330) were fine with AI use provided their doctor verified its output, and 31.5% (n=175) were enthusiastic about its use without conditions. DeepSeek was used primarily for academic and educational purposes, 50.7% (n=282) used DeepSeek as a search engine, and 47.7% (n=265) used it for health-related queries. When asked about their intent to adopt DeepSeek over other LLMs such as ChatGPT, 52.1% (n=290) were likely to switch, and 28.9% (n=161) were very likely to do so. The study revealed that trust plays a pivotal mediating role; ease of use exerts a significant indirect impact on usage intentions through trust. At the same time, perceived usefulness contributes to trust development and direct adoption. By contrast, risk perception negatively affects usage intent, emphasizing the importance of robust data governance and transparency. Significant nonlinear paths were observed for ease of use and risk, indicating threshold or plateau effects.
Conclusions
Users are receptive to DeepSeek when it is easy to use, useful, and trustworthy. The model highlights trust as a mediator and shows nonlinear dynamics shaping AI-driven health care tool adoption. Expanding the model with mediators such as privacy and cultural differences could provide deeper insights. Longitudinal experimental designs could establish causality. Further investigation into threshold and plateau phenomena could refine our understanding of user perceptions as they become more familiar with AI-driven health care tools.}
}
@article{LIU2024104977,
title = {Investigating students’ cognitive processes in generative AI-assisted digital multimodal composing and traditional writing},
journal = {Computers & Education},
volume = {211},
pages = {104977},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104977},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002543},
author = {Meilu Liu and Lawrence Jun Zhang and Christine Biebricher},
keywords = {Cognitive process, Generative artificial intelligence, Digital multimodal composing, Writing},
abstract = {Recently, generative artificial intelligence (AI)-powered chatbots such as ChatGPT and Bing Chat have garnered increasing attention on a global scale. Previous studies have focused mostly on the influence of generative AI on writing while few researchers have investigated how generative AI can facilitate students' multimodal writing process. To fill in this gap, we explored the generative AI-assisted composing processes of two groups of English as a foreign language (EFL) writers over two weeks in this qualitative study. One group completed a multimodal PowerPoint (PPT) project, and the other group completed a traditional argumentative essay project. Our data consist of students’ screen recordings with think-aloud protocols, final multimodal texts, and post-project interviews. Our analysis showed different patterns in text production across the two groups. Students in the PPT group tended to construct more bridge texts and examples to corroborate their sub-claims in the hierarchical order. They also inclined to borrow the summarized search results from the Bing Chat to expand texts for their PPT slides. With regard to image generation for PPT slides, descriptions of AI images from ChatGPT were used as effective prompts to generate AI images from Bing Image Creator. Moreover, students were interested in producing and refining AI images following the recommended prompts by Bing Chat. They also evaluated these AI images from different perspectives. We conclude the study with a discussion on the pedagogical implications and suggestions for further study.}
}
@article{ZHAO2025101167,
title = {Large language models (LLMs) as research Subjects: Status, opportunities and challenges},
journal = {New Ideas in Psychology},
volume = {79},
pages = {101167},
year = {2025},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2025.101167},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X25000236},
author = {Chenguang Zhao and Meirewuti Habule and Wei Zhang},
keywords = {Generative artificial intelligence (GAI), Large language models (LLMs), Chat-GPT, Cognitive psychology, Clinical psychology},
abstract = {As large language models (LLMs) exhibit human-like cognitive abilities, their potential as participants in psychological studies is gaining attention. This paper reviewed recent research utilizing LLMs as subjects, analyzing their cognitive capacities and experimental applications. This study proposed a theoretical model to assess their feasibility, highlighting key considerations such as model parameters and biases. Using LLMs may help lower costs, enhance efficiency, and address sensitive topics. Future research may explore LLM-assisted questionnaire design, interactive dialogue agents, and task simulations for specific populations, offering new methodological tools for psychological research and beyond.}
}
@article{TAHTOUH2025100181,
title = {Technological enhancements in personalized dietary management for chronic conditions},
journal = {Biomedical Engineering Advances},
volume = {10},
pages = {100181},
year = {2025},
issn = {2667-0992},
doi = {https://doi.org/10.1016/j.bea.2025.100181},
url = {https://www.sciencedirect.com/science/article/pii/S2667099225000374},
author = {Tania Tahtouh and Hadil Salman and Nermin Eissa and Najla Al Nassar and Sofyan Maghaydah and Marah Alhalabi and Maha Yaghi and Abdalla Gad and Dana Abdallah and Salma Elberry and Aysha Alhosani and Shaikha Alshehhi and Mohammad Alkhedher and Mohamad Ramadan and Mohammed Ghazal},
keywords = {Dietary management, Chronic conditions, mHealth, Personalized health, Artificial intelligence, Smart technology},
abstract = {Dietary compliance plays a vital role in the control of chronic diseases and influences response to therapy. The rapid development experienced nowadays through smart technology has enabled the personalization of dietary advice to meet individual needs. This paper provides an overview of the current technological solutions to dietary adherence among patients with chronic conditions. With the increasing prevalence of chronic diseases requiring diet-specific interventions, this review encompasses mobile apps and wearables to IoT-based devices and generative intelligence tools, including chatbots, aimed at offering specific guidance as well as providing individualized support for dietary requirements. This review provides an overview of the strengths and limitations of these approaches in real world applications, as well as emerging methodologies that attempt to improve this by focusing on means to personalize dietary management more effectively. The study suggests that technology-enabled dietary interventions can be useful to support chronic disease management and generative artificial intelligence may have a profound effect on the further personalization of dietary guidance. However, issues surrounding regulatory alignment, content validity and long-term user engagement remain to be resolved in order to maximize the tools’ functionality in clinical and home settings.}
}
@article{BARA2025106063,
title = {AI contextual information shapes moral and aesthetic judgments of AI-generated visual art},
journal = {Cognition},
volume = {257},
pages = {106063},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2025.106063},
url = {https://www.sciencedirect.com/science/article/pii/S0010027725000034},
author = {Ionela Bara and Richard Ramsey and Emily S. Cross},
keywords = {AI-generated art, Moral judgments, Aesthetic judgments, Contextual information, Implicit moral associations},
abstract = {Throughout history, art creation has been regarded as a uniquely human means to express original ideas, emotions, and experiences. However, as Generative Artificial Intelligence reshapes visual, aesthetic, legal, and economic culture, critical questions arise about the moral and aesthetic implications of AI-generated art. Despite the growing use of AI tools in art, the moral impact of AI involvement in the art creation process remains underexplored. Understanding moral judgments of AI-generated art is essential for assessing AI's impact on art and its alignment with ethical norms. Across three pre-registered experiments combining explicit and implicit paradigms with Bayesian modelling, we examined how information about AI systems influences moral and aesthetic judgments and whether human art is implicitly associated with positive attributes compared to AI-generated art. Experiment 1 revealed that factual information about AI backend processes reduced moral acceptability and aesthetic appeal in certain contexts, such as gaining financial incentives and art status. Experiment 2 showed that additional information about AI art's success had no clear impact on moral judgments. Experiment 3 demonstrated that an implicit association task did not reliably link human art with positive attributes and AI art with negative ones. These findings show that factual information about AI systems shapes judgments, while different information doses about AI art's success have limited moral impact. Additionally, implicit associations between human-made and AI-generated art are similar. This work enhances understanding of moral and aesthetic perceptions of AI-generated art, emphasizing the importance of examining human—AI interactions in an arts context, and their current and evolving societal implications.}
}
@article{SIVARAJKUMAR2024,
title = {An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/55318},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000383},
author = {Sonish Sivarajkumar and Mark Kelley and Alyssa Samolyk-Mazzanti and Shyam Visweswaran and Yanshan Wang},
keywords = {large language model, LLM, LLMs, natural language processing, NLP, in-context learning, prompt engineering, evaluation, zero-shot, few shot, prompting, GPT, language model, language, models, machine learning, clinical data, clinical information, extraction, BARD, Gemini, LLaMA-2, heuristic, prompt, prompts, ensemble},
abstract = {Background
Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches.
Objective
The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models.
Methods
This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches.
Results
The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types.
Conclusions
This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.}
}
@article{WOLF2024102821,
title = {ChatGPT usage in everyday life: A motivation-theoretic mixed-methods study},
journal = {International Journal of Information Management},
volume = {79},
pages = {102821},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102821},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000690},
author = {Vinzenz Wolf and Christian Maier},
keywords = {Generative artificial intelligence (GenAI), Continuance intention, Motivation, Fuzzy-set qualitative comparative analysis (fsQCA), Mixed-methods design},
abstract = {GenAI-driven technologies such as ChatGPT influence activities in all areas of life and are used in private and work contexts. This study uses an individual-centered perspective to explain what motivates users to use ChatGPT continuously. We propose that four motivational factors and two technology characteristics together lead to continuance intention among individual ChatGPT users. Therefore, we use a mixed-methods design to combine findings from a quantitative survey study and a qualitative interview study. In Study 1, we follow a configurational approach to analyze multi-wave data from 279 participants with fsQCA. We identify five configurations that lead to high continuance intention and show that perceived ease of use and perceived novelty are necessary for this outcome. Interestingly, the observed factors together cannot explain low continuance intention. In Study 2, we complement these findings with insights based on 15 semi-structured interviews. We illustrate the configurations by identifying 27 individual use cases in the private and work contexts as well as additional factors that facilitate and hinder individual ChatGPT continuance intention. We draw meta-inferences by combining findings of both studies to develop five propositions. Based on that, we contribute a motivational, individual perspective on GenAI continuance intention, present practical implications as well as valuable future research opportunities.}
}
@article{LI2025115329,
title = {Computer vision in branding: A conceptual framework and future research agenda},
journal = {Journal of Business Research},
volume = {193},
pages = {115329},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115329},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325001523},
author = {Yaqiu Li and Hsin Hsuan {Meg Lee} and Lorena Blasco-Arcas},
keywords = {Branding, Computer vision, Machine learning, Image analysis, Visual analysis, Deep learning},
abstract = {This study examines how computer vision transforms branding research by offering a typology of visual features and introducing an integrative CTV-CBBE framework that bridges computational processes and branding outcomes. Through an integrative literature review, we analyze the impact of computer vision across different levels of brand equity, highlighting a progression from single-level to integrative visual analysis, from single to multimodal approaches, and from static imagery to broader visuals. These advancements underscore the growing importance of computer vision in navigating dynamic, hyperconnected branding environments. Our findings contribute to assessing brand identity, enhancing product design, interpreting brand meaning, evaluating consumer sentiment, and improving engagement. To advance the field, we propose a future research agenda centered on leveraging underexplored visual features, generative artificial intelligence, and multimodality while aligning technical innovations with branding theories. This study offers a strategic roadmap for researchers and practitioners to harness computer vision to enhance branding strategies.}
}
@article{FU2025105347,
title = {Generative AI in the context of assistive technologies: Trends, limitations and future directions},
journal = {Image and Vision Computing},
volume = {154},
pages = {105347},
year = {2025},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2024.105347},
url = {https://www.sciencedirect.com/science/article/pii/S0262885624004529},
author = {Biying Fu and Abdenour Hadid and Naser Damer},
keywords = {Assistive AI, Generative AI, Generative models, Assistive systems, Assistive technologies and services},
abstract = {With the tremendous successes of Large Language Models (LLMs) like ChatGPT for text generation and Dall-E for high-quality image generation, generative Artificial Intelligence (AI) models have shown a hype in our society. Generative AI seamlessly delved into different aspects of society ranging from economy, education, legislation, computer science, finance, and even healthcare. This article provides a comprehensive survey on the increased and promising use of generative AI in assistive technologies benefiting different parties, ranging from the assistive system developers, medical practitioners, care workforce, to the people who need the care and the comfort. Ethical concerns, biases, lack of transparency, insufficient explainability, and limited trustworthiness are major challenges when using generative AI in assistive technologies, particularly in systems that impact people directly. Key future research directions to address these issues include creating standardized rules, establishing commonly accepted evaluation metrics and benchmarks for explainability and reasoning processes, and making further advancements in understanding and reducing bias and its potential harms. Beyond showing the current trends of applying generative AI in the scope of assistive technologies in four identified key domains, which include care sectors, medical sectors, helping people in need, and co-working, the survey also discusses the current limitations and provides promising future research directions to foster better integration of generative AI in assistive technologies.}
}
@article{YOCKEL2024e827,
title = {Mental Health Experts’ Opinions About the Use of AI to Support Grieving Families: Helpful or Hype? (GP134)},
journal = {Journal of Pain and Symptom Management},
volume = {67},
number = {5},
pages = {e827-e828},
year = {2024},
issn = {0885-3924},
doi = {https://doi.org/10.1016/j.jpainsymman.2024.02.525},
url = {https://www.sciencedirect.com/science/article/pii/S0885392424006080},
author = {Mary Rose Yockel and Marcelo Sleiman and Heather Doherty and Rachel Adams and Kimberly M. Davis and Hunter Groninger and Kathryn A. Walker and Kenneth P. Tercyak},
abstract = {Outcomes
1. Gain familiarity with generative artificial intelligence and its applications to mental health. 2. Learn how to conduct empirical research in palliative care focused on the opinions of children's mental health professionals regarding artificial intelligence.
Key Message
Generative artificial intelligence (AI) is emerging as a tool in healthcare, with the potential to support grief counseling and legacy-building in families. The authors discuss new research on the intersection of AI with legacy-building among terminally ill parents for their children, and mental health experts' opinions about AI for children.
Importance
With the advent of generative artificial intelligence (AI), opportunities exist to help terminally ill parents co-create legacies for children. However, the impact of such practices on children's well-being is unknown.
Objective(s)
Assess children's mental health professionals’ (CMHPs) opinions about psychological needs surrounding, and applications of AI for, children's coping with the loss of a parent.
Scientific Methods Utilized
Practicing CMHPs were approached via association listservs and targeted social media ads. Data from N=298 (69% male, 72% white, 26% Latine, 56% rural/underserved communities; 87% of study total) physicians, psychologists, social workers, hospital chaplains, and community health workers were analyzed.
Results
Among CMHPs, 54% engaged with families upon diagnosis of parental terminal illness, 34% believed anticipatory guidance about loss could begin at diagnosis, and 26% following parental death. Across 10 dimensions of childhood, Plackett-Luce Model rank-ordering revealed that: 1) children's premorbid exposure to traumatic events, 2) surviving caregiver presence, and 3) child age were important factors to consider in CMHP treatment decision-making. Regarding AI, 91% were frequent AI users (e.g., smart speakers) and 87% foresaw a role for generative AI (e.g., new audio, images, text, and videos based on someone's likeness) in supporting children's mental health. Opinions toward AI as a legacy-building tool varied: 47% denied its potential, 18% believed it could be introduced at parents’ diagnosis, and 20% during treatment. In an adjusted multivariable model of the timing of generative AI introduction, CMHPs who believed anticipatory guidance could be introduced earlier in terminal illness believed AI could also be introduced earlier (B=.39, SE=.06, t=6.3, p<.01).
Conclusion(s)
AI may become a legacy-building tool for terminally ill parents to support children prior to and following loss.
Impact
Research should explore the scope and impact that AI-generated content could have on children's mental health, grief, and long-term recovery.}
}
@article{ATHE2024113526,
title = {Knowledge representation to support EMDAP implementation in advanced reactor licensing applications},
journal = {Nuclear Engineering and Design},
volume = {428},
pages = {113526},
year = {2024},
issn = {0029-5493},
doi = {https://doi.org/10.1016/j.nucengdes.2024.113526},
url = {https://www.sciencedirect.com/science/article/pii/S0029549324006265},
author = {Paridhi Athe and Nam Dinh and Abhinav Gupta},
keywords = {Evaluation model, EMDAP, Knowledge representation, Adequacy decision},
abstract = {The Data, Information, Knowledge, and Wisdom (DIKW) pyramid depicts the general principle of a decision-making process. Various levels of abstraction are required to formalize the available data/information/knowledge with respect to the decision being supported. The Evaluation Model Development and Assessment Process (EMDAP) was developed by the United States Nuclear Regulatory Commission (US NRC) to guide the development and assessment of Evaluation Models (EMs) for transient and accident analysis of nuclear power plants under design basis accidents. It concerns the decision of adequacy of an EM with respect to the purpose of analysis (NPP application). However, lack of data, scaling issues, modeling limitations, computation, and experimental overhead are some of the key factors that challenge the EM adequacy decision in EMDAP. Phenomena Identification and Ranking Table (PIRT) which is used for complexity resolution can also introduce noise due to bias and variance in expert opinion and judgment. The uncertainty in the decision due to these issues and challenges can be minimized by enhancing the EMDAP from the DIKW perspective. In this work, we formulate a systematic scheme for knowledge representation, and classification and characterization of evidence to enhance clarity and transparency in the EMDAP implementation. The proposed scheme is governed by the concept of the value of information, where we contextualize, classify, characterize, and evaluate the evidence (relevant data/knowledge/information related to EM development, verification, validation, and uncertainty quantification) with respect to the relevant decision attributes or elements of EMDAP. We make use of the Predictive Capability Maturity Model (PCMM), Argumentation technique, and process quality assurance for knowledge representation to support EMDAP implementation in advanced reactor licensing applications. The main objective of the proposed scheme is to support decision-making by making it more transparent, traceable, and accountable. The illustration of the proposed scheme is provided using a system simulation code (SAS4A/SASSYS-1) as the primary EM and a generic sodium fast reactor under loss of flow accident as the target reactor application. EMDAP involves different elements that require expert input and insights. However, the process of expert elicitation may require significant resources and time. To address these issues, we identify generative artificial intelligence models as potential tool which (after systematic testing and capabilities analysis) can be used for domain specific expert elicitation and information extraction for efficient implementation of EMDAP.}
}
@article{AYEMOWA2024100518,
title = {A systematic review of the literature on deep learning approaches for cross-domain recommender systems},
journal = {Decision Analytics Journal},
volume = {13},
pages = {100518},
year = {2024},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2024.100518},
url = {https://www.sciencedirect.com/science/article/pii/S277266222400122X},
author = {Matthew O. Ayemowa and Roliana Ibrahim and Yunusa Adamu Bena},
keywords = {Recommender systems, Decision making, Deep learning, Predictive analytics, Users behavior analysis, Cross-domain},
abstract = {The increase in online information and the expanding diversity of user preferences require developing improved recommender systems. Cross-domain recommender systems (CDRS) have emerged as a favorable solution to solve issues related to cold start, data sparsity, and diversity by leveraging knowledge from the source domains. This systematic literature review delves into the latest deep learning approaches utilized for CDRS, comprehensively analyzing state-of-the-art techniques, methodologies, metrics, datasets, and applications. We systematically review selected primary studies from popular databases covering sixty-eight publications from 2019 to March 2024. The review process involved selecting relevant studies based on the predefined inclusion and exclusion criteria to ensure the inclusion of high-quality research. Key deep learning (DL) models explored include neural collaborative filtering, convolutional neural networks, recurrent neural networks, variational autoencoder, and generative adversarial networks. We also examine the hybrid models that integrate DL with traditional machine learning techniques to enhance recommendation performance. Our findings reveal that DL approaches significantly improve accuracy, cold start, and data sparsity. This review also identifies current trends and future research directions, emphasizing the potential of Artificial Intelligence (AI), transfer learning, and reinforcement learning in advancing CDRS. In our analysis, we discovered that the domains mainly utilized are movies, books, and music, respectively, and the most widely used evaluation metrics are root mean square error (RMSE) and normalized discounted cumulative gain (NDCG). Research challenges and future scope are also highlighted to assist the researchers and practitioners seeking to develop robust cross-domain recommender systems using DL techniques.}
}
@article{BLANCHARD20242166,
title = {AB1583-HPR GENERATIVE AI-BASED KNOWLEDGE GRAPH AND TEXT NETWORK ANALYSIS FOR THE ILLUSTRATION AND DEVELOPMENT OF MHEALTH SELF-MANAGEMENT CONTENT},
journal = {Annals of the Rheumatic Diseases},
volume = {83},
pages = {2166-2167},
year = {2024},
issn = {0003-4967},
doi = {https://doi.org/10.1136/annrheumdis-2024-eular.1565},
url = {https://www.sciencedirect.com/science/article/pii/S0003496724182362},
author = {M. Blanchard and V. Venerito and T. Hügle},
keywords = {Artificial Intelligence, Self-management, Digital health/Measuring health},
abstract = {Background:
Digital therapeutics (DTx) in the form of mobile Health (mHealth) self-management programs have shown efficacy in reducing disease activity in different rheumatic diseases, including fibromyalgia and arthritis. They are mostly based on cognitive behavior therapy, lifestyle modification, adherence and physical exercise. The specific content of individual online programs are heterogeneous and hardly comparable.
Objectives:
To use generative artificial intelligence (AI)-based knowledge graphs and network analysis to illustrate and structure mHealth content in order to improve its quality.
Methods:
The content of a previously developed mHealth online program (POCOS) for post-viral fibromyalgia-like syndromes was used for this analysis (24 modules, 22.150 words in total). Animated or video files were excluded. We used ChatGPT4 (OpenAI) and Infranodus (Nodus Labs) with built-in GPT-4 as generative AI web-applications to create knowledge graphs and perform text network analysis.
Results:
ChatGPT-generated knowledge graph provided a visual overview with 5 main edges: ‘Mental health challenges’, ‘stress and its impact’, ‘immune system function’, ‘long covid and fibromyalgia’, ‘pain management and therapeutic approaches’. In the 3-dimensional visualization, the term ‘pain’ had the highest betweenness with ‘sleep’, ‘body’ and ‘stress’. Topical cluster analysis revealed the following categories: chronic pain management, sleep hygiene, immune system function cognitive therapy, healthy eating, emotional development, fibromyalgia causes and deep relaxation. A gap analysis revealed several lacking connections such as between the terms ‘negative behavior’ and ‘systemic inflammation’. Selected Concepts Relation Analysis was performed for several nodes. For example, the node ‘pain’ and ‘covid’ had an influence of 0.48 (19% of total). It was connected to 23 of 150 nodes (15%) in the knowledge graph with a relation to the terms sleep, muscle and breathing.
Conclusion:
Generative AI-tools for text network analysis structure and illustrate DTx content. They can be used to highlight concepts and work on knowledge-synapses and to elucidate gaps in order to improve content.
REFERENCES:
NIL.
Acknowledgements:
NIL.
Disclosure of Interests:
Marc Blanchard Atreon, Vincenzo Venerito: None declared, Thomas Hügle Pfizer, GSK, Roche, Abbvie, Galapagos, Novartis, Janssen, Atreon, Vtuls, Sidekick. Figure 1}
}
@article{ANDREW20256,
title = {Overview of the emerging role of chatbots, including large language models, in supporting tobacco smoking and vaping cessation: a narrative review},
journal = {Global Health Journal},
volume = {9},
number = {1},
pages = {6-11},
year = {2025},
issn = {2414-6447},
doi = {https://doi.org/10.1016/j.glohj.2025.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2414644725000041},
author = {Albert Andrew},
keywords = {Smoking, Tobacco, Vaping, Cessation, ChatGPT, Chatbots},
abstract = {Despite a global decline in tobacco use, smoking remains a leading cause of preventable death, with rising vaping rates among adolescents and young adults further complicating nicotine cessation efforts. Digital interventions, particularly chatbots, have gained attention for their potential to support tobacco and vaping cessation by simulating human-like conversations and providing instant feedback. However, evidence of their effectiveness is limited. The emergence of generative artificial intelligence (AI) chatbots, such as ChatGPT, offers a promising avenue for more personalised and effective cessation support. This article reviews existing literature on traditional chatbot interventions for cessation services, explores the potential of AI chatbots, namely ChatGPT, in continuing to support tobacco and vaping cessation efforts, and identifies areas for future research. It highlights the need to further monitor the reliability and accuracy of AI-generated content and to develop frameworks ensuring healthcare professionals receive adequate training in using these new tools effectively to support patients in quitting smoking and/or vaping.}
}
@article{ALHASHIMI2025100509,
title = {Exploring the role of generative AI in enhancing cybersecurity in software development life cycle},
journal = {Array},
volume = {28},
pages = {100509},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100509},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625001365},
author = {Hussein A. Al-Hashimi and Rafiq Ahmad Khan and Hathal S. Alwageed and Asaad M. Algarni and Sarra Ayouni and Alaa Omran Almagrabi},
keywords = {Generative artificial intelligence, Cybersecurity, Software development lifecycle, Risks and practices, Systematic literature review, Survey},
abstract = {Context
The rapid integration of Generative AI (GenAI) technologies in various sectors has introduced new opportunities and challenges. One of the areas where GenAI is gaining prominence is cybersecurity, particularly within the Software Development Life Cycle (SDLC). As cyber threats evolve, there is a growing need to explore innovative solutions to mitigate vulnerabilities during software development.
Objectives
This study investigates the role of GenAI in enhancing cybersecurity in the SDLC. It examines current security practices, recent advancements in AI-driven security solutions, and the potential of GenAI to strengthen threat detection, vulnerability management, and risk mitigation. Additionally, the research identifies key opportunities and challenges associated with integrating GenAI into SDLC processes, highlighting its implications for secure software development and future industry practices.
Methods
This research employs a mixed-methods approach to investigate the role of GenAI in cybersecurity. Specifically, it combines a Systematic Literature Review (SLR) with questionnaire-based data collection targeting software development and cyber defense experts. The SLR aims to identify prevailing themes and gaps, while the questionnaire gathers insights from IT professionals about their experiences and perspectives on GenAI systems.
Results
Our research shows that GenAI technology enhances SDLC security by supporting development through vulnerability detection, threat modeling, secure coding practices, and incident response. However, our review shows that AI adoption introduces ethical risks alongside reliability issues with AI-created results and challenges to integrate it into standard development methods.
Conclusion
The integration of GenAI into the SDLC offers significant potential for enhancing cybersecurity. While challenges such as algorithm transparency and the need for skilled professionals remain, the benefits of AI in proactive threat detection and response make it a promising tool for future cybersecurity strategies in software development.}
}