@article{JANSSEN2025101791,
title = {Barriers to breakthroughs: A scoping review of generative AI in healthcare simulation},
journal = {Clinical Simulation in Nursing},
volume = {107},
pages = {101791},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101791},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001082},
author = {Erika Janssen and Rebecca McLagan and Jessica Habeck and Seon Yoon Chung and Erin C. McArthur and Polly Anderson},
keywords = {Generative pre-trained transformer, Generative artificial intelligence, Healthcare simulation, Nursing education, Review, Simulation-based learning},
abstract = {Background
Generative artificial intelligence (AI) is an emerging technology in healthcare education with potential to enhance simulation by addressing logistical barriers and by providing increased access to diverse settings in healthcare education, leading to improved learning outcomes. This rapid scoping review explores the use of generative AI in simulation-based education.
Methods
Searches were conducted in CINAHL, Medline, PsycINFO, ScienceDirect, and Web of Science using terms such as “generative artificial intelligence” and “healthcare simulation.” The review followed the World Health Organization (WHO) Rapid Review Guide and was structured using Arksey and O'Malley's five-stage framework for scoping reviews.
Results
After applying inclusion and exclusion criteria, 15 articles were included. Five themes emerged: (1) removal of logistical barriers, (2) authentic practice, (3) distinctive value, (4) limitations of generative AI, and (5) potential with human oversight. Generative AI improves access to simulation by creating cost-effective, scalable, and realistic scenarios while fostering critical thinking through reflective learning. However, challenges such as misinformation and ethical concerns remain.
Conclusions
This scoping review identified growing momentum around generative AI's role in healthcare simulation. While early studies highlight its potential to support scalable, adaptive, and authentic training experiences, effective integration requires strong governance, ethical safeguards, and human oversight.}
}
@article{BILGIHAN2024103929,
title = {The GAI marketing model: A conceptual framework and future research directions},
journal = {International Journal of Hospitality Management},
volume = {123},
pages = {103929},
year = {2024},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.103929},
url = {https://www.sciencedirect.com/science/article/pii/S027843192400241X},
author = {Anil Bilgihan and Tarik Dogru and Lydia Hanks and Nathan Line and Makarand Mody},
keywords = {Generative artificial intelligence, GAI, AI, Marketing, Conceptual framework},
abstract = {This research introduces the GAI Marketing Model, a comprehensive conceptual framework for understanding and applying generative artificial intelligence (GAI) within marketing, specifically in the hospitality and tourism sectors. Building on existing classifications of GAI, this model incorporates critical elements such as adoption factors, marketing stages, and downstream outcomes. The framework offers a structured approach to exploring GAI’s potential to transform marketing strategies by enhancing personalization, improving customer engagement, and optimizing decision-making processes. The GAI Marketing Model synthesizes elements of technology, marketing theory, and consumer psychology, offering crucial insights that are instrumental for researchers and practitioners seeking to harness GAI for competitive advantage. Additionally, the model underscores the importance of ethical considerations and regulatory compliance, thereby ensuring that the integration of GAI into marketing practices remains both efficacious and responsible. This study establishes a foundational framework for future research, emphasizing the interdisciplinary scope of GAI’s influence on marketing strategies and practices}
}
@article{ZHANG2025100767,
title = {The impact of generative AI on management innovation},
journal = {Journal of Industrial Information Integration},
volume = {44},
pages = {100767},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24002103},
author = {Caiming Zhang and Hui Zhang},
keywords = {Generative artificial intelligence, Management decision-making, Management Algorithms, Information Integration},
abstract = {Generative Artificial Intelligence (GAI) demonstrates significant potential in the application of management and organizational innovation. This paper systematically investigates the multifaceted impacts of GAI on management decision-making, management algorithms, information integration, and various specific domains. GAI significantly enhances the accuracy of management decisions through its robust data analysis and predictive capabilities. By effectively integrating internal and external information, it reduces information asymmetry and improves both information transparency and the quality of decisions. In terms of specific application areas, GAI shows broad prospects in multiple fields, including business, education, healthcare, content creation, and game development. As GAI technology continues to advance, it will become more intelligent and adaptive. However, further research and the establishment of relevant ethical guidelines and legal frameworks are necessary to ensure its safety and reliability.}
}
@incollection{OCKEY2025,
title = {Assessing Second Language Listening in the 21st Century},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00449-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395504100449X},
author = {Gary J. Ockey and Inyoung Na},
keywords = {Artificial intelligence, Assessment, Construct approach, Dynamic assessment, Listening, Technology},
abstract = {The assessment of second language listening is critical for both understanding language learners' abilities and progress and promoting effective second language learning and instruction. Advances in the understanding of the construct of listening, factors that can impact listening and how it is assessed, and developments in technology, specifically generative artificial intelligence have led to more effective listening assessment. This entry provides researchers and practitioners with an overview of the assessment of listening that can help to guide decisions about selecting listening assessments for their particular purposes.}
}
@article{RATHEE2025265,
title = {Enhanced healthcare using generative AI for disabled people in Saudi Arabia},
journal = {Alexandria Engineering Journal},
volume = {124},
pages = {265-272},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.03.073},
url = {https://www.sciencedirect.com/science/article/pii/S1110016825003813},
author = {Geetanjali Rathee and Sahil Garg and Georges Kaddoum and Samah M. Alzanin and Mohammad Mehedi Hassan},
keywords = {Generative Artificial Intelligence (GAI), Improved healthcare sector, Health services for disabled people, Accurate decision-making},
abstract = {Saudi Arabia’s Vision 2030 prioritizes advances in healthcare to improve accessibility, improve medical services, and support people with disabilities. Despite the adoption of telemedicine and AI-driven healthcare solutions, disabled and elderly people continue to face challenges in accessing real-time medical services, receiving accurate diagnoses and independently navigate healthcare facilities. Current healthcare systems often struggle with delays, lack of personalization, and inefficiencies in medical data processing, limiting their effectiveness in providing inclusive and responsive healthcare. To address these challenges, this paper proposes an AI-powered healthcare framework that integrates Generative Artificial Intelligence (GAI), Reinforcement Learning from Human Feedback (RLHF), and the Analytic Network Process (ANP). RLHF enables AI models to learn and adapt based on real-time user feedback, ensuring a personalized and interactive healthcare experience. Meanwhile, ANP optimizes decision-making processes, allowing for faster, more accurate medical service delivery by considering multiple healthcare factors. This combined approach improves remote consultations, intelligent diagnostics, and seamless real-time interactions, significantly improving accessibility to healthcare for disabled individuals. The proposed framework is evaluated against existing AI-driven healthcare models. Results demonstrate that the system outperforms traditional methods, providing a faster, more reliable, and patient-centered healthcare experience. By combining GAI, RLHF, and ANP, this research offers a practical solution to improve healthcare accessibility for disabled individuals, aligning with the goals of Saudi Arabia’s Vision 2030.}
}
@article{YANG202523,
title = {The Engagement of Prospective Chinese Engineers in Translation Software and Generative AI toward Learning English},
journal = {Procedia Computer Science},
volume = {257},
pages = {23-30},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925007422},
author = {Kaiwen Yang and Yikerong Wang and Lin Ma and Shiru Qiao and Haoran Lin and Yichen Yang and Edison B. Estigoy and Sun Hao},
keywords = {Non-language Major, Language Learning, Translation Softwar, Generative AI},
abstract = {Learning a new language in a globalized world is seen as a valuable asset in the job market, opening up more career and networking opportunities. In anticipation of these possibilities, students are learning a new language, especially English, in addition to their chosen discipline. In an increasingly connected world, language technologies are perceived as a bridge to language barriers, fostering global communication and collaboration, especially in learning a new language. This quantitative study utilized a questionnaire to determine the level of engagement in two language technologies: translation software and Generative Artificial Intelligence (GAI) toward language learning of 334 prospective Chinese engineers in an International Engineering College. It also explored significant differences in respondents’ level of engagement in translation software and GAI across different disciplines of engineering and examined the relationship between the two language technologies. Results reveal that respondents demonstrated ‘sometimes’ in their engagement in language technologies. Further, a significant difference was identified in engagement with translation and GAI when respondents were categorized according to discipline. Finally, engagement in translation software was found to be significantly related to engagement in Generative Artificial Intelligence.}
}
@article{GUNTUKA2025215,
title = {Generative AI in minimizing cyber-attacks: Developing the Vehicular Threat Intelligence Flowchart},
journal = {Procedia Computer Science},
volume = {257},
pages = {215-224},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925007665},
author = {Sony Guntuka and Elhadi Shakshuki and Haroon Malik},
keywords = {Cyber attacks, GenAI, Vehicular Networks, Cybersecurity, Threat Detection},
abstract = {This paper delves into the innovative applications of Generative Artificial Intelligence (GenAI) in enhancing the cybersecurity of vehicular networks, a critical area given the increasing integration of intelligent transport systems and autonomous vehicles. As vehicular networks become more sophisticated, they also become more susceptible to cyber-attacks that can compromise vehicle control systems, endangering public safety and personal privacy. GenAI offers advanced capabilities for automating defences, improving threat intelligence, and creating dynamic security frameworks that can adapt to emerging threats. This research is a comprehensive overview of the current state of GenAI in the context of vehicular network cybersecurity, highlighting the development and implementation of the Vehicular Threat Intelligence Flowchart (VTIF). The VTIF features a threat detection rule algorithm that automates the identification of cyber threats, significantly improving detection accuracy. While the integration of GenAI presents substantial benefits, it also introduces new risks, necessitating robust ethical, legal, and technical oversight. This paper outlines the potential advantages and challenges of employing GenAI in vehicular cybersecurity and proposes future research directions aimed at developing resilient and ethical cybersecurity mechanisms.}
}
@article{NIEDBAL20233059,
title = {Students' Use of the Artificial Intelligence Language Model in their Learning Process},
journal = {Procedia Computer Science},
volume = {225},
pages = {3059-3066},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.299},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014576},
author = {Rafał Niedbał and Adam Sokołowski and Artur Wrzalik},
keywords = {ChatGPT, Generative Artificial Intelligence, chatbot, Large Language Models, modern IT in education, innovative education},
abstract = {Generative Artificial Intelligence (GAI), of which ChatGPT is an exemplary tool, is beginning to revolutionize the way people search for information and use the information they acquire in their personal and professional lives. ChatGPT is showing a strong track record in a variety of tasks, such as generating text, summarizing text and answering questions during a conversation. It has the potential to revolutionize a wide range of fields - including education. The purpose of this article is to evaluate the extent to which the ChatGPT language model can be applied in the learning process for two types of students: full-time and part-time. Additionally, this article assesses the level of students' familiarity with intelligent chat functionality and their ability to construct queries directed to it. The study found that the use of an advanced language model based on artificial intelligence is more beneficial for full-time students in the learning process. However, there was no statistically significant difference in the knowledge of intelligent chat functionality and the ability to construct queries directed to it between full-time and part-time students.}
}
@article{ADAM2025102771,
title = {Generative AI-driven reinforcement learning for beamforming and scheduling in multi-cell MIMO-NOMA systems},
journal = {Physical Communication},
volume = {72},
pages = {102771},
year = {2025},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2025.102771},
url = {https://www.sciencedirect.com/science/article/pii/S1874490725001740},
author = {Abuzar B.M. Adam and Elhadj Moustapha Diallo and Mohammed Saleh Ali Muthanna and Reem Ibrahim Alkanhel and Ammar Muthanna and Mohammad Hammoudeh},
keywords = {Multi-cell, Non-orthogonal multiple access (NOMA), Multiple-input and multiple-output (MIMO), Beamforming, User scheduling, Primal–dual, Proximal policy optimization (PPO), User generative artificial intelligence (GAI)},
abstract = {This article introduces a novel generative artificial intelligence-enhanced primal–dual proximal policy optimization (GAI-PDPPO) framework for joint user scheduling and beamforming in downlink multi-cell multiple-input and multiple-output non-orthogonal multiple access (MC-MIMO-NOMA) networks. Designed to address the challenges of interference-laden environments typical in beyond the fifth generation (B5G)/sixth generation (6G) systems, the proposed method formulates a complex mixed-integer nonlinear programming problem to minimize transmit power under stringent Quality-of-Service (QoS) constraints. Unlike conventional approaches, GAI-PDPPO incorporates an invertible transformer-based actor-critic architecture capable of modeling high-dimensional channel state information and unknown-source interference. Through the integration of generative pretraining and prioritized experience replay, the framework accelerates convergence and enhances policy generalization. Extensive simulations demonstrate that GAI-PDPPO consistently outperforms standard primal–dual PPO and benchmark solutions, achieving lower power consumption and higher spectral efficiency under varying signal-to-interference-plus-noise ratio (SINR) thresholds and interference conditions.}
}
@article{FRUEHAUF2024102876,
title = {Developing a foundation for the informational needs of generative AI users through the means of established interdisciplinary relationships},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {3},
pages = {102876},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102876},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000375},
author = {Evan Fruehauf and Andrew Beman-Cavallaro and LeEtta Schmidt},
keywords = {Generative artificial intelligence, AI, Libraries, Reference services},
abstract = {University faculty immediately had many questions and concerns in response to the public proliferation of generative artificial intelligence programs leveraging large language models to generate complex text responses to simple prompts. Librarians at the University of South Florida (USF) pooled their skills, existing relationships with faculty and professional staff across campus to provide information that answered common questions raised by those faculty on generative artificial intelligence usage within research related topics. Faculty concern regarding the worry of plagiarism, how to instruct students to use the new tools and how to discern the reliability of information generated by artificial intelligence tools were placed at the forefront. By augmenting existing tutorials and instruction sessions, and creating a new information resource, the library was able to build a timely foundation to support future efforts to address the changing information needs of faculty and students using generative artificial intelligence programs and tools.}
}
@article{BELTRAMIN2025,
title = {Foundation Models for Generative AI in Time-Series Forecasting},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/76964},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125009811},
author = {Diva Beltramin and Cedric Bousquet},
keywords = {large language models, LLM, foundation models, time series, generative artificial intelligence, artificial intelligence, electronic health records, electronic medical records, systematic reviews, disease trajectory, machine learning, algorithms, forecasting}
}
@article{BIBRI2025106826,
title = {Generative AI of Things for Sustainable Smart Cities: Synergies in Cognitive Augmentation, Resource Efficiency, Network Traffic, and Anomaly and Threat Detection for Environmental Optimization},
journal = {Sustainable Cities and Society},
pages = {106826},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106826},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725006997},
author = {Simon Elias Bibri and Jeffrey Huang},
keywords = {Generative Artificial Intelligence, Generative Internet of Things, Generative Artificial Intelligence of Things, Sustainable Smart Cities, Environmental Sustainability, Cybersecurity, Network Traffic, and Anomaly Detection},
abstract = {Artificial Intelligence of Things (AIoT) has emerged as a transformative technology driving environmental sustainability in smart city development. However, the integration of Generative Artificial Intelligence (GenAI) within AIoT ecosystems remains largely unexplored. Current research predominantly addresses conventional AIoT frameworks, overlooking the innovative potential of advanced deep generative models, such as GANs, VAEs, Diffusion Models, transformers, and hybrid architectures, to significantly enhance situational awareness, system optimization, operational robustness, real-time responsiveness, and adaptive decision-making in complex urban environments. Current IoT and AIoT systems continue to face persistent challenges such as data scarcity, poor data quality, limited adaptability, imbalanced datasets, and inadequate context-awareness. This study addresses these gaps by systematically exploring how GenAI can enhance IoT and AIoT functionalities across key domains—namely cognitive augmentation, resource efficiency, cybersecurity, network traffic, and anomaly detection—while examining their synergistic potential to improve environmental performance in sustainable smart cities. Key findings reveal that emerging advancements in integrating GenAI with IoT and AIoT systems greatly improve urban adaptability, autonomy, and resilience by fostering more dynamic, autonomous, and robust systems and infrastructures. Generative models advance the five core pillars of AIoT: sensing, perceiving, learning, visualizing, and decision-making, by enabling proactive, context-aware, and self-adaptive urban systems to enhance their environmental performance. The fusion of generative intelligence with federated learning promotes sustainable, energy-efficient IoT and AIoT deployments by reducing data transmission, thereby lowering communication overhead and safeguarding user privacy. In networked environments, generative models improve synthetic traffic realism and communication efficiency. GenAI also strengthens cybersecurity through enhanced intrusion prevention, threat detection, and resilience in IoT- and AIoT-enabled smart cities. Furthermore, GenAI-driven anomaly detection facilitates early identification and mitigation of irregularities, boosting operational efficiency and system robustness. These findings underscore the powerful synergies of these domains enabled by GAIoT, emphasizing their collaborative potential to cultivate resilient, efficient, and environmentally conscious smart city ecosystems. The proposed conceptual framework, distilled from key findings, integrates GenAI and AIoT by highlighting both domain-specific advancements and their synergistic interactions. This framework holds significant potential to drive sustainable smart city development by fostering AIoT ecosystems that are more intelligent, resource-efficient, adaptive, secure, robust, and autonomous through the strategic application of generative intelligence. The insights from this study provide policymakers, urban planners, system designers, and technology developers with practical guidance to harness GAIoT for enhancing smart city resilience, sustainability, and operational intelligence.}
}
@article{HERMANN2025215,
title = {Illusion, dilution, or loss: psychological ownership and GenAI},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {3},
pages = {215-217},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324003322},
author = {Erik Hermann},
keywords = {generative artificial intelligence, psychological ownership, content creators, users},
abstract = {Generative artificial intelligence (GenAI) reshapes and challenges psychological ownership of created content. This article examines how GenAI disrupts original content creators’ and GenAI users’ sense of ownership and control and illustrates how both can perceive the illusion, dilution, and potential loss of control and ownership of content in the GenAI era.}
}
@article{MENDESMONTEIRO2025284,
title = {Using structure-function information from IFN-γ-binding proteins and biased agonists to uncouple immunostimulatory and immunosuppressive activities},
journal = {Trends in Immunology},
volume = {46},
number = {4},
pages = {284-294},
year = {2025},
issn = {1471-4906},
doi = {https://doi.org/10.1016/j.it.2025.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S1471490625000560},
author = {Lucas Mendes-Monteiro and Abel Viejo-Borbolla},
keywords = {IFN-γ, IFN-γ receptor, viral IFN-binding protein, biased agonist, generative artificial intelligence},
abstract = {IFN-γ is a pleiotropic antiviral cytokine that coordinates innate and adaptive immune responses and induces both immunostimulatory and immunosuppressive activities, limiting its use in the clinic. Due to its antiviral role, several viruses express proteins that bind IFN-γ, blocking its interaction with the IFN-γ receptor (IFNGR). However, varicella zoster virus glycoprotein C binds IFN-γ and induces the expression of a subset of specific ISGs, similar to biased IFN-γ agonists generated based on the crystal structure of the IFN-γ – IFNGR complex. Here, we propose using structural and mechanistic information from viral proteins and biased agonists to design novel IFN-γ agonists that fine-tune IFN-γ – IFNGR activity, reducing the immunosuppressive and toxic effects of this cytokine.}
}
@article{HERMANN2025,
title = {Self-driving labs: The new frontier for GenAI-driven marketing research},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001028},
author = {Erik Hermann},
keywords = {Generative artificial intelligence, Marketing research, Self-driving labs, Chemistry},
abstract = {Generative artificial intelligence (GenAI) is not only becoming central to marketing research, but it can even enable the transition to fully autonomous marketing research. This paper introduces a new approach to marketing research inspired by self-driving laboratories (SDLs): autonomous research systems originally used in scientific fields like chemistry to accelerate discovery through real-time, closed-loop experimentation. We lay out a framework for GenAI-driven marketing research that shows how GenAI can autonomously generate hypotheses, create and test marketing content and stimuli, and continuously improve results using both real and synthetic consumer data. By integrating SDL principles like the Design-Make-Test-Analyze (DMTA) cycle, synthetic data use, multi-objective optimization, and parallel experimentation, this approach allows marketers to simulate, experiment, and adapt at scale. Additionally, we highlight emerging real-world applications and conclude with offering recommendations for effectively and responsibly deploying GenAI-driven, SDL-inspired marketing research systems. Thereby, our work can inform and inspire marketers aiming to build more adaptive, data-driven, efficient, and scalable research systems.}
}
@article{MARTINEZMARROQUIN2025353,
title = {Activity theory as framework for analysis of workplace learning technologies: the case of generative AI conversational agents},
journal = {International Journal of Information and Learning Technology},
volume = {42},
number = {4},
pages = {353-365},
year = {2025},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-07-2024-0141},
url = {https://www.sciencedirect.com/science/article/pii/S2056488025000083},
author = {Elisa {Martinez Marroquin} and Bouchra Senadji},
keywords = {Workplace learning, Informal learning, Learning technology, Generative artificial intelligence, Conversational agents, Activity theory, ChatGPT},
abstract = {Purpose
Technology, such as artificial intelligence (AI), is transforming the way we work; however, it is yet to systemically transform learning at the workplace beyond augmentation of formal education’s learning processes. This paper derives functional requirements for technologies that support workplace learning and assesses the suitability and limitations of generative AI conversational agents, as an example of application.
Design/methodology/approach
Using activity theory (AT) as theoretical framework, we model workplace learning as an activity, intertwined with work and mediated by technology, and expose contradictions that arise when technology developed for formal education is adopted at work. From these tensions, we derive functional requirements and illustrate their use by comparing them to ChatGPT’s affordances.
Findings
A framework is proposed for design and assessment of enabling technologies for workplace learning. In applying it to ChatGPT, as paradigm of conversational agents, we find the aspects that are particularly suitable to enhance workplace learning, and those that need further development.
Originality/value
The theoretical approach is novel. Previous research is based on reported use-cases of enabling technologies, such as generative artificial intelligence (GenAI), in the workplace or on the analysis of the learner’s experience when these technologies are embedded in structured training modules. The present study addresses the limitations of current retrospective research, providing a forward-looking approach.}
}
@article{LEITE2025124115,
title = {Artificial intelligence in higher education: Research notes from a longitudinal study},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124115},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124115},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525001465},
author = {Higor Leite},
keywords = {Generative artificial intelligence, Higher education, Innovation, Technology, Transformative service research},
abstract = {Generative artificial intelligence (GenAI) has disrupted traditional educational approaches. Students are applying GenAI tools to access and create new content. However, the emergence of GenAI in higher education comes with caveats and academics and university administrators are learning to navigate this uncharted territory. GenAI is treated as a double-edged sword, with several benefits, such as innovation and productivity, but also drawbacks regarding ethics and academic misconduct. Therefore, our study aims to understand the impact of GenAI on students' experiences in the higher education ecosystem as students move to a new AI-enhanced job market. This research note article presents preliminary results from a 12-month longitudinal study with students interacting with GenAI. We conducted 35 semi-structured interviews and collected private diary entries (n = 108). Our results show six meaningful themes: Harnessing AI for Enhanced Academic Performance, AI Ethics and Trust Impact on Learning, GenAI as a Supplement to Human Work, Integration and Versatility of GenAI Tools, Balancing GenAI Limitations, and Navigating the AI Adoption Journey. The study also uses the transformative service research lens to present the transformative impact of GenAI in higher education. To contribute to practice and policymakers, we designed a research agenda to inform future studies on GenAI.}
}
@article{RODRIGUEZ2024,
title = {Leveraging Generative AI Tools to Support the Development of Digital Solutions in Health Care Research: Case Study},
journal = {JMIR Human Factors},
volume = {11},
year = {2024},
issn = {2292-9495},
doi = {https://doi.org/10.2196/52885},
url = {https://www.sciencedirect.com/science/article/pii/S2292949524000245},
author = {Danissa V Rodriguez and Katharine Lawrence and Javier Gonzalez and Beatrix Brandfield-Harvey and Lynn Xu and Sumaiya Tasneem and Defne L Levine and Devin Mann},
keywords = {digital health, GenAI, generative, artificial intelligence, ChatGPT, software engineering, mHealth, mobile health, app, apps, application, applications, diabetes, diabetic, diabetes prevention, digital prescription, software, engagement, behaviour change, behavior change, developer, developers, LLM, LLMs, language model, language models, NLP, natural language processing},
abstract = {Background
Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting.
Objective
This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program.
Methods
We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency.
Results
Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies.
Conclusions
ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation.
Trial Registration
ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500}
}
@article{SRIVASTAVA2025,
title = {Theoretical Perspectives on the Impact of Generative AI on the Tourism Sector:},
journal = {Journal of Global Information Management},
volume = {33},
number = {1},
year = {2025},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.388177},
url = {https://www.sciencedirect.com/science/article/pii/S1062737525000733},
author = {Gautam Srivastava and Surajit Bag and P. Janaki Ramudu and Santosh Kumar Shrivastav and Julia Pueschel and Abla Chaouni Benabdellah},
keywords = {Generative Artificial Intelligence, Information Technology, Theories, Tourism Management},
abstract = {ABSTRACT
Advanced information technological tools, particularly generative artificial intelligence (GAI), accelerate transformation in the tourism industry. This study investigates GAI’s theoretical foundations and implications in revolutionizing tourism management. Employing a systematic literature review, followed by preferred report items for systematic review and meta-analysis (PRISMA), the study rigorously selects and interprets past research. The Theory, Context, Characteristics, and Method (TCCM) framework synthesizes, analyzes, and interprets the findings. The results reveal that GAI has significant potential in various domains of the tourism industry, including marketing, operations, sustainability, and human resources. The study maps the potential and challenges of GAI integration in tourism by identifying ten key theories. These findings provide a roadmap for scholars and managers to address the opportunities and challenges. The findings can help scholars deepen their understanding of GAI’s role and assist managers in developing effective strategies for its implementation.}
}
@article{DEOLIVEIRA2025101184,
title = {Using AI-text generated mentor texts for genre-based pedagogy in second language writing},
journal = {Journal of Second Language Writing},
volume = {67},
pages = {101184},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101184},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000098},
author = {Luciana C. {de Oliveira} and Allessandra Elisabeth {dos Santos}},
keywords = {Generative Artificial Intelligence (GenAI), ChatGPT, Mentor texts, Systemic functional linguistics, Teaching and learning cycle, Elementary L2 writing},
abstract = {This article explores the integration of Generative Artificial Intelligence (GenAI) tools as a resource to augment the writing of mentor texts for second language (L2) writing instruction. We show how two AI-generated mentor texts demonstrate typical stages and language features in two genres: Cyclical Explanation and Discussion. Guided by the theoretical perspective of systemic functional linguistics, this article identifies key language features in these mentor texts. We highlight how AI text generators integrated into the Teaching and Learning Cycle (TLC) can offer an unprecedented resource in L2 writing classrooms to identify genre features for L2 writers.}
}
@article{DUONG20251024,
title = {Entrepreneurial education and higher education students’ e-entrepreneurial intention: a moderated mediation model of generative AI incorporation and e-entrepreneurial self-efficacy},
journal = {Higher Education, Skills and Work-based Learning},
volume = {15},
number = {5},
pages = {1024-1048},
year = {2025},
issn = {2042-3896},
doi = {https://doi.org/10.1108/HESWBL-12-2024-0390},
url = {https://www.sciencedirect.com/science/article/pii/S2042389625000538},
author = {Cong Doanh Duong and Trong Nghia Vu},
keywords = {Entrepreneurship education, E-entrepreneurial self-efficacy, Generative AI incorporation, E-entrepreneurial intention},
abstract = {Purpose
This study investigates how entrepreneurship education influences e-entrepreneurial intention through e-entrepreneurial self-efficacy, with generative artificial intelligence incorporation as a moderating factor. The study uses the stimulus-organism-response (SOR) framework to comprehensively understand the relationship between educational, psychological and technological factors in fostering e-entrepreneurship among university students.
Design/methodology/approach
A quantitative study was conducted using survey data collected from 504 university students in Vietnam. The PROCESS macro was employed to test the mediating role of e-entrepreneurial self-efficacy and the moderating effect of generative artificial intelligence incorporation on the relationships among entrepreneurship education, e-entrepreneurial self-efficacy and intention.
Findings
The results demonstrate that entrepreneurship education significantly influences both e-entrepreneurial self-efficacy and intention. E-entrepreneurial self-efficacy mediates the relationship between entrepreneurship education and intention. Generative artificial intelligence incorporation amplifies the effects of entrepreneurship education and e-entrepreneurial self-efficacy on intention, both directly and indirectly, highlighting its role as a transformative driver in e-entrepreneurship.
Practical implications
The findings suggest that integrating generative artificial intelligence tools and entrepreneurship-focused education into training programs can enhance students’ digital entrepreneurial skills. Policymakers and educators should develop strategies to foster digital literacy and entrepreneurial competence to prepare students for technology-driven business environments.
Originality/value
This study contributes to the literature by extending the stimulus-organism-response framework to e-entrepreneurship. It uniquely integrates educational, psychological and technological factors, offering new insights into the mechanisms that foster e-entrepreneurial intention in emerging markets.}
}
@article{LI2025105220,
title = {Detecting multi-modal GAI-manipulated tourism review},
journal = {Tourism Management},
volume = {111},
pages = {105220},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105220},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725000901},
author = {Jianqiang Li and Weimin Zheng and Xin Guo},
keywords = {Generative artificial intelligence, Multi-modal tourism review, Deepfake detection, Text linguistic features, Image texture patch features},
abstract = {With the increasingly crucial role played by electronic word-of-mouth, online reviews have become an indispensable informational element for multiple stakeholders in the competitive tourism market. However, the rapid development of generative artificial intelligence (GAI) has not only threatened the unique position of humans as the sole producers of reviews but also broken new ground in the covertness and disorientation of manipulated reviews. To address this emerging issue, this study proposes a novel detection system, namely, multi-modal GAI-manipulated tourism review detector, which can accurately detect both textual and visual tourism manipulation through the innovative extraction of text linguistic features and image texture patch features. The superiority and effectiveness of the proposed detection system are demonstrated through empirical system application. This study not only offers theoretical and methodological references for tourism review detection research, but also contributes to the decision-making of tourists, the reputation of tourism enterprises and online travel agents.}
}
@article{CHOI20242616,
title = {Leveraging Generative Artificial Intelligence in Diagnosis of Thrombotic Microangiopathies: Focus on Thrombotic Thrombocytopenic Purpura},
journal = {Blood},
volume = {144},
pages = {2616},
year = {2024},
note = {66th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2024-194769},
url = {https://www.sciencedirect.com/science/article/pii/S0006497124053692},
author = {Eunhee Choi and Jung-Hyun Lee and Robert McDougal and William W Lytton},
abstract = {Introduction Thrombotic microangiopathies (TMA), with etiologies ranging from benign to life-threatening, necessitates rapid and accurate diagnosis, particularly for thrombotic thrombocytopenic purpura (TTP), to initiate timely plasmapheresis preventing severe outcomes. Diagnosing TTP is challenging due to overlapping clinical features with other causes of TMA, such as disseminated intravascular coagulation (DIC), immune thrombocytopenic purpura (ITP), and atypical hemolytic uremic syndrome (aHUS), compounded by that specific diagnostic tests such as biopsies or ADAMTS13 activity assays do not result immediately. This study explored GPT-4's capability in suggesting differential diagnoses for TMA patients and identifying a provisional diagnosis of TTP based on clinical presentation and basic diagnostic workup to determine the need for prompt plasmapheresis, assessing its potential as a diagnostic support tool. Method We utilized open-access case reports from PubMed Central that provided a comprehensive list of cases with diagnosis of TMA. The exclusion criteria included cases with no access, copyright permission issues, preprints, insufficient description, non-case reports, non-English language, and no established diagnosis for TMA. Each case input including only the history and physical examination (H&P) and basic diagnostic workup excluding the confirmatory diagnosis was presented to GPT-4 in three separate trials and was prompted to provide clinical reasoning that both favored or rejected the diagnosis of TTP, create a top three differential diagnoses list selected from a comprehensive list of TMA diagnoses, and determine the necessity of plasmapheresis. Generated results were subsequently compared with the confirmed case diagnosis and management provided within the case report. Result An initial PubMed Central search identified 424 cases; 326 were excluded, resulting in 98 eligible cases. The top three differential diagnoses generated for each case in all three trials exhibited relatively higher F1-scores for ITP, TTP, HUS, and HELLP syndrome, with values of 0.58, 0.59, 0.53, and 0.7, respectively. Other causes of TMA scored below 0.5. Overall performance metrics indicated a specificity of 0.85, sensitivity of 0.80, precision of 0.28, and an F1-score of 0.42. When grouped into TTP versus non-TTP cases, the sensitivity was notably high at 0.98, showing that GPT-4 could adequately rule out TTP, although the specificity was 0.76. When comparing the case diagnosis with the primary diagnosis within the top three differential diagnoses, the overall specificity was 0.96, sensitivity was 0.56, precision was 0.58, and the F1-score was 0.57. The match rate of GPT-4 suggesting plasmapheresis compared to the case report was 76%. In cases confirmed as TTP, GPT-4 demonstrated 100% accuracy in recommending plasmapheresis. For non-TTP cases, GPT-4 showed a 66% match rate compared to the case report's decision to initiate plasmapheresis, indicating a 34% reduction in suggesting plasmapheresis for these cases. Error analysis revealed that errors were primarily due to GPT-4 ignoring pertinent findings, inaccurate knowledge, and confounding symptoms or findings within the case report itself. Discussion This study demonstrated that GPT-4 could adequately assist in the diagnosis of TMA and provide suggestions for early management of TTP based on clinical presentation and basic diagnostic workup. GPT-4 appropriately recommended plasmapheresis for TTP cases and showed a comparable performance of that of a clinically commonly used tool in these settings, PLASMIC score. However, in our study, GPT-4 made errors such as ignoring pertinent findings and demonstrating incomplete knowledge, highlighting the need for pretraining and areas to improve regarding diagnosis of TMA. The study suggested that GPT-4 could be integrated as a diagnostic support tool, especially for complex, time-sensitive conditions, while emphasizing that it should complement, not replace, clinical judgment.}
}
@article{NAGHDY2025102445,
title = {Collaboration with GenAI in engineering research design},
journal = {Data & Knowledge Engineering},
volume = {159},
pages = {102445},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102445},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000400},
author = {Fazel Naghdy},
keywords = {Literature review, hypothesis, research design, GenAI, research gaps},
abstract = {Over the past five years, the fast development and use of generative artificial intelligence (GenAI) and large language models (LLMs) has ushered in a new era of study, teaching, and learning in many domains. The role that GenAIs can play in engineering research is addressed. The related previous works report on the potential of GenAIs in the literature review process. However, such potential is not demonstrated by case studies and practical examples. The previous works also do not address how GenAIs can assist with all the steps traditionally taken to design research. This study examines the effectiveness of collaboration with GenAIs at various stages of research design. It explores whether collaboration with GenAIs can result in more focused and comprehensive outcomes. A generalised approach for collaboration with AI tools in research design is proposed. A case study to develop a research design on the concept of “shared machine-human driving” is deployed to show the validity of the articulated concepts. The case study demonstrates both the pros and cons of collaboration with GenAIs. The results generated at each stage are rigorously validated and thoroughly examined to ensure they remain free from inaccuracies or hallucinations and align with the original research objectives. When necessary, the results are manually adjusted and refined to uphold their integrity and accuracy. The findings produced by the various GenAI models utilized in this study highlight the key attributes of generative artificial intelligence, namely speed, efficiency, and scope. However, they also underscore the critical importance of researcher oversight, as unexamined inferences and interpretations can render the results irrelevant or meaningless.}
}
@article{YIN2025,
title = {Intelligent multi-channel classification of microseismic events upon TBM excavation},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
year = {2025},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2025.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1674775525004172},
author = {Xin Yin and Feng Gao and Zitao Chen and Yucong Pan and Quansheng Liu and Shouye Cheng},
keywords = {Tunnel boring machine (TBM), Microseismic monitoring, Microseismic classification, Stacking learning, Generative artificial intelligence, Generative adversarial network},
abstract = {In recent years, tunnel boring machines (TBMs) have been widely used in tunnel construction. Rockbursts, as a dynamic geological disaster, pose a serious threat to the safety and efficient tunneling of TBMs. The microseismic monitoring technique provides an effective solution for rockburst warning. However, due to the complexity and variability of the TBM excavation environment, microseismic events induced by rock fracture are often accompanied by interference events, such as electrical noise, TBM vibration, and mechanical knock. This study proposes a multi-channel intelligent classification approach for microseismic events in TBM excavation scenarios, based on double-layer stacking learning, to identify rock fractures. In this approach, decision tree is used as the base classifier on each microseismic channel, while extreme learning machine is employed as the meta-classifier to aggregate all base classifiers. Additionally, mind evolutionary computation is integrated to optimize the built-in hyperparameters of various classifiers. Meanwhile, a comprehensive preprocessing and augmentation flow for microseismic data has been developed, encompassing feature extraction, dimensionality reduction, outlier detection, and outlier substitution. The results reveal that the multi-channel stacking model, which combines classification and regression tree and extreme learning machine, achieves optimal global and local generalization performance compared to other multi-channel stacking models and traditional single-channel models. The accuracy, Hamming loss, and Cohen’s kappa are 96.75%, 0.0325, and 0.9148, respectively, and the F1-score and AUC on rock fracture events are 0.9366 and 0.9818, respectively. Finally, a generative artificial intelligence-based scheme is invented to enhance the robustness of the model for signal-mixing events.}
}
@article{ULLA2024100314,
title = {How can GenAI foster an inclusive language classroom? A critical language pedagogy perspective from Philippine university teachers},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100314},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100314},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001176},
author = {Mark Bedoya Ulla and Ma Jenny C. Advincula and Christine Dawn S. Mombay and Harriette Mae A. Mercullo and Joseph P. Nacionales and Antonia D. Entino-Señorita},
keywords = {Critical language pedagogy, Generative artificial intelligence (gen AI), Philippine universities, Language classroom, Language teachers},
abstract = {Recent studies have recognized the potential and drawbacks of using generative artificial intelligence (GenAI), especially ChatGPT, in education. However, studies exploring the possibility of GenAI tools in language education are scarce from the perspective of critical pedagogy. This qualitative study explores the perspectives of 14 academics in Philippine higher education institutions (HEIs) regarding the use of GenAI in pedagogical contexts and how such use of these GenAI tools fosters an environment of inclusivity and equality among learners. Employing an open-ended survey questionnaire and follow-up individual interviews, the findings not only highlight the perceived benefits of GenAI in terms of boosting inclusion, participation, and confidence among students, as well as supporting tailored learning experiences and providing feedback in real-time but also its transformative potential, fostering educational fairness, and maximizing the learning experiences of all students. Teachers viewed the integration of GenAI positively, as it could enhance language education by providing students with personalized learning experiences, interactive simulations, and real-time feedback. We discuss the limitations and offer some recommendations.}
}
@article{SHIRAISHI2025100196,
title = {Gender and racial diversity Assumed by text-to-image generators in microsurgery and plastic surgery-related subspecialities},
journal = {Journal of Hand and Microsurgery},
volume = {17},
number = {1},
pages = {100196},
year = {2025},
issn = {0974-3227},
doi = {https://doi.org/10.1016/j.jham.2024.100196},
url = {https://www.sciencedirect.com/science/article/pii/S0974322724005581},
author = {Makoto Shiraishi and Chihena Hansini Banda and Mayuri Nakajima and Mildred Nakazwe and Zi Yi Wong and Yoko Tomioka and Yuta Moriwaki and Hakuba Takeishi and Haesu Lee and Daichi Kurita and Kiichi Furuse and Jun Ohba and Kou Fujisawa and Shimpei Miyamoto and Mutsumi Okazaki},
keywords = {Gender, Race, Generative artificial intelligence, Microsurgery, DALL-E 3},
abstract = {Background
Since the release of ChatGPT by OpenAI in November 2022, generative artificial intelligence (AI) models have attracted significant attention in various fields, including surgery. These advancements have been particularly notable for creating highly detailed and contextually accurate images from textual prompts. A notable area of clinical application is the representation of surgeon demographics in various specialties, particularly in the context of microsurgery and plastic surgery-related subspecialties.
Methods
This cross-sectional study, conducted in June 2024, utilized the latest version of the Copilot Creative Mode powered by DALL-E 3 to generate images of surgeons across various plastic surgery subspecialties. Real-world demographic data from the US, Japan, and Zambia were compared with AI-generated images for an accurate representation analysis.
Results
Five hundred images (350 from various subspecialties and 150 from geographical sources) were analyzed. The AI model predominantly generated images of male and female surgeons with a statistical underrepresentation of female and Black microsurgeons. Geographical prompts influenced the representation, with an overrepresentation of female (64.0 %; p < 0.001) and Black (16.0 %; p < 0.001) plastic surgeons in the US and exclusively Asian surgeons in Japan. Discrepancies were also observed in the depiction of surgical equipment, with the majority of AI-generated microsurgeons inaccurately portrayed using either surgical loupes (46.0 %) or optical microscopes (32.0 %), not with surgical microscopes (4.0 %).
Conclusions
This study revealed significant disparities between AI-generated images and actual demographics in the fields of microsurgery and plastic surgery-related subspecialties, highlighting the need for more diverse and accurate training datasets for AI models.}
}
@article{SONG2025,
title = {Machine learning methods to predict transvalvular gradient waveform post–transcatheter aortic valve replacement using preprocedural echocardiogram},
journal = {The Journal of Thoracic and Cardiovascular Surgery},
year = {2025},
issn = {0022-5223},
doi = {https://doi.org/10.1016/j.jtcvs.2025.04.044},
url = {https://www.sciencedirect.com/science/article/pii/S002252232500385X},
author = {Wenyuan Song and Taylor Sirset-Becker and Luis René {Mata Quinonez} and Dhruv Polsani and Venkateshwar Polsani and Pradeep Yadav and Vinod Thourani and Lakshmi Prasad Dasi},
keywords = {deep machine learning, generative active learning, generative artificial intelligence, predictive surgical planning, pressure gradient, transcatheter aortic valve implantation/replacement},
abstract = {Objective
Time-varying transvalvular pressure gradient after transcatheter aortic valve replacement indicates the effectiveness of the therapy. The objective was to develop a novel machine learning method enhanced by generative artificial intelligence and smart data selection strategies to predict the post–transcatheter aortic valve replacement gradient waveform using preprocedural Doppler echocardiogram.
Methods
A total of 110 patients undergoing transcatheter aortic valve replacement (mean age 78.2 ± 9.0 years, 52.5% female) were included for pressure gradient collection. A deep machine learning model was trained and tested to predict postprocedural pressure gradient waveform from preprocedural pressure gradient waveform based on the proposed generative active learning framework.
Results
The trained model demonstrated an average prediction accuracy of 84.85% across the 10 test patients measured from the relative mean absolute error between the predicted gradient waveform and the ground truth. The generative method improved prediction accuracy by 3.11%, whereas the data selection strategy increased it by 16.03% compared with the baseline experimental group using plain machine learning. Additionally, Bland–Altman analysis demonstrated a strong agreement between the proposed method and clinical measurements for both mean and peak pressure gradient predictions.
Conclusions
A deep, generative, active machine learning model was developed to output the prediction of post–transcatheter aortic valve replacement time-varying pressure gradient from the preprocedural time-varying gradient obtained from Doppler echocardiogram. Such a predictive method may help guide decision-making for the prevention of various post–transcatheter aortic valve replacement complications. Further studies are necessary to investigate the gradient change of other valve types.}
}
@article{SUTERA2025,
title = {Generative AI in Medicine: Pioneering Progress or Perpetuating Historical Inaccuracies? Cross-Sectional Study Evaluating Implicit Bias},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/56891},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000468},
author = {Philip Sutera and Rohini Bhatia and Timothy Lin and Leslie Chang and Andrea Brown and Reshma Jagsi},
keywords = {Artificial Intelligence, generative artificial intelligence, workforce diversity, bias, historical inequity, social inequity, implicit bias, AI bias},
abstract = {Background
Generative artificial intelligence (gAI) models, such as DALL-E 2, are promising tools that can generate novel images or artwork based on text input. However, caution is warranted, as these tools generate information based on historical data and are thus at risk of propagating past learned inequities. Women in medicine have routinely been underrepresented in academic and clinical medicine and the stereotype of a male physician persists.
Objective
The primary objective is to evaluate implicit bias among gAI across medical specialties.
Methods
To evaluate for potential implicit bias, 100 photographs for each medical specialty were generated using the gAI platform DALL-E2. For each specialty, DALL-E2 was queried with “An American [specialty name].” Our primary endpoint was to compare the gender distribution of gAI photos to the current distribution in the United States. Our secondary endpoint included evaluating the racial distribution. gAI photos were classified according to perceived gender and race based on a unanimous consensus among a diverse group of medical residents. The proportion of gAI women subjects was compared for each medical specialty to the most recent Association of American Medical Colleges report for physician workforce and active residents using χ2 analysis.
Results
A total of 1900 photos across 19 medical specialties were generated. Compared to physician workforce data, AI significantly overrepresented women in 7/19 specialties and underrepresented women in 6/19 specialties. Women were significantly underrepresented compared to the physician workforce by 18%, 18%, and 27% in internal medicine, family medicine, and pediatrics, respectively. Compared to current residents, AI significantly underrepresented women in 12/19 specialties, ranging from 10% to 36%. Additionally, women represented <50% of the demographic for 17/19 specialties by gAI.
Conclusions
gAI created a sample population of physicians that underrepresented women when compared to both the resident and active physician workforce. Steps must be taken to train datasets in order to represent the diversity of the incoming physician workforce.}
}
@article{TAN2025105057,
title = {ChatGPT and online service recovery: How potential customers react to managerial responses of negative reviews},
journal = {Tourism Management},
volume = {107},
pages = {105057},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105057},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724001766},
author = {Karen Pei-Sze Tan and Yi Vanessa Liu and Stephen Wayne Litvin},
keywords = {Online service recovery, Managerial responses, Online reviews, Algorithm aversion, Perceived authenticity, Uncanniness, Generative artificial intelligence, ChatGPT},
abstract = {This study investigates the efficacy of generative artificial intelligence in online service recovery; specifically, the use of ChatGPT (vs. human employees) in preparing managerial response(s) (MR or MRs) to online hotel reviews is considered. ChatGPT could be used to generate human-like MRs for online service recovery but this could backfire due to algorithm aversion when an individual discounts algorithm decisions relative to human-made decisions. Data collected via interviews, a modified Turing test and an online experiment provide empirical support for this. Findings reveal that potential customers could not clearly differentiate between the two types of MR and could not clearly identify the ‘better’ of the two. Yet, when informed of the MR source, ChatGPT MRs led to lower affective, cognitive and conative outcomes. Findings also unveiled perceived authenticity and uncanniness as significant parallel mediating pathways in this algorithm aversion. Theoretical and managerial implications are discussed.}
}
@incollection{GAUR20261,
title = {Chapter 1 - Generative AI in healthcare: Introduction, concept, applications, and challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {1-24},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00013-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000138},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Artificial intelligence, Deep learning, GenAI, Generative AI, Healthcare, Large language models, Machine learning},
abstract = {Generative artificial intelligence (AI), with its ability to create new data such as text and imagery, is surfacing the way for improved patient management, groundbreaking methods of diagnosing illnesses, and broadened options for treatment. Nonetheless, the benefits and efficacy of generative AI within the medical sector are not fully grasped, sparking debates over its ethical and legal implications, its integration into the provision of healthcare services, and how it might be best utilized by the healthcare workforce. Additionally, a clear strategy for the deployment and assimilation of generative AI into the healthcare system is yet to be established. This chapter will lay the groundwork for the book, offering a comprehensive overview of fundamental concepts, diverse applications such as clinical documentation and evidence-based medicine summarization, and the inherent challenges faced within the field.}
}
@article{HAMPSON2025100258,
title = {Automate the ‘boring bits’: An assessment of AI-assisted systematic review (AIASR)},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100258},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100258},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000795},
author = {Timothy Hampson and Kelly Cargos and Jim McKinley},
abstract = {Systematic review is a powerful tool for disseminating the findings of research, particularly in applied linguistics where we hope to provide insights for practising language teachers. Yet, systematic review is also often prohibitively time-consuming, particularly for small, underfunded teams or solo researchers. In this study, we explore the use of generative artificial intelligence to ease the burden of screening and organising papers. Our findings suggest that AI excels in some tasks, particularly when those tasks involve explicitly stated information, and struggles in others, particularly when information is more implicit. A comparison of generative artificial intelligence for filtering papers with ASReview, a popular non-generative tool, reveals trade-offs, with Generative AI being replicable and more efficient, but with concerns about accuracy. We conclude that generative artificial intelligence can be a useful tool for systematic review but requires rigorous validation before use. We conclude by emphasising the importance of testing AI for systematic review tasks and exploring how this can practically be achieved.}
}
@article{BERTGES2025129,
title = {Testing ChatGPT's Ability to Provide Patient and Physician Information on Aortic Aneurysm},
journal = {Journal of Surgical Research},
volume = {307},
pages = {129-138},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000332},
author = {Daniel J. Bertges and Adam W. Beck and Marc Schermerhorn and Mark K. Eskandari and Jens Eldrup-Jorgensen and Sean Liebscher and Robyn Guinto and Mead Ferris and Andy Stanley and Georg Steinthorsson and Matthew Alef and Salvatore T. Scali},
keywords = {Abdominal aortic aneurysm, Generative artificial intelligence (GAI), SVS guidelines},
abstract = {Introduction
Our objective was to test the ability of ChatGPT 4.0 to provide accurate information for patients and physicians about abdominal aortic aneurysms (AAA) and to assess its alignment with Society for Vascular Surgery (SVS) clinical practice guidelines (CPG) for AAA care.
Material and methods
Fifteen patient-level questions, 37 questions selected to reflect 28 SVS CPGs and 4 questions regarding AAA rupture risk were posed to ChatGPT 4.0. Single responses were recorded and graded for accuracy and quality by ten board-certified vascular surgeons as well as two fellow trainees using a 5-point Likert scale; 1 = very poor, 2 = poor, 3 = fair, 4 = good, and 5 = excellent.
Results
The mean of the means (MoM) accuracy rating across all 15 patient-level questions was 4.4 (SD 0.4, quartile range (QR) 4.2-4.7). ChatGPT 4.0 demonstrated good alignment with SVS practice guidelines (MoM: 4.2, SD: 0.4, QR: 3.9-4.5). The accuracy of responses was consistent across guideline categories; screening or surveillance (4.2), indications for surgery (4.5), preoperative risk assessment (4.5), perioperative coronary revascularization (4.1), and perioperative management (4.2). The generative artificial intelligence bot demonstrated only fair performance in answering the annual AAA rupture risk (MoM: 3.4, SD: 1.2, QR: 2.3-4.3).
Conclusions
ChatGPT 4.0 provided accurate responses to a variety of patient-level questions regarding AAA. Responses were well-aligned with current SVS CPGs except for inaccuracies in the risk of AAA rupture at varying diameters. The emergence of generative artificial intelligence bots presents an opportunity for study of applications in patient education and to determine their ability to augment the vascular specialist's knowledge base.}
}
@article{SIMSEK2025e806,
title = {The predictive effect of nursing students' attitudes and acceptance towards artificial intelligence on their clinical competencies},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {e806-e814},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000824},
author = {Enes Şimşek and Aslı Akdeniz Kudubeş and Remziye {Semerci Şahin}},
keywords = {Acceptance, Artificial intelligence, Attitude, Clinical competency, Nursing student},
abstract = {Background
AI integration in education is gaining interest, including in nursing, as students seek formal training on its healthcare applications and limitations.
Aim
To evaluate the predictive effect of nursing students' attitudes and acceptance of artificial intelligence on their clinical competencies.
Methods
This descriptive-correlational study was conducted at 2 universities (February–June 2024) with 441 nursing students. Full-time students in clinical practice participated; those absent or on leave were excluded. The Nursing Students Competency Scale, General Attitudes to Artificial Intelligence Scale, and Generative Artificial Intelligence Acceptance Scale were used. Descriptive statistics and linear regression were used.
Results
The main factors affecting nursing students' clinical competence were “facilitating conditions,” “social influence,” and “negative attitudes” toward AI. A weak correlation was found between positive AI attitudes and acceptance, which explained 8.6% of the competency levels.
Conclusion
Positive perceptions of AI may increase competence, while skepticism may deepen engagement and critical learning. Strategies to improve the acceptance and use of AI are crucial to maximize its benefits in nursing education and practice.}
}
@article{MOORHOUSE2025103779,
title = {Generative AI tools and empowerment in L2 academic writing},
journal = {System},
volume = {133},
pages = {103779},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103779},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25001897},
author = {Benjamin Luke Moorhouse and Yuwei Wan and Chenze Wu and Meixin Wu and Tsz Ying Ho},
keywords = {Generative artificial intelligence, L2 writers, Critical digital literacies, Empowerment, ChatGPT, Post-graduate students, Language assessment, Academic writing},
abstract = {Generative Artificial Intelligence (GenAI) developments have ignited interest in how they will impact L2 writers' agency over their academic writing processes. At the same time, higher education (HE) institutions have responded to GenAI by devising policies on their use. Recognizing that L2 writers' processes can be shaped by GenAI, as well as their institutions and instructors' policies, there is a need to understand how L2 writers engage with GenAI tools and negotiate agency as they transition into their studies and find themselves within the boundaries of their HE institution's policies. Through the lens of critical digital literacies (CDL), agency and empowerment, this qualitative study adopted in-depth focus group interviews with a preference selection task to explore how twenty-one post-graduate L2 writers position themselves in relation to GenAI tools and how they and GenAI have been positioned by their instructors. Data were collected within the first month of their post-graduate studies. The findings show that the L2 writers have integrated GenAI into various aspects of their academic writing processes. Their responses suggest that the L2 writers believe the tools empower them and augment their writing abilities. Yet, from a CDL perspective, this may be false empowerment, as the writers showed little critical awareness of how the tools work. At the same time, tensions exist between their perceptions of agency and some of their instructors' GenAI policies. The L2 writers prefer GenAI policies that give them the autonomy to use GenAI flexibly. However, they recognize the need to be accountable for their academic writing and transparent in their GenAI use. Bans on GenAI use were perceived as unfair, restricted agency, and not reflective of GenAI affordances. The findings can inform academic writing training and instructors' policies.}
}
@article{BERLINSKI2024102723,
title = {Artificial imaginaries: Generative AIs as an advanced form of capitalism},
journal = {Critical Perspectives on Accounting},
volume = {99},
pages = {102723},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102723},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000224},
author = {Elise Berlinski and Jérémy Morales and Samuel Sponem},
keywords = {Generative AI, ChatGPT, Social imaginaries, Standardization, Domination},
abstract = {In this essay, we characterize three paradoxical imaginaries that structure the development of generative artificial intelligence (genAI). At the institutional level, these technologies develop in a context that celebrates openness and liberality. Yet, both in the US and in Europe, they serve to centralize power and resources. At the organizational level, while the imaginary is that these technologies make work more interesting, we show that they rather produce anxiety and a new class of precarious workers. At the epistemic level, generative artificial intelligence promises access to unlimited knowledge. This knowledge may appear robust, as these technologies become performative. However, the knowledge they produce is doubtful. Overall, these technologies centralize power and exclude, they standardize knowledge, and they produce, reproduce, amplify and extend various structures of domination.}
}
@article{YILMAZ2023100147,
title = {The effect of generative artificial intelligence (AI)-based tool use on students' computational thinking skills, programming self-efficacy and motivation},
journal = {Computers and Education: Artificial Intelligence},
volume = {4},
pages = {100147},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000267},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Artificial intelligence, ChatGPT, Generative pretrained transformer, Programming education, Computational thinking},
abstract = {ChatGPT (generative pre-trained transformer) is one of the artificial intelligence (AI) technologies that have started to be used in programming education. However, the effect of using ChatGPT in programming education on learning processes and outcomes is not yet known. This study investigated the effect of programming education using the ChatGPT on students' computational thinking skills, programming self-efficacy, and motivation toward the lesson. The research was conducted on 45 undergraduate students who took a university-level programming course. The research was carried out according to the experimental design with the pretest-posttest control group. Students were randomly divided into experimental (n = 21) and control (n = 24) groups. While the experimental group students benefited from the ChatGPT during the weekly programming practices, the control group students did not use this tool. Research data were obtained through the computational thinking scale, computer programming self-efficacy scale, and learning motivation in computer programming courses scale. Research findings revealed that the experimental group students' computational thinking skills, programming self-efficacy, and motivation for the lesson were significantly higher than the control group students. In line with this result, it can be said that it may be useful to benefit from AI technologies such as ChatGPT in programming trainings. The research findings, it was emphasized how the most effective use of AI support in the lessons could be made, and various suggestions were made for researchers and educators in this regard.}
}
@article{KWOK2025103618,
title = {GenAI as a translation assistant? A corpus-based study on lexical and syntactic complexity of GPT-post-edited learner translation},
journal = {System},
volume = {130},
pages = {103618},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103618},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25000284},
author = {Ho Ling Kwok and Yining Shi and Han Xu and Dechao Li and Kanglong Liu},
keywords = {Generative artificial intelligence, Learner translation, Lexical complexity, Syntactic complexity},
abstract = {The advent of generative artificial intelligence (GenAI) models, most notably ChatGPT in late 2022, marked a significant milestone in AI development, attracting widespread attention from various research fields. Among its emerging applications, GenAI demonstrates potential in translation education. This study examines the role of GenAI as a post-editing assistant in learner translation by comparing the lexical and syntactic complexity of second language (L2) translations produced by Hong Kong students, with and without post-editing by GPT. The analysis revealed that GPT post-editing improved lexical complexity in learner translations, though its effect on syntactic complexity was inconsistent. While GPT post-editing resulted in longer clauses, more complex nominals, and an increased use of coordinate phrases, non-edited translations featured greater subordination and more verbal structures. These findings suggest that GenAI holds promise in enhancing translation practice but also highlight the need for critical AI literacy to ensure effective use in translation education, particularly in advancing students’ linguistic and instrumental competence.}
}
@article{HADARSOUVAL2025,
title = {Transforming Perceptions: Exploring the Multifaceted Potential of Generative AI for People With Cognitive Disabilities},
journal = {JMIR Neurotechnology},
volume = {4},
year = {2025},
issn = {2817-092X},
doi = {https://doi.org/10.2196/64182},
url = {https://www.sciencedirect.com/science/article/pii/S2817092X2500002X},
author = {Dorit {Hadar Souval} and Yuval Haber and Amir Tal and Tomer Simon and Tal Elyoseph and Zohar Elyoseph},
keywords = {generative artificial intelligence, cognitive disability, social participation, AI ethics, assistive technology, cognitive disorder, societal barriers, social inclusion, disability study, social mirror, cognitive partner, empowerment, user involvement, GenAI, artificial intelligence, neurotechnology, neuroinformatics, digital health, health informatics, neuroscience, mental health, computer science, machine learning},
abstract = {Background
The emergence of generative artificial intelligence (GenAI) presents unprecedented opportunities to redefine conceptions of personhood and cognitive disability, potentially enhancing the inclusion and participation of individuals with cognitive disabilities in society.
Objective
We aim to explore the transformative potential of GenAI in reshaping perceptions of cognitive disability, dismantling societal barriers, and promoting social participation for individuals with cognitive disabilities.
Methods
This study is a critical review of current literature in disability studies, artificial intelligence (AI) ethics, and computer science, integrating insights from disability theories and the philosophy of technology. The analysis focused on 2 key aspects: GenAI as a social mirror reflecting societal values and biases, and GenAI as a cognitive partner for individuals with cognitive disabilities.
Results
This paper proposes a theoretical framework for understanding the impact of GenAI on perceptions of cognitive disability. It introduces the concepts of GenAI as a “social mirror” that reflects and potentially amplifies societal biases and as a “cognitive copilot” providing personalized assistance in daily tasks, social interactions, and environmental navigation. This paper also presents a novel protocol for developing AI systems tailored to the needs of individuals with cognitive disabilities, emphasizing user involvement, ethical considerations, and the need to address both the opportunities and challenges posed by GenAI.
Conclusions
Although GenAI has great potential for promoting the inclusion and empowerment of individuals with cognitive disabilities, realizing this potential requires a change in societal attitudes and development practices. This paper calls for interdisciplinary collaboration and close partnership with the disability community in the development and implementation of GenAI technologies. Realizing the potential of GenAI for promoting the inclusion and empowerment of individuals with cognitive disabilities requires a multifaceted approach. This involves a shift in societal attitudes, inclusive AI development practices that prioritize the needs and perspectives of the disability community, and ongoing interdisciplinary collaboration. This paper emphasizes the importance of proceeding with caution, recognizing the ethical complexities and potential risks alongside the transformative possibilities of GenAI technology.}
}
@article{WAMBATAGUIMDJE2024,
title = {Why Should Users Take the Risk of Sustainable Use of Generative Artificial Intelligence Chatbots:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.365600},
url = {https://www.sciencedirect.com/science/article/pii/S106273752400043X},
author = {Serge-Lopez Wamba-Taguimdje and Samuel Fosso Wamba and Hossana Twinomurinzi},
keywords = {ChatGPT, GenAI-Chatbot, Artificial Intelligence, Risks, User Satisfaction, Sustainable Use},
abstract = {ABSTRACT
Despite the risks associated with generative AI (GenAI) chatbots, people increasingly use these technologies, which may seem contradictory. This study identified and explored factors and risks related to trust, perceived values, satisfaction, and sustainable use of GenAI chatbots. Relying on IS theories to build a stimulus-organism-response model, the authors tested a model using PLS-SEM with data from 393 ChatGPT users. The results show that user competence and autonomy dramatically increase a user's trust in ChatGPT, and trust improves hedonic value (HV), utilitarian value (UV), value-in-use, perceived task-technology fit (TTF), information accuracy, knowledge acquisition, perceived informativeness, and user satisfaction. In addition to trust, user satisfaction depends on HV, UV, and TTF. The sustainability use of ChatGPT depends on HV and satisfaction. However, perceived privacy concerns, perceived privacy risks, and privacy awareness do not affect consumer trust. There is a complete mediation between trust and sustainability, as well as HV and sustainability.}
}
@article{SIGALA2024384,
title = {Understanding the impact of ChatGPT on tourism and hospitality: Trends, prospects and research agenda},
journal = {Journal of Hospitality and Tourism Management},
volume = {60},
pages = {384-390},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S144767702400086X},
author = {Marianna Sigala and Keng-Boon Ooi and Garry Wei-Han Tan and Eugene Cheng-Xi Aw and Dimitrios Buhalis and Tat-Huei Cham and Meng-Mei Chen and Yogesh K. Dwivedi and Ulrike Gretzel and Alessandro Inversini and Timothy Jung and Rob Law and Ivy Huiyue Ye},
keywords = {Generative artificial intelligence, ChatGPT, Tourism, Hospitality management, Destination management, Research agenda, Sustainable tourism},
abstract = {The prevalence of ChatGPT (and generative artificial intelligence in general) has precipitated a paradigm shift in diverse industries, including tourism and hospitality. ChatGPT revolutionalises all business functions (from marketing to operations), empowering tourism and hospitality organisations to transform and innovate their business models. This study seeks to comprehensively examine the use and implications of ChatGPT in tourism and hospitality by discussing the current and future state of the technology, while also suggesting an agenda for future research. To that end, six areas, namely, business intelligence and tourism analytics, tourism marketing and experience, hospitality services, cultural and heritage tourism, travel services, and destination management, are elaborated on in depth. By compiling views solicited from international experts, this groundbreaking opinion piece unveils profound insights into the evolutionary journey of an emerging technology that is shaping tourism and hospitality. The paper provides useful implications for tourism scholars and professionals alike.}
}
@article{HU2025101331,
title = {A method for generating personalized learning content based on AIGC},
journal = {Sustainable Futures},
volume = {10},
pages = {101331},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101331},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825008925},
author = {Zhenghua Hu},
keywords = {Customized education, AIGC, Learner assessment, Extensive models, Smart education},
abstract = {In the realm of the swift advancement of Generative Artificial Intelligence (AIGC), the methodologies for generating individualized learning content have emerged as a forefront subject of inquiry in education. This study examines recent research developments and application trends of AIGC in educational content production, emphasizing individualized learning content generation techniques utilizing AIGC technology and its usefulness in practical applications. Initially, by employing educational resource libraries and learning behavior data, data quality is augmented, and analytical efficiency is refined by preprocessing techniques including data cleansing, resource categorization and labeling, multimodal alignment, and consistency verification. Subsequently, the Transformer architecture is employed to extract learning characteristics from behavioral data, while content relevance is augmented via knowledge point embedding and multimodal content production. A reinforcement learning approach is incorporated to execute a feedback-driven dynamic optimization procedure. Ultimately, comparison trials confirm the substantial benefits of the AIGC-based individualized learning material generation method in enhancing generation efficiency, optimizing resource flexibility, and improving learning outcomes. AIGC enhances educational quality by producing tailored learning materials, so effectively advancing the United Nations' Sustainable Development Goal (SDG 4) for excellent education. AIGC, through technology-driven educational innovation, can revolutionize traditional educational resource allocation, enhance social inclusion, and guarantee equitable educational opportunities, thus fostering comprehensive societal transformation.}
}
@article{YANG2025103375,
title = {Auth-Graph: GenAI-empowered attribute-masked backdoor for on-demand authorizable graph learning},
journal = {Information Fusion},
volume = {124},
pages = {103375},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103375},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004488},
author = {Xiao Yang and Gaolei Li and Kai Zhou and Yuni Lai and Jianhua Li},
keywords = {Graph learning, Generative artificial intelligence, Authorizable access, Access control, Backdoor paradigm},
abstract = {Owing to the ability to fuse non-Euclidean node-edge information, Graph Learning (GL) is pervasively leveraged across applications including web recommendation, community detection, and molecular classification. Current GL paradigms extremely emphasize absolute fairness and impartiality for all clients. This limits its flexibility and adaptability in addressing specific circumstances that demand customizable model queries (e.g., access control and intellectual property protection), where authorizable GL models present non-trivial obstacles in realization. Inspired by Generative Artificial Intelligence (GenAI), to overcome this limitation, we propose Auth-Graph, the first authorizable GL methodology via a built-in-model access control mechanism. Specifically, our Auth-Graph employs a generative perturbating-driven backdoor to reach authorizable access. The activation of the backdoor is exclusively confined to rightly masked and perturbed inputs, which yield accurate results, whereas all other inputs induce the GL model to produce erroneous outcomes. Moreover, to strengthen compatibility and support multi-user functionality, the masking mechanism operates correctly with a generative masker solely for authorized users possessing valid tokens, with each user’s token being uniquely distinct. Empirical results across benchmark GL models and datasets substantiate that Auth-Graph robustly prevents unauthorized access (average accuracy 3.68%) while promoting legitimate users to attain standard outputs (average accuracy drop 3.45%).}
}
@article{SHAUNNMATTINGLY2025,
title = {AI as an emerging trend for managing employee efficiency in the retail and services industries},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001089},
author = {E. {Shaunn Mattingly} and James R. Kroes and Andrew S. Manikas},
keywords = {Generative artificial intelligence, Employee efficiency, Research and development intensity, AI benefits by industry, AI in retail and services},
abstract = {Generative artificial intelligence (AI) is transforming the nature of work, offering clear benefits in efficiency and innovation. Yet, for practitioners, adoption remains complex because of limited resources and the demands of existing operations. This study explores how firms manage these challenges by examining AI adoption through the lens of the exploration–exploitation trade-off. Using data from public company filings, we analyze adoption rates, drivers and barriers, links to R&D investment, and industry-specific patterns. We find that firms with lower employee efficiency and greater size adopt AI more readily. AI adoption also correlates with changes in the scale and focus of R&D spending. Notably, retail and services firms—among the least efficient in terms of labor productivity—are leading in AI uptake. However, their focus remains on automating routine tasks and expanding product offerings, rather than investing in workforce development. These results provide useful guidance for leaders who want to use AI effectively, particularly in industries needing to improve employee productivity.}
}
@article{HERMANN2025802,
title = {GenAI and the psychology of work},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {9},
pages = {802-813},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661325000889},
author = {Erik Hermann and Stefano Puntoni and Carey K. Morewedge},
keywords = {generative artificial intelligence, work, psychological threat, competence, autonomy, relatedness},
abstract = {Work is a central source of identity and meaning. The rapid and widespread adoption of generative artificial intelligence (GenAI) is reshaping workplaces. Unlike previous technologies, GenAI can demonstrate cognitive, creative, and interpersonal capabilities that challenge traditional human–machine boundaries and redefine the knowledge, task, and social characteristics of work. GenAI can benefit workers by enhancing their productivity and performance. It can also psychologically threaten workers’ needs for competence, autonomy, and relatedness, which can initiate five coping strategies to mitigate these threats. We unpack the effects of GenAI on work and workers, show the importance of addressing its potential psychological threats, and explain how to foster human-centered workplaces that balance the benefits and risks of GenAI.}
}
@article{SAPUTRA2025104605,
title = {GenAI and psychiatry: Between multimodal promise and ethical perils},
journal = {Asian Journal of Psychiatry},
volume = {110},
pages = {104605},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104605},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825002485},
author = {Rio Saputra and Moh Ramdhan Arif Kaluku and  Hartoto and Edi Setiawan and  Arizona and Triana Asih and Andika Ari Saputra},
keywords = {Generative artificial intelligence, Neuropsychiatry, Digital mental health, AI ethics: Language models: Personalized}
}
@article{ZOU2025101521,
title = {Doctoral student’s strategy use in GAI chatbot-assisted L2 writing: An activity theory perspective},
journal = {Journal of English for Academic Purposes},
volume = {76},
pages = {101521},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101521},
url = {https://www.sciencedirect.com/science/article/pii/S1475158525000529},
author = {Min Zou and Delin Kong and Icy Lee},
keywords = {Chatbot-assisted writing, Strategy use, Generative artificial intelligence, Activity theory, Doctoral students, L2 writing},
abstract = {Generative artificial intelligence (GAI) chatbots (e.g., ChatGPT) have significantly reshaped the landscape of writing, presenting both opportunities and challenges for L2 writers, especially at advanced academic levels. However, limited research has examined the strategies learners adopt when they proactively use GAI chatbots to support L2 writing. To fill the void, this qualitative case study explored seven doctoral students’ strategy use in GAI chatbot-assisted writing from an activity theory perspective. Data were collected from multiple sources, including chat logs between students and ChatGPT, semi-structured interviews, and student writing drafts. Data analysis showed that the doctoral students formed a writing community with ChatGPT, in which they used six strategies to boost the writing process and enhance writing quality. These strategies included using code-mixed prompts, employing writing conventions, adhering to research ethics, ensuring information security, seeking help from others, and assuming multiple roles with a human-centered approach. The findings offer valuable insights into the complex interplays between doctoral students and GAI chatbots in GAI chatbot-assisted L2 writing and shed useful light on the responsible use of GAI chatbots in doctoral writing.}
}
@article{ROGGE2025,
title = {AI meets IA: A typology of generative-AI-supported work through individual ambidexterity},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001090},
author = {Nikolina Dragičević Rogge and Amadeja Lamovšek and Saša Batistič},
keywords = {Generative artificial intelligence, Individual ambidexterity, Work typology, Future of work, AI-driven workforce},
abstract = {As generative artificial intelligence (GenAI) reshapes job roles and creates new challenges for workforce adaptation, managers require a clear framework to navigate this transformation. This study develops a typology of GenAI-supported work grounded in individual ambidexterity (IA), which highlights employees’ capacity to balance exploration and exploitation while navigating competing demands. Through a thorough review of the literature and empirical examples, we identify four GenAI-enabled work types: Design and Innovation, Data Analysis and Insight Evocation, Customer Service and Engagement, and Content Generation and Optimization. These types reflect the interplay of two critical IA tensions – specialization (generalist vs. specialist) and task routinization (routine vs. non-routine), offering insights into how employees can adapt their skills and roles. Our findings provide actionable recommendations for workforce development, including designing targeted skill-building programs, implementing ethical guidelines, and fostering empowering organizational environments. Additionally, we address the psychological and procedural challenges of integrating GenAI into workplaces and propose strategies to align workforce transformation with policy objectives. By bridging theoretical insights with practical recommendations, this study offers managers a structured roadmap for fostering an ambidextrous and resilient workforce in the age of GenAI.}
}
@article{BOARETO2025129,
title = {Generative assistant for digital twin simulations},
journal = {Procedia CIRP},
volume = {132},
pages = {129-134},
year = {2025},
note = {12th CIRP Global Web Conference (CIRPe 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125000228},
author = {Pedro Antonio Boareto and Eduardo {de Freitas Rocha Loures} and Eduardo Alves {Portela Santos} and Fernando Deschamps},
keywords = {Process Mining, Discrete Event Simulation, Generative Artificial Intelligence, Digital Twin, Industry 4.0, Chatbot, Decision-making},
abstract = {One of the key emerging technologies in Industry 4.0 is the Digital Twin (DT). Although it promises increased efficiency, productivity, and innovation, its adoption faces challenges such as high investment costs and the need for workforce requalification. Generative Artificial Intelligence (GAI) emerges as a promising solution, offering capabilities to accelerate development processes and reduce costs. This study aims to leverage GAI to enhance the development of DT and support decision-making in industrial environments by proposing a Generative Assistant for Digital Twin Simulations (GADTS). This proposal generates operational models quickly, offers greater customization, and facilitates the creation of efficient scenario simulations in natural language. The proposal was tested with artificial data. As a result, the development of highly personalized DT simulations with Key Performance Indicators (KPIs) was entirely abstracted into natural language requests.}
}
@article{WILLERMARK2025101893,
title = {The subject is the subject: Why TPACK matters in the era of GenAI},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101893},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101893},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125006217},
author = {Sara Willermark},
keywords = {Technological Pedagogical Content Knowledge (TPACK), Generative Artificial Intelligence (GenAI), Digital development, Teacher Knowledge},
abstract = {Generative artificial intelligence (GenAI) has quickly gained a prominent role in discussions within education, especially regarding issues such as plagiarism, assessment, and personalized learning experiences. This position paper advocates for research on how GenAI transforms disciplinary knowledge and redefines subject-specific teaching practices. Through a historical exposé on the role of digital technology in education, this inquiry foregrounds an epistemic perspective that examines how research in technological advances is altering the nature of knowledge and its acquisition. Consequently, the TPACK framework is revisited to highlight the complex interplay of technology, pedagogy, and content in the era of GenAI, sparking critical examination of how it alters the conditions for teachers and teaching. It underscores the importance of studies that explore the meaning of TPACK in the evolving landscape and that enhance the framework with contemporary subject-specific examples rooted in practice.}
}
@article{KANG2025,
title = {Nurse Researchers’ Experiences and Perceptions of Generative AI: Qualitative Semistructured Interview Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/65523},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011495},
author = {Ruifu Kang and Zehui Xuan and Ling Tong and Yanling Wang and Shuai Jin and Qian Xiao},
keywords = {generative artificial intelligence, large language model, nurse researcher, nursing research, qualitative study},
abstract = {Background
With the rapid development and iteration of generative artificial intelligence, the growing popularity of such groundbreaking tools among nurse researchers, represented by ChatGPT (OpenAI), is receiving passionate debate and intrigue. Although there has been qualitative research on generative artificial intelligence in other fields, little is known about the experiences and perceptions of nurse researchers; this study seeks to report on the topic.
Objective
This study aimed to describe the experiences and perceptions of generative artificial intelligence among Chinese nurse researchers, as well as provide a reference for the application of generative artificial intelligence in nursing research in the future.
Methods
Semistructured interviews were used to collect data in this qualitative study. Researchers mainly conducted interviews on the cognition, experience, and future expectations of nurse researchers regarding the use of generative artificial intelligence. Twenty-seven nurse researchers were included in the study. Through purposive sampling and snowball sampling, there were 7 nursing faculty researchers, 10 nursing graduate students, and 10 clinical nurse researchers. Data were analyzed using inductive content analysis.
Results
Five themes and 12 subthemes were categorized from 27 original interview documents as follows: (1) diverse reflections on human-machine symbiosis, which includes the interplay between substitution and assistance, researchers shaping the potential of generative artificial intelligence, and acceptance of generative artificial intelligence with alacrity; (2) multiple factors of the usage experience, including individual characteristics and various usage scenarios; (3) research paradigm reshaping in the infancy stage, which involves full-process groundbreaking assistive tools and emergence of new research paths; (4) application risks of generative artificial intelligence, including intrinsic limitations of generative artificial intelligence and academic integrity and medical ethics; and (5) the co-improvement of technology and literacy, which concerns reinforcement needs for generative artificial intelligence literacy, development of nursing research generative artificial intelligence and urgent need for artificial intelligence–generated content detection tools. In this context, the first 4 themes form the rocket of the human-machine symbiosis journey. Only when humans fully leverage the advantages of machines (generative artificial intelligence) and overcome their shortcomings can this human-machine symbiosis journey reach the correct future direction (fifth theme).
Conclusions
This study explored the experiences and perceptions of nurse researchers interacting with generative artificial intelligence, which was a “symbiotic journey” full of twists and turns, and provides a reference and basis for achieving harmonious coexistence between nurse researchers and generative artificial intelligence in the future. Nurse researchers, policy makers, and application developers can use the conclusions of this study to further promote the application of generative artificial intelligence in nursing research, policy making, and product development.}
}
@article{KIM2025101123,
title = {Exploring the potential of acupuncture practice education using artificial intelligence},
journal = {Integrative Medicine Research},
volume = {14},
number = {1},
pages = {101123},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101123},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025000034},
author = {Kyeong Han Kim and Hyein Jeong and Gyeong Seo Lee and Seung-Hee Lee},
keywords = {Artificial intelligence, Acupuncture, Education},
abstract = {Generative artificial intelligence (AI) is being applied in various areas such as education, clinical practice, and research within the medical field. This review explores the potential use of AI models in acupuncture practice education. Recent and relevant findings were searched from literature. Active research on the use of AI in acupuncture education, particularly in areas such as acupoint selection and acupuncture manipulation, is ongoing. Additionally, AI-powered educational tools are being developed in the field of traditional medicine. The development of AI-driven educational tools for acupuncture education holds significant potential to enhance the effectiveness and efficiency of traditional medicine education.}
}
@article{DOO2023877,
title = {Exploring the Clinical Translation of Generative Models Like ChatGPT: Promise and Pitfalls in Radiology, From Patients to Population Health},
journal = {Journal of the American College of Radiology},
volume = {20},
number = {9},
pages = {877-885},
year = {2023},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2023.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1546144023005161},
author = {Florence X. Doo and Tessa S. Cook and Eliot L. Siegel and Anupam Joshi and Vishwa Parekh and Ameena Elahi and Paul H. Yi},
keywords = {generative artificial intelligence, radiology, limitations, large language models, ChatGPT},
abstract = {Generative artificial intelligence (AI) tools such as GPT-4, and the chatbot interface ChatGPT, show promise for a variety of applications in radiology and health care. However, like other AI tools, ChatGPT has limitations and potential pitfalls that must be considered before adopting it for teaching, clinical practice, and beyond. We summarize five major emerging use cases for ChatGPT and generative AI in radiology across the levels of increasing data complexity, along with pitfalls associated with each. As the use of AI in health care continues to grow, it is crucial for radiologists (and all physicians) to stay informed and ensure the safe translation of these new technologies.}
}
@article{MARZI2025103254,
title = {Artificial intelligence and the reconfiguration of NPD Teams: Adaptability and skill differentiation in sustainable product innovation},
journal = {Technovation},
volume = {145},
pages = {103254},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103254},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000860},
author = {Giacomo Marzi and Marco Balzano},
keywords = {Sustainable development goals, Sustainable product innovation, Generative artificial intelligence, New product development teams, Team adaptability, Team skill diversity, Sustainability, Green Innovation},
abstract = {Sustainable product innovation (SPI) is increasingly central to New Product Development (NPD) teams, aligning with global sustainability goals and industry expectations. However, the factors associated with SPI at team level remain underexplored. This study examines the roles of team skill differentiation and team adaptability in fostering SPI, proposing that these factors support teams in the pursuit of sustainability-oriented innovation more effectively. Furthermore, we investigate the moderating role of generative artificial intelligence (GenAI) in shaping the strength of these relationships. Drawing on the double diamond framework and its AI-augmented adaptation, we hypothesize that skill differentiation expands the range of potential solutions in the divergent phase of innovation, while adaptability enhances responsiveness in the convergent phase. GenAI is posited to enhance these effects by augmenting knowledge recombination and real-time strategic adaptation. To test our hypotheses, we conducted a multi-industry survey of NPD teams engaged in sustainability initiatives, applying multiple regression analysis to assess the proposed relationships. All our hypotheses were empirically supported. Overall, this study contributes to SPI research by integrating team capability theory with AI-driven innovation frameworks. The findings highlight the need for firms to cultivate multidisciplinary teams with adaptive capacities while leveraging GenAI as an amplifier rather than a substitute for human expertise. The results also underscore that effective SPI requires both internal knowledge diversity and external responsiveness, alongside AI tools that enhance creativity and sustainability-driven decision-making. Finally, this research provides insights into how NPD teams can enhance their engagement in sustainable innovation, aligning with the broader objectives of Sustainable Development Goals (SDGs) 9 and 12.}
}
@article{CHOUDHARY2025114500,
title = {Modeling the role of generative AI in organizational privacy and security},
journal = {Decision Support Systems},
volume = {196},
pages = {114500},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114500},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001010},
author = {Shweta Kumari Choudhary and Arpan Kumar Kar},
keywords = {Cyber security, Mixed methods, SOIPSVM, Generative artificial intelligence, Organizational structure, Information governance},
abstract = {In today's digital environment, organizations face security challenges like intentional breaches influenced by their specific policies and structures. As emerging technologies like Generative Artificial Intelligence (GAI) become more integrated into organizational processes, the adoption of GAI moderates organizational contextual conditions and rule characteristics, which affects the perceived risk of violating security rules. We extend the SOIPSV model to analyze cybersecurity practices and the strategic use of GAI in enhancing organizational resilience against security breaches. We establish the direct and moderating impacts of contextual conditions and rule characteristics, along with interactions in complex organizational cyber security. Our first study uses text mining for inferential and configurational analysis. Our second qualitative study explained the model of dynamic interplay between GAI and organizational factors. Our findings have implications for perceived risk management and managers redesigning business processes to manage security breaches.}
}
@article{GARCIASANCHEZ2025,
title = {Health Care Professionals’ Experiences and Opinions About Generative AI and Ambient Scribes in Clinical Documentation: Protocol for a Scoping Review},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/73602},
url = {https://www.sciencedirect.com/science/article/pii/S192907482500486X},
author = {Carolina {Garcia Sanchez} and Anna Kharko and Maria Hägglund and Sara Riggare and Charlotte Blease},
keywords = {artificial intelligence, AI, generative artificial intelligence, GenAI, ambient scribes, health care professionals, clinical documentation, attitude, scoping review},
abstract = {Background
Generative artificial intelligence (GenAI) leverages large language models (LLMs) that are transforming health care. Specialized ambient GenAI tools, like Nuance Dax, Speke, and Tandem Health, “listen” to consultations and generate clinical notes. Medical-focused models, like Med-PaLM, provide tailored health care insights. GenAI’s capability to summarize complex data and generate responses in various conversational styles or literacy levels makes it particularly valuable since it has the potential to alleviate the burden of clinical documentation on health care professionals (HCPs). While GenAI may prove to be helpful, offering novel benefits, it comes with its own set of challenges. The quality of the source data can introduce biases, leading to skewed recommendations or outright false information (so-called hallucinations). In addition, due to the conversational nature of chatbot responses, users may be susceptible to misinformation, posing risks to both safety and privacy. Therefore, careful implementation and rigorous oversight are essential to ensure accuracy, ethical integrity, and alignment with clinical standards. Despite these advances, currently, no review has investigated HCPs’ experiences and opinions about GenAI in clinical documentation. Yet, such a perspective is crucial to better understand how these technologies can be safely and ethically adopted and implemented in clinical practice.
Objective
We aim to present the protocol for a scoping review exploring HCPs’ experiences and opinions about GenAI and ambient scribes in clinical documentation.
Methods
This scoping review will be carried out following the methodological framework of Arksey and O’Malley and the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses for Scoping Reviews) checklist. Relevant papers will be searched for in PubMed, IEEE Xplore, APA PsycInfo, CINAHL, and Web of Science. The review will include studies published between January 2023 and September 2025. Studies will be included that represent original peer-reviewed work that explores HCPs’ experiences and opinions about the use of GenAI or ambient scribes for clinical documentation. Data extraction will include publication type, country, sample characteristics, clinical setting, study aim, study design, research question, and key findings. Study quality will be assessed using the Mixed Methods Appraisal Tool.
Results
The results will be presented as a narrative synthesis structured along the key themes of the evidence mapped. Data will be collated and presented in charts and tabular format. Findings will be reported in a peer-reviewed scoping review.
Conclusions
This will be the first scoping review that considers HCPs’ experiences and opinions about GenAI and ambient scribes in clinical documentation. The results will clarify how HCPs use—or avoid using—GenAI in daily health care work. This insight will help address perceived benefits, risks, expectations, and uncertainties. It may also reveal key research gaps in the field.
International Registered Report Identifier (IRRID)
PRR1-10.2196/73602}
}
@article{MERINO2025,
title = {Complex diseases meet deep phenotyping and generative AI},
journal = {Trends in Genetics},
year = {2025},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2025.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0168952525002173},
author = {Jordi Merino},
keywords = {precision health, deep phenotyping, complex diseases, heterogeneity},
abstract = {Complex diseases are heterogeneous and evolve along a continuum, limiting individual-level prediction with current approaches. The Human Phenotype Project (HPP) integrates deep phenotyping with generative artificial intelligence (AI) to identify early deviations in health parameters. While the project has already provided significant insights, the challenge is converting these findings into actionable, equitable, and scalable interventions, advancing precision healthcare across diverse populations.}
}
@article{SCHAAFF2025,
title = {Youth Perspectives on Generative AI and Its Use in Health Care},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/72197},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125007319},
author = {Christian Schaaff and Manvir Bains and Sophie Davis and Trinity Amalraj and Abby Frank and Marika Waselewski and Tammy Chang and Andrew Wong},
keywords = {generative artificial intelligence, medical informatics, adolescent health, health technology, young adult},
abstract = {A nationwide survey of youth aged 14 to 24 years on generative artificial intelligence (GAI) found that many youths are wary about the use of GAI in health care, suggesting that health professionals should acknowledge concerns about AI health tools and address them with adolescent patients as they become more pervasive.
}
}
@article{ERDIWANSYAH2025100099,
title = {Emerging role of generative AI in renewable energy forecasting and system optimization},
journal = {Sustainable Chemistry for Climate Action},
volume = {7},
pages = {100099},
year = {2025},
issn = {2772-8269},
doi = {https://doi.org/10.1016/j.scca.2025.100099},
url = {https://www.sciencedirect.com/science/article/pii/S2772826925000446},
author = { Erdiwansyah and Rizalman Mamat and  Syafrizal and Mohd Fairusham Ghazali and Firdaus Basrawi and S.M. Rosdi},
keywords = {Generative artificial intelligence, Renewable energy forecasting, Energy system optimization, Smart grid management, Federated learning in energy},
abstract = {The rapid integration of renewable energy sources (RES) into modern power systems introduces significant challenges in forecasting accuracy, grid stability, and energy optimization. Generative Artificial Intelligence (Gen-AI), including architectures such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformers, offers new capabilities to overcome data sparsity, nonlinearity, and uncertainty in renewable-dominant systems. This study aims to comprehensively review the emerging role of Gen-AI in improving solar and wind forecasting, load prediction, energy storage management, and smart grid optimization. Using a comparative and synthesis-based methodology, this review analyses findings from high-impact publications between 2023 and 2025. Results indicate that GAN-based models reduce root mean square error (RMSE) by 15–20 % in solar irradiance forecasting and significantly enhance spatial-temporal wind simulations. Time-series GAN-LSTM hybrids enhance demand forecasting accuracy under nonlinear conditions, while VAE-driven dispatch models achieve gains of 9–12 % in energy efficiency and curtailment reduction. The novelty of this review lies in mapping Gen-AI's integration with digital twins, federated learning, and AI–IoT frameworks, which enables the real-time, privacy-preserving optimisation of complex energy systems. The principal conclusion is that Gen-AI serves as a transformative tool to enhance system resilience, forecasting precision, and operational flexibility in renewable energy networks. For sustainable implementation, future developments must address challenges in model explainability, data privacy, and scalability. These findings support the journal’s scope by highlighting AI-driven advancements for the reliable, efficient, and sustainable transformation of energy systems.}
}
@article{HOOMANFARD2025101570,
title = {Generative AI in dissertation writing: L2 doctoral students’ self-reported use, AI-giarism, and perceived training needs},
journal = {Journal of English for Academic Purposes},
volume = {78},
pages = {101570},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101570},
url = {https://www.sciencedirect.com/science/article/pii/S1475158525001018},
author = {MohammadHamed Hoomanfard and Yaser Shamsi},
keywords = {Generative artificial intelligence (GenAI), Dissertation writing, L2 academic writing, Perceptions, Perceived training needs, Ethical issues},
abstract = {Generative Artificial Intelligence (GenAI) has been extensively employed by L2 doctoral students to assist with their dissertation writing. However, little is known about how these students engage with GenAI tools to complete their significant writing tasks in higher education. To address this gap, we conducted a qualitative study exploring L2 doctoral students' self-reported use of GenAI tools for dissertation writing purposes, concerns about AI-induced plagiarism (AI-giarism), and perceived training needs. We interviewed 54 doctoral students from different departments at a public university in the American Central South and applied thematic analysis to explore students’ perspectives. The findings showed that L2 doctoral students use GenAI tools for 18 distinct purposes, which can be categorized into exploration, confirmation, and execution. Two major themes emerged regarding AI-giarism: (1) students' uncertainty about the boundary between legitimate GenAI use and plagiarism, and (2) their dilemma over whether to acknowledge using GenAI in their dissertations. Regarding perceived training needs, students expressed a desire to learn about various GenAI tools suited for specific tasks, effective prompting, addressing plagiarism concerns, and managing data privacy issues.}
}
@article{ENSLIN2025265,
title = {Past, Present, and Future: A History Lesson in Artificial Intelligence},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {265-278},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724000850},
author = {Sarah Enslin and Vivek Kaul},
keywords = {Artificial intelligence, Machine learning, Deep learning, Computer-aided detection, Computer-aided diagnosis, Generative artificial intelligence}
}
@article{CIUDADFERNANDEZ2025108325,
title = {People are not becoming “AIholic”: Questioning the “ChatGPT addiction” construct},
journal = {Addictive Behaviors},
volume = {166},
pages = {108325},
year = {2025},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2025.108325},
url = {https://www.sciencedirect.com/science/article/pii/S030646032500084X},
author = {Víctor Ciudad-Fernández and Cora {von Hammerstein} and Joël Billieux},
keywords = {ChatGPT addiction, Generative large language models, Conversational artificial intelligence, Behavioral addictions},
abstract = {Generative artificial intelligence (AI) chatbots such as ChatGPT have rapidly gained popularity in many daily life spheres, even sparking scholarly debate about a potential “ChatGPT addiction.” Throughout history, new technologies have repeatedly been associated with widespread concerns and “moral panics,” especially when their adoption is sudden and involves significant changes in daily functioning. It is thus no surprise that researchers have examined whether intensive use of ChatGPT can be considered an addictive behavior. At least four scales measuring ChatGPT addiction have been developed so far, all framed after substance use disorder criteria. Drawing parallels with previous cases of pathologizing everyday behaviors, we caution against labeling and defining intensive or habitual chatbot use as addictive behavior. To label a behavior as addictive, there must be convincing evidence of negative consequences, impaired control, psychological distress, and functional impairment. However, the existing research on problematic use of ChatGPT or other conversational AI bots fails to provide such robust scientific evidence. Caution is thus warranted to avoid (over)pathologization, inappropriate or unnecessary treatments, and excessive regulation of tools that have many benefits when used in a mindful and regulated manner.}
}
@article{AN2025105227,
title = {Impacts of generative AI on student teachers' task performance and collaborative knowledge construction process in mind mapping-based collaborative environment},
journal = {Computers & Education},
volume = {227},
pages = {105227},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105227},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524002410},
author = {Shuowen An and Si Zhang and Tongyu Guo and Shuang Lu and Wenying Zhang and Zhihui Cai},
keywords = {Cooperative/collaborative learning, Improving classroom teaching, Teaching/learning strategies, 21st century abilities},
abstract = {Collaboration has long been recognized as an efficacious pedagogical strategy. With the visual pedagogical scaffold, for instance, mind maps, learners can externalize their comprehension and engage in meaning negotiation. However, given the limitations posed by the conventional collaborative environment such as the difficulty for groups to achieve deep discussions and generate group intelligence, the generative artificial intelligence (GAI) tool was introduced. The efficacy of the GAI tool in boosting task performance is still contested and its influence on collaborative knowledge construction remains unclear. Therefore, this study was conducted in an elective course at a university. A total of 30 student teachers were the participants, including 10 groups of 3 students. In the subsequent quasi-experimental study, 5 experimental groups employed the GAI tool and mind mapping based collaborative environment (GMMCE) and 5 control groups employed the conventional mind mapping based collaborative environment (MMCE). The results showed that the experimental groups outperformed the control groups on both collaborative tasks in the course. According to Ordered Network Analysis (ONA), the experimental groups developed a collaborative knowledge construction process in cognitive dimension, i.e., progressive interaction from individual to peer to group. On the contrary, the control groups were mainly reflected in the transition between learners' individual expression and peer interaction since they were more centered on the regulative dimension. We also supplemented students’ perception of using the GAI tool from the interview data. Finally, we highlighted the implications for pedagogy and described the research limitations as well as future directions.}
}
@article{NGU2025105421,
title = {A generative AI educational game framework with multi-scaffolding supports workplace competency development},
journal = {Computers & Education},
volume = {239},
pages = {105421},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105421},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001897},
author = {Pei-Ching Ngu and Chih-Chung Chien and Yen-Ting Ho and Huei-Tse Hou},
keywords = {Games, Human-computer interface, Simulations, Lifelong learning},
abstract = {This study proposes a game design framework using generative artificial intelligence based non-player character for providing simulated interactions and instant feedback as a metacognitive scaffolding to help learners develop workplace communication skills and stress resistance through situational experience learning. This study investigates learning effectiveness and psychological responses, including flow, perceived fidelity, cognitive load, and qualitative feedback, and specifically analyzes the behavioral patterns of learners interacting with generative artificial intelligence. A total of 91 participants were enrolled in this study and divided into three groups: experimental group 1 (generative artificial intelligence interactive metacognitive scaffolding), experimental group 2 (video metacognitive scaffolding), and control group (text metacognitive scaffolding). The results showed that students in the generative artificial intelligence group responded with higher perceived fidelity and were significantly better than the control group with text-based metacognitive scaffolding in terms of learning effectiveness, flow, and germane cognitive load. Behavioral pattern analysis reveals that learners can effectively obtain a lot of positive help in solving tasks through positive interactions with non-player character chatbot. This framework and the findings of the study can be used as a reference for related studies in the field of game-based learning in the use of metacognitive scaffolding, contextual learning, and generative AI. Due to the short experimental period, the results may only reflect the short-term learning effects, and the novelty of Gen AI may also cause bias in affecting the learning outcomes, future studies can increase the duration or number of experiences, and explore the effectiveness in other professional domains.}
}
@article{HAKANSSON20245458,
title = {Generative AI and Large Language Models - Benefits, Drawbacks, Future and Recommendations},
journal = {Procedia Computer Science},
volume = {246},
pages = {5458-5468},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.689},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027492},
author = {Anne Håkansson and Gloria Phillips-Wren},
keywords = {Natural Language Processing, Generative AI, Large Language Models},
abstract = {Natural language processing, with parsing and generation, has a long tradition. Parsing has been easier to perform than a generation but with generative artificial intelligence (a.k.a Gen AI) and large language models (abbr. LLMs), this has changed. Generative artificial intelligence is a type of artificial intelligence that uses a large data set to create something in the genre of that data set. It can generate different outputs ranging from texts, audio, objects, pictures, and paintings to videos, but also synthetic data. LLMs use deep learning and deep neural networks to train on large text corpora for recognizing and generating texts. These models are based on massive data sets, collected from databases and the web. They use transformer models to detect how elements in sequences relate to each other. This provides context support. Two well-known large language models are the Generative Pre-trained Transformer, GPT, used in ChatGPT and Bidirectional Encoder Representations from Transformers, BERT. Although LLMs have advantages, they have problems. This paper presents generative artificial intelligence and LLMs with benefits and drawbacks. Results from applying these models have shown that they can work well for accuracy in specificity, user personalization and human-computer communication but they may not provide acceptable, reliable and truthful results. For example, ethics, hallucinations and incorrect information, or misjudgments, are some major problems. The paper ends with future directions, research questions on LLMs, and recommendations.}
}
@article{GARMANNJOHNSEN2025450,
title = {Open Innovation Workspaces: Applying the Triple Bottom Line Co-Creation Canvas for the Wine Industry},
journal = {Procedia Computer Science},
volume = {256},
pages = {450-457},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925004983},
author = {Niels F. Garmann-Johnsen and Dag H. Olsen and Tom R. Eikebrokk},
keywords = {Business canvases, Co-creation, Triple Bottom Line, electronic workspaces, workshop-setting, inter-disciplinary ideation, innovation pedagogics, generative AI},
abstract = {This article suggests a shift towards more sustainable and digitally integrated business models and practices. This article discusses the potential benefits of using a business canvas, the Triple Bottom Line (TBL) Co-creation canvas, in planning for sustainable business growth and the role of co-creation in achieving sustainability goals, through digital transformation and collaboration. Based on a test, with students from different informatics and Information system disciplines in the CoDeAI summer school, 2024, this article concludes that the TBL Co-creation canvas is a useful tool in this matter, thus giving a proof of concept to this method. It functioned well in a social setting such as this summer school. Inter-disciplinary as in this summer school is comparable to what the context will be like in industry innovation work. Also, the authors found that the outcome of such workshops can be processed further using generative artificial intelligence (AI).}
}
@article{ABOUCHAAR2024674,
title = {ChatGPT vs Expert-Guided Care Pathways for Postesophagectomy Symptom Management},
journal = {Annals of Thoracic Surgery Short Reports},
volume = {2},
number = {4},
pages = {674-679},
year = {2024},
issn = {2772-9931},
doi = {https://doi.org/10.1016/j.atssr.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S277299312400250X},
author = {Mohamad K. {Abou Chaar} and Giovanna Grigsby-Rocca and Ming Huang and Shanda H. Blackmon},
abstract = {Background
The objective of this study was to compare generative artificial intelligence–initiated care pathways, using ChatGPT, with expert-guided consensus-initiated care pathways from AskMayoExpert (AME) for symptom management of esophageal cancer patients after esophagectomy.
Methods
A formal protocol for development of 9 AME care pathways was followed for specific patient-identified domains after esophagectomy for esophageal cancer. Domain scores were measured and assessed through the Upper Digestive Disease tool. These care pathways were developed by experts validated by a consensus-driven methodology. ChatGPT was used to answer specific questions similar to the AME care pathway on April 9, 2023, and March 28, 2024. To compare outcomes, answers were recorded, and algorithms were compared with a survey tool composed of 5 questions.
Results
Both modalities were able to provide a clear definition with multidirectional management options for all 9 domains: dysphagia, generalized dumping, gastrointestinal dumping, pain, regurgitation, heartburn, nausea, physical health, and mental health. When provided with a simple prompt, ChatGPT 3.5 failed to provide a comprehensive stepwise approach for providers, any testing recommendations, or any form of triage process. However, ChatGPT 4.0 provided plans, similar to AME care pathways, when a sophisticated prompt was used.
Conclusions
Generative artificial intelligence–initiated care pathways can be used by physicians as a supplementary tool to guide provider management of patients with complex symptoms after esophagectomy. This technology will continue to advance but is currently insufficient to solely guide clinical management of complex patients with severe symptoms.}
}
@article{TSANG2024,
title = {Semantic-Driven Internet of Behaviours for Enhancing Supply Chain ESG Capabilities Through Generative AI},
journal = {International Journal on Semantic Web and Information Systems},
volume = {21},
number = {1},
year = {2024},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.385572},
url = {https://www.sciencedirect.com/science/article/pii/S1552628325000304},
author = {Y. P. Tsang and C. H. Wu and Yue Wang and W. H. Ip},
keywords = {GenAI, Large Language Model, Sustainable Development Goals, Recommendation System, Sustainability},
abstract = {ABSTRACT
Pursuing sustainable development goals requires enterprises to enhance their environmental, social, and governance (ESG) capabilities. In logistics and supply chain management, where small and medium enterprises dominate, integrating ESG practices is challenging and often favors larger companies with established frameworks. This study introduces an ESG recommendation system based on generative artificial intelligence (GERS) to provide accessible, tailored ESG guidance. Leveraging large language models and an ESG knowledge base, GERS offers actionable recommendations, particularly benefiting small and medium enterprises. Evaluated through a case study with a Hong Kong Logistics Association ESG assessment programme, expert panels confirmed the quality of its recommendations. Results demonstrate the GERS’s ability to generate ESG improvement plans, enhancing capabilities efficiently. This research highlights the transformative potential of generative artificial intelligence in fostering sustainability, showcasing its role in creating adaptive, context-aware services that drive collaborative learning and sustainable practices in supply chains.}
}
@article{LI2025110382,
title = {Comparative diagnostic accuracy of GPT-4o and LLaMA 3-70b: Proprietary vs. open-source large language models in radiology},
journal = {Clinical Imaging},
volume = {118},
pages = {110382},
year = {2025},
issn = {0899-7071},
doi = {https://doi.org/10.1016/j.clinimag.2024.110382},
url = {https://www.sciencedirect.com/science/article/pii/S0899707124003127},
author = {David Li and Kartik Gupta and Mousumi Bhaduri and Paul Sathiadoss and Sahir Bhatnagar and Jaron Chong},
keywords = {Large language model, Generative artificial intelligence, Generative pre-trained transformer, Open source, Radiology}
}
@article{HUANG2025280,
title = {Promoting students’ data literacy using technologies through lesson study},
journal = {International Journal for Lesson and Learning Studies},
volume = {14},
number = {3},
pages = {280-297},
year = {2025},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-10-2024-0222},
url = {https://www.sciencedirect.com/science/article/pii/S2046825325000113},
author = {Rongjin Huang and Dovie Kimmins and Jeremy Winters and Jennifer M. Suh},
keywords = {Technology, Google sheet, Generative artificial intelligence (Gen-AI), ChatGPT, Data literacy, Scatterplot, Teacher learning, Student learning, Lesson study},
abstract = {Purpose
This article examines a lesson study (LS) approach bringing teachers and university faculty together to develop a lesson in data literacy using transformative technologies, including Generative Artificial Intelligence (Gen-AI) such as ChatGPT.
Design/methodology/approach
An LS team with four teachers from a private school, facilitated by three researchers, conducted two iterations of LS on teaching scatterplots using technologies. Multiple data were collected: Videos of research lessons, videos of lesson planning and post-lesson debriefings, and post-LS focus student group and teacher interviews. Based on an enriched LS framework (Lewis, 2016), this study investigates both students’ and teachers’ learning.
Findings
The students learned new concepts and skills to investigate contextual problems using technologies through the data literacy cycle. Teachers developed an understanding of relevant statistical concepts and pedagogical content knowledge needed for teaching the topic in a technology-rich environment. Teachers realized the potential of using Gen-AI for planning lessons and were eager to explore the effective use of Gen-AI further. Meanwhile, some challenges in using Gen-AI in LS were identified.
Research limitations/implications
This study focuses on both teachers’ and students’ perceived learning based on interview data. However, the integration of classroom teaching data and debriefing data could provide a richer picture of their learning processes.
Practical implications
This study demonstrates how data literacy could be taught through addressing contextual problems using various technologies, revealing both positive effects and associated challenges.
Originality/value
The study contributes to a better understanding of how transformative technology like Gen-AI could be incorporated into LS to strengthen teachers’ and students’ learning.}
}
@article{SEKHAR2024,
title = {A Use Case for Generative AI in Medical Education},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/56117},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000679},
author = {Tejas C Sekhar and Yash R Nayak and Emily A Abdoler},
keywords = {medical education, med ed, generative artificial intelligence, artificial intelligence, GAI, AI, Anki, flashcard, undergraduate medical education, UME}
}
@article{LIU2025103826,
title = {Examining language learners’ GenAI-assisted writing self-efficacy profiles and the relationship with their writing self-regulated learning strategies},
journal = {System},
volume = {134},
pages = {103826},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103826},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002362},
author = {Meilu Liu and Lawrence Jun Zhang},
keywords = {Generative Artificial Intelligence (GenAI), Writing self-efficacy, Writing self-regulated learning strategies, EFL writing performance,},
abstract = {Generative artificial intelligence (GenAI) has emerged as an effective scaffolding tool for facilitating English-as-a-foreign-language (EFL) learners' writing performance. Nevertheless, most studies have investigated the impacts of GenAI on learners' final written outputs instead of their writing processes. To fill this research gap, we examined EFL learners' self-efficacy and writing self-regulated learning (SRL) strategies, which were essential motivational constructs underlying GenAI-assisted writing processes. Our person-centered latent profile analysis of 193 EFL learners revealed four groups of students with diverse GenAI-assisted writing self-efficacy levels: highly confident all-rounders, practical assistance seekers, interaction-oriented communicators, and unconfident less-adaptable users. These four profiles were found to be closely tied to their writing SRL strategy use. Furthermore, years of English learning experience and perceived English proficiency seemed to be significant antecedents of EFL learners’ GenAI-assisted writing self-efficacy profiles. These findings could chart new ways for EFL writing syllabus design in the GenAI context.}
}
@article{PEZZULO202497,
title = {Generating meaning: active inference and the scope and limits of passive AI},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {2},
pages = {97-112},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002607},
author = {Giovanni Pezzulo and Thomas Parr and Paul Cisek and Andy Clark and Karl Friston},
keywords = {generative AI, large language models, active inference, predictive processing, foundation models, embodied cognition},
abstract = {Prominent accounts of sentient behavior depict brains as generative models of organismic interaction with the world, evincing intriguing similarities with current advances in generative artificial intelligence (AI). However, because they contend with the control of purposive, life-sustaining sensorimotor interactions, the generative models of living organisms are inextricably anchored to the body and world. Unlike the passive models learned by generative AI systems, they must capture and control the sensory consequences of action. This allows embodied agents to intervene upon their worlds in ways that constantly put their best models to the test, thus providing a solid bedrock that is – we argue – essential to the development of genuine understanding. We review the resulting implications and consider future directions for generative AI.}
}
@article{MOTOKI2025105600,
title = {Generative AI framework for sensory and consumer research},
journal = {Food Quality and Preference},
volume = {133},
pages = {105600},
year = {2025},
issn = {0950-3293},
doi = {https://doi.org/10.1016/j.foodqual.2025.105600},
url = {https://www.sciencedirect.com/science/article/pii/S0950329325001752},
author = {Kosuke Motoki and Julia Low and Carlos Velasco},
keywords = {Artificial intelligence, Generative AI, GenAI, Digitalization in sensory and consumer science, Large Language Models, AI-assisted research, Natural Language Processing, AI in product testing, AI Ethics, Digital sensory methods, LLMs, Human-AI interaction, Human-centered AI, AI-assisted sensory research design, Digitalization},
abstract = {Generative artificial intelligence (GenAI) technologies, including ChatGPT, offer innovative capabilities in sensory and consumer science. Recent empirical studies in sensory and consumer science highlight the potential utility of GenAI in, for example, AI-generated food images and recipes. To the best of our knowledge, this is the first paper to propose a comprehensive framework for integrating GenAI into research and development in sensory and consumer science. The framework highlights how GenAI can be applied across the concept, design, and testing phases through an iterative process. The concept phase utilises GenAI to generate research concepts (e.g., proposing ideas such as research questions and hypotheses). The design phase employs GenAI to formulate research designs. During this stage, GenAI assists with creating and validating survey/experimental stimuli and measurement scales. The testing phase applies GenAI to evaluate research ideas and designs by employing “silicon samples,” interactive surveys that enhance engagement and response quality. In the testing phase, GenAI can also analyse unstructured text data, offering more accurate and scalable text analysis than traditional methods, even across diverse languages and cultures. This study also acknowledges potential pitfalls, such as biases in AI outputs, data privacy and security concerns, oversimplification, lack of transparency, and GenAI user misperception. This article encourages greater integration of GenAI by highlighting its potential for the sensory and consumer science community, while addressing its limitations and ensuring adherence to high ethical standards.}
}
@article{BENJAMIN2024,
title = {Reflections From the Pandemic: Is Connectivism the Panacea for Clinicians?},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/53344},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124008963},
author = {Jennifer Benjamin and Tyson Pillow and Heather MacNeill and Ken Masters and Anoop Agrawal and Neil Mehta},
keywords = {learning theory, learning framework, connectivism, panacea, COVID-19, generative artificial intelligence, GAI, health care community, clinician, health care, airborne disease, learning, information, misinformation, autonomy, diversity},
abstract = {The COVID-19 pandemic and the recent increased interest in generative artificial intelligence (GenAI) highlight the need for interprofessional communities’ collaboration to find solutions to complex problems. A personal narrative experience of one of the authors compels us to reflect on current approaches to learning and knowledge acquisition and use solutions to the challenges posed by GenAI through social learning contexts using connectivism. We recognize the need for constructivism and experiential learning for knowledge acquisition to establish foundational understanding. We explore how connectivist approaches can enhance traditional constructivist paradigms amid rapidly changing learning environments and online communities. Learning in connectivism includes interacting with experts from other disciplines and creating nodes of accurate and accessible information while distinguishing between misinformation and accurate facts. Autonomy, connectedness, diversity, and openness are foundational for learners to thrive in this learning environment. Learning in this environment is not just acquiring new knowledge as individuals but being connected to networks of knowledge, enabling health professionals to stay current and up-to-date. Existing online communities with accessible GenAI solutions allow for the application of connectivist principles for learning and knowledge acquisition.}
}
@article{CORVELLO2025100456,
title = {Generative AI and the future of innovation management: A human centered perspective and an agenda for future research},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {1},
pages = {100456},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100456},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124002506},
author = {Vincenzo Corvello},
keywords = {Generative Artificial Intelligence, Technology appropriation, Innovation management, Adaptive structuration theory, Technology customization, Human-technology interaction},
abstract = {Generative Artificial Intelligence (GenAI) is revolutionizing innovation management by reshaping organizational structures and processes. Unlike traditional AI, which primarily focused on automation and prediction, GenAI introduces the capability to create new content, ideas, and solutions, profoundly impacting industries reliant on creativity and problem-solving. As organizations integrate GenAI, human agency and organizational dynamics play a critical role in determining the technology’s impact, raising key questions about its appropriation in various contexts. This paper explores the role of GenAI in innovation management through the lens of Technology Appropriation, a specific application of Adaptive Structuration Theory (AST), which analyzes how technology and organizational structures mutually shape each other. The study emphasizes the importance of human-centered models for understanding the socio-technical dynamics involved in GenAI appropriation. It identifies customization, reinterpretation, and power dynamics as critical factors influencing the successful integration of GenAI across industries. The paper also outlines future research directions, focusing on diversity in AI adoption, the customization of GenAI in innovation processes, and the ethical and regulatory challenges posed by its widespread use. By examining how individuals and organizations adapt and reconfigure GenAI to fit specific needs, this paper contributes to a deeper understanding of the reciprocal relationship between technology and human agency, offering insights into the transformative potential of GenAI in enhancing innovation.}
}
@article{RODGER2025104461,
title = {Generative AI in healthcare education: How AI literacy gaps could compromise learning and patient safety},
journal = {Nurse Education in Practice},
volume = {87},
pages = {104461},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104461},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002173},
author = {Daniel Rodger and Sebastian Porsdam Mann and Brian Earp and Julian Savulescu and Christopher Bobier and Bruce P. Blackshaw},
keywords = {Artificial intelligence, Nursing, Chatbot, ChatGPT, Generative artificial intelligence, Machine learning, Patient safety, Workforce, Literacy, Universities, AI},
abstract = {Aim
To examine the challenges and opportunities presented by generative artificial intelligence in healthcare education and explore how it can be used ethically to enhance rather than compromise future healthcare workforce competence.
Background
Generative artificial intelligence is fundamentally changing healthcare education, yet many universities and healthcare educators have failed to keep pace with its rapid development.
Design
A discussion paper.
Methods
Discussion and analysis of the challenges and opportunities presented by students' increasing use of generative artificial intelligence in healthcare education, with particular focus on assessment approaches, critical thinking development and artificial intelligence literacy.
Results
Students' widespread use of generative artificial intelligence threatens assessment integrity and may inhibit critical thinking, problem-solving skills and knowledge acquisition. Without adequate artificial intelligence literacy there is a risk of eroding future healthcare workforce competence and compromising patient safety and professional integrity.
Conclusion
While generative artificial intelligence presents significant challenges to healthcare education, it offers great promise if used carefully with awareness of its limitations. The development of artificial intelligence literacy is crucial for maintaining professional standards and ensuring patient safety and mitigating its potentially negative impact on the formation of critical thinking skills.}
}
@article{REED2025103448,
title = {The HARMONEE project: Using GenAI images for reminiscence with older adults in long-term care},
journal = {Geriatric Nursing},
volume = {65},
pages = {103448},
year = {2025},
issn = {0197-4572},
doi = {https://doi.org/10.1016/j.gerinurse.2025.103448},
url = {https://www.sciencedirect.com/science/article/pii/S0197457225002915},
author = {J.M Reed and T. Dodson and A. Petrinec and J. Hughes and R.D. Miller},
keywords = {Generative artificial intelligence, Older adults, Reminiscence, Life review, Image creation, Long-term care},
abstract = {Social isolation and demoralization in older adults in long-term care facilities are critical public health concerns linked to higher morbidity, mortality, and reduced quality of life. The HARMONEE project (Harnessing Artificial Intelligence Resources for Mental Well-being for Older Adults and Nurturing Empathy in Education) addressed these issues using AI-generated images based on participants’ memories to support personalized reminiscence. This pilot study (n = 34) employed a mixed-methods feasibility design across two facilities over 60 days to evaluate the practicality and acceptability of the intervention. Findings revealed an 85 % retention rate with 100 % of participants expressing high satisfaction with the intervention. A statistically significant improvement in older adults’ short-term mood (p < 0.05) was observed highlighting its ability to elicit positive emotions and memories. Qualitative data revealed the intervention evoked happiness, enjoyment, nostalgia, memory stimulation, and social connectedness. The HARMONEE intervention shows promise for enhancing mood, engagement, and emotional well-being in older adults.}
}
@incollection{GAUR202691,
title = {Chapter 6 - Ethical concerns of generative AI in healthcare applications},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {91-106},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00009-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000096},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Accountability, AI bias, Generative AI, Healthcare ethics, Patient privacy, Personalized medicine, Transparency},
abstract = {Generative artificial intelligence (AI) in healthcare causes great ethical implications, such as data privacy of patients due to high reliance on sensitive health information, inducing risks of violations and unauthorized access. Additionally, biases in data can lead to unequal treatment and exacerbate health disparities. Certain ethical risks include over-reliance on AI in diagnostics, where incorrect diagnoses could have disastrous results. In personalized medicine, AI must avoid supporting health inequalities through biased data. The use of AI in drug development and clinical trials also raises concerns regarding informed consent and patient safety. To address these concerns, best practices must emphasize transparency, accountability, and building trust with patients and providers. Collaborative efforts and emerging ethical frameworks will shape a responsible future for AI in healthcare, ensuring ethical guidelines are integral to AI development.}
}
@article{BAIER2025104278,
title = {Measuring technology acceptance over time using transfer models based on online customer reviews},
journal = {Journal of Retailing and Consumer Services},
volume = {85},
pages = {104278},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104278},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925000578},
author = {Daniel Baier and Andreas Karasenko and Alexandra Rese},
keywords = {Online customer reviews, Technology acceptance, Transfer models, LLMs (large language models), Transformer architecture, Generative artificial intelligence chatbots, ChatGPT},
abstract = {Online customer reviews (OCRs) are user-generated, semi-formal evaluations of products, services, or technologies. They usually consist of a timestamp, a star rating, and, in many cases, a comment that reflects perceived strengths and weaknesses. OCRs are easily accessible in large numbers on the Internet – for example, through app stores, electronic marketplaces, online shops, and review websites. This paper presents new transfer models to predict technology acceptance and its determinants from OCRs. We train, test, and validate these prediction models using large OCR samples and corresponding observed construct ratings by human experts and generative artificial intelligence chatbots as well as estimated ratings from a traditional customer survey. From a management perspective, the new approach enhances former technology acceptance measurement since we use OCRs as a basis for prediction and discuss the evolution of acceptance over time.}
}
@article{PEREZGUERRERO2025579,
title = {Large language models as partners in medical literature},
journal = {Heart Rhythm},
volume = {22},
number = {2},
pages = {579-584},
year = {2025},
note = {Focus on Devices/Leads},
issn = {1547-5271},
doi = {https://doi.org/10.1016/j.hrthm.2024.07.097},
url = {https://www.sciencedirect.com/science/article/pii/S154752712403073X},
author = {Eduardo J. Pérez-Guerrero and Isha Mehrotra and Sneha S. Jain and Marco V. Perez},
keywords = {Generative artificial intelligence, Large language models, Machine learning, Ethics, Atrial fibrillation, Wearable devices, Artificial intelligence in medicine}
}
@article{HE2025,
title = {Authors’ Reply: Foundation Models for Generative AI in Time-Series Forecasting},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/79772},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125009835},
author = {Rosemary He and Jeffrey Chiang},
keywords = {generative artificial intelligence, artificial intelligence, time series, electronic health records, electronic medical records, systematic reviews, disease trajectory, machine learning, algorithms, forecasting}
}
@article{HU2025100174,
title = {Utilizing generative AI in ophthalmic medical paper writing: Applications, limitations, and practical tools},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {14},
number = {2},
pages = {100174},
year = {2025},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2025.100174},
url = {https://www.sciencedirect.com/science/article/pii/S2162098925000416},
author = {Fang-Yu Hu and Le-Yu Chen and Pin-Jung Cheng and Jen-Yu Liu and Jo-Hsuan Wu and Wei-Li Chen},
keywords = {Generative artificial intelligence, Medical research, Ophthalmology, Journal guideline, AI tools}
}
@article{SCHILKE2025104405,
title = {The transparency dilemma: How AI disclosure erodes trust},
journal = {Organizational Behavior and Human Decision Processes},
volume = {188},
pages = {104405},
year = {2025},
issn = {0749-5978},
doi = {https://doi.org/10.1016/j.obhdp.2025.104405},
url = {https://www.sciencedirect.com/science/article/pii/S0749597825000172},
author = {Oliver Schilke and Martin Reimann},
keywords = {Trust, Disclosure, Generative artificial intelligence, Legitimacy},
abstract = {As generative artificial intelligence (AI) has found its way into various work tasks, questions about whether its usage should be disclosed and the consequences of such disclosure have taken center stage in public and academic discourse on digital transparency. This article addresses this debate by asking: Does disclosing the usage of AI compromise trust in the user? We examine the impact of AI disclosure on trust across diverse tasks—from communications via analytics to artistry—and across individual actors such as supervisors, subordinates, professors, analysts, and creatives, as well as across organizational actors such as investment funds. Thirteen experiments consistently demonstrate that actors who disclose their AI usage are trusted less than those who do not. Drawing on micro-institutional theory, we argue that this reduction in trust can be explained by reduced perceptions of legitimacy, as shown across various experimental designs (Studies 6–8). Moreover, we demonstrate that this negative effect holds across different disclosure framings, above and beyond algorithm aversion, regardless of whether AI involvement is known, and regardless of whether disclosure is voluntary or mandatory, though it is comparatively weaker than the effect of third-party exposure (Studies 9–13). A within-paper meta-analysis suggests this trust penalty is attenuated but not eliminated among evaluators with favorable technology attitudes and perceptions of high AI accuracy. This article contributes to research on trust, AI, transparency, and legitimacy by showing that AI disclosure can harm social perceptions, emphasizing that transparency is not straightforwardly beneficial, and highlighting legitimacy’s central role in trust formation.}
}
@article{XU2026105304,
title = {Empathy order effects on shaping GenAI online complaint management in tourism},
journal = {Tourism Management},
volume = {113},
pages = {105304},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105304},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001748},
author = {Xing'an Xu and Najuan Wen and Ruiying Cai},
keywords = {Generative artificial intelligence, Empathy, Complaining practice, Customer satisfaction, Attitude, Social exchange theory},
abstract = {Recent studies have illuminated the potential of generative artificial intelligence (GenAI) to influence customer behavior in tourism and hospitality. However, effective strategies for using GenAI to manage online customer complaints remain underexplored. This research examines how GenAI's empathy order (affective/cognitive vs. cognitive/affective) affects customer satisfaction and attitudes. Study 1 found that integrating both empathy types leads to higher satisfaction and more positive attitudes than using either type alone. Study 2 demonstrated that in support-seeking scenarios, both empathy orders elicited comparable satisfaction and attitudes, whereas in solution-seeking scenarios, the cognitive/affective empathy order was rated higher than the affective/cognitive order. Study 3 indicated that perceived competence and perceived warmth mediate these effects. This study deepens understanding of GenAI in online complaint management and offers actionable insights for leveraging empathy in online customer interactions.}
}
@article{HOEYER2024159,
title = {Searching for information about stem cells online in an age of artificial intelligence: How should the stem cell community respond?},
journal = {Stem Cell Reports},
volume = {19},
number = {2},
pages = {159-162},
year = {2024},
issn = {2213-6711},
doi = {https://doi.org/10.1016/j.stemcr.2023.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S2213671123005027},
author = {Klaus Hoeyer and Anna Couturier and Kali Barawi and Cheney Drew and Anders Grundtvig and Emma Lane and Anders Kristian Munk and Louise Emma Whiteley and Megan Munsie},
abstract = {Patients and their families routinely use the Internet to learn about stem cell research. What they find, is increasingly influenced by ongoing changes in how information is filtered and presented online. This article reflects on recent developments in generative artificial intelligence and how the stem cell community should respond.}
}
@article{LIU2025,
title = {Leveraging Artificial Intelligence for Digital Symptom Management in Oncology: The Development of CRCWeb},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/68516},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000710},
author = {Darren Liu and Yufen Lin and Runze Yan and Zhiyuan Wang and Delgersuren Bold and Xiao Hu},
keywords = {colorectal cancer, health disparity, health equity, generative artificial intelligence, large language model, software engineering, artificial intelligence},
abstract = {Digital health interventions offer promise for scalable and accessible health care, but access is still limited by some participatory challenges, especially for disadvantaged families facing limited health literacy, language barriers, low income, or living in marginalized areas. These issues are particularly pronounced for patients with colorectal cancer (CRC), who often experience distressing symptoms and struggle with educational materials due to complex jargon, fatigue, or reading level mismatches. To address these issues, we developed and assessed the feasibility of a digital health platform, CRCWeb, to improve the accessibility of educational resources on symptom management for disadvantaged patients with CRC and their caregivers facing limited health literacy or low income. CRCWeb was developed through a stakeholder-centered participatory design approach. Two-phase semistructured interviews with patients, caregivers, and oncology experts informed the iterative design process. From the interviews, we developed the following 5 key design principles: user-friendly navigation, multimedia integration, concise and clear content, enhanced accessibility for individuals with vision and reading disabilities, and scalability for future content expansion. Initial feedback from iterative stakeholder engagements confirmed high user satisfaction, with participants rating CRCWeb an average of 3.98 out of 5 on the postintervention survey. Additionally, using generative artificial intelligence tools, including large language models like ChatGPT and multimedia generation tools such as Pictory, complex health care guidelines were transformed into concise, easily comprehensible multimedia content, and made accessible through CRCWeb. User engagement was notably higher among disadvantaged participants with limited health literacy or low income, who logged into the platform 2.52 times more frequently than nondisadvantaged participants. The structured development approach of CRCWeb demonstrates that generative artificial intelligence–powered multimedia interventions can effectively address health care accessibility barriers faced by disadvantaged patients with CRC and caregivers with limited health literacy or low income. This structured approach highlights how digital innovations can enhance health care.
International Registered Report Identifier (IRRID)
RR2-10.2196/48499}
}
@article{LUO2025,
title = {Scientific Mapping of GenAI in English as a Foreign Language (EFL) Context:},
journal = {International Journal of Technology and Human Interaction},
volume = {21},
number = {1},
year = {2025},
issn = {1548-3908},
doi = {https://doi.org/10.4018/IJTHI.384377},
url = {https://www.sciencedirect.com/science/article/pii/S1548390825000061},
author = {Qianjun Luo and Feifei Chen},
keywords = {Academic Integrity, Bibliometric Analysis, Challenges, English as a Foreign Language (EFL), Gaps, Generative Artificial Intelligence (GenAI), Pedagogical Innovation, Trends},
abstract = {ABSTRACT
This bibliometric analysis of 239 articles from 2016 to 2025 maps the trends, gaps, and challenges of generative artificial intelligence (GenAI) in English-as-a-foreign-language education. Since 2024, research has surged due to technological progress and student-centered learning trends. Asian countries, notably China, lead in output, driven by high English proficiency demands and proactive technology integration. Leading journals such as Education and Information Technologies, System, and Computer Assisted Language Learning dominate the scholarly landscape. Research themes highlight GenAI tools’ effectiveness in language acquisition, while challenges such as academic integrity and the digital divide persist. Scholars advocate for teacher training in technology use and ethics. Future research should explore GenAI’s role in cross-cultural interactions, marginalized engagement, and long-term impacts and acceptance among teachers and students. Promoting collaboration, ethical use, and pedagogical innovation would enhance GenAI’s potential to meet the evolving needs of English-as-a-foreign-language learners.}
}
@article{XU2025121889,
title = {Generative AI for dangerous wave environments in marine dynamics},
journal = {Ocean Engineering},
volume = {337},
pages = {121889},
year = {2025},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2025.121889},
url = {https://www.sciencedirect.com/science/article/pii/S0029801825015951},
author = {Wenzhe Xu and Kevin J. Maki},
keywords = {Generative artificial intelligence, Machine learning, Extreme events, Marine dynamics},
abstract = {Ships and offshore structures are designed to perform optimally in typical conditions, and to survive the harshest conditions that will occur in their lifetime. While there is a substantial corpus of research into design-event analysis, the arrival of generative artificial intelligence (AI) has opened a new portal into describing and distilling the complex ocean environment into something controllable for the engineer to create new realistic ocean environments that can be used for extreme event observation and calculation. In this paper a generative AI method, called GenWave, is presented that shares the same principle as large-language modeling. The method learns the phase relationships in filtered wave data sets so that new wave fields can be generated on demand. GenWaveis based on recurrent neural nets, and it is cast into a bootstrapping algorithm to generate focused wave fields of increasing amplitude. The method is used to generate large waves for both a Gaussian linear water wave, and a non-Gaussian second-order water wave. The comparison of the distributions of phases for the generative AI model to those from Monte-Carlo simulation demonstrate the effectiveness of the method to create new dangerous wave fields for time-domain simulation or laboratory experiment.}
}
@article{CONSOLI2025100431,
title = {Which educational approaches predict students’ generative AI confidence and responsibility?},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100431},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100431},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000712},
author = {Tessa Consoli and Dominik Petko},
keywords = {Generative artificial intelligence, Media literacy education, AI education, Digital agency, Digital responsibility, Digital self-efficacy, Upper secondary education},
abstract = {Given the risks and ethical concerns of integrating generative artificial intelligence (GenAI) into education, scholars have argued for a critical-reflective education approach that addresses the long-term implications of GenAI. However, empirical research on GenAI education approaches is scarce. This study investigates the prevalence of protective-preventive, critical-reflective, and creative-productive GenAI education approaches in highly digitized Swiss upper secondary schools and how students' experiences of these approaches relate to two aspects of their digital agency: GenAI confidence and GenAI responsibility. Using data from 2357 students, the results showed that the critical-reflective approach was the most commonly experienced and significantly predicted students’ GenAI confidence and responsibility. The creative-productive approach positively and significantly predicted GenAI confidence but not responsibility, while the protective-preventive approach, although the second most common approach, was not significantly related to either outcome. However, these approaches explained little variance in the dependent variables, suggesting that they may not yet be effectively implemented or that digital agency is primarily developed outside schools. Analysis of the control variables showed that identifying as a female had a negative significant effect on GenAI confidence and a positive significant effect on GenAI responsibility. The findings highlight the importance of adopting a critical-reflective GenAI education approach with attention to gender issues in fostering responsible and confident digital citizens.}
}
@article{TORRES2025100183,
title = {Generative latent diffusion language modeling yields anti-infective synthetic peptides},
journal = {Cell Biomaterials},
pages = {100183},
year = {2025},
issn = {3050-5623},
doi = {https://doi.org/10.1016/j.celbio.2025.100183},
url = {https://www.sciencedirect.com/science/article/pii/S3050562325001746},
author = {Marcelo D.T. Torres and Leo Tianlai Chen and Fangping Wan and Pranam Chatterjee and Cesar {de la Fuente-Nunez}},
keywords = {generative artificial intelligence, peptide design, latent diffusion language models, peptides, antibiotics, AMP-Diffusion, antimicrobial peptides},
abstract = {Summary
Generative artificial intelligence (AI) offers a powerful avenue for peptide design, yet this process remains challenging due to vast sequence space, complex structure-activity relationships, and the need to balance antimicrobial potency with low toxicity. Here, we introduce AMP-Diffusion, a latent diffusion model fine-tuned on antimicrobial peptide (AMP) sequences using embeddings from protein language models (pLMs). AMP-Diffusion enables the rapid discovery of antibiotic candidates by systematically exploring sequence space. We generated 50,000 candidate sequences, filtered and ranked them using our APEX deep learning (DL) model, and synthesized 46 top candidates. These peptides showed broad-spectrum antibacterial activity, including against multidrug-resistant strains, while exhibiting low cytotoxicity. Mechanistic studies revealed membrane permeabilization and depolarization as primary modes of action. In a preclinical mouse model, lead peptides reduced bacterial loads with efficacy comparable to polymyxin B and levofloxacin, with no detectable adverse effects. AMP-Diffusion thus presents a robust platform for designing antibiotics.}
}
@article{TUOMI2025103863,
title = {Customized language models for tourism management: Implications and future research},
journal = {Annals of Tourism Research},
volume = {110},
pages = {103863},
year = {2025},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2024.103863},
url = {https://www.sciencedirect.com/science/article/pii/S0160738324001403},
author = {Aarni Tuomi and Iis Tussyadiah and Mário Passos Ascenção},
keywords = {Human-computer interaction, Human-artificial intelligence interaction, Artificial intelligence, Chatgpt}
}
@article{ECKARDT20232268,
title = {Mimicking Clinical Trials with Synthetic Acute Myeloid Leukemia Patients Using Generative Artificial Intelligence},
journal = {Blood},
volume = {142},
pages = {2268},
year = {2023},
note = {65th ASH Annual Meeting Abstracts},
issn = {0006-4971},
doi = {https://doi.org/10.1182/blood-2023-179817},
url = {https://www.sciencedirect.com/science/article/pii/S0006497123088705},
author = {Jan-Niklas Eckardt and Waldemar Hahn and Christoph Röllig and Sebastian Stasik and Uwe Platzbecker and Carsten Müller-Tidow and Hubert Serve and Claudia D Baldus and Christoph Schliemann and Kerstin Schäfer-Eckart and Maher Hanoun and Martin Kaufmann and Andreas Burchert and Christian Thiede and Johannes Schetelig and Martin Bornhäuser and Markus Wolfien and Jan Moritz Middeke},
abstract = {Data sharing is often hindered by concerns of patient privacy, regulatory aspects, and proprietary interests thereby impeding scientific progress and establishing a gatekeeping mechanism in clinical medicine since obtaining large data sets is costly and time-consuming. We employed two different generative artificial intelligence (AI) technologies: CTAB-GAN+ and Normalizing Flows (NFlow) to synthesize clinical trial data based on pooled patient data from four previous multicenter clinical trials of the German Study Alliance Leukemia (AML96, AML2003, AML60+, SORAML) that enrolled adult patients (n=1606) with acute myeloid leukemia (AML) who received intensive induction therapy. As a generative adversarial network (GAN), CTAB-GAN+ consists of two adversarial networks: a generator producing synthetic samples from random noise and a discriminator aiming to distinguish between real and synthetic samples. The model converges as the discriminator can no longer reliably differentiate between real or synthetic data. Contrastingly, NFlow consists of a sequence of invertible transformations (flows) starting from a simple base distribution and gradually adding complexity to better mirror the training data. Both models were trained on tabular data including demographic, laboratory, molecular genetic and cytogenetic patient variables. Detection of molecular alterations in the original cohort was performed via next-generation sequencing (NGS) using the TruSight Myeloid Sequencing Panel (Illumina, San Diego, CA, USA) with a 5% variant-allele frequency (VAF) mutation calling cut-off. For cytogenetics, standard techniques for chromosome banding and fluorescence-in-situ-hybridization (FISH) were used. Hyperparameter tuning of generative models was conducted using the Optuna Framework. For each model, we used a total of 70 optimization trials to optimize a custom score inspired by TabSynDex which assesses both the resemblance of the synthetic data to real training data and its utility. Pairwise analyses were conducted between the original and both synthetic data sets, respectively. All tests were carried out as two-sided tests using a significance level α of 0.05. Table 1 summarizes baseline patient characteristics and outcome for both synthetic cohorts compared to the original cohort. Firstly, we found both models to adequately represent patient features, albeit that some individual variables showed a statistically significant deviation from the original cohort. It is important to note that for such a large sample size (n=1606 for each cohort), even miniscule differences can be rendered statistically significant notwithstanding any meaningful clinical difference. Interestingly, variables that deviated from the original distribution were different for both models indicating model architecture to play a vital role in sample representation: While CTAB-GAN+ showed significant deviations for both age and sex, NFlow showed significant deviations for AML status. Complete remission rate was similar between original (70.7%, odds ratio [OR]: 2.41) and CTAB-GAN+ (73.7%, OR: 2.81, p=0.059) and NFlow (69.1%, OR: 2.24, p=0.356). For event-free survival (EFS), which was not included as a target in hyperparameter tuning, both networks deviated significantly from the original cohort (original: median 7.2 months, HR: 1.36; CTAB-GAN+: median 12.8 months, HR 0.74, p<0.001; NFlow: median 9.0 months, HR: 0.87, p=0.001). Overall survival (OS) was well represented by NFlow compared to the original cohort, while CTAB-GAN+ showed a significant deviation (original: median 17.5 months, HR: 1.14; CTAB-GAN+: median 19.5 months, HR 0.88, p<0.001; NFlow: median 16.2 months, HR: 1.00, p=0.055). Both models showed an adequate graph representation in Kaplan-Meier analysis (Figure 1). Here, we demonstrate using two different generative AI technologies that synthetic data generation provides an attractive solution to circumvent issues in current standards of data collection and sharing. It effectively allows for bypassing logistical, organizational, and financial burdens, as well as regulatory and ethical concerns. Ultimately, this enables explorative research inquiries into previously inaccessible data sets and offers the prospect of fully synthetic control arms in prospective clinical trials.}
}
@article{SALAH2025100899,
title = {Generative AI and sustainable policy implementation: Expanding UTAUT2 to examine sustainable policy alignment and ambiguity impact on street-level bureaucrats’ discretion},
journal = {Sustainable Futures},
volume = {10},
pages = {100899},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.100899},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825004642},
author = {Mohammed Salah and Alhamzah Alnoor and Fadi Abdelfattah and Khalid Dahleez and Saleh Al Sinawi and Jabbar Salman Hussein and Ahmed Kadim Bareas and Maria Mohd Ismail and Hussam Al Halbusi},
keywords = {Generative Artificial Intelligence (GenAI), Policy implementation, UTAUT2 policy alignment, Ambiguity, Discretion},
abstract = {This study investigates the adoption of Generative Artificial Intelligence (GenAI) by street-level bureaucrats (SLBs) and examines its impact on their discretion in implementing sustainable policies in Iraq and Oman. By extending the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) to include sustainable policy alignment and policy ambiguity as moderating factors, the research explores how these policy elements influence the relationship between GenAI adoption and SLBs’ discretionary actions. Data was collected from 489 SLBs and analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM). The findings demonstrate that performance expectancy, effort expectancy, hedonic motivation, and habit significantly drive the continuous intention to use GenAI. In contrast, social influence and facilitating conditions do not have a significant effect. Furthermore, the continuous intention to use GenAI positively influences SLBs’ discretion in policy implementation, with sustainable policy alignment strengthening this relationship and diminishing policy ambiguity. A multi-group analysis reveals notable differences between Iraq and Oman. In Oman, all UTAUT2 variables are significant, reflecting a supportive and stable governance environment. In contrast, in Iraq, individual perceptions dominate, likely due to higher policy ambiguity and weaker institutional support. These results underscore the importance of emphasizing GenAI’s practical benefits and ease of use and advocate for developing clear, supportive policies that empower SLBs. This study extends the theoretical foundations of UTAUT2 in the public sector, offering practical insights for policymakers and organizations seeking to leverage GenAI for enhanced sustainability outcomes.}
}
@article{XIAO2025118310,
title = {Geometric learning for computational mechanics Part IV: Efficient mesh-based plasticity from a domain-specific foundation model},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {446},
pages = {118310},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118310},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525005821},
author = {Mian Xiao and Jarett Poliner and WaiChing Sun},
keywords = {Plasticity, Mesh, Triangulation, Generative artificial intelligence},
abstract = {Classical plasticity models typically rely on equations to express constitutive behaviors such as yield surfaces and elastic energy. However, deducing these equation-based models requires extensive trial-and-error and strong intuitions. While neural networks may enable the parameterization of material models, they require additional costs for supervised learning and may lead to slower inference. In this paper, we introduce a generative artificial intelligence approach that does not require additional supervised learning to recover the yield surface. Instead, a generative latent diffusion model allows us to deduce yield points with maximum likelihood in the stress space, allowing the model to generalize from sparse or incomplete experimental data. A new projection-based stress update algorithm designed specifically for the mesh-based models enables parallelized integration without the numerical instability or high computational cost of traditional return mapping schemes. Numerical benchmarks–ranging from classical plasticity models to data from discrete dislocation dynamics simulations of single-crystal copper–demonstrate that the proposed framework improves robustness, scalability, and inference accuracy. This work contributes a new class of data-driven plasticity models that are computationally efficient and well-suited for complex, path-dependent material behaviors.}
}
@article{ELYOSEPH2024,
title = {An Ethical Perspective on the Democratization of Mental Health With Generative AI},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/58011},
url = {https://www.sciencedirect.com/science/article/pii/S236879592400115X},
author = {Zohar Elyoseph and Tamar Gur and Yuval Haber and Tomer Simon and Tal Angert and Yuval Navon and Amir Tal and Oren Asman},
keywords = {ethics, generative artificial intelligence, generative AI, mental health, ChatGPT, large language model, LLM, digital mental health, machine learning, AI, technology, accessibility, knowledge, GenAI},
abstract = {Knowledge has become more open and accessible to a large audience with the “democratization of information” facilitated by technology. This paper provides a sociohistorical perspective for the theme issue “Responsible Design, Integration, and Use of Generative AI in Mental Health.” It evaluates ethical considerations in using generative artificial intelligence (GenAI) for the democratization of mental health knowledge and practice. It explores the historical context of democratizing information, transitioning from restricted access to widespread availability due to the internet, open-source movements, and most recently, GenAI technologies such as large language models. The paper highlights why GenAI technologies represent a new phase in the democratization movement, offering unparalleled access to highly advanced technology as well as information. In the realm of mental health, this requires delicate and nuanced ethical deliberation. Including GenAI in mental health may allow, among other things, improved accessibility to mental health care, personalized responses, and conceptual flexibility, and could facilitate a flattening of traditional hierarchies between health care providers and patients. At the same time, it also entails significant risks and challenges that must be carefully addressed. To navigate these complexities, the paper proposes a strategic questionnaire for assessing artificial intelligence–based mental health applications. This tool evaluates both the benefits and the risks, emphasizing the need for a balanced and ethical approach to GenAI integration in mental health. The paper calls for a cautious yet positive approach to GenAI in mental health, advocating for the active engagement of mental health professionals in guiding GenAI development. It emphasizes the importance of ensuring that GenAI advancements are not only technologically sound but also ethically grounded and patient-centered.}
}
@article{OWENS2025,
title = {Evaluating an AI Chatbot “Prostate Cancer Info” for Providing Quality Prostate Cancer Screening Information: Cross-Sectional Study},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/72522},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000606},
author = {Otis L Owens and Michael S Leonard},
keywords = {generative artificial intelligence, chatbot, chatGPT, prostate cancer, cancer screening, shared decision making, artificial intelligence},
abstract = {Background
Generative artificial intelligence (AI) chatbots may be useful tools for supporting shared prostate cancer (PrCA) screening decisions, but the information produced by these tools sometimes lack quality or credibility. “Prostate Cancer Info” is a custom GPT chatbot developed to provide plain-language PrCA information only from websites of key authorities on cancer and peer-reviewed literature.
Objective
The objective of this paper was to evaluate the accuracy, completeness, and readability of Prostate Cancer Info’s responses to frequently asked PrCA screening questions.
Methods
A total of 23 frequently asked PrCA questions were individually input into Prostate Cancer Info. Responses were recorded in Microsoft Word and reviewed by 2 raters for their accuracy and completeness. Readability of content was determined by pasting responses into a web-based Flesch Kincaid Reading Ease Scores calculator.
Results
Responses to all questions were accurate and culturally appropriate. In total, 17 of the 23 questions (74%) had complete responses. The average readability of responses was 64.5 (SD 8.7; written at an 8th-grade level).
Conclusions
Generative AI chatbots, such as Prostate Cancer Info, are great starting places for learning about PrCA screening and preparing men to engage in shared decision-making but should not be used as independent sources of PrCA information because key information may be omitted. Men are encouraged to use these tools to complement information received from a health care provider.}
}
@incollection{GILQUIN2025,
title = {Data-Driven Learning},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00845-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041008450},
author = {Gaëtanelle Gilquin},
keywords = {Corpus-based teaching, Corpus linguistics, Direct DDL, Evaluation of DDL, Expert corpora, Generative artificial intelligence, Indirect DDL, Foreign language learning, Learner corpora, Multimodal corpora, Native corpora, Parallel corpora, Pedagogical practice, Second language acquisition},
abstract = {Data-driven learning (DDL) is a pedagogical approach which involves letting students use corpus data to help them gain knowledge of a target language. In this article, various ways of doing DDL are presented, depending on whether it is carried out in a direct or indirect manner, what corpora are used and what types of searches are performed. Research on the evaluation of DDL is also reported on, as well as future directions, including the place of DDL in relation to generative artificial intelligence.}
}
@article{HANYCZ2025153903,
title = {A practical review of generative AI in cardiac electrophysiology medical education},
journal = {Journal of Electrocardiology},
volume = {90},
pages = {153903},
year = {2025},
issn = {0022-0736},
doi = {https://doi.org/10.1016/j.jelectrocard.2025.153903},
url = {https://www.sciencedirect.com/science/article/pii/S0022073625000317},
author = {Shaun A. Hanycz and Pavel Antiperovitch},
keywords = {Artificial intelligence (AI), Generative adversarial networks (GANs), Surface electrocardiogram (ECG), Medical education},
abstract = {Generative artificial intelligence (AI) is a component of artificial intelligence that creates synthetic multi-modal output in the form of text, images, and audio. Multiple approaches have been implemented into teaching surface ECG interpretation. However, learner performance remains poor. Generative AI in the form of Generative Adversarial Networks (GANs) is a novel AI model that has the potential to augment trainee ECG interpretation via creation of synthetic ECGs and anatomical depiction of conduction defects. Generative AI may be implemented in medical education to customize trainee surface ECG interpretation to improve learning and retention.}
}
@article{WANG2025103888,
title = {Digital resurrection technology in destination promotion},
journal = {Annals of Tourism Research},
volume = {110},
pages = {103888},
year = {2025},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2024.103888},
url = {https://www.sciencedirect.com/science/article/pii/S0160738324001658},
author = {Yuchen Wang and Rui Guo and Mengmeng Song and Rob Law},
keywords = {Generative artificial intelligence, Digital resurrection, Destination word of mouth, Innovation diffusion theory, Character recreation},
abstract = {This study, from a technology acceptance perspective using innovation diffusion theory and a mixed-method approach, explores how digital resurrection technology influences destination word of mouth. Grounded theory and experimental results show: First, for non-serious destinations, adopting digital resurrection technology enhances word of mouth, while for serious destinations, not adopting it leads to better word of mouth. Second, in non-serious destinations, perceived compatibility mediates the positive effect of adoption, while in serious destinations, adoption weakens word of mouth through moral disgust. Third, in non-serious destinations, resurrection image with high appearance realism enhances perceived compatibility, thus improving word of mouth; in serious destinations, low appearance realism evokes greater moral disgust, reducing word of mouth. Fourth, Tourists' openness to experience moderates these mediating effects.}
}