@article{BURKE2024,
title = {Assessing the Ability of a Large Language Model to Score Free-Text Medical Student Clinical Notes: Quantitative Study},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/56342},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000886},
author = {Harry B Burke and Albert Hoang and Joseph O Lopreiato and Heidi King and Paul Hemmer and Michael Montgomery and Viktoria Gagarin},
keywords = {medical education, generative artificial intelligence, natural language processing, ChatGPT, generative pretrained transformer, standardized patients, clinical notes, free-text notes, history and physical examination, large language model, LLM, medical student, medical students, clinical information, artificial intelligence, AI, patients, patient, medicine},
abstract = {Background
Teaching medical students the skills required to acquire, interpret, apply, and communicate clinical information is an integral part of medical education. A crucial aspect of this process involves providing students with feedback regarding the quality of their free-text clinical notes.
Objective
The goal of this study was to assess the ability of ChatGPT 3.5, a large language model, to score medical students’ free-text history and physical notes.
Methods
This is a single-institution, retrospective study. Standardized patients learned a prespecified clinical case and, acting as the patient, interacted with medical students. Each student wrote a free-text history and physical note of their interaction. The students’ notes were scored independently by the standardized patients and ChatGPT using a prespecified scoring rubric that consisted of 85 case elements. The measure of accuracy was percent correct.
Results
The study population consisted of 168 first-year medical students. There was a total of 14,280 scores. The ChatGPT incorrect scoring rate was 1.0%, and the standardized patient incorrect scoring rate was 7.2%. The ChatGPT error rate was 86%, lower than the standardized patient error rate. The ChatGPT mean incorrect scoring rate of 12 (SD 11) was significantly lower than the standardized patient mean incorrect scoring rate of 85 (SD 74; P=.002).
Conclusions
ChatGPT demonstrated a significantly lower error rate compared to standardized patients. This is the first study to assess the ability of a generative pretrained transformer (GPT) program to score medical students’ standardized patient-based free-text clinical notes. It is expected that, in the near future, large language models will provide real-time feedback to practicing physicians regarding their free-text notes. GPT artificial intelligence programs represent an important advance in medical education and medical practice.}
}
@article{LEISER2025,
title = {Large Language Model Architectures in Health Care: Scoping Review of Research Perspectives},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70315},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500843X},
author = {Florian Leiser and Richard Guse and Ali Sunyaev},
keywords = {large language models, scoping review, ChatGPT, generative artificial intelligence, digital health, medical informatics},
abstract = {Background
Large language models (LLMs) can support health care professionals in their daily work, for example, when writing and filing reports or communicating diagnoses. With the rise of LLMs, current research investigates how LLMs could be applied in medical practice and their benefits for physicians in clinical workflows. However, most studies neglect the importance of selecting suitable LLM architectures.
Objective
In this literature review, we aim to provide insights on the different LLM model architecture families (ie, Bidirectional Encoder Representations from Transformers [BERT]–based or generative pretrained transformer [GPT]–based models) used in previous research. We report on the suitability and benefits of different LLM model architecture families for various research foci.
Methods
To this end, we conduct a scoping review to identify which LLMs are used in health care. Our search included manuscripts from PubMed, arXiv, and medRxiv. We used open and selective coding to assess the 114 identified manuscripts regarding 11 dimensions related to usage and technical facets and the research focus of the manuscripts.
Results
We identified 4 research foci that emerged previously in manuscripts, with LLM performance being the main focus. We found that GPT-based models are used for communicative purposes such as examination preparation or patient interaction. In contrast, BERT-based models are used for medical tasks such as knowledge discovery and model improvements.
Conclusions
Our study suggests that GPT-based models are better suited for communicative purposes such as report generation or patient interaction. BERT-based models seem to be better suited for innovative applications such as classification or knowledge discovery. This could be due to the architectural differences where GPT processes language unidirectionally and BERT bidirectionally, allowing more in-depth understanding of the text. In addition, BERT-based models seem to allow more straightforward extensions of their models for domain-specific tasks that generally lead to better results. In summary, health care professionals should consider the benefits and differences of the LLM architecture families when selecting a suitable model for their intended purpose.}
}
@article{CHIARELLO2024103002,
title = {Future applications of generative large language models: A data-driven case study on ChatGPT},
journal = {Technovation},
volume = {133},
pages = {103002},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103002},
url = {https://www.sciencedirect.com/science/article/pii/S016649722400052X},
author = {Filippo Chiarello and Vito Giordano and Irene Spada and Simone Barandoni and Gualtiero Fantoni},
keywords = {Generative artificial intelligence, Generative large language models, ChatGPT, Social media analysis, Technology adoption, Emerging technologies},
abstract = {This study delves into the evolving role of generative Large Language Models (LLMs). We develop a data-driven approach to collect and analyse tasks that users are asking to generative LLMs. Thanks to the focus on tasks this paper contributes to give a quantitative and granular understanding of the potential influence of LLMs in different business areas. Utilizing a dataset comprising over 3.8 million tweets, we identify and cluster 31,747 unique tasks, with a specific case study on ChatGPT. To reach this goal, the proposed method combines two Natural Language Processing (NLP) Techniques, Named Entity Recognition (NER) and BERTopic. The combination makes it possible to collect granular tasks of LLMs (NER) and clusters them in business areas (BERTopic). Our findings reveal a wide spectrum of applications, from programming assistance to creative content generation, highlighting LLM's versatility. The analysis highlighted six emerging areas of application for ChatGPT: human resources, programming, social media, office automation, search engines, education. The study also examines the implications of these findings for innovation management, proposing a research agenda to explore the intersection of the identified areas, with four stages of the innovation process: idea generation, screening/idea selection, development, and diffusion/sales/marketing.}
}
@article{DENG2025103275,
title = {ChatGPT is a comprehensive education tool for patients with patellar tendinopathy, but it currently lacks accuracy and readability},
journal = {Musculoskeletal Science and Practice},
volume = {76},
pages = {103275},
year = {2025},
issn = {2468-7812},
doi = {https://doi.org/10.1016/j.msksp.2025.103275},
url = {https://www.sciencedirect.com/science/article/pii/S2468781225000232},
author = {Jie Deng and Lun Li and Jelle J. Oosterhof and Peter Malliaras and Karin Grävare Silbernagel and Stephan J. Breda and Denise Eygendaal and Edwin HG. Oei and Robert-Jan {de Vos}},
keywords = {Self-management, Communication, Large language models, Patient education},
abstract = {Background
Generative artificial intelligence tools, such as ChatGPT, are becoming increasingly integrated into daily life, and patients might turn to this tool to seek medical information.
Objective
To evaluate the performance of ChatGPT-4 in responding to patient-centered queries for patellar tendinopathy (PT).
Methods
Forty-eight patient-centered queries were collected from online sources, PT patients, and experts and were then submitted to ChatGPT-4. Three board-certified experts independently assessed the accuracy and comprehensiveness of the responses. Readability was measured using the Flesch-Kincaid Grade Level (FKGL: higher scores indicate a higher grade reading level). The Patient Education Materials Assessment Tool (PEMAT) evaluated understandability, and actionability (0–100%, higher scores indicate information with clearer messages and more identifiable actions). Semantic Textual Similarity (STS score, 0–1; higher scores indicate higher similarity) assessed variation in the meaning of texts over two months (including ChatGPT-4o) and for different terminologies related to PT.
Results
Sixteen (33%) of the 48 responses were rated accurate, while 36 (75%) were rated comprehensive. Only 17% of treatment-related questions received accurate responses. Most responses were written at a college reading level (median and interquartile range [IQR] of FKGL score: 15.4 [14.4–16.6]). The median of PEMAT for understandability was 83% (IQR: 70%–92%), and for actionability, it was 60% (IQR: 40%–60%). The medians of STS scores in the meaning of texts over two months and across terminologies were all ≥ 0.9.
Conclusions
ChatGPT-4 provided generally comprehensive information in response to patient-centered queries but lacked accuracy and was difficult to read for individuals below a college reading level.}
}
@article{DWIVEDI2023102642,
title = {Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
journal = {International Journal of Information Management},
volume = {71},
pages = {102642},
year = {2023},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102642},
url = {https://www.sciencedirect.com/science/article/pii/S0268401223000233},
author = {Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright},
keywords = {Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models},
abstract = {Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.}
}
@article{TAO2025112683,
title = {An outline of Prognostics and health management Large Model: Concepts, Paradigms, and challenges},
journal = {Mechanical Systems and Signal Processing},
volume = {232},
pages = {112683},
year = {2025},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2025.112683},
url = {https://www.sciencedirect.com/science/article/pii/S088832702500384X},
author = {Laifa Tao and Shangyu Li and Haifei Liu and Qixuan Huang and Liang Ma and Guoao Ning and Yiling Chen and Yunlong Wu and Bin Li and Weiwei Zhang and Zhengduo Zhao and Wenchao Zhan and Wenyan Cao and Chao Wang and Hongmei Liu and Jian Ma and Mingliang Suo and Yujie Cheng and Yu Ding and Dengwei Song and Chen Lu},
keywords = {Large model (LM), Large language model (LLM), Prognosis and health management (PHM), Fault diagnosis, Prediction, State assessment},
abstract = {Prognosis and Health Management (PHM), critical for preventing unexpected failures and ensuring task completion of complex systems, is widely adopted in the fields of aviation, aerospace, manufacturing, rail transportation, energy, etc. However, PHM’s developments and applications have been seriously constrained by bottlenecks like generalization, interpretation and verification abilities. Large Model (LM), a typical and powerful representation of generative artificial intelligence (AI), heralds a technological revolution with the potential to fundamentally reshape traditional technological fields. Its strong generalization and reasoning capabilities present opportunities to address those PHM’s bottlenecks existing. To this end, by systematically analyzing the current challenges and bottlenecks in PHM, as well as the advantages of Large Model, we propose a novel concept and corresponding three typical paradigms of PHM Large Model (PHM-LM) by the combination of the Large Model with PHM. Additionally, couples of feasible technical approaches for PHM-LM within the framework of the three paradigms are provided to address core issues confronting PHM and to bolster PHM’s core capabilities. Moreover, a series of technical challenges throughout the entire construction and application process of PHM-LM have been deeply discussed for further research recommendation. The comprehensive effort herein offers a comprehensive PHM-LM technical framework, and provides avenues for new methodologies, new technologies, new tools, new platforms and applications of PHM, which also potentially innovates design mode, research & development mode, verification and application mode of PHM, i.e., from traditional customization to generalization, from discriminative approaches to generative methods, and from idealized conditions to practical applications.}
}
@article{CAI2023141,
title = {Performance of Generative Large Language Models on Ophthalmology Board–Style Questions},
journal = {American Journal of Ophthalmology},
volume = {254},
pages = {141-149},
year = {2023},
issn = {0002-9394},
doi = {https://doi.org/10.1016/j.ajo.2023.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0002939423002301},
author = {Louis Z. Cai and Abdulla Shaheen and Andrew Jin and Riya Fukui and Jonathan S. Yi and Nicolas Yannuzzi and Chrisfouad Alabiad},
abstract = {PURPOSE
To investigate the ability of generative artificial intelligence models to answer ophthalmology board–style questions.
DESIGN
Experimental study.
METHODS
This study evaluated 3 large language models (LLMs) with chat interfaces, Bing Chat (Microsoft) and ChatGPT 3.5 and 4.0 (OpenAI), using 250 questions from the Basic Science and Clinical Science Self-Assessment Program. Although ChatGPT is trained on information last updated in 2021, Bing Chat incorporates a more recently indexed internet search to generate its answers. Performance was compared with human respondents. Questions were categorized by complexity and patient care phase, and instances of information fabrication or nonlogical reasoning were documented.
MAIN OUTCOME MEASURES
Primary outcome was response accuracy. Secondary outcomes were performance in question subcategories and hallucination frequency.
RESULTS
Human respondents had an average accuracy of 72.2%. ChatGPT-3.5 scored the lowest (58.8%), whereas ChatGPT-4.0 (71.6%) and Bing Chat (71.2%) performed comparably. ChatGPT-4.0 excelled in workup-type questions (odds ratio [OR], 3.89, 95% CI, 1.19-14.73, P = .03) compared with diagnostic questions, but struggled with image interpretation (OR, 0.14, 95% CI, 0.05-0.33, P < .01) when compared with single-step reasoning questions. Against single-step questions, Bing Chat also faced difficulties with image interpretation (OR, 0.18, 95% CI, 0.08-0.44, P < .01) and multi-step reasoning (OR, 0.30, 95% CI, 0.11-0.84, P = .02). ChatGPT-3.5 had the highest rate of hallucinations and nonlogical reasoning (42.4%), followed by ChatGPT-4.0 (18.0%) and Bing Chat (25.6%).
CONCLUSIONS
LLMs (particularly ChatGPT-4.0 and Bing Chat) can perform similarly with human respondents answering questions from the Basic Science and Clinical Science Self-Assessment Program. The frequency of hallucinations and nonlogical reasoning suggests room for improvement in the performance of conversational agents in the medical domain.}
}
@article{MARTIN2025,
title = {Prevalence of artificial intelligence use and instruction in nursing education: A national study of prelicensure nursing programs in the United States},
journal = {Journal of Nursing Regulation},
year = {2025},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000924},
author = {Brendan Martin and Michaela Reid},
keywords = {Prelicensure nursing education, Artificial intelligence},
abstract = {Background
There is ample evidence that the integration of artificial intelligence (AI) tools into nursing practice is becoming more commonplace, but there are fewer national resources indicating to what degree prelicensure nursing programs employ these technologies and incorporate related topics into their curriculum.
Purpose
The current survey study sought to determine the prevalence of registered nurse (RN) and licensed practical nurse (LPN) education programs’ use of generative AI technologies, and the extent to which they embed AI and other digital health topics into their instructional content.
Methods
A national survey was conducted of all RN and LPN program administrators nationwide for which we had email contact information (N = 2744).
Results
Prelicensure RN programs (n = 122, 24 %) were more likely to use generative AI technology than LPN programs (n = 27, 12 %, p < 0.001), but more than three-quarters of both types of programs reported they do not use such tools or are not sure. In addition to the low usage of generative AI technology, few programs reported teaching advancements in AI and/or other digital health–related topics to their students (RN n = 87, 17 %; LPN n = 25, 11 %).
Conclusion
Nursing education programs that limit integration of AI into their curriculum risk potentially limiting students’ learning on evidence-based practice and may miss opportunities to promote critical reflection. The results of our study underscore the need to support nursing faculty to ensure prelicensure instructional content prepares nursing students for advancements in clinical practice.}
}
@article{JIANG2024105286,
title = {Automated site planning using CAIN-GAN model},
journal = {Automation in Construction},
volume = {159},
pages = {105286},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105286},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524000220},
author = {Feifeng Jiang and Jun Ma and Christopher John Webster and Wei Wang and Jack C.P. Cheng},
keywords = {Automated site planning, Generative design, Generative adversarial networks (GAN), Attention mechanism, Generative artificial intelligence (generative AI), Planning guidance},
abstract = {Automated site planning, powered by deep generative methods, excels in creating solutions responsive to exiting city structures but often overlooks user-specific design scenarios, leading to less performative solutions across varied urban contexts. Overcoming this challenge requires integrating domain knowledge and nuances of the built environment to enhance context-awareness in automated site planning. This study therefore proposes the context-aware site planning generative adversarial networks (CAIN-GAN) framework. In the case study of New York City (NYC), CAIN-GAN demonstrates its capability to not only synthesize visually realistic and semantically reasonable design solutions, but also evaluate their performance in urban sustainability for informed decision-making. This context-aware, learning-based, data-driven, and user-guided generation process signifies a pivotal advancement in more performative and tailored design solutions. Future studies will focus on refining the CAIN-GAN framework to accommodate diverse user-centric design needs and enhance human-machine interaction in urban development.}
}
@article{KESSEL2024111971,
title = {Promoting open science in test-driven software experiments},
journal = {Journal of Systems and Software},
volume = {212},
pages = {111971},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.111971},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000141},
author = {Marcus Kessel and Colin Atkinson},
keywords = {Software, Engineering, Empirical, Experimentation, Observation, Behavior, Reproducibility, Replication, Data structures, Open science, Large language models, Machine learning, Generative artificial intelligence, Benchmark, Language-to-code, HumanEval, Automation, Measurement},
abstract = {A core principle of open science is the clear, concise and accessible publication of empirical data, including “raw” observational data as well as processed results. However, in empirical software engineering there are no established standards (de jure or de facto) for representing and “opening” observations collected in test-driven software experiments — that is, experiments involving the execution of software subjects in controlled scenarios. Execution data is therefore usually represented in ad hoc ways, often making it abstruse and difficult to access without significant manual effort. In this paper we present new data structures designed to address this problem by clearly defining, correlating and representing the stimuli and responses used to execute software subjects in test-driven experiments. To demonstrate their utility, we show how they can be used to promote the repetition, replication and reproduction of experimental evaluations of AI-based code completion tools. We also show how the proposed data structures facilitate the incremental expansion of execution data sets, and thus promote their repurposing for new experiments addressing new research questions.}
}
@article{AHMED2026103527,
title = {From data to diagnosis: AI-driven multi-modal fusion and generative AI-enhanced GAN-based MRI for brain tumour detection},
journal = {Information Fusion},
volume = {126},
pages = {103527},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103527},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525005998},
author = {Imran Ahmed and Misbah Ahmad and Abdellah Chehri and Gwanggil Jeon},
keywords = {Brain tumour, Generative artificial intelligence, Generative Adversarial Networks (GANs), Self-supervised learning (SSL), Synthetic medical images},
abstract = {Brain tumour is one of the most significant challenges in medical imaging, where early and accurate detection is crucial for improving patient outcomes. However, the lack of labelled Magnetic Resonance Imaging (MRI) data severely limits the development of reliable diagnostic methods, resulting in issues such as class imbalance and reduced accuracy. This study addresses these challenges by leveraging Self-Supervised Learning (SSL) and Generative Adversarial Networks (GANs) to generate synthetic MRI images. We present a dual-enhancement pipeline with domain-specific innovations, combining contrastive SSL pretraining with GAN-augmented data to improve brain tumour classification. Our GAN architecture features medical-specific normalization layers, tumour-focused conditioning, and loss stabilization techniques to enhance the quality of synthesis. The SSL component employs domain-adapted, tumour-preserving augmentations and tailored pretext tasks (e.g., spatial context prediction) to ensure semantically meaningful representations. Experimental results demonstrate the effectiveness of the proposed approach, showing an improvement in diagnostic precision. Additionally, the Fréchet Inception Distance (FID) score indicates that the synthetic images exhibit a high degree of similarity to real MRI scans. These findings highlight the transformative potential of SSL techniques in mitigating the limitations associated with the lack of labelled medical data. Furthermore, the integration of Generative AI (GenAI) within multi-source (rather than multimodal) data fusion frameworks represents a significant advancement in medical imaging. By synthesizing and harmonizing diverse data sources, GenAI enhances information aggregation, which is particularly valuable in healthcare applications. Case studies and practical implementations demonstrate how GenAI-powered fusion methods enhance diagnostic accuracy; support improved patient monitoring, facilitate timely interventions, and enable more effective clinical decision-making. To support clinical integration, we incorporate explainable AI (XAI) methods to ensure transparency and interpretability, enabling rapid and informed decision-making in brain tumour detection. This research positions SSL and GenAI not merely as engineering tools but as essential enablers of data-efficient and precision-driven healthcare.}
}
@incollection{GONZALEZANTA2026346,
title = {Digitalization},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {346-352},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00069-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013000694},
author = {Baltasar González-Anta},
keywords = {AIlization, AI-lization, AIzation, Artificial intelligence (AI), Automation, Digital competences, Digital transformation, Digitalization, Digitalized competences, Digitization, Fourth industrial revolution., Knowledge economy, Remote work, Robotization, Telework},
abstract = {Digitalization is transforming society and organizations in the knowledge economy. This chapter provides a comprehensive overview of digitalization and related concepts in Business Management. We first define key terms such as digitalization, digitization, digital transformation, and mention specific contexts in which digitalization can be implemented. We then adopt a sociotechnical approach to analyze opportunities and challenges of digitalization, considering organizational adaptability and work competences as central elements. In particular, we highlight the growing relevance of digital and digitalized competences to leverage technology while mitigating potential negative outcomes. Looking ahead, we reflect on the impact of Generative AI and the “AI-lization”, and how this can augment yet also potentially displace human capabilities. We conclude by summarizing key insights and identifying areas for future research on sustainable digitalization that promotes synergistic human-technology collaboration. The chapter offers an integrative analysis of technological and social factors to advance the understanding of digitalization in contemporary business.}
}
@article{CHAN2024101395,
title = {Will generative AI replace teachers in higher education? A study of teacher and student perceptions},
journal = {Studies in Educational Evaluation},
volume = {83},
pages = {101395},
year = {2024},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2024.101395},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X24000749},
author = {Cecilia Ka Yuk Chan and Louisa H.Y. Tsi},
keywords = {ChatGPT, Generative AI, AI Literacy, Social-emotional competencies, Holistic competencies},
abstract = {This paper evaluates the potential of generative artificial intelligence (AI) in higher education, specifically its capacity to replace or assist human teachers. By reviewing relevant literature and analysing survey data from students and teachers, this mixed-methods study provides a comprehensive perspective on the future role of educators in the face of advancing generative AI technologies. An online survey was conducted to explore the perceptions of 399 university students and 184 teachers across different disciplines in eight higher education institutions in Hong Kong concerning the use of generative AI technologies. Findings suggest that although some believed generative AI may eventually replace teachers, the majority of participants argued that human teachers possess unique qualities, including critical thinking and emotions, which make them irreplaceable. Similarly, findings also emphasized the importance of social-emotional competencies developed through human interactions, something which generative AI technologies cannot currently replicate. Crucially, this study further found that students value and respect their human teachers, even as generative AI becomes more prevalent. As such, the authors propose that teachers can seek to effectively integrate generative AI to enhance teaching and learning without viewing it as their replacement. To do so, they must understand how generative AI can work well with teachers and students, avoid potential pitfalls, develop AI literacy, and address practical issues including ethics and privacy. Recommendations are offered on how universities, teachers, and students can adopt generative AI technologies in an approach that balances the strengths of human educators with generative AI technologies. As the future of education lies in the synergy between human teachers and generative AI, teachers, students, and universities should all understand and refine their unique qualities in order to effectively navigate the integration of generative AI, ensuring well-rounded and impactful learning experiences.}
}
@article{ARSLAN2025174,
title = {Evaluating LLM-based generative AI tools in emergency triage: A comparative study of ChatGPT Plus, Copilot Pro, and triage nurses},
journal = {The American Journal of Emergency Medicine},
volume = {89},
pages = {174-181},
year = {2025},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2024.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S0735675724007071},
author = {B. Arslan and C. Nuhoglu and M.O. Satici and E. Altinbilek},
keywords = {ChatGPT, Copilot, Triage, Emergency medicine, Emergency severity index, Large language models, Generative artificial intelligence},
abstract = {Background
The number of emergency department (ED) visits has been on steady increase globally. Artificial Intelligence (AI) technologies, including Large Language Model (LLMs)-based generative AI models, have shown promise in improving triage accuracy. This study evaluates the performance of ChatGPT and Copilot in triage at a high-volume urban hospital, hypothesizing that these tools can match trained physicians' accuracy and reduce human bias amidst ED crowding challenges.
Methods
This single-center, prospective observational study was conducted in an urban ED over one week. Adult patients were enrolled through random 24-h intervals. Exclusions included minors, trauma cases, and incomplete data. Triage nurses assessed patients while an emergency medicine (EM) physician documented clinical vignettes and assigned emergency severity index (ESI) levels. These vignettes were then introduced to ChatGPT and Copilot for comparison with the triage nurse's decision.
Results
The overall triage accuracy was 65.2 % for nurses, 66.5 % for ChatGPT, and 61.8 % for Copilot, with no significant difference (p = 0.000). Moderate agreement was observed between the EM physician and ChatGPT, triage nurses, and Copilot (Cohen's Kappa = 0.537, 0.477, and 0.472, respectively). In recognizing high-acuity patients, ChatGPT and Copilot outperformed triage nurses (87.8 % and 85.7 % versus 32.7 %, respectively). Compared to ChatGPT and Copilot, nurses significantly under-triaged patients (p < 0.05). The analysis of predictive performance for ChatGPT, Copilot, and triage nurses demonstrated varying discrimination abilities across ESI levels, all of which were statistically significant (p < 0.05). ChatGPT and Copilot exhibited consistent accuracy across age, gender, and admission time, whereas triage nurses were more likely to mistriage patients under 45 years old.
Conclusion
ChatGPT and Copilot outperform traditional nurse triage in identifying high-acuity patients, but real-time ED capacity data is crucial to prevent overcrowding and ensure high-quality of emergency care.}
}
@article{SHIN2025111393,
title = {Subthalamic nucleus or globus pallidus internus deep brain stimulation for the treatment of parkinson’s disease: An artificial intelligence approach},
journal = {Journal of Clinical Neuroscience},
volume = {138},
pages = {111393},
year = {2025},
issn = {0967-5868},
doi = {https://doi.org/10.1016/j.jocn.2025.111393},
url = {https://www.sciencedirect.com/science/article/pii/S0967586825003662},
author = {David Shin and Timothy Tang and Joel Carson and Rekha Isaac and Chandler Dinh and Daniel Im and Andrew Fay and Asael Isaac and Stephen Cho and Zachary Brandt and Kai Nguyen and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Samantha Spellicy and Miguel Angel Lopez-Gonzalez and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Deep brain stimulation, Neurosurgery, Parkinson’s disease},
abstract = {Background
Generative artificial intelligence (AI) in deep brain stimulation (DBS) is currently unvalidated in its content. This study sought to analyze AI responses to questions and recommendations from the 2018 Congress of Neurological Surgeons (CNS) guidelines on subthalamic nucleus and globus pallidus internus DBS for the treatment of patients with Parkinson’s Disease.
Methods
Seven questions were generated from CNS guidelines and asked to ChatGPT 4o, Perplexity, Copilot, and Gemini. Answers were “concordant” if they highlighted all points provided by the CNS guidelines; otherwise, answers were considered “non-concordant” and sub-categorized as either “insufficient” or “overconclusive.” AI responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, Simple Measure of Gobbledygook (SMOG) Index, and Flesch Reading Ease tests.
Results
ChatGPT 4o showcased 42.9% concordance, with non-concordant responses classified as 14.3% insufficient and 42.8% over-conclusive. Perplexity displayed a 28.6% concordance rate, with 14.3% insufficient and 57.1% over-conclusive responses. Copilot showed 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. Gemini demonstrated 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. The Flesch-Kincaid Grade Level scores ranged from 14.44 (Gemini) to 18.94 (Copilot), Gunning Fog Index scores varied between 17.9 (Gemini) and 22.06 (Copilot), SMOG Index scores ranged from 16.54 (Gemini) to 19.67 (Copilot), and all Flesch Reading Ease scores were low, with Gemini showing the highest score of 30.91.
Conclusion
ChatGPT 4o displayed the most concordance, Perplexity displayed the highest over-conclusive rate, and Copilot and Gemini showcased the most insufficient answers. All responses showcased complex readability. Despite the possible benefits of future developments and innovation in AI capabilities, AI requires further improvement before independent clinical usage in DBS.}
}
@article{KE2024,
title = {Mitigating Cognitive Biases in Clinical Decision-Making Through Multi-Agent Conversations Using Large Language Models: Simulation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/59439},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124008124},
author = {Yuhe Ke and Rui Yang and Sui An Lie and Taylor Xin Yi Lim and Yilin Ning and Irene Li and Hairil Rizal Abdullah and Daniel Shu Wei Ting and Nan Liu},
keywords = {clinical decision-making, cognitive bias, generative artificial intelligence, large language model, multi-agent},
abstract = {Background
Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field.
Objective
This study aimed to explore the role of large language models (LLMs) in mitigating these biases through the use of the multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy compared with humans.
Methods
A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent framework, we leveraged GPT-4 (OpenAI) to facilitate interactions among different simulated agents to replicate clinical team dynamics. Each agent was assigned a distinct role: (1) making the final diagnosis after considering the discussions, (2) acting as a devil’s advocate to correct confirmation and anchoring biases, (3) serving as a field expert in the required medical subspecialty, (4) facilitating discussions to mitigate premature closure bias, and (5) recording and summarizing findings. We tested varying combinations of these agents within the framework to determine which configuration yielded the highest rate of correct final diagnoses. Each scenario was repeated 5 times for consistency. The accuracy of the initial diagnoses and the final differential diagnoses were evaluated, and comparisons with human-generated answers were made using the Fisher exact test.
Results
A total of 240 responses were evaluated (3 different multi-agent frameworks). The initial diagnosis had an accuracy of 0% (0/80). However, following multi-agent discussions, the accuracy for the top 2 differential diagnoses increased to 76% (61/80) for the best-performing multi-agent framework (Framework 4-C). This was significantly higher compared with the accuracy achieved by human evaluators (odds ratio 3.49; P=.002).
Conclusions
The multi-agent framework demonstrated an ability to re-evaluate and correct misconceptions, even in scenarios with misleading initial investigations. In addition, the LLM-driven, multi-agent conversation framework shows promise in enhancing diagnostic accuracy in diagnostically challenging medical scenarios.}
}
@article{LI2026103665,
title = {SearchExpert: A GenAI-driven framework for reasoning-intensive multimedia information fusion through fine-tuning and reinforcement learning},
journal = {Information Fusion},
volume = {126},
pages = {103665},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103665},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525007377},
author = {Jinzheng Li and Yiqing Shen and Wei Zhou and Hui Chen},
keywords = {Large language models, Complex reasoning, Multimodal search, Reinforcement learning, DAG planning, Vision-language models},
abstract = {The rapid advancement of Generative Artificial Intelligence (GenAI) has opened new frontiers in multimodal information fusion, yet current large language model (LLM)-driven search agents remain limited in their ability to handle reasoning-intensive queries and integrate multimedia data effectively. In this paper, we propose SearchExpert, a GenAI-enhanced framework that augments LLMs with powerful multimedia search and reasoning capabilities via a novel two-stage training paradigm. First, we introduce an efficient natural language representation for directed acyclic graph (DAG)-based search plans to reduce token overhead and support structured reasoning. We then propose Supervised Fine-Tuning for Searching (SFTS), enabled by an automated data construction pipeline that adapts LLMs to generate token-efficient, structured search plans from complex queries. Second, to further enhance reasoning ability, we introduce Reinforcement Learning from Search Feedback (RLSF), which uses reward signals based on semantic alignment and intrinsic quality assessments of retrieved results to optimize LLM behavior. To address the limitations of unimodal input and output, we integrate a multimedia understanding and generation module based on vision-language models and image synthesis tools (e.g., BLIP-2, and DALLE-3), enabling the GenAI-based fusion of text and visual data. We also establish SearchExpertBench-25, a benchmark comprising 200 multimedia-rich, reasoning-intensive queries spanning financial and global news domains, accompanied by a rigorous human evaluation framework. Experimental results demonstrate that SearchExpert surpasses state-of-the-art baselines such as FinSearch and Perplexity Pro, achieving up to 71.5% accuracy on complex benchmark tasks while reducing token consumption by over 40%. Human evaluations further highlight improvements in completeness, analytical integrity, and multimodal fluency. This work presents a scalable and generalizable GenAI framework for information fusion, with implications for real-time decision-making in complex, multi-source environments. The code is available at https://anonymous.4open.science/r/SearchExpert-2343/.}
}
@article{MGADZAH2025,
title = {Enhancing Diagnostic Accuracy of Ophthalmological Conditions With Complex Prompts in GPT-4: Comparative Analysis of Global and Low- and Middle-Income Country (LMIC)–Specific Pathologies},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/64986},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25004445},
author = {Shona Alex Tapiwa M'gadzah and Andrew O'Malley},
keywords = {artificial intelligence, AI, ophthalmology, clinical diagnostics, medical technology, data project, complex prompt, diagnostic accuracy, ophthalmological conditions, ophthalmological disorder, eyes, blindness, low- and middle-income countries, LMIC, low-income or middle-income economies, health care, LLMs, NLP, machine learning, statistical analysis, GPT-4},
abstract = {Background
The global incidence of blindness has continued to increase, despite the enactment of a Global Eye Health Action Plan by the World Health Assembly. This can be attributed, in part, to an aging population, but also to the limited diagnostic resources within low- and middle-income countries (LMICs). The advent of generative artificial intelligence (AI) within health care could pose a novel solution to combating the prevalence of blindness globally.
Objective
The objectives of this study are to quantify the effect the addition of a complex prompt has on the diagnostic accuracy of a commercially available LLM, and to assess whether such LLMs are better or worse at diagnosing conditions that are more prevalent in LMICs.
Methods
Ten clinical vignettes representing globally and LMIC-prevalent ophthalmological conditions were presented to GPT-4‐0125-preview using simple and complex prompts. Diagnostic performance metrics, including sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were calculated. Statistical comparison between prompts was conducted using a chi-square test of independence.
Results
The complex prompt achieved a higher diagnostic accuracy (90.1%) compared to the simple prompt (60.4%), with a statistically significant difference (χ2=428.86; P<.001). Sensitivity, specificity, PPV, and NPV were consistently improved for most conditions with the complex prompt. The simple prompt struggled with LMIC-prevalent conditions, diagnosing only 1 of 5 accurately, while the complex prompt successfully diagnosed 4 of 5.
Conclusions
The study established that overall, the inclusion of a complex prompt positively affected the diagnostic accuracy of GPT-4‐0125-preview, particularly for LMIC-prevalent conditions. This highlights the potential for LLMs, when appropriately tailored, to support clinicians in diverse health care settings. Future research should explore the generalizability of these findings across other models and specialties.}
}
@article{CRAWFORD2024504,
title = {Digital Ink and Surgical Dreams: Perceptions of Artificial Intelligence–Generated Essays in Residency Applications},
journal = {Journal of Surgical Research},
volume = {301},
pages = {504-511},
year = {2024},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S002248042400355X},
author = {Loralai M. Crawford and Peter Hendzlik and Justine Lam and Lisa M. Cannon and Yanjie Qi and Lauren DeCaporale-Ryan and Nicole A. Wilson},
keywords = {Ethics, Generative artificial intelligence, Large language model, Surgical education},
abstract = {Introduction
Large language models like Chat Generative Pre-Trained Transformer (ChatGPT) are increasingly used in academic writing. Faculty may consider use of artificial intelligence (AI)–generated responses a form of cheating. We sought to determine whether general surgery residency faculty could detect AI versus human-written responses to a text prompt; hypothesizing that faculty would not be able to reliably differentiate AI versus human-written responses.
Methods
Ten essays were generated using a text prompt, “Tell us in 1-2 paragraphs why you are considering the University of Rochester for General Surgery residency” (Current trainees: n = 5, ChatGPT: n = 5). Ten blinded faculty reviewers rated essays (ten-point Likert scale) on the following criteria: desire to interview, relevance to the general surgery residency, overall impression, and AI- or human-generated; with scores and identification error rates compared between the groups.
Results
There were no differences between groups for %total points (ChatGPT 66.0 ± 13.5%, human 70.0 ± 23.0%, P = 0.508) or identification error rates (ChatGPT 40.0 ± 35.0%, human 20.0 ± 30.0%, P = 0.175). Except for one, all essays were identified incorrectly by at least two reviewers. Essays identified as human-generated received higher overall impression scores (area under the curve: 0.82 ± 0.04, P < 0.01).
Conclusions
Whether use of AI tools for academic purposes should constitute academic dishonesty is controversial. We demonstrate that human and AI-generated essays are similar in quality, but there is bias against presumed AI-generated essays. Faculty are not able to reliably differentiate human from AI-generated essays, thus bias may be misdirected. AI-tools are becoming ubiquitous and their use is not easily detected. Faculty must expect these tools to play increasing roles in medical education.}
}
@article{CHEN2025112891,
title = {Can large language models replace human experts? Effectiveness and limitations in building energy retrofit challenges assessment},
journal = {Building and Environment},
volume = {276},
pages = {112891},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112891},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325003737},
author = {Linyan Chen and Amos Darko and Fan Zhang and Albert P.C. Chan and Qiang Yang},
keywords = {Large language model, Building energy retrofit, Challenges assessment, Prompt engineering, Generative artificial intelligence},
abstract = {Retrofitting existing buildings is essential to improve energy efficiency and achieve carbon neutrality in the fight against global climate change. Large language models (LLMs) have recently attracted significant attention for their ability to process data efficiently. While LLMs have emerged as useful tools for various tasks, their potential to replace human experts in assessing building energy retrofit challenges remains unexplored. This research explores the potential of replacing human experts with LLMs by evaluating four mainstream LLM chatbots and comparing their performance against a human expert benchmark through semantic similarity and text correlation metrics. It answers the research question: can LLMs replace human experts in assessing the challenges to building energy retrofits? Prompt engineering techniques, including zero-shot and chain-of-thought (CoT) prompting, were employed to guide LLM responses. Results show that LLMs perform well in identifying challenges but are less reliable in ranking them. CoT prompting improves challenge ranking accuracy but does not enhance challenge identification. Incorporating domain-specific knowledge in prompts significantly enhances LLM performance, whereas prompts designed to simulate experts have notable limitations in improving LLM performance. Furthermore, there are no significant performance differences among LLMs, including their advanced versions. While LLMs can streamline the initial identification of building energy retrofit challenges, they cannot fully replace expert judgment in ranking challenges due to their lack of tacit knowledge. This research provides valuable insight into the capabilities and limitations of LLMs in the challenge assessment, offering practical guidance for industry practitioners seeking to integrate LLMs into their building energy efficiency practices.}
}
@article{AYOUB2024186,
title = {Inherent Bias in Large Language Models: A Random Sampling Analysis},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {2},
number = {2},
pages = {186-191},
year = {2024},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949761224000208},
author = {Noel F. Ayoub and Karthik Balakrishnan and Marc S. Ayoub and Thomas F. Barrett and Abel P. David and Stacey T. Gray},
abstract = {There are mounting concerns regarding inherent bias, safety, and tendency toward misinformation of large language models (LLMs), which could have significant implications in health care. This study sought to determine whether generative artificial intelligence (AI)-based simulations of physicians making life-and-death decisions in a resource-scarce environment would demonstrate bias. Thirteen questions were developed that simulated physicians treating patients in resource-limited environments. Through a random sampling of simulated physicians using OpenAI’s generative pretrained transformer (GPT-4), physicians were tasked with choosing only 1 patient to save owing to limited resources. This simulation was repeated 1000 times per question, representing 1000 unique physicians and patients each. Patients and physicians spanned a variety of demographic characteristics. All patients had similar a priori likelihood of surviving the acute illness. Overall, simulated physicians consistently demonstrated racial, gender, age, political affiliation, and sexual orientation bias in clinical decision-making. Across all demographic characteristics, physicians most frequently favored patients with similar demographic characteristics as themselves, with most pairwise comparisons showing statistical significance (P<.05). Nondescript physicians favored White, male, and young demographic characteristics. The male doctor gravitated toward the male, White, and young, whereas the female doctor typically preferred female, young, and White patients. In addition to saving patients with their own political affiliation, Democratic physicians favored Black and female patients, whereas Republicans preferred White and male demographic characteristics. Heterosexual and gay/lesbian physicians frequently saved patients of similar sexual orientation. Overall, publicly available chatbot LLMs demonstrate significant biases, which may negatively impact patient outcomes if used to support clinical care decisions without appropriate precautions.}
}
@article{MATHIS2024108356,
title = {Inductive thematic analysis of healthcare qualitative interviews using open-source large language models: How does it compare to traditional methods?},
journal = {Computer Methods and Programs in Biomedicine},
volume = {255},
pages = {108356},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108356},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003493},
author = {Walter S Mathis and Sophia Zhao and Nicholas Pratt and Jeremy Weleff and Stefano {De Paoli}},
keywords = {Artificial intelligence, Large language models, Qualitative methods, Thematic analysis, Mental health},
abstract = {Background
Large language models (LLMs) are generative artificial intelligence that have ignited much interest and discussion about their utility in clinical and research settings. Despite this interest there is sparse analysis of their use in qualitative thematic analysis comparing their current ability to that of human coding and analysis. In addition, there has been no published analysis of their use in real-world, protected health information.
Objective
Here we fill that gap in the literature by comparing an LLM to standard human thematic analysis in real-world, semi-structured interviews of both patients and clinicians within a psychiatric setting.
Methods
Using a 70 billion parameter open-source LLM running on local hardware and advanced prompt engineering techniques, we produced themes that summarized a full corpus of interviews in minutes. Subsequently we used three different evaluation methods for quantifying similarity between themes produced by the LLM and those produced by humans.
Results
These revealed similarities ranging from moderate to substantial (Jaccard similarity coefficients 0.44–0.69), which are promising preliminary results.
Conclusion
Our study demonstrates that open-source LLMs can effectively generate robust themes from qualitative data, achieving substantial similarity to human-generated themes. The validation of LLMs in thematic analysis, coupled with evaluation methodologies, highlights their potential to enhance and democratize qualitative research across diverse fields.}
}
@article{RIGAS2025S-318,
title = {1300: AN AUTONOMOUS, AI-ENHANCED, PALM-SIZE, HAND-HELD BREATHALYZER DEVICE FOR POINT-OF-CARE AND HOME SELF-TESTING AND A NATURAL UREA BREATH TEST (UBT) DETECTING H. PYLORI INFECTION WITH 100% SENSITIVITY AND 100% SPECIFICITY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01678-6},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016786},
author = {Anastasia Rigas}
}
@article{GERMANMORALES2025103247,
title = {Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations},
journal = {Information Fusion},
volume = {123},
pages = {103247},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103247},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525003203},
author = {M. Germán-Morales and A.J. Rivera-Rivas and M.J. {del Jesus Díaz} and C.J. Carmona},
keywords = {Time series forecasting, Transfer Learning, Foundational Models, Large Language Models, Low-rank Adaptations},
abstract = {Foundational Models are an emerging widely used technique of Generative Artificial Intelligence. These models are distinguished by their scalability and the ease with which they can be adapted through the exploitation of Transfer Learning. The availability of high computational power and large datasets have supported their development, achieving a high generalization capacity due to the enormous and heterogeneous amounts of data used in their initial training. These characteristics contribute to a solid base that can be adapted or adjusted to a wide range of tasks, increasing their applicability. This study proposes the methodology LLIAM, a straightforward adaptation of a kind of Foundational Models, Large Language Models, for the Time Series Forecasting task. An adequate time-series prompting schema and Low-Rank Adaptations are used to enhance the knowledge of the model with diverse time series datasets, known as the fine-tuning phase. A study divided in two stages has been performed for evaluating the effectiveness of the proposed methodology. Initially, a comparison was made between the performance of LLIAM and different state-of-the-art Deep Learning algorithms, including Recurrent Neural Networks and Temporal Convolutional Networks, as well as a LLM-based method, TimeLLM. Following this, a zero-shot study is presented in order to evaluate the generalization capacity of the proposed methodology with time series datasets from unknown domains not considered in the model training. The outcomes of this investigation demonstrate the efficacy of LLIAM, highlighting that this straightforward and general approach can attain competent results without the necessity for applying complex modifications. This work also encourages the use of available resources (such as these pre-trained models) and efficient fine-tuning techniques to avoid unnecessary and costly training, narrowing the gap between the goals of traditional Artificial Intelligence and Green Artificial Intelligence.}
}
@article{DENG2025110123,
title = {Weed image augmentation by ControlNet-added stable diffusion for multi-class weed detection},
journal = {Computers and Electronics in Agriculture},
volume = {232},
pages = {110123},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110123},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925002297},
author = {Boyang Deng and Yuzhen Lu},
keywords = {Deep Learning, Generative Modeling, Stable Diffusion, Precision Agriculture, Weed Detection},
abstract = {Robust weed recognition for vision-guided weeding relies on curating large-scale, diverse field datasets, which however are practically difficult to come by. Text-to-image generative artificial intelligence opens new avenues for synthesizing perceptually realistic images beneficial for wide-ranging computer vision tasks in precision agriculture. This study investigates the efficacy of state-of-the-art diffusion models as an image augmentation technique for synthesizing multi-class weed images towards enhanced weed detection performance. A three-season 10-weed-class dataset was created as a testbed for image generation and weed detection tasks. The ControlNet-added stable diffusion models were trained to generate weed images with broad intra-class variations of targeted weed species and diverse backgrounds to adapt to changing field conditions. The quality of generated images was assessed using metrics including the Fréchet Inception Distance (FID) and Inception Score (IS), resulting in an average FID of 0.98 and IS of 3.63. The generated weed images were selected to supplement real-world images for weed detection by YOLOv8-large. Combining the manually selected, generated images with real images yielded an overall mAP@50:95 of 88.3 % and mAP@50 of 95.0 %, representing performance gains of 1.4 % and 0.8 %, respectively, compared to the baseline model trained using only real images. It also performed competitively or comparably with modeling by combining real images with the images generated by external, traditional data augmentation techniques. The proposed automated post-generation image filtering approach still needs improvements to select high-quality images for enhanced weed detection. Both the weed dataset11https://doi.org/10.5281/zenodo.14861516 and software programs22https://github.com/vicdxxx/ControlNet-involved-Weed-Detection developed in this study have been made publicly available. Considerable research is needed to exploit more controllable diffusion models for generating high-fidelity, diverse weed images to substantially enhance weed detection in changing field conditions.}
}
@article{SELVARAJ2026109362,
title = {Automating the Observer OPTION-5 measure of shared decision making: Assessing validity by comparing large language models to human ratings},
journal = {Patient Education and Counseling},
volume = {142},
pages = {109362},
year = {2026},
issn = {0738-3991},
doi = {https://doi.org/10.1016/j.pec.2025.109362},
url = {https://www.sciencedirect.com/science/article/pii/S0738399125007293},
author = {Sai P. Selvaraj and Renata W. Yen and Rachel Forcino and Glyn Elwyn},
keywords = {Generative AI, LLM, GPT, Option talk, Shared decision-making},
abstract = {Objectives
Observer-based measures of shared decision rely on human raters, it is resource-intensive, limiting routine assessment and improvement. Generative artificial intelligence could increase the speed and accuracy of observer-based evaluation while reducing the burden. This study aimed to assess the performance of large language models (LLMs) from Gemini, GPT, and LLaMA family of models in evaluating the extent of shared decision-making between clinicians and women considering surgery for early-stage breast cancer.
Methods
LLM-generated scores were compared with those of trained human raters from a randomized controlled trial using the 5-item Observer OPTION-5 measure. We analyzed 287 anonymized transcripts of breast cancer consultations. A series of prompts were tested across models, assessing correlations with human scores. We also evaluated the ability of LLMs to distinguish high versus low encounters and the impact of inter-rater agreement on performance.11Codes available here
Results
The scores for Observer OPTION-5 items generated by the GPT-4o and Gemini-1.5-Pro-002 correlated with human ratings (Pearson r ≈ 0.6, p-value<0.01), representing ≈ 75–80 % of the correlation observed between human raters themselves (r = 0.77). Providing detailed descriptions and examples improved the models’ performance. The results also confirm that the models could distinguish high- from low-scoring encounters, with an independent-samples t-test showing a large and significant separation between the two groups (t > 10, p < 0.01).
Conclusions
Based on the breast cancer surgery dataset we explored, LLMs can evaluate aspects of clinician-patient dialog using existing measures, providing the basis for the development and fine-tuning of prompts. Future work should focus on generalizability, larger datasets, and improving model performance.
Practice implications
The prospect of being able to automate the assessment of shared decision-making opens the door to rapid feedback as a means for reflective practice improvement.}
}
@article{CHERIF2024,
title = {Appraisal of ChatGPT’s Aptitude for Medical Education: Comparative Analysis With Third-Year Medical Students in a Pulmonology Examination},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/52818},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000862},
author = {Hela Cherif and Chirine Moussa and Abdel Mouhaymen Missaoui and Issam Salouage and Salma Mokaddem and Besma Dhahri},
keywords = {medical education, ChatGPT, GPT, artificial intelligence, natural language processing, NLP, pulmonary medicine, pulmonary, lung, lungs, respiratory, respiration, pneumology, comparative analysis, large language models, LLMs, LLM, language model, generative AI, generative artificial intelligence, generative, exams, exam, examinations, examination},
abstract = {Background
The rapid evolution of ChatGPT has generated substantial interest and led to extensive discussions in both public and academic domains, particularly in the context of medical education.
Objective
This study aimed to evaluate ChatGPT’s performance in a pulmonology examination through a comparative analysis with that of third-year medical students.
Methods
In this cross-sectional study, we conducted a comparative analysis with 2 distinct groups. The first group comprised 244 third-year medical students who had previously taken our institution’s 2020 pulmonology examination, which was conducted in French. The second group involved ChatGPT-3.5 in 2 separate sets of conversations: without contextualization (V1) and with contextualization (V2). In both V1 and V2, ChatGPT received the same set of questions administered to the students.
Results
V1 demonstrated exceptional proficiency in radiology, microbiology, and thoracic surgery, surpassing the majority of medical students in these domains. However, it faced challenges in pathology, pharmacology, and clinical pneumology. In contrast, V2 consistently delivered more accurate responses across various question categories, regardless of the specialization. ChatGPT exhibited suboptimal performance in multiple choice questions compared to medical students. V2 excelled in responding to structured open-ended questions. Both ChatGPT conversations, particularly V2, outperformed students in addressing questions of low and intermediate difficulty. Interestingly, students showcased enhanced proficiency when confronted with highly challenging questions. V1 fell short of passing the examination. Conversely, V2 successfully achieved examination success, outperforming 139 (62.1%) medical students.
Conclusions
While ChatGPT has access to a comprehensive web-based data set, its performance closely mirrors that of an average medical student. Outcomes are influenced by question format, item complexity, and contextual nuances. The model faces challenges in medical contexts requiring information synthesis, advanced analytical aptitude, and clinical judgment, as well as in non-English language assessments and when confronted with data outside mainstream internet sources.}
}
@article{HIRAHARA2025109849,
title = {D4: Text-guided diffusion model-based domain adaptive data augmentation for vineyard shoot detection},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109849},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109849},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924012407},
author = {Kentaro Hirahara and Chikahito Nakane and Hajime Ebisawa and Tsuyoshi Kuroda and Yohei Iwaki and Tomoyoshi Utsumi and Yuichiro Nomura and Makoto Koike and Hiroshi Mineno},
keywords = {Agriculture, Generative data augmentation, Domain adaptation, Image-based phenotyping, Image generation},
abstract = {In agricultural practices, plant phenotyping using object detection models is gaining attention, plant phenotyping is a technology that accurately measures the quality and condition of cultivated crops from images, contributing to the improvement of crop yield and quality, as well as reducing environmental impact. However, collecting the training data necessary to create generic and high-precision models is extremely challenging due difficulties associated with annotations and the diversity of domains. Such difficulties arise from the unique shapes and backgrounds of plants, as well as the significant changes in appearance due to environmental conditions and growth stages. Furthermore, it is difficult to transfer training data across different crops, and although machine learning models effective for specific environments, conditions, and crops have been developed, they cannot be widely applied in real-world conditions. Therefore, in this study, we propose a generative artificial intelligence data augmentation method (D4) and investigated its application towards a shoot detection task in a vineyard. D4 uses a pre-trained text-guided diffusion model based on a large number of original images culled from video data collected by unmanned ground vehicles or other means, and a small number of annotated datasets. The proposed method generates new annotated images with background information adapted to the target domain while retaining annotation information necessary for object detection. In addition, D4 overcomes the lack of training data in agriculture, including the difficulty of annotation and diversity of domains. We confirmed that this generative data augmentation method improved the mean average precision by up to 28.65% for the BBox detection task and the average precision by up to 13.73% for the keypoint detection task for vineyard shoot detection. D4 generative data augmentation is expected to simultaneously solve the cost and domain diversity issues of training data generation for agricultural applications and improve the generalization performance of detection models.}
}
@article{ZHANG20243166,
title = {SeisResoDiff: Seismic resolution enhancement based on a diffusion model},
journal = {Petroleum Science},
volume = {21},
number = {5},
pages = {3166-3188},
year = {2024},
issn = {1995-8226},
doi = {https://doi.org/10.1016/j.petsci.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1995822624001869},
author = {Hao-Ran Zhang and Yang Liu and Yu-Hang Sun and Gui Chen},
keywords = {Seismic resolution enhancement, Diffusion model, High resolution, Reservoir characterization, Deep learning, Seismic data processing},
abstract = {High resolution of post-stack seismic data assists in better interpretation of subsurface structures as well as high accuracy of impedance inversion. Therefore, geophysicists consistently strive to acquire higher resolution seismic images in petroleum exploration. Although there have been successful applications of conventional signal processing and machine learning for post-stack seismic resolution enhancement, there is limited reference to the seismic applications of the recent emergence and rapid development of generative artificial intelligence. Hence, we propose to apply diffusion models, among the most popular generative models, to enhance seismic resolution. Specifically, we apply the classic diffusion model—denoising diffusion probabilistic model (DDPM), conditioned on the seismic data in low resolution, to reconstruct corresponding high-resolution images. Herein the entire scheme is referred to as SeisResoDiff. To provide a comprehensive and clear understanding of SeisResoDiff, we introduce the basic theories of diffusion models and detail the optimization objective's derivation with the aid of diagrams and algorithms. For implementation, we first propose a practical workflow to acquire abundant training data based on the generated pseudo-wells. Subsequently, we apply the trained model to both synthetic and field datasets, evaluating the results in three aspects: the appearance of seismic sections and slices in the time domain, frequency spectra, and comparisons with the synthetic data using real well-logging data at the well locations. The results demonstrate not only effective seismic resolution enhancement, but also additional denoising by the diffusion model. Experimental comparisons indicate that training the model on noisy data, which are more realistic, outperforms training on clean data. The proposed scheme demonstrates superiority over some conventional methods in high-resolution reconstruction and denoising ability, yielding more competitive results compared to our previous research.}
}
@article{BRAGA2025128034,
title = {Towards a methodology for ethical artificial intelligence system development: A necessary trustworthiness taxonomy},
journal = {Expert Systems with Applications},
volume = {286},
pages = {128034},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128034},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425016550},
author = {Carlos Mario Braga and Manuel A. Serrano and Eduardo Fernández-Medina},
keywords = {Artificial Intelligence, Methodology, Trustworthy, Ethics, Generative AI, Taxonomy, Sociotechnical system},
abstract = {Recently, generative artificial intelligence (GenAI) has arisen and been rapidly adopted; due to its emergent abilities, there is a significantly increased need for risk management in the implementation of such systems. At the same time, many proposals for translating ethics into AI, as well as the first agreements by regulators governing the use of artificial intelligence (AI), have surfaced. This underscores the need for Trustworthy AI, which implies reliability, compliance, and ethics. However, there is still a lack of unified criteria, and more critically, a lack of systematic methodologies for operationalizing trustworthiness within AI development processes. Trustworthiness is crucial, as it ensures that the system performs consistently under expected conditions while adhering to moral and legal standards. The problem of ensuring trustworthiness must be addressed as a preliminary step in creating a methodology for building AI systems with these desirable features. Based on a systematic literature review (SLR), we analyze the ethical, legal, and technological challenges that AI projects face, identifying key considerations and gaps in current approaches. This article presents a detailed and structured sociotechnical taxonomy related to the concept of Trustworthy AI, grounded in the analysis of all relevant texts on the topic, and designed to enable the systematic integration of ethical, legal, and technological principles into AI development processes. The taxonomy establishes a sociotechnical foundation that reflects the interconnected nature of technological, ethical, and legal considerations, and serves as the conceptual basis for CRISP-TAI, a proposed specialized development lifecycle currently under validation, aimed at systematically operationalizing trustworthiness principles across all phases of AI system engineering.}
}
@article{FAUGHT2025e731,
title = {Implementing Generative AI in Radiation Oncology: What Could Possibly Go Wrong?},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {123},
number = {1, Supplement },
pages = {e731},
year = {2025},
note = {ASTRO 2025: 67th Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2025.06.3145},
url = {https://www.sciencedirect.com/science/article/pii/S0360301625037502},
author = {A.M. Faught and P.E. Klages and P. Sadeghi and J.M. Pakela and E. Lee and A.S. Ayan},
abstract = {Purpose/Objective(s)
The rapid gains in generative artificial intelligence (AI) have resulted in a myriad of potential uses in the radiation oncology domain. We have been interested in using a large language model (LLM) as an advisor on group, departmental, and industry policies and guidelines. We sought to identify the risks associated with the tool through a failure modes and effects analysis (FMEA) study.
Materials/Methods
Six medical physicists were instructed to generate a list of failure modes (FMs) associated with using a LLM to offer guidance in clinical decision making for the medical physics group based on adopted standard operating procedures, departmental policies, and American Association of Physicists in Medicine (AAPM) guidance documents. The FMs were then redistributed to the physicists for independent scoring of probability of occurrence (O), severity (S), and lack of detectability (D). Average scores for each of the three metrics were calculated along with a final risk probability number (RPN). As an example of its proposed use, and as a method for further evaluating the risk, an LLM model was asked to perform on FMEA on its own list of ten FMs. The LLM was pointed to a directory of 32 AAPM task group (TG) reports, including TG-100, the report on risk analysis methods in radiation therapy, as a knowledge base for the task.
Results
The human scorers identified 22 unique FMs. Only one FM, a limited ability to handle updates to policy or procedures, was independently identified by all six physicists. A total of 11 of the 22 FMs were identified by at least two physicists. Fourteen of twenty-two FMs had an RPN greater than or equal to 125, the cutoff at which AAPM TG-100 suggests more attention is warranted for a FM. Of the ten FMs generated by the AI, six overlapped with FMs identified by the human scorers, including the FM identified by all six physicists. Nine of the ten AI generated FMs were scored with RPNs greater than 125, and the lone FM less than 125 had a severity of 10. The root mean squared error of the difference between AI RPNs and human scored RPNs in the overlapping FMs was 66, with differences as small as 0 and as large as 144. There were no instances of an overlapping human and AI generated FM having an RPN greater than 125 from one methodology and not the other.
Conclusion
Generative AI has the potential to be an invaluable tool in the field of radiation oncology. Specifically, the use of LLM models can help to enforce departmental consistency in practice, adherence to industry standards, and efficient means of referencing departmental guidelines. Even as an advisor, and not as a decision-making entity directly touching patients, the implementation of generative AI is not without risk. This work outlined those risks and highlighted the utility of the AI by having it perform its own risk assessment through an FMEA. Prospective risk mitigation strategies such as this exercise can be invaluable in both understanding risk and implementing preventions and barriers to reduce risk associated with adopting new technologies.}
}
@article{ACETO2024103926,
title = {Synthetic and privacy-preserving traffic trace generation using generative AI models for training Network Intrusion Detection Systems},
journal = {Journal of Network and Computer Applications},
volume = {229},
pages = {103926},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.103926},
url = {https://www.sciencedirect.com/science/article/pii/S1084804524001036},
author = {Giuseppe Aceto and Fabio Giampaolo and Ciro Guida and Stefano Izzo and Antonio Pescapè and Francesco Piccialli and Edoardo Prezioso},
keywords = {Network Intrusion Detection System, User privacy, Traffic trace generation, Traffic malware classification, Generative artificial intelligence, Conditional variational autoencoder},
abstract = {Network Intrusion Detection Systems (NIDS) are crucial tools for protecting networked devices from cyberattacks. Recent development in the field of Artificial Intelligence (AI) has provided tremendous advantages in implementing NIDSs able to monitor network traffic and block cyberattacks in real-time. In the literature, it is widely recognized that the effective training of a NIDS requires a large quantity of labeled traffic, representative of attacks. Nonetheless, the availability of public and abundant datasets remains remarkably restricted due to the cost of gathering and labeling real traffic traces and privacy concerns for sharing them. To tackle these challenges, in this paper we present a generative AI model capable of synthesizing anonymized traffic traces from real ones, thus dealing with privacy, abundance, and representativeness. The proposal is based on a Conditional Variational Autoencoder (CVAE) and a preprocessing procedure specifically designed for the generation of new traffic traces. To validate our solution, we conduct an extensive empirical study leveraging three recent and publicly-available datasets, containing benign and malicious traffic. The validation is carried out from both the perspectives of classification performance of a robust NIDS and the quality of synthetic data, in comparison to the utilization of real data. We compare our CVAE with two state-of-the-art AI-based traffic data generators and prove that, trained with traces emitted by our generative model, a NIDS has a limited F1-score loss compared to training on real data; competing models instead struggle or fail to generate traces that are as effective for NIDS training and as statistically similar to the original. We make the synthetic datasets available in both PCAP and tabular formats, to facilitate the reproducibility of our findings and encourage further exploration in the field of generative AI for networking.}
}
@article{ELBANNA202316,
title = {Exploring the integration of ChatGPT in education: adapting for the future},
journal = {Management & Sustainability: An Arab Review},
volume = {3},
number = {1},
pages = {16-29},
year = {2023},
issn = {2752-9819},
doi = {https://doi.org/10.1108/MSAR-03-2023-0016},
url = {https://www.sciencedirect.com/science/article/pii/S2752981923000102},
author = {Said Elbanna and Loreta Armstrong},
keywords = {ChatGPT, AI, Learning, Education, Responsible education, Content creation, Ethics},
abstract = {Purpose
This article aims to explore the advantages of integrating a new generative artificial intelligence (AI) technology in education. It investigates the use of ChatGPT in personalized learning, assessment and content creation and examines ways to manage its limitations and some ethical considerations. The purpose is to stimulate discussion on the effective application of ChatGPT as a tool for learning and skill development while remaining mindful of the ethical issues involved.
Design/methodology/approach
The methodology in this article includes four steps: a literature search, screening and selection, analysis and synthesis. The literature was thoroughly screened and selected on the basis of its relevance to the research question, before selected material were carefully read and analyzed. The insights gained from this analysis were then synthesized to identify key considerations in integrating ChatGPT in education.
Findings
The study concludes that ChatGPT can be effectively integrated into education to automate routine tasks and enhance the learning experience for students, ultimately increasing productivity and efficiency and fostering adaptive learning. However, the limitations of ChatGPT, even when updated, must be borne in mind, including factual inconsistencies, potential bias promotion, lack of in-depth understanding and safety concerns. The study nevertheless highlights the benefits of responsibly integrating ChatGPT within the field of education.
Practical implications
This study has practical implications for educators and policymakers who are interested in the integration of AI technology in education. The study provides insights of using ChatGPT in education.
Originality/value
This article contributes to the existing literature by specifically examining the advantages of integrating ChatGPT in higher education and offering recommendations for its responsible use. Moreover, the article emphasizes ethical considerations in the context of ChatGPT integration.}
}
@article{ALKHALAF2024104662,
title = {Applying generative AI with retrieval augmented generation to summarize and extract key clinical information from electronic health records},
journal = {Journal of Biomedical Informatics},
volume = {156},
pages = {104662},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104662},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000807},
author = {Mohammad Alkhalaf and Ping Yu and Mengyang Yin and Chao Deng},
keywords = {Generative AI, Nursing notes, LLAMA, Malnutrition, Summarization, RAG},
abstract = {Background
Malnutrition is a prevalent issue in aged care facilities (RACFs), leading to adverse health outcomes. The ability to efficiently extract key clinical information from a large volume of data in electronic health records (EHR) can improve understanding about the extent of the problem and developing effective interventions. This research aimed to test the efficacy of zero-shot prompt engineering applied to generative artificial intelligence (AI) models on their own and in combination with retrieval augmented generation (RAG), for the automating tasks of summarizing both structured and unstructured data in EHR and extracting important malnutrition information.
Methodology
We utilized Llama 2 13B model with zero-shot prompting. The dataset comprises unstructured and structured EHRs related to malnutrition management in 40 Australian RACFs. We employed zero-shot learning to the model alone first, then combined it with RAG to accomplish two tasks: generate structured summaries about the nutritional status of a client and extract key information about malnutrition risk factors. We utilized 25 notes in the first task and 1,399 in the second task. We evaluated the model’s output of each task manually against a gold standard dataset.
Result
The evaluation outcomes indicated that zero-shot learning applied to generative AI model is highly effective in summarizing and extracting information about nutritional status of RACFs’ clients. The generated summaries provided concise and accurate representation of the original data with an overall accuracy of 93.25%. The addition of RAG improved the summarization process, leading to a 6% increase and achieving an accuracy of 99.25%. The model also proved its capability in extracting risk factors with an accuracy of 90%. However, adding RAG did not further improve accuracy in this task. Overall, the model has shown a robust performance when information was explicitly stated in the notes; however, it could encounter hallucination limitations, particularly when details were not explicitly provided.
Conclusion
This study demonstrates the high performance and limitations of applying zero-shot learning to generative AI models to automatic generation of structured summarization of EHRs data and extracting key clinical information. The inclusion of the RAG approach improved the model performance and mitigated the hallucination problem.}
}
@article{RUSSELL2025102483,
title = {Toward amplifying the good in nursing education: A quality improvement study on implementing artificial intelligence-based assistants in a learning system},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102483},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102483},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001368},
author = {Regina G. Russell and Jules White and Allen Karns and Karely Rodriguez and Pamela R. Jeffries and Patricia Sengstack},
keywords = {Nursing education, Artificial intelligence, Generative AI, Large language models, Innovation, Systems thinking, Leadership, Change management, Quality improvement, Interprofessional education},
abstract = {ABSTRACT
Effective integration of artificial intelligence-based tools into nursing care and science will depend on aligned integration in nursing education. Our quality improvement study documents the process and short-term outcomes of introducing a generative AI-based tool into a nursing education system. Nursing school faculty and staff at one private, southeastern university (n = 364) piloted an internally constrained chatbot system for 2 months in 2024. Data were captured to evaluate the (a) costs of implementation, (b) use cases in nursing education, and (c) projected system impact. Costs were lower than $2 per month, per user. There were 148 diverse case reports from 35 unique users. On a separate survey, 35 respondents rated technology acceptability as 5.2/7.0. Projected impact is high (6.3/7.0), but not entirely positive (5.9/7.0). Benefits and challenges were identified. Nursing will need to invest expert time and community resources to evolve education systems along with these evolving technologies.}
}
@incollection{2026i,
title = {Front Matter},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {i-ii},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00301-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244003015}
}
@article{JIANG2024104103,
title = {Estimating and explaining regional land value distribution using attention-enhanced deep generative models},
journal = {Computers in Industry},
volume = {159-160},
pages = {104103},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104103},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000319},
author = {Feifeng Jiang and Jun Ma and Christopher John Webster and Weiwei Chen and Wei Wang},
keywords = {Land price estimation, Generative adversarial networks (GAN), Generative artificial intelligence (generative AI), Deep learning, Attention mechanism, Deep generative models},
abstract = {Accurate land valuation is crucial in sustainable urban development, influencing pivotal decisions on resource allocation and land-use strategies. Most existing studies, primarily using point-based modeling approaches, face challenges on granularity, generalizability, and spatial effect capturing, limiting their effectiveness in regional land valuation with high granularity. This study therefore proposes the LVGAN (i.e., land value generative adversarial networks) framework for regional land value estimation. The LVGAN model redefines land valuation as an image generation task, employing deep generative techniques combined with attention mechanisms to forecast high-resolution relative value distributions for informed decision-making. Applied to a case study of New York City (NYC), the LVGAN model outperforms typical deep generative methods, with MAE (Mean Absolute Error) and MSE (Mean Squared Error) averagely reduced by 36.58 % and 59.28 %, respectively. The model exhibits varied performance across five NYC boroughs and diverse urban contexts, excelling in Manhattan with limited value variability, and in areas characterized by residential zoning and high density. It identifies influential factors such as road network, built density, and land use in determining NYC land valuation. By enhancing data-driven decision-making at early design stages, the LVGAN model can promote stakeholder engagement and strategic planning for sustainable and well-structured urban environments.}
}
@article{CHEN2024112113,
title = {Enhancing interaction in virtual-real architectural environments: A comparative analysis of generative AI-driven reality approaches},
journal = {Building and Environment},
volume = {266},
pages = {112113},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324009557},
author = {Xinxing Chen and Weizhi Gao and Yingnan Chu and Yehao Song},
keywords = {Mixed reality, Generative AI, Computational design, Architectural environments},
abstract = {The architectural environment is expanding into digital, virtual, and informational dimensions, introducing challenges in virtual-real space interaction. Traditional design methods struggle with real-time interaction, integration with existing workflows, and rapid space modification. To address these issues, we present a generative design method that enables symbiotic interaction between virtual and real spaces using Mixed Reality (MR) and Generative Artificial Intelligence (AI) technologies. We developed two approaches: one using the Rhino modeling platform and the other based on the Unity3D game engine, tailored to different application needs. User experience testing in exhibition, leisure, and residential spaces evaluated our method's effectiveness. Results showed significant improvements in design flexibility, interactive efficiency, and user satisfaction. In the exhibition scenario, the Unity3D-based method excelled in rapid design modifications and immersive experiences. Questionnaire data indicated that MR offers good visual comfort and higher immersion than VR, effectively supporting architects in interface and scale design. Clustering analysis of participants' position and gaze data revealed diverse behavioral patterns in the virtual-physical exhibition space, providing insights for optimizing spatial layouts and interaction methods. Our findings suggest that the generative AI-driven MR method simplifies traditional design processes by enabling real-time modification and interaction with spatial interfaces through simple verbal and motion interactions. This approach streamlines workflows by reducing steps like measuring, modeling, and rendering, while enhancing user engagement and creativity. Overall, this method offers new possibilities for experiential exhibition and architectural design, contributing to future environments where virtual and real spaces coexist seamlessly.}
}
@article{ZHU2025,
title = {The Impact of ChatGPT Exposure on User Interactions With a Motivational Interviewing Chatbot: Quasi-Experimental Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/56973},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25002288},
author = {Jiading Zhu and Alec Dong and Cindy Wang and Scott Veldhuizen and Mohamed Abdelwahab and Andrew Brown and Peter Selby and Jonathan Rose},
keywords = {chatbot, digital health, motivational interviewing, natural language processing, ChatGPT, large language models, artificial intelligence, experimental, smoking cessation, conversational agent},
abstract = {Background
The worldwide introduction of ChatGPT in November 2022 may have changed how its users perceive and interact with other chatbots. This possibility may confound the comparison of responses to pre-ChatGPT and post-ChatGPT iterations of pre-existing chatbots, in turn affecting the direction of their evolution. Before the release of ChatGPT, we created a therapeutic chatbot, MIBot, whose goal is to use motivational interviewing to guide smokers toward making the decision to quit smoking. We were concerned that measurements going forward would not be comparable to those in the past, impacting the evaluation of future changes to the chatbot.
Objective
The aim of the study is to explore changes in how users interact with MIBot after the release of ChatGPT and examine the relationship between these changes and users’ familiarity with ChatGPT.
Methods
We compared user interactions with MIBot prior to ChatGPT’s release and 6 months after the release. Participants (N=143) were recruited through a web-based platform in November of 2022, prior to the release of ChatGPT, to converse with MIBot, in an experiment we refer to as MIBot (version 5.2). In May 2023, a set of (n=129) different participants were recruited to interact with the same version of MIBot and asked additional questions about their familiarity with ChatGPT, in the experiment called MIBot (version 5.2A). We used the Mann-Whitney U test to compare metrics between cohorts and Spearman rank correlation to assess relationships between familiarity with ChatGPT and other metrics within the MIBot (version 5.2A) cohort.
Results
In total, 83(64.3%) participants in the MIBot (version 5.2A) cohort had used ChatGPT, with 66 (51.2%) using it on a regular basis. Satisfaction with MIBot was significantly lower in the post-ChatGPT cohort (U=11,331.0; P=.001), driven by a decrease in perceived empathy as measured by the Average Consultation and Relational Empathy Measure (U=10,838.0; P=.01). Familiarity with ChatGPT was positively correlated with average response length (ρ=0.181; P=.04) and change in perceived importance of quitting smoking (ρ=0.296; P<.001).
Conclusions
The widespread reach of ChatGPT has changed how users interact with MIBot. Post-ChatGPT users are less satisfied with MIBot overall, particularly in terms of perceived empathy. However, users with greater familiarity with ChatGPT provide longer responses and demonstrated a greater increase in their perceived importance of quitting smoking after a session with MIBot. These findings suggest the need for chatbot developers to adapt to evolving user expectations in the era of advanced generative artificial intelligence.}
}
@article{CARL202491,
title = {Comparing Patient’s Confidence in Clinical Capabilities in Urology: Large Language Models Versus Urologists},
journal = {European Urology Open Science},
volume = {70},
pages = {91-98},
year = {2024},
issn = {2666-1683},
doi = {https://doi.org/10.1016/j.euros.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S2666168324010942},
author = {Nicolas Carl and Lisa Nguyen and Sarah Haggenmüller and Martin {Joachim Hetz} and Jana {Theres Winterstein} and Friedrich {Otto Hartung} and Britta Gruene and Jakob {Nikolas Kather} and Tim Holland-Letz and Maurice {Stephan Michel} and Frederik Wessels and Titus {Josef Brinker}},
keywords = {Clinical trial, Generative artificial intelligence, Implementation science, Large language models, Patient interaction},
abstract = {Background and objective
Data on interaction of patients with artificial intelligence (AI) are limited, primarily derived from small-scale studies, cross-sectional surveys, and qualitative reviews. Most patients have not yet encountered AI in their clinical experience. This study explored patients’ confidence in AI, specifically large language models, after a direct interaction with a chatbot in a clinical setting. Through hands-on experience, the study sought to reduce potential biases due to an anticipated lack of AI experience in a real-world urological patient sample.
Methods
A total of 300 patients scheduled for counseling were enrolled from February to July 2024. Participants voluntarily conversed about their medical questions with a GPT-4 powered chatbot, followed by a survey assessing their confidence in clinical capabilities of AI compared with their counseling urologists. Clinical capabilities included history taking, diagnostics, treatment recommendation, anxiety reduction, and time allocation.
Key findings and limitations
Of the 292 patients who completed the study, AI was significantly preferred to physicians for consultation time allocation (p < 0.001). However, urologists were overwhelmingly favored for all other capabilities, especially treatment recommendations and anxiety reduction. Notably, age did not influence patients’ confidence in AI. Limitations include a potential social desirability bias.
Conclusions and clinical implications
Our study demonstrates that urological patients prefer AI as a powerful complement to—rather than a replacement for—human expertise in clinical care. Patients appreciated the additional consultation time provided by AI. Interestingly, age was not associated with confidence in AI, suggesting that large language models are user-friendly tools for patients of all age groups.
Patient summary
In this report, we explored how patients feel about using an artificial intelligence (AI)-powered chatbot in a medical setting. Patients interacted with the AI for medical questions and compared its skills with those of doctors through a survey. They appreciated the AI for providing more time during consultations but preferred doctors for other tasks, for example, diagnostics, recommendation of treatments, and reduction of anxieties.}
}
@article{PARISE2025108523,
title = {CTGAN-driven synthetic data generation: A multidisciplinary, expert-guided approach (TIMA)},
journal = {Computer Methods and Programs in Biomedicine},
volume = {259},
pages = {108523},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108523},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724005169},
author = {Orlando Parise and Rani Kronenberger and Gianmarco Parise and Carlo {de Asmundis} and Sandro Gelsomino and Mark {La Meir}},
keywords = {Generative artificial intelligence, Synthetic structured data, SARS-CoV-2, Pandemic, COVID-19},
abstract = {Objective
We generated synthetic data starting from a population of two hundred thirty-eight adults SARS-CoV-2 positive patients admitted to the University Hospital of Brussels, Belgium, in 2020, utilizing a Conditional Tabular Generative Adversarial Network (CTGAN)-based technique with the aim of testing the performance, representativeness, realism, novelty, and diversity of synthetic data generated from a small patient sample. A Multidisciplinary Approach (TIMA) incorporates active participation from a medical team throughout the various stages of this process.
Methods
The TIMA committee scrutinized data for inconsistencies, implementing stringent rules for variables unlearned by the system. A sensitivity analysis determined 100,000 epochs, leading to the generation of 10,000 synthetic data. The model's performance was tested using a general-purpose dataset, comparing real and synthetic data.
Results
Outcomes indicate the robustness of our model, with an average contingency score of 0.94 across variable pairs in synthetic and real data. Continuous variables exhibited a median correlation similarity score of 0.97. Novelty received a top score of 1. Principal Component Analysis (PCA) on synthetic values demonstrated diversity, as no patient pair displayed a zero or close-to-zero value distance. Remarkably, the TIMA committee's evaluation revealed that synthetic data was recognized as authentic by nearly 100%.
Conclusions
Our trained model exhibited commendable performance, yielding high representativeness in the synthetic dataset compared to the original. The synthetic dataset proved realistic, boasting elevated levels of novelty and diversity.}
}
@incollection{SAAVEDRAALAMILLAS2025623,
title = {Library Instruction and Research Training in the Context of Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {623-629},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00122-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395689500122X},
author = {César Saavedra-Alamillas and Josmel Pacheco-Mendoza and Erik M. Ortiz-Díaz and Youness {El Hamzaoui} and Marc A. Astbury},
keywords = {Academic production., Artificial intelligence, Embedded librarian, Information literacy, Liaison librarian, Librarian, Library instruction, Research, Researcher training, Scientific communication},
abstract = {The librarian has played a crucial role throughout history, evolving from a guardian of humanity׳s collective memory to guiding the use of collections and, in recent years, a trainer in the use of information and emerging digital technologies. Currently, the librarian is an active collaborator who understands scientific communication processes and the mechanisms for improving high-impact academic production.}
}
@article{MAIBAUM2024114269,
title = {Selecting textual analysis tools to classify sustainability information in corporate reporting},
journal = {Decision Support Systems},
volume = {183},
pages = {114269},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114269},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624001027},
author = {Frederik Maibaum and Johannes Kriebel and Johann Nils Foege},
keywords = {Sustainability, Natural language processing, Corporate reporting, Performance evaluation, ChatGPT},
abstract = {Information on firms' sustainability often partly resides in unstructured data published, for instance, in annual reports, news, and transcripts of earnings calls. In recent years, researchers and practitioners have started to extract information from these data sources using a broad range of natural language processing (NLP) methods. While there is much to be gained from these endeavors, studies that employ these methods rarely reflect upon the validity and quality of the chosen method—that is, how adequately NLP captures the sustainability information from text. This practice is problematic, as different NLP techniques lead to different results regarding the extraction of information. Hence, the choice of method may affect the outcome of the application and thus the inferences that users draw from their results. In this study, we examine how different types of NLP methods influence the validity and quality of extracted information. In particular, we compare four primary methods, namely (1) dictionary-based techniques, (2) topic modeling approaches, (3) word embeddings, and (4) large language models such as BERT and ChatGPT, and evaluate them on 75,000 manually labeled sentences from 10-K annual reports that serve as the ground truth. Our results show that dictionaries have a large variation in quality, topic models outperform other approaches that do not rely on large language models, and large language models show the strongest performance. In large language models, individual fine-tuning remains crucial. One-shot approaches (i.e., ChatGPT) have lately surpassed earlier approaches when using well-designed prompts and the most recent models.}
}
@article{TELBANY2025S-318,
title = {1298: COMPARATIVE EFFECTIVENESS OF POTASSIUM-COMPETITIVE ACID BLOCKERS VERSUS PROTON PUMP INHIBITORS IN UPPER GASTROINTESTINAL BLEEDING: A U.S. MULTICENTER PROPENSITY-MATCHED STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01676-2},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016762},
author = {Ahmed Telbany and Abhishek Patel and Evelyn Inga and Pooja Viswanath and Christopher Chang}
}
@article{LI2025110496,
title = {Solid propellant grain reverse design via generative deep learning},
journal = {Aerospace Science and Technology},
volume = {165},
pages = {110496},
year = {2025},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2025.110496},
url = {https://www.sciencedirect.com/science/article/pii/S127096382500567X},
author = {W.T. Li and Y.Q. He and G.Z. Liang},
keywords = {Solid rocket motor, Propellant grain reverse design, Generative artificial intelligence, Auto-decoder, Latent space, Diffusion model},
abstract = {The primary objective of solid propellant grain reverse design is to determine the optimal grain geometries, which may be not standard traditional grain shapes, that can produce an internal ballistic performance curve (abbreviated as performance curve) matching the target curve. To address the fundamental challenges of grain shape interpolation, reconstruction, and generation, a deep learning approach is proposed. Firstly, the fast-sweeping method is introduced to rapidly realize the calculation of burning surface regression and performance curve prediction. Secondly, a deep neural field with conditional auto-decoder is constructed, which can output the phase field of the grain shape matching the target performance curve according to a latent vector and conditional vector. Thirdly, a latent denoising diffusion probability model is developed to realize grain generation in latent space. The latent vector can be generated from a Gauss noisy through a stochastic process. Moreover, the intensity of classifier-free guidance can be manipulated to adjust the diversity of the results. Finally, the grain shape interpolation, reconstruction, and generation are verified through typical cases. All the optimal and suboptimal solutions are successfully identified by our model. The reconstructed and generated dual-thrust grain achieves performance matching degrees of 0.9852 and 0.9870, respectively, which closely align with the best results reported in previous method of single-objective evolutionary neural network. Consequently, the deep neural field and generative diffusion model proposed in this study offer promising solutions to grain reverse design problems. These findings can provide a solid foundation for future investigations into complex 3D grain reverse design.}
}
@article{GE20244017,
title = {Data-augmented landslide displacement prediction using generative adversarial network},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {16},
number = {10},
pages = {4017-4033},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2024.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1674775524000726},
author = {Qi Ge and Jin Li and Suzanne Lacasse and Hongyue Sun and Zhongqiang Liu},
keywords = {Machine learning (ML), Time series, Generative adversarial network (GAN), Three Gorges reservoir (TGR), Landslide displacement prediction},
abstract = {Landslides are destructive natural disasters that cause catastrophic damage and loss of life worldwide. Accurately predicting landslide displacement enables effective early warning and risk management. However, the limited availability of on-site measurement data has been a substantial obstacle in developing data-driven models, such as state-of-the-art machine learning (ML) models. To address these challenges, this study proposes a data augmentation framework that uses generative adversarial networks (GANs), a recent advance in generative artificial intelligence (AI), to improve the accuracy of landslide displacement prediction. The framework provides effective data augmentation to enhance limited datasets. A recurrent GAN model, RGAN-LS, is proposed, specifically designed to generate realistic synthetic multivariate time series that mimics the characteristics of real landslide on-site measurement data. A customized moment-matching loss is incorporated in addition to the adversarial loss in GAN during the training of RGAN-LS to capture the temporal dynamics and correlations in real time series data. Then, the synthetic data generated by RGAN-LS is used to enhance the training of long short-term memory (LSTM) networks and particle swarm optimization-support vector machine (PSO-SVM) models for landslide displacement prediction tasks. Results on two landslides in the Three Gorges Reservoir (TGR) region show a significant improvement in LSTM model prediction performance when trained on augmented data. For instance, in the case of the Baishuihe landslide, the average root mean square error (RMSE) increases by 16.11%, and the mean absolute error (MAE) by 17.59%. More importantly, the model's responsiveness during mutational stages is enhanced for early warning purposes. However, the results have shown that the static PSO-SVM model only sees marginal gains compared to recurrent models such as LSTM. Further analysis indicates that an optimal synthetic-to-real data ratio (50% on the illustration cases) maximizes the improvements. This also demonstrates the robustness and effectiveness of supplementing training data for dynamic models to obtain better results. By using the powerful generative AI approach, RGAN-LS can generate high-fidelity synthetic landslide data. This is critical for improving the performance of advanced ML models in predicting landslide displacement, particularly when there are limited training data. Additionally, this approach has the potential to expand the use of generative AI in geohazard risk management and other research areas.}
}
@article{UPTEGRAFT2025,
title = {The Elastic Electronic Health Record: A Five-Tiered Framework for Applying Artificial Intelligence to Electronic Health Record Maintenance, Configuration, and Use},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66741},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000407},
author = {Colby Uptegraft and Kameron Collin Black and Jonathan Gale and Andrew Marshall and Shuhan He},
keywords = {semi-autonomous database, back-end EHR, self-configuring database, machine learning, health care, generative artificial intelligence, elastic EHR, electronic record, electronic health record, artificial intelligence, AI, EHR, database},
abstract = {Properly configuring modern electronic health records (EHRs) has become increasingly challenging for human operators, failing to fully meet the efficiency and cost-saving potential seen with the digitization of other sectors. The integration of artificial intelligence (AI) offers a promising solution, particularly through a comprehensive governance approach that moves beyond front-end enhancements such as user- and patient-facing copilots. These copilots, although useful, are limited by the underlying EHR configuration, leading to inefficiencies and high maintenance costs. To address this, we propose the concept of an “Elastic EHR,” which proactively suggests and validates optimal content and configuration changes, significantly reducing governance costs and enhancing user experience, as well as reducing many of the common frustrations including the documentation burden, alert fatigue, system responsiveness, outdated content, and unintuitive design. Our five-tiered model details a structured approach to AI integration within EHRs. Tier I focuses on autonomous database reconfiguration, akin to Oracle Autonomous Database functionalities, to ensure continuous system improvements without direct edits to the production environment. Tier II empowers EHR clients to shape system performance according to predefined strategies and standards, ensuring coordinated and efficient EHR solution builds. Tier III optimizes EHR choice architecture by analyzing user behaviors and suggesting content and configuration changes that minimize clicks and keystrokes, thereby enhancing workflow efficiency. Tier IV maintains the currency of EHR clinical content and decision support by linking content and configuration to updated guidelines and literature, ensuring the EHR remains evidence-based and compliant with evolving standards. Finally, Tier V incorporates context-dependent AI copilots to enhance care efficiency, quality, and user experience. Despite the potential benefits, major limitations exist. The market dominance of a few major EHR vendors—Epic Systems, Oracle Health, and MEDITECH—poses a challenge, as any enhancements require their cooperation and financial motivation. Furthermore, the diverse and complex nature of health care environments demands a flexible yet robust AI system that can adapt to various institutional needs that has not yet been developed, researched, or tested. The Elastic EHR model proposes a five-tiered framework for optimizing EHR systems and user experience with AI. By overcoming the identified limitations through vendor-led, collaborative efforts, AI-enabled EHRs could improve the efficiency, quality, and user experience of health care delivery, fully delivering on the promises of digitization within health care.}
}
@article{NIE2024100172,
title = {SkyGPT: Probabilistic ultra-short-term solar forecasting using synthetic sky images from physics-constrained VideoGPT},
journal = {Advances in Applied Energy},
volume = {14},
pages = {100172},
year = {2024},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2024.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666792424000106},
author = {Yuhao Nie and Eric Zelikman and Andea Scott and Quentin Paletta and Adam Brandt},
keywords = {Cloud motion prediction, Probabilistic solar forecasting, Deep learning, Generative models, Stochastic video prediction, Sky images, Photovoltaic power},
abstract = {The variability of solar photovoltaic (PV) power output, driven by rapidly changing cloud dynamics, hinders the transition to reliable renewable energy systems. Information on future sky conditions, especially cloud coverage, holds the promise for improving PV output forecasting. Leveraging recent advances in generative artificial intelligence (AI), we introduce SkyGPT, a physics-constrained stochastic video prediction model, which predicts plausible future images of the sky using historical sky images. We show that SkyGPT can accurately capture cloud dynamics, producing highly realistic and diverse future sky images. We further demonstrate its efficacy in 15-minute-ahead probabilistic PV output forecasting using real-world power generation data from a 30-kW rooftop PV system. By coupling SkyGPT with a U-Net-based PV power prediction model, we observe superior prediction reliability and sharpness compared with several benchmark methods. The propose approach achieves a continuous ranked probability score (CRPS) of 2.81 kW, outperforming a classic convolutional neural network (CNN) baseline by 13% and the smart persistence model by 23%. The findings of this research could aid efficient and resilient management of solar electricity generation, particularly as we transition to renewable-heavy grids. The study also provides valuable insights into stochastic cloud modeling for a broad research community, encompassing fields such as solar energy meteorology and atmospheric sciences.}
}
@incollection{2026i,
title = {Titlepage},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {i},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00302-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244003027}
}
@incollection{2026261,
title = {Index},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {261-264},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00483-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244004835}
}
@article{DESIANO2025107785,
title = {Translating code with Large Language Models and human-in-the-loop feedback},
journal = {Information and Software Technology},
volume = {186},
pages = {107785},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107785},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001247},
author = {Gabriele Dario {De Siano} and Anna Rita Fasolino and Giancarlo Sperlí and Andrea Vignali},
keywords = {Large Language Model, Human-centered AI, Code translation, Software engineering},
abstract = {Context:
In recent years, the code translation task has arisen as one of the major software issues in maintaining software quality during migration over complex infrastructure. This task involves human subjects with different background knowledge and could introduce errors due to the semantic gap between the programming languages and the complexity of the task. Generative Artificial Intelligence (AI) showed good capabilities in code generation, albeit this is highly dependent on the human factor.
Objective:
This paper investigates, from the human perspective, the use of three Generative AI tools (ChatGPT, Google Bard, and GitHub Copilot) in the context of translation tasks from code written in query languages to code written in framework-specific code languages, specifically focused on SQL dialects and PySpark. This translation is especially crucial during the migration from centralized architectures to cloud-based architectures.
Methods:
We evaluate the usefulness of these tools, the quality of the generated code, and their impact on performance. The models are tested with queries of various type in three different SQL dialects considering three usage scenarios of increasing complexity. It involves 15 participants with diverse programming backgrounds, who aim to solve tasks by interacting multiple times with the tools and manually changing the code.
Results:
The findings show a positive performance, demonstrating their reliability in generating coherent translations, achieving 100% precision in most tasks with a slight decrease in more complex scenarios, and producing well-documented code, with a response time of under 2 min, with Google Bard responding 50% faster than the others.
Conclusion:
In conclusion, this paper establishes a methodology and both quantitative and qualitative metrics for evaluating how generative AI tools streamline code translation, shifting the emphasis from production to refinement. It underscores the importance of continuously improving these tools to integrate them into developers’ workflows and to provide guidelines for intelligent use.}
}
@article{RENSHAW2024100154,
title = {Linking online activity to offline behavior: A meta-review of three decades of online-to-offline scholarship with future implications for AI},
journal = {Emerging Trends in Drugs, Addictions, and Health},
volume = {4},
pages = {100154},
year = {2024},
issn = {2667-1182},
doi = {https://doi.org/10.1016/j.etdah.2024.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2667118224000138},
author = {Scott Leo Renshaw and Kathleen M. Carley},
keywords = {Network analysis, Social reinforcement, Meta-review, Online influences, Offline behavior},
abstract = {As society grapples with the emerging significance and implications of Large Language Models (LLMs), such as OpenAI’s ChatGPT, or Google’s Gemini, as well as other advancements in modern generative Artificial Intelligence (AI), it is crucial to recognize the existing role that data, algorithms, and online social networks have already played in shaping our contemporary society. This review article provides the first comprehensive examination of the current state of knowledge, across disciplinary divides, on how online influences impact offline behaviors, laying the necessary groundwork for investigating and researching the potential impact that these new technologies will have on our “offline” lives. Through a deep-dive collection of articles (n=149), we review and analyze research with measurable Online-to-Offline impacts (n=88). Within this Online-to-Offline criteria, we identify five emergent cross-cutting themes, namely: Social Diffusion, Social Reinforcement, Social Boundary & Identity Maintenance, Cognitive and Attitudinal Research, and Research on Vulnerable & Marginalized Impacts. Through a second wave snowball collection process, we construct a citation network from the broader Online and Offline research literature, allowing us to locate the Online-to-Offline subset as part of a larger intellectual discussion. Finally, we conduct a Term Frequency-Inverse Document Frequency (TF-IDF) analysis of terms used in the titles of these online/offline research papers, from 1990 to 2023, to identify the evolution of researchers’ conceptualization and framing of Online and Offline research across the past 30 years. The meta-review, presentation of high-level cross-cutting interdisciplinary themes, co-citation network analysis, and TF-IDF analysis collectively provide a cohesive and deeper understanding of the research space of online/offline influences. By taking stock of the ways in which online factors have already shaped individual, group, or organizational behaviors and social dynamics broadly in “offline” contexts, this work aims to provide a cohesive theoretical and empirical foundation for future researchers to better anticipate, address, and frame the future consequences of the rapidly evolving digitally influenced landscape we find ourselves in today.}
}
@article{MASROURI2024100492,
title = {Towards data-efficient mechanical design of bicontinuous composites using generative AI},
journal = {Theoretical and Applied Mechanics Letters},
volume = {14},
number = {1},
pages = {100492},
year = {2024},
issn = {2095-0349},
doi = {https://doi.org/10.1016/j.taml.2024.100492},
url = {https://www.sciencedirect.com/science/article/pii/S2095034924000035},
author = {Milad Masrouri and Zhao Qin},
keywords = {Generative artificial intelligence, Stable diffusion, Composite design, Phase field model, Molecular dynamics simulation},
abstract = {The distribution of material phases is crucial to determine the composite's mechanical property. While the full structure-mechanics relationship of highly ordered material distributions can be studied with finite number of cases, this relationship is difficult to be revealed for complex irregular distributions, preventing design of such material structures to meet certain mechanical requirements. The noticeable developments of artificial intelligence (AI) algorithms in material design enables to detect the hidden structure-mechanics correlations which is essential for designing composite of complex structures. It is intriguing how these tools can assist composite design. Here, we focus on the rapid generation of bicontinuous composite structures together with the stress distribution in loading. We find that generative AI, enabled through fine-tuned Low Rank Adaptation models, can be trained with a few inputs to generate both synthetic composite structures and the corresponding von Mises stress distribution. The results show that this technique is convenient in generating massive composites designs with useful mechanical information that dictate stiffness, fracture and robustness of the material with one model, and such has to be done by several different experimental or simulation tests. This research offers valuable insights for the improvement of composite design with the goal of expanding the design space and automatic screening of composite designs for improved mechanical functions.}
}
@article{SHAIKH2025104005,
title = {Fields of the future: Digital transformation in smart agriculture with large language models and generative AI},
journal = {Computer Standards & Interfaces},
volume = {94},
pages = {104005},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104005},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000340},
author = {Tawseef Ayoub Shaikh and Tabasum Rasool and Waseem Ahmad Mir},
keywords = {Language models, Agricultural text classification, Very large pre-trained language model, Generative pre-trained enerative pre-trained transformer (GPT), ChatGPT, Generative AI, Natural language processing, Semantic matching},
abstract = {Language models (LLMs) have shown to be very useful in many fields like healthcare and finance, as natural language comprehension and generation have advanced. The capacity of LLM to participate in textual discussion has been the subject of much research, and the findings have proved encouraging across several domains. The inability of conventional image classification networks to comprehend the causes of crop diseases and etiology further impedes precise diagnosis. Agricultural diagnostic models on a grand scale will be based on generative pre-trained transformers (GPT) assisted with agrarian settings. By examining the efficacy of text corpora linked to agriculture for pretraining transformer-based language (TBL) models, this research delves into agricultural natural language processing (ANLP). To make the most of it, we looked at several important aspects, including prompt building, response parsing, and several ChatGPT versions. Despite the proven effectiveness and huge potential, there has been little exploration of LLM and Generative AI to agriculture artificial intelligence (AI). Therefore, this study aims to explore the possibility of LLM and Generative AI in smart agriculture. In particular, we present conceptual tools and technical background to facilitate understanding the problem space and uncover new research directions in this field. The paper presents an overview of the evolution of generative adversarial network (GAN) architectures followed by a first systematic review of various applications in smart agriculture and precision farming systems, involving a diversity of visual recognition tasks for smart farming and livestock, precision agriculture, agricultural language processing (ALP), agricultural robots (AR), plant phenotyping (PP), and postharvest quality assessment. We outline the possibilities, difficulties, constraints, and shortcomings. The study lays forth a road map of accessible areas in agriculture where LLM integration is likely to happen shortly. The research suggests exciting directions for further study in this area, which could lead to better agricultural NLP applications.}
}
@article{ARSLAN2025116276,
title = {Monitoring indoor environmental conditions in office buildings using a sustainable Agentic RAG-LLM system},
journal = {Energy and Buildings},
volume = {347},
pages = {116276},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.116276},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825010060},
author = {Muhammad Arslan and Saba Munawar and Lamine Mahdjoubi and Patrick Manu},
keywords = {Thermal Comfort Monitoring (TCM), Building Information Modeling (BIM), Sensors, Large Language Models (LLMs), Sustainable Building Management},
abstract = {Indoor Environmental Conditions (IEC) play a crucial role in determining the health, productivity, and overall building performance of employees, as well as their energy consumption. Key parameters, such as temperature and humidity, are not only vital for thermal comfort but also offer opportunities to enhance energy efficiency when effectively monitored and managed. Accurate Thermal Comfort Monitoring (TCM) remains challenging to achieve because it requires the integration of diverse data sources and intelligent analysis, particularly in light of evolving global energy and sustainability standards. Although Building Information Modeling (BIM) is increasingly being adopted to manage complex building data, its integration with real-time sensor inputs remains vastly underutilized. Existing thermal monitoring systems are often development-intensive, require significant domain expertise, lack Natural Language (NL) interaction capabilities, and are not inherently adaptable, necessitating frequent technical upgrades. These limitations give rise to pressing concerns about long-term scalability, usability, and sustainability. To address these limitations, this study introduces ThermalComfortBot, an integrated Information System (IS) powered by Generative Artificial Intelligence (GenAI). ThermalComfortBot utilizes open-source technologies, including Large Language Models (LLMs) and Agentic Retrieval-Augmented Generation (RAG), to enhance thermal comfort and support energy optimization in buildings. The system integrates Building Information Modeling (BIM), sensor data, and external datasets to generate actionable insights, delivered through both textual explanations and graphical visualizations. This system utilizes flexible and adjustable LLMs that are guided by principles of sustainability, thereby making them cost-efficient, scalable, and practical for a diverse range of organizational environments. In a real-world case study, ThermalComfortBot outperforms traditional RAG-LLM, achieving 94% accuracy, 92% precision, and 89% recall, enhancing comfort and efficiency.}
}
@article{ZHANG2025127587,
title = {Dual-archive guided multi-objective neural architecture search with decomposition},
journal = {Expert Systems with Applications},
volume = {282},
pages = {127587},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127587},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425012096},
author = {Kexin Zhang and Hao Sun and Lixin Wei and Ziyu Hu},
keywords = {Neural architecture search, Multi-objective optimization, Dual-archive, Decomposition-based optimization, Training-free metrics},
abstract = {The rapid development of generative artificial intelligence puts forward higher requirements for efficient neural network architecture design. Traditional neural architecture search (NAS) focuses on single-objective optimization, while multi-objective NAS (MONAS) needs to balance performance, parameter number, inference delay and other objectives at the same time. The existing methods based on multi-objective evolutionary algorithms often deviate from the optimal search direction due to target conflict, and rely on time-consuming weight pre-training, which seriously limits the practical application efficiency. Therefore, this paper proposes a dual-archive guided decomposition-based DANAS algorithm. The algorithm employs a dynamic decomposition strategy to map the multi-objective space into a set of subproblems. A convergence archive is utilized to preserve solutions approximating the Pareto front, while a diversity archive maintains the distribution characteristics of the solution set. The dual-archive mechanism effectively coordinates exploitation and exploration during the search process. On this basis, two training-free metrics are introduced, and an efficient variant without parameter training called TF-DANAS is proposed, which greatly reduces the search cost. In EvoXbench, NAS-Bench-101,and NAS-Bench-201 benchmark tests, DANAS algorithm obtains the optimal HV value on 57.6% of the test sets on EvoXbench. On NAS-Bench-101, the proposed method achieved a top average accuracy of 93.83% on CIFAR-10. Furthermore, it attained average accuracies of 94.34%, 73.42%, and 46.50% on CIFAR-10, CIFAR-100, and ImageNet16-120 respectively when evaluated on NAS-Bench-201.}
}
@article{JACOBS2023,
title = {Reimagining Core Entrustable Professional Activities for Undergraduate Medical Education in the Era of Artificial Intelligence},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/50903},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000909},
author = {Sarah Marie Jacobs and Neva Nicole Lundy and Saul Barry Issenberg and Latha Chandran},
keywords = {artificial intelligence, entrustable professional activities, medical education, competency-based education, educational technology, machine learning},
abstract = {The proliferation of generative artificial intelligence (AI) and its extensive potential for integration into many aspects of health care signal a transformational shift within the health care environment. In this context, medical education must evolve to ensure that medical trainees are adequately prepared to navigate the rapidly changing health care landscape. Medical education has moved toward a competency-based education paradigm, leading the Association of American Medical Colleges (AAMC) to define a set of Entrustable Professional Activities (EPAs) as its practical operational framework in undergraduate medical education. The AAMC’s 13 core EPAs for entering residencies have been implemented with varying levels of success across medical schools. In this paper, we critically assess the existing core EPAs in the context of rapid AI integration in medicine. We identify EPAs that require refinement, redefinition, or comprehensive change to align with the emerging trends in health care. Moreover, this perspective proposes a set of “emerging” EPAs, informed by the changing landscape and capabilities presented by generative AI technologies. We provide a practical evaluation of the EPAs, alongside actionable recommendations on how medical education, viewed through the lens of the AAMC EPAs, can adapt and remain relevant amid rapid technological advancements. By leveraging the transformative potential of AI, we can reshape medical education to align with an AI-integrated future of medicine. This approach will help equip future health care professionals with technological competence and adaptive skills to meet the dynamic and evolving demands in health care.}
}
@article{FREEMAN2025102868,
title = {Adolescents' Trust in Health Information in an Evolving Social Media Landscape},
journal = {Academic Pediatrics},
volume = {25},
number = {7},
pages = {102868},
year = {2025},
issn = {1876-2859},
doi = {https://doi.org/10.1016/j.acap.2025.102868},
url = {https://www.sciencedirect.com/science/article/pii/S1876285925000932},
author = {Jaimie L. Freeman and Patrina H.Y. Caldwell and Karen M. Scott},
keywords = {adolescent, health education, health literacy, information seeking behavior, internet}
}
@article{PATEL2025102296,
title = {Patient-centered reporting: Should this become the new standard?},
journal = {Journal of Nuclear Cardiology},
volume = {51},
pages = {102296},
year = {2025},
issn = {1071-3581},
doi = {https://doi.org/10.1016/j.nuclcard.2025.102296},
url = {https://www.sciencedirect.com/science/article/pii/S1071358125001709},
author = {Krishna K. Patel and John A. Spertus},
keywords = {Patient-centered reporting, Myocardial perfusion imaging, Reporting}
}
@article{CHEN2024,
title = {EyeGPT for Patient Inquiries and Medical Education: Development and Validation of an Ophthalmology Large Language Model},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60063},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124009361},
author = {Xiaolan Chen and Ziwei Zhao and Weiyi Zhang and Pusheng Xu and Yue Wu and Mingpu Xu and Le Gao and Yinwen Li and Xianwen Shang and Danli Shi and Mingguang He},
keywords = {large language model, generative pretrained transformer, generative artificial intelligence, ophthalmology, retrieval-augmented generation, medical assistant, EyeGPT, generative AI},
abstract = {Background
Large language models (LLMs) have the potential to enhance clinical flow and improve medical education, but they encounter challenges related to specialized knowledge in ophthalmology.
Objective
This study aims to enhance ophthalmic knowledge by refining a general LLM into an ophthalmology-specialized assistant for patient inquiries and medical education.
Methods
We transformed Llama2 into an ophthalmology-specialized LLM, termed EyeGPT, through the following 3 strategies: prompt engineering for role-playing, fine-tuning with publicly available data sets filtered for eye-specific terminology (83,919 samples), and retrieval-augmented generation leveraging a medical database and 14 ophthalmology textbooks. The efficacy of various EyeGPT variants was evaluated by 4 board-certified ophthalmologists through comprehensive use of 120 diverse category questions in both simple and complex question-answering scenarios. The performance of the best EyeGPT model was then compared with that of the unassisted human physician group and the EyeGPT+human group. We proposed 4 metrics for assessment: accuracy, understandability, trustworthiness, and empathy. The proportion of hallucinations was also reported.
Results
The best fine-tuned model significantly outperformed the original Llama2 model at providing informed advice (mean 9.30, SD 4.42 vs mean 13.79, SD 5.70; P<.001) and mitigating hallucinations (97/120, 80.8% vs 53/120, 44.2%, P<.001). Incorporating information retrieval from reliable sources, particularly ophthalmology textbooks, further improved the model's response compared with solely the best fine-tuned model (mean 13.08, SD 5.43 vs mean 15.14, SD 4.64; P=.001) and reduced hallucinations (71/120, 59.2% vs 57/120, 47.4%, P=.02). Subgroup analysis revealed that EyeGPT showed robustness across common diseases, with consistent performance across different users and domains. Among the variants, the model integrating fine-tuning and book retrieval ranked highest, closely followed by the combination of fine-tuning and the manual database, standalone fine-tuning, and pure role-playing methods. EyeGPT demonstrated competitive capabilities in understandability and empathy when compared with human ophthalmologists. With the assistance of EyeGPT, the performance of the ophthalmologist was notably enhanced.
Conclusions
We pioneered and introduced EyeGPT by refining a general domain LLM and conducted a comprehensive comparison and evaluation of different strategies to develop an ophthalmology-specific assistant. Our results highlight EyeGPT’s potential to assist ophthalmologists and patients in medical settings.}
}
@article{NABILA2025100501,
title = {Data efficiency assessment of generative adversarial networks in energy applications},
journal = {Energy and AI},
volume = {20},
pages = {100501},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100501},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825000333},
author = {Umme Mahbuba Nabila and Linyu Lin and Xingang Zhao and William L. Gurecky and Pradeep Ramuhalli and Majdi I. Radaideh},
keywords = {Generative AI, Generative adversarial networks, Critical heat flux, Data augmentation, Power grid energy forecasting},
abstract = {This study investigates the data requirements of generative artificial intelligence (AI), particularly generative adversarial networks (GANs), for reliable data augmentation in energy applications. Generative AI, though seen as a solution to data limitations, requires substantial data to learn meaningful distributions—a challenge often overlooked. This study addresses the challenge through synthetic data generation for critical heat flux (CHF) and power grid demand, focusing on renewable and nuclear energy. Two variants of GAN employed are conditional GAN (cGAN) and Wasserstein GAN (wGAN). Our findings include the strong dependency of GAN on data size, with performance declining on smaller datasets and varying performance when generalizing to unseen experiments. Mass flux and heated length significantly influence CHF predictions. wGAN is more robust to feature exclusion, making it suitable for constrained synthetic data generation. In energy demand forecasting, wGAN performed well for solar, wind, and load predictions. Longer lookback hours and larger datasets improved predictions, especially for load power. Seasonal variations posed challenges, with wGAN achieving a relatively high error of Root Mean Squared Error (RMSE) of 0.32 for load power prediction, compared to RMSE of 0.07 under same-season conditions. Feature exclusions impacted cGAN the most, while wGAN showed greater robustness. This study concludes that, while generative AI is effective for data augmentation, it requires substantial data and careful training to generate realistic synthetic data and generalize to new experiments in engineering applications.}
}
@article{CHIA2025100468,
title = {A design-based approach to analysing student engagement with a GenAI-Enabled brainstorming app},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100468},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100468},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001080},
author = {Joanne Chia and Angela Frattarola},
keywords = {GenAI for education, Writing assistant apps, Customised apps, Personalization in technology, Student engagement, Human-AI interactions, Design thinking, Data storytelling, Technological use and innovation in institutes of higher learning, Faculty and student collaborations},
abstract = {While there are several “writing buddy” Generative Artificial Intelligence (GenAI) apps that check grammar and language usage, not many focus exclusively on enhancing the brainstorming process for writing across disciplines. To fill this gap, a team of staff and student assistants with programming and User Interface (UI) and User Experience (UX) expertise designed and prototyped a web app named “Waai,” which rhymes with ‘why,’ that could assist students throughout the writing process for a first-year general writing module for all undergraduate students at a Singaporean university. Utilising surveys, focus group discussions, and app data that shows the nature and type of student engagement with the Waai app, this paper studies the impact of one aspect of the Waai app, an uni-directional chatbot named “Nudgy,” as a first step to optimising interactions with an AI chatbot for writing purposes. Overall, we found that students were able to benefit from the GenAI chatbot Nudgy in 5 distinct ways: 1) its pre-engineered prompts, which were tailored to the course assignment rubrics; 2) its tendency to recommend topics to research rather than give students answers; 3) its suggested research topics, which helped students to consider different perspectives on their topics; 4) how it modelled ways to ideate new insights; and 5) its constant availability. Students, however, expressed reservations about the Nudgy, particularly in terms of: 1) the limitations of pre-engineered prompts within the app; 2) difficulty in discerning the most relevant of the Nudgy feedback; 3) mistrust in GenAI and Aigiarism; and 4) a recognition of the limitations of GenAI in supporting argumentative writing. “Waai” essentially presents a decision-making framework for brainstorming based on cognitive socialisation, a method of learning that emphasises inductive as opposed to deductive experience that could be applied to online environments, as an ideology of learning that considers, among other aspects, the development of selfhood, where learning is both guided and mediated (Kesebir & Gardner, 2010). In the context of asynchronous learning, meaning is not intrinsic but rather picked up through interactions on online platforms. Interacting with a chatbot with pre-designed prompts result in a ritual that both define and explore the limits of knowledge building. Symbolic interactionism (Aksan et al., 2009) through the medium of technology is a key objective of 21st century education, where ‘learning’ is internalised as an individual experience. Waai offers educatros additional understanding of the effects of personalization (Mygland et al., 2021) as proposed by this design-based study of the role of instruction in the creation of online ‘learning’ experiences. The centrality of instruction and standards of reasoning through the process of brainstorming suggests that the developmental stages of ‘learning’ concepts could empower a process for self-regulation (Zimmerman, 1989) that goes beyond immediate causes and effects to inspire a spiral of reflection and change essential to ideation.}
}
@article{NORDLINGER2024536,
title = {Rapport 24-03. Systèmes d’IA générative en santé : enjeux et perspectives},
journal = {Bulletin de l'Académie Nationale de Médecine},
volume = {208},
number = {5},
pages = {536-547},
year = {2024},
issn = {0001-4079},
doi = {https://doi.org/10.1016/j.banm.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001407924000943},
author = {Bernard Nordlinger and Claude Kirchner and Olivier {de Fresnoye}},
abstract = {Résumé
La santé est un des domaines majeurs d’application des technologies dites d’intelligence artificielle. Tous les domaines de la santé et toutes les spécialités sont concernés. Les systèmes d’intelligence artificielle générative (SIAgen) impressionnent par leur capacité à produire en quelques secondes des textes souvent pertinents, mais aussi parfois erronés. Leurs champs d’applications dans le domaine de la santé sont vastes et peuvent aller de l’aide à la rédaction de notes d’information à la rédaction de thèses ou de projets de programme de recherche. Pour les utiliser à bon escient il est important d’en connaître les principes de fonctionnement. Les SIAgen fonctionnent à partir d’auto-apprentissage basé sur un nombre extrêmement élevé d’exemples, ce qui est très différent de l’approche humaine, qui s’appuie sur l’expérience, le contexte et un système de valeurs. Ils génèrent des textes avec une grande rapidité mais ne sont pas entraînés à rechercher ou à dire la vérité. Une validation humaine est donc toujours nécessaire. Par ce rapport, l’Académie nationale de médecine explicite plusieurs de ces avancées pour la santé, décrit les enjeux d’éthique associés et recommande des points d’actions à mettre en œuvre sans délai.
Summary
Healthcare is one of the major application fields of Artificial Intelligence technologies. All areas of healthcare and all specialties are concerned. Generative Artificial Intelligence systems are impressive in their ability to produce texts in a matter of seconds, often relevant, but sometimes erroneous. They can be used in a wide range of healthcare applications, from helping to write briefing notes to drafting theses and research programs. To use them properly, it is important to understand how they work. Large Language Models use neural networks trained on massive amounts of text data, which is very different from the human, experience-based approach. They generate language but are not trained to tell or search for the truth. Human validation is therefore always necessary. Through this report, the Académie nationale de médecine explains the resulting progress and discoveries for health, describes associated ethical issues and recommends action points to be implemented without delay.}
}
@article{HANDLER2024102811,
title = {Large language models present new questions for decision support},
journal = {International Journal of Information Management},
volume = {79},
pages = {102811},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102811},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000598},
author = {Abram Handler and Kai R. Larsen and Richard Hackathorn},
keywords = {Decision support systems, Generative artificial intelligence, Large language models, Natural language processing, Business intelligence},
abstract = {Large language models (LLMs) have proven capable of assisting with many aspects of organizational decision making, such as helping to collect information from databases and helping to brainstorm possible courses of action ahead of making a choice. We propose that broad adoption of these technologies introduces new questions in the study of decision support systems, which assist people with complex and open-ended choices in business. Where traditional study of decision support has focused on bespoke tools to solve narrow problems in specific domains, LLMs offer a general-purpose decision support technology which can be applied in many contexts. To organize the wealth of new questions which result from this shift, we turn to a classic framework from Herbert Simon, which proposes that decision making requires collecting evidence, considering alternatives, and finally making a choice. Working from Simon’s framework, we describe how LLMs introduce new questions at each stage of this decision-making process. We then group new questions into three overarching themes for future research, centered on how LLMs will change individual decision making, how LLMs will change organizational decision making, and how to design new decision support technologies which make use of the new capabilities of LLMs.}
}
@article{PFLEDERER2025e772,
title = {Development of an In-House Application that Uses Generative AI to Summarize Oncology Histories},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {123},
number = {1, Supplement },
pages = {e772-e773},
year = {2025},
note = {ASTRO 2025: 67th Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2025.06.3239},
url = {https://www.sciencedirect.com/science/article/pii/S0360301625038441},
author = {T. Pflederer and Z. Zhang and E. Covington and L. Higgins and J.D. Nieto and C. Mayo and J.R. Evans},
abstract = {Purpose/Objective(s)
While the development of the electronic health record (EHR) has led to improvements in patient care and quality, EHR systems have also led to increased physician time burden for documentation. Oncology histories are complex - generating accurate, extensive histories by gathering data manually scattered throughout the EHR contributes significantly to physician workload prior to meeting the patient in consultation. Generative artificial intelligence (GenAI) has been implemented to improve efficiency, with examples including but not limited to scribing of clinical visits. We aim to utilize GenAI to automate the generation of accurate, complex oncology histories prior to initial consultation.
Materials/Methods
We developed an in-house application that pulls pertinent elements of an oncology history (imaging, pathology, clinical notes from specific subspecialties, etc.) from the enterprise EHR reporting database in health care software and summarizes it in a succinct format via an institutionally sponsored OpenAI-compatible application programming interface. We used a prompt engineering approach to distill the information into a condensed and readable format. The histories are organized into a chronological format. Prompts were iteratively developed and tailored for each oncologic disease site. For this study we initially focused on a small retrospective cohort of early-stage lung cancer and localized prostate cancer patients.
Results
We crafted 11 prompts for each component of an early-stage lung cancer oncologic history and 5 prompts for localized prostate cancer. We found that prompts asking for summarization, rather than interpretation, subjectively led to fewer errors. We found that hallucinations were possible – for example, if a radiology report does not comment on lymph nodes, this could be misinterpreted by AI as there being no evidence of lymphadenopathy. Errors like this were avoided if explicit instructions were included to only comment on what is stated in the radiology report. Multiple iterations of these prompts will be required and recorded as our retrospective patient population grows.
Conclusion
We developed a proof-of-concept GenAI custom software utility for summarizing oncology histories. We plan to continue prompt engineering to expand our retrospective cohort to those with more complex oncologic histories. Our preliminary results highlight the importance of prompt engineering to clinically optimize results from current generations of GenAI. We plan on testing, scoring, and modifying this software with real-time physician input for a larger prospective patient cohort in our department. As this is developed further, our goal is to significantly reduce the pre-consultation EHR burden on physicians.}
}
@article{SHIN2025108662,
title = {Artificial intelligence versus clinical judgement: how accurately do generative models reflect CNS guidelines for chiari malformation?},
journal = {Clinical Neurology and Neurosurgery},
volume = {248},
pages = {108662},
year = {2025},
issn = {0303-8467},
doi = {https://doi.org/10.1016/j.clineuro.2024.108662},
url = {https://www.sciencedirect.com/science/article/pii/S0303846724005493},
author = {David Shin and Hyunah Park and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Justin Dye and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Chiari malformation, Guidelines},
abstract = {Objective
This study investigated the response and readability of generative artificial intelligence (AI) models to questions and recommendations proposed by the 2023 Congress of Neurological Surgeons (CNS) guidelines for Chiari 1 malformation.
Methods
Thirteen questions were generated from CNS guidelines and asked to Perplexity, ChatGPT 4o, Microsoft Copilot, and Google Gemini. AI answers were divided into two categories, "concordant" and "non-concordant," according to their alignment with current CNS guidelines. Non-concordant answers were sub-categorized as “insufficient” or “over-conclusive.” Responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, SMOG (Simple Measure of Gobbledygook) Index, and Flesch Reading Ease test.
Results
Perplexity displayed the highest concordance rate of 69.2 %, with non-concordant responses classified as 0 % insufficient and 30.8 % over-conclusive. ChatGPT 4o had the lowest concordance rate at 23.1 %, with 0 % insufficient and 76.9 % over-conclusive classifications. Copilot showed a 61.5 % concordance rate, with 7.7 % insufficient and 30.8 % over-conclusive. Gemini demonstrated a 30.8 % concordance rate, with 7.7 % insufficient and 61.5 % as over-conclusive. Flesch-Kincaid Grade Level scores ranged from 14.48 (Gemini) to 16.48 (Copilot), Gunning Fog Index scores varied between 16.18 (Gemini) and 18.8 (Copilot), SMOG Index scores ranged from 16 (Gemini) to 17.54 (Copilot), and Flesch Reading Ease scores were low across all models, with Gemini showing the highest mean score of 21.3.
Conclusion
Perplexity and Copilot emerged as the best-performing for concordance, while ChatGPT and Gemini displayed the highest over-conclusive rates. All responses showcased high complexity and difficult readability. While AI can be valuable in certain aspects of clinical practice, the low concordance rates show that AI should not replace clinician judgement.}
}
@article{SAPKOTA2024100614,
title = {Synthetic meets authentic: Leveraging LLM generated datasets for YOLO11 and YOLOv10-based apple detection through machine vision sensors},
journal = {Smart Agricultural Technology},
volume = {9},
pages = {100614},
year = {2024},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2024.100614},
url = {https://www.sciencedirect.com/science/article/pii/S2772375524002193},
author = {Ranjan Sapkota and Zhichao Meng and Manoj Karkee},
keywords = {Large language model, YOLO11, YOLOv10, Generative artificial intelligence, Text-to-image generation, Machine learning, Deep learning, YOLO, You Only Look Once, LLM},
abstract = {Training machine learning (ML) models for artificial intelligence (AI) and computer vision-based object detection process typically requires large, labeled datasets, a process often burdened by significant human effort and high costs associated with imaging systems and image acquisition. This research aimed to simplify image data collection for object detection in orchards by avoiding traditional fieldwork with different imaging sensors. Utilizing OpenAI's DALLE, a large language model (LLM) for realistic image generation, we generated and annotated a cost-effective dataset. This dataset, exclusively generated by LLM, was then utilized to train two state-of-the-art deep learning models: YOLOV10 and YOLO11. The YOLO11 model for apple detection was trained with its five configurations (YOLO11n, YOLO11 s, YOLO11 m, YOLO11l and YOLO11x), and YOLOv10 model with its six configurations (YOLOv10n, YOLOv10 s, YOLOv10 m, YOLOv10b, YOLOv10l and YOLOv10x), which was then tested with real-world (outdoor orchard) images captured by a digital (Nikon D5100) camera and a consumer RGB-D camera (Microsoft Azure Kinect). YOLO11 outperformed YOLOv10 as YOLO11x and YOLO11n exhibited superior precision of 0.917 and 0.916, respectively. Furthermore, YOLO11l demonstrated the highest recall among its counterparts, achieving a recall of 0.889. Likewise, the YOLO11n variant excelled in terms of mean average precision (mAP@50), achieving the highest value of 0.958. Validation tests against actual images collected through a digital camera (Nikon D5100) over Scilate apple variety in a commercial orchard environment showed a highest precision of 0.874 for YOLO11 s, recall of 0.877 for YOLO11l and mAP@50 of 0.91 for YOLO11x. Additionally, validation test against actual images collected through a Microsoft Azure camera over the same orchard showed a highest precision, recall and mAP@50 respectively of 0.924, 0.781 and 0.855 with YOLO11x. All variants of YOLO11 surprisingly demonstrated a pre-processing time of just 0.2 milliseconds (ms), which was faster than any variant of YOLOv10. The fastest inference time for the YOLO11n model using the training dataset generated by the language model was 3.2 ms, while YOLOv10n, fastest among YOLOv10 variants, had a longer inference time of 5.5 ms. Likewise, the fastest inference time for the sensor-based images was 7.1 ms (for Nikon D5100 camera images) and 4.7 ms (for Azure images) with YOLO11n. This study presents a pathway for generating large image datasets using LLM in challenging agricultural fields with minimal or no labor-intensive efforts in field data-collection, which could accelerate the development and deployment of computer vision and robotic technologies in orchard environments.}
}
@article{WIEDENMANN2024100591,
title = {An Immunofluorescence-Guided Segmentation Model in Hematoxylin and Eosin Images Is Enabled by Tissue Artifact Correction Using a Cycle-Consistent Generative Adversarial Network},
journal = {Modern Pathology},
volume = {37},
number = {11},
pages = {100591},
year = {2024},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100591},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224001716},
author = {Marcel Wiedenmann and Mariya Barch and Patrick S. Chang and Jennifer Giltnane and Tyler Risom and Andries Zijlstra},
keywords = {cross-modality learning, cycle-consistent generative adversarial network, deep learning, digital pathology, generative adversarial network, generative artificial intelligence, image segmentation},
abstract = {Despite recent advances, the adoption of computer vision methods into clinical and commercial applications has been hampered by the limited availability of accurate ground truth tissue annotations required to train robust supervised models. Generating such ground truth can be accelerated by annotating tissue molecularly using immunofluorescence (IF) staining and mapping these annotations to a post-IF hematoxylin and eosin (H&E) (terminal H&E) stain. Mapping the annotations between IF and terminal H&E increases both the scale and accuracy by which ground truth could be generated. However, discrepancies between terminal H&E and conventional H&E caused by IF tissue processing have limited this implementation. We sought to overcome this challenge and achieve compatibility between these parallel modalities using synthetic image generation, in which a cycle-consistent generative adversarial network was applied to transfer the appearance of conventional H&E such that it emulates terminal H&E. These synthetic emulations allowed us to train a deep learning model for the segmentation of epithelium in terminal H&E that could be validated against the IF staining of epithelial-based cytokeratins. The combination of this segmentation model with the cycle-consistent generative adversarial network stain transfer model enabled performative epithelium segmentation in conventional H&E images. The approach demonstrates that the training of accurate segmentation models for the breadth of conventional H&E data can be executed free of human expert annotations by leveraging molecular annotation strategies such as IF, so long as the tissue impacts of the molecular annotation protocol are captured by generative models that can be deployed prior to the segmentation process.}
}
@article{NAZAR2025,
title = {How to Design, Create, and Evaluate an Instruction-Tuning Dataset for Large Language Model Training in Health Care: Tutorial From a Clinical Perspective},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70481},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003863},
author = {Wojciech Nazar and Grzegorz Nazar and Aleksandra Kamińska and Ludmila Danilowicz-Szymanowicz},
keywords = {generative artificial intelligence, large language models, instruction-tuning datasets, tutorials, evaluation framework, health care},
abstract = {High-quality data are critical in health care, forming the cornerstone for accurate diagnoses, effective treatment plans, and reliable conclusions. Similarly, high-quality datasets underpin the development and performance of large language models (LLMs). Among these, instruction-tuning datasets (ITDs) used for instruction fine-tuning have been pivotal in enhancing LLM performance and generalization capabilities across diverse tasks. This tutorial provides a comprehensive guide to designing, creating, and evaluating ITDs for health care applications. Written from a clinical perspective, it aims to make the concepts accessible to a broad audience, especially medical practitioners. Key topics include identifying useful data sources, defining the characteristics of well-designed datasets, and crafting high-quality instruction-input-output examples. We explore practical approaches to dataset construction, examining the advantages and limitations of 3 primary methods: fully manual preparation by expert annotators, fully synthetic generation using artificial intelligence (AI), and an innovative hybrid approach in which experts draft the initial dataset and AI generates additional data. Moreover, we discuss strategies for metadata selection and human evaluation to ensure the quality and effectiveness of ITDs. By integrating these elements, this tutorial provides a structured framework for establishing ITDs. It bridges technical and clinical domains, supporting the continued interdisciplinary advancement of AI in medicine. Additionally, we address the limitations of current practices and propose future directions, emphasizing the need for a global, unified framework for ITDs. We also argue that artificial general intelligence (AGI), if realized, will not replace empirical research in medicine. AGI will depend on human-curated datasets to process and apply medical knowledge. At the same time, ITDs will likely remain the most effective method of supplying this knowledge to AGI, positioning them as a critical tool in AI-driven health care.}
}
@article{KWON2024114570,
title = {Sentiment analysis of the United States public support of nuclear power on social media using large language models},
journal = {Renewable and Sustainable Energy Reviews},
volume = {200},
pages = {114570},
year = {2024},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2024.114570},
url = {https://www.sciencedirect.com/science/article/pii/S136403212400296X},
author = {O. Hwang Kwon and Katie Vu and Naman Bhargava and Mohammed I. Radaideh and Jacob Cooper and Veda Joynt and Majdi I. Radaideh},
keywords = {Sentiment analysis, Natural language processing, Nuclear power, Public policy, Social media, Large language models},
abstract = {This study utilized large language models (LLMs) to analyze public sentiment in the United States (US) regarding nuclear power on social media, focusing on X/Twitter, considering climate change challenges and advancements in nuclear power technology. Approximately, 1.26 million nuclear tweets from 2008–2023 were examined to fine-tune LLMs for sentiment classification. We found the crucial role of accurate data labeling for model performance, with potential implications for a 15% improvement, achieved through high-confidence labels. LLMs demonstrated better performance compared to traditional machine learning classifiers, with reduced susceptibility to overfitting and up to 96% classification accuracy. LLMs are used to segment the US public tweets into policy and energy-related categories, revealing that 68% are politically themed. Policy tweets tended to convey negative sentiment, often reflecting opposing political perspectives and focusing on nuclear deals and international relations. Energy-related tweets covered diverse topics with predominantly neutral to positive sentiment, indicating broad support for nuclear power in 48 out of 50 US states. The US public positive sentiments toward nuclear power stemmed from its high power density, reliability regardless of weather conditions, environmental benefits, application versatility, and recent innovations and advancements in both fission and fusion technologies. Negative sentiments primarily focused on waste management, high capital costs, and safety concerns. The neutral campaign highlighted global nuclear facts and advancements, with varying tones leaning towards positivity or negativity. An interesting neutral theme was the advocacy for the combined use of renewable and nuclear energy to attain net-zero goals.}
}
@article{PAN2025100991,
title = {Effects of GenAI-empowered interactive support on university EFL students' self-regulated strategy use and engagement in reading},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100991},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2024.100991},
url = {https://www.sciencedirect.com/science/article/pii/S1096751624000538},
author = {Mengru Pan and Chun Lai and Kai Guo},
keywords = {Artificial intelligence, Self-regulated learning, EFL learners, Reading engagement, Chatbots},
abstract = {Reading poses challenges for learners of English as a foreign language (EFL), as it requires strategic engagement with the text through an interactive meaning-making process. Self-regulated learning (SRL) training, which helps learners develop the ability to make strategic efforts to manage their reading process and maintain engagement in reading, has been increasingly used to assist EFL learners. However, one limitation of existing SRL training is the lack of interactive personalised support tailored to the specific needs of individual students. Recent developments in generative artificial intelligence (GenAI) may help address this limitation. This study explores how interactive personalised SRL support via a GenAI chatbot might affect university EFL learners' self-regulated strategy use and engagement in reading. Sixty-one Chinese EFL students from two classes at a university received a 45-min training session on SRL in reading and then engaged in a 12-week self-directed reading using an online reading platform embedded with SRL support. One class (the experimental group, N = 31) had access to the chatbot on the platform to support their self-regulated reading, while the other class (the control group, N = 30) received no chatbot assistance on the platform. Self-regulated reading strategy use and reading engagement were assessed through pre- and post-questionnaires, log data on the platform, and semi-structured interviews. It was found that the intervention significantly improved students' self-regulated reading strategy use and reading engagement, indicating the positive effect of GenAI-enabled interactive personalised SRL support. This study substantiates the value of interactive SRL support in the context of EFL reading.}
}
@article{CAHYANA2024100078,
title = {Application of ChatGPT in soil science research and the perceptions of soil scientists in Indonesia},
journal = {Artificial Intelligence in Geosciences},
volume = {5},
pages = {100078},
year = {2024},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2666544124000194},
author = {Destika Cahyana and Agus Hadiarto and  Irawan and Diah Puspita Hati and Mira Media Pratamaningsih and Vicca Karolinoerita and Anny Mulyani and  Sukarman and Muhammad Hikmat and Fadhlullah Ramadhani and Rachmat Abdul Gani and Edi Yatno and R. Bambang Heryanto and  Suratman and Nuni Gofar and Abraham Suriadikusumah},
keywords = {Artificial intelligence, ChatGPT, Soil science, Tools, Paradigm},
abstract = {Since its arrival in late November 2022, ChatGPT-3.5 has rapidly gained popularity and significantly impacted how research is planned, conducted, and published using a generative artificial intelligence approach. ChatGPT-4 was released four months later and became more popular in November 2023. However, there is little study about the perception of scientists of these chatbots, especially in soil science. This article presents the new findings of a brief research investigating soil scientists' responses and perceptions towards chatbots in Indonesia. This artificial intelligence application facilitates conversation-based interactions in text format. The study evaluated ten ChatGPT answers to fundamental questions in soil science, which has developed into a normal science with a mutually agreed-upon paradigm. The evaluation was carried out by seven soil scientists recognized for their expertise in Indonesia, using a scale of 1–100. In addition, a questionnaire was distributed to soil scientists at the National Research and Innovation Agency of the Republic of Indonesia (BRIN), universities, and Indonesian Soil Science Society (HITI) members to gauge their perception of ChatGPT's presence in the research field. The study results indicate that the scores of ChatGPT answers range from 82.99 to 92.24. ChatGPT-4 is better than both the paid and free versions of ChatGPT-3.5. There is no significant difference between the English and Indonesian versions of ChatGPT-4.0. However, the perception of general soil scientists about the level of trust is only 55%. Furthermore, 80% of soil scientists believe that chatbots can only be used as digital tools to assist in soil science research and cannot be used without the involvement of soil scientists.}
}
@article{MAHMOUDI2025,
title = {Critical Assessment of Large Language Models’ (ChatGPT) Performance in Data Extraction for Systematic Reviews: Exploratory Study},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/68097},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000705},
author = {Hesam Mahmoudi and Doris Chang and Hannah Lee and Navid Ghaffarzadegan and Mohammad S Jalali},
keywords = {large language models, generative artificial intelligence, systematic reviews, evidence synthesis, human-AI collaboration},
abstract = {Background
Systematic literature reviews (SLRs) are foundational for synthesizing evidence across diverse fields and are especially important in guiding research and practice in health and biomedical sciences. However, they are labor intensive due to manual data extraction from multiple studies. As large language models (LLMs) gain attention for their potential to automate research tasks and extract basic information, understanding their ability to accurately extract explicit data from academic papers is critical for advancing SLRs.
Objective
Our study aimed to explore the capability of LLMs to extract both explicitly outlined study characteristics and deeper, more contextual information requiring nuanced evaluations, using ChatGPT (GPT-4).
Methods
We screened the full text of a sample of COVID-19 modeling studies and analyzed three basic measures of study settings (ie, analysis location, modeling approach, and analyzed interventions) and three complex measures of behavioral components in models (ie, mobility, risk perception, and compliance). To extract data on these measures, two researchers independently extracted 60 data elements using manual coding and compared them with the responses from ChatGPT to 420 queries spanning 7 iterations.
Results
ChatGPT’s accuracy improved as prompts were refined, showing improvements of 33% and 23% between the initial and final iterations for extracting study settings and behavioral components, respectively. In the initial prompts, 26 (43.3%) of 60 ChatGPT responses were correct. However, in the final iteration, ChatGPT extracted 43 (71.7%) of the 60 data elements, showing better performance in extracting explicitly stated study settings (28/30, 93.3%) than in extracting subjective behavioral components (15/30, 50%). Nonetheless, the varying accuracy across measures highlighted its limitations.
Conclusions
Our findings underscore LLMs’ utility in extracting basic as well as explicit data in SLRs by using effective prompts. However, the results reveal significant limitations in handling nuanced, subjective criteria, emphasizing the necessity for human oversight.}
}
@article{JOSHI2025100317,
title = {Harnessing the potential of generative AI in digital marketing using the Behavioral Reasoning Theory approach},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100317},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100317},
url = {https://www.sciencedirect.com/science/article/pii/S266709682400106X},
author = {Sujata Joshi and Sonali Bhattacharya and Pankaj Pathak and N.A. Natraj and Juhi Saini and Soumya Goswami},
keywords = {Generative AI (GAI), Digital marketing, Customer experience, Personalization, ChatGPT, Behavioral Reasoning Theory (BRT)},
abstract = {Generative AI (GAI) is an upcoming field and its impact on marketing is indisputable. Very little evidence in academic literature is present regarding the factors affecting the usage of GAI in Digital Marketing (DM). This study addresses this gap by exploring the key drivers and barriers associated with using GAI in DM. Leveraging Behavioral Reasoning Theory (BRT), the research validates prior findings and introduces a conceptual model outlining factors that shape attitudes toward adopting GAI in DM to enhance customer experiences. A qualitative inductive approach was undertaken by conducting expert interviews to investigate the “reasons for” and ‘reasons against’ using GAI in DM and its impact on customer experience. The transcripts generated were manually coded and a deductive thematic analysis was done using the BRT as the theoretical framework. The findings indicate four significant themes for adopting GAI in digital marketing viz: innovation, creative communication and content creation, speed, efficiency and timesaving, enhanced customization and personalization; predictive analytics and simulation. It also indicates five significant themes related to the key barriers were also identified viz: ethics and infringement of Intellectual Property; security and deepfake; learning ecosystem for the adoption of new technology; quality of data; reduced manpower requirement. The study further highlights how GAI influences customer experience in DM. This study contributes to the field by (a) proposing a conceptual framework for applying GAI in DM to improve customer experiences, (b) examining the drivers and challenges of GAI adoption in DM, and (c) presenting a research agenda to guide future studies. These insights offer value to researchers, marketing practitioners, and academics navigating the dynamic intersection of GAI and Digital Marketing}
}
@article{HASSANIPOUR2024,
title = {The Ability of ChatGPT in Paraphrasing Texts and Reducing Plagiarism: A Descriptive Analysis},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/53308},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000783},
author = {Soheil Hassanipour and Sandeep Nayak and Ali Bozorgi and Mohammad-Hossein Keivanlou and Tirth Dave and Abdulhadi Alotaibi and Farahnaz Joukar and Parinaz Mellatdoust and Arash Bakhshi and Dona Kuriyakose and Lakshmi D Polisetty and Mallika Chimpiri and Ehsan Amini-Salehi},
keywords = {ChatGPT, paraphrasing, text generation, prompts, academic journals, plagiarize, plagiarism, paraphrase, wording, LLM, LLMs, language model, language models, prompt, generative, artificial intelligence, NLP, natural language processing, rephrase, plagiarizing, honesty, integrity, texts, text, textual, generation, large language model, large language models},
abstract = {Background
The introduction of ChatGPT by OpenAI has garnered significant attention. Among its capabilities, paraphrasing stands out.
Objective
This study aims to investigate the satisfactory levels of plagiarism in the paraphrased text produced by this chatbot.
Methods
Three texts of varying lengths were presented to ChatGPT. ChatGPT was then instructed to paraphrase the provided texts using five different prompts. In the subsequent stage of the study, the texts were divided into separate paragraphs, and ChatGPT was requested to paraphrase each paragraph individually. Lastly, in the third stage, ChatGPT was asked to paraphrase the texts it had previously generated.
Results
The average plagiarism rate in the texts generated by ChatGPT was 45% (SD 10%). ChatGPT exhibited a substantial reduction in plagiarism for the provided texts (mean difference −0.51, 95% CI −0.54 to −0.48; P<.001). Furthermore, when comparing the second attempt with the initial attempt, a significant decrease in the plagiarism rate was observed (mean difference −0.06, 95% CI −0.08 to −0.03; P<.001). The number of paragraphs in the texts demonstrated a noteworthy association with the percentage of plagiarism, with texts consisting of a single paragraph exhibiting the lowest plagiarism rate (P<.001).
Conclusion
Although ChatGPT demonstrates a notable reduction of plagiarism within texts, the existing levels of plagiarism remain relatively high. This underscores a crucial caution for researchers when incorporating this chatbot into their work.}
}
@article{QORICH2025128405,
title = {Detection of artificial intelligence-generated essays for academic assessment integrity using large language models},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128405},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128405},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502024X},
author = {Mohammed Qorich and Rajae {El Ouazzani}},
keywords = {Artificial intelligence (AI), AI-Generated essays detection, Automatic optimization, ChatGPT, Education, Large language models (LLMs), Plagiarism detection},
abstract = {Across various fields of human life, the lightning adoption of generative artificial intelligence (AI) tools is driven by their ease of use and ability to produce high-quality outputs, transforming communication and productivity. However, the growing popularity and influence of models such as ChatGPT have raised concerns in education regarding academic integrity, as AI-generated content challenges the authenticity of student work and complicates traditional assessment practices. Existing plagiarism detection tools, such as Turnitin and GPTZero, attempt to identify AI-generated content; however, their reliability remains limited, as most struggle to accurately differentiate between human and AI essays. To address existing tools limitations, we propose a novel detection model leveraging three large language models (LLMs): Generative Pre-trained Transformer 2 (GPT-2), Robustly Optimized BERT Pretraining Approach (RoBERTa), and Bidirectional and Auto-Regressive Transformers (BART). We first fine-tuned each model on two large-scale datasets to evaluate their effectiveness in distinguishing between human and AI-generated essays. To further enhance the performance, we applied both manual and automated hyperparameter optimization techniques, including Random Search, Grid Search, and Bayesian Optimization. Building on these experiments, we developed our BART-CNN model, which incorporates the best-performing BART configuration with an additional convolutional head classifier. Our BART-CNN model achieved impressive Macro F1-scores of 99.78 % and 98.10 % on the Kaggle and Hugging Face datasets, respectively, and demonstrated significant performance gains over baseline methods in cross-domain validation. Our study offers a critical advancement in AI plagiarism detection, helping to uphold academic standards and the assessment quality in an evolving AI landscape.}
}
@article{NODA2025,
title = {Exploring Generative Pre-Trained Transformer-4-Vision for Nystagmus Classification: Development and Validation of a Pupil-Tracking Process},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/70070},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005001},
author = {Masao Noda and Ryota Koshu and Reiko Tsunoda and Hirofumi Ogihara and Tomohiko Kamo and Makoto Ito and Hiroaki Fushiki},
keywords = {nystagmus, GPT-4Vision, generative AI, deep learning, dizziness, artificial intelligence},
abstract = {Background
Conventional nystagmus classification methods often rely on subjective observation by specialists, which is time-consuming and variable among clinicians. Recently, deep learning techniques have been used to automate nystagmus classification using convolutional and recurrent neural networks. These networks can accurately classify nystagmus patterns using video data. However, associated challenges including the need for large datasets when creating models, limited applicability to address specific image conditions, and the complexity associated with using these models.
Objective
This study aimed to evaluate a novel approach for nystagmus classification that used the Generative Pre-trained Transformer 4 Vision (GPT-4V) model, which is a state-of-the-art large-scale language model with powerful image recognition capabilities.
Methods
We developed a pupil-tracking process using a nystagmus-recording video and verified the optimization model’s accuracy using GPT-4V classification and nystagmus recording. We tested whether the created optimization model could be evaluated in six categories of nystagmus: right horizontal, left horizontal, upward, downward, right torsional, and left torsional. The traced trajectory was input as two-dimensional coordinate data or an image, and multiple in-context learning methods were evaluated.
Results
The developed model showed an overall classification accuracy of 37% when using pupil-traced images and a maximum accuracy of 24.6% when pupil coordinates were used as input. Regarding orientation, we achieved a maximum accuracy of 69% for the classification of horizontal nystagmus patterns but a lower accuracy for the vertical and torsional components.
Conclusions
We demonstrated the potential of versatile vertigo management in a generative artificial intelligence model that improves the accuracy and efficiency of nystagmus classification. We also highlighted areas for further improvement, such as expanding the dataset size and enhancing input modalities, to improve classification performance across all nystagmus types. The GPT-4V model validated only for recognizing still images can be linked to video classification and proposed as a novel method.}
}
@article{YUNG2025,
title = {Examining How Technology Supports Shared Decision-Making in Oncology Consultations: Qualitative Thematic Analysis},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/70827},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000679},
author = {Alan Yung and Tim Shaw and Judy Kay and Anna Janssen},
keywords = {digital health, patient-centered care, person-centered care, shared decision-making, cancer care, oncology, artificial intelligence, AI},
abstract = {Background
Commonly used digital health technologies, such as electronic health record systems and patient portals as well as custom-built digital decision aids, have the potential to enhance person-centered shared decision-making (SDM) in cancer care. SDM is a 2-way exchange of information between at least a clinician and the patient and a shared commitment to make informed decisions. However, there is little evidence in the literature on how technologies are used for SDM or how best they can be designed and integrated into workflows and practice. This may be due to the nature of SDM, which is fundamentally human interactions and conversations that produce desired human outcomes. Therefore, technology must be nonintrusive while supporting the human decision-making process.
Objective
This study examined how digital technologies can help cancer care professionals improve SDM in oncology consultations.
Methods
Health care professionals who treat patients with cancer were invited to participate in online co-design focus group meetings. During these sessions, they shared their experiences using digital technologies for SDM and provided suggestions to improve their use of digital technologies. The session recordings were transcribed and then analyzed using qualitative thematic analysis. The 3-talk SDM model, which consists of 3 steps—team talk, option talk, and decision talk—was used as the guiding framework. This approach was chosen because the 3-talk SDM model has been adopted in Australia. The researchers walked the participants through the SDM model and discussed their routine clinical workflows.
Results
In total, 9 health care professionals with experience treating patients with cancer and using technologies participated in the study. Two focus groups and 2 interviews were conducted in 2024. Three themes and 7 subthemes were generated from the thematic analysis. The findings indicated that various digital technologies, such as electronic health record systems, mobile devices, and patient portals, are used by cancer care professionals to help improve patients’ understanding of their disease and available care options. Digital technologies can both improve and undermine SDM. Current systems are generally not designed to support SDM. Key issues such as data integration and interoperability between systems negatively impact the ability of digital technologies to support SDM. Emerging technologies such as generative artificial intelligence were discussed as potential facilitators of SDM by automating information gathering and sharing with patients and between health professionals.
Conclusions
This research indicates that digital technologies have the potential to impact SDM in oncology consultations. However, this potential has not yet been fully realized, and significant modifications are required to optimize their usefulness in person-centered SDM. Although technology can facilitate information sharing and improve the efficiency of consultation workflows, it is only part of a complex human communication process that needs support from multiple sources, including the broader multidisciplinary cancer team.}
}
@article{CURRY2024100082,
title = {Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT},
journal = {Applied Corpus Linguistics},
volume = {4},
number = {1},
pages = {100082},
year = {2024},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2023.100082},
url = {https://www.sciencedirect.com/science/article/pii/S2666799123000424},
author = {Niall Curry and Paul Baker and Gavin Brookes},
keywords = {ChatGPT, Corpus linguistics, Discourse analysis, Generative AI, Qualitative analysis},
abstract = {This paper explores the potential of generative artificial intelligence technology, specifically ChatGPT, for advancing corpus approaches to discourse studies. The contribution of artificial intelligence technologies to linguistics research has been transformational, both in the contexts of corpus linguistics and discourse analysis. However, shortcomings in the efficacy of such technologies for conducting automated qualitative analysis have limited their utility for corpus approaches to discourse studies. Acknowledging that new technologies in data analysis can replace and supplement existing approaches, and in view of the potential affordances of ChatGPT for automated qualitative analysis, this paper presents three replication case studies designed to investigate the applicability of ChatGPT for supporting automated qualitative analysis within studies using corpus approaches to discourse analysis. The findings indicate that, generally, ChatGPT performs reasonably well when semantically categorising keywords; however, as the categorisation is based on decontextualised keywords, the categories can appear quite generic, limiting the value of such an approach for analysing corpora representing specialised genres and/or contexts. For concordance analysis, ChatGPT performs poorly, as the results include false inferences about the concordance lines and, at times, modifications of the input data. Finally, for function-to-form analysis, ChatGPT also performs poorly, as it fails to identify and analyse direct and indirect questions. Overall, the results raise questions about the affordances of ChatGPT for supporting automated qualitative analysis within corpus approaches to discourse studies, signalling issues of repeatability and replicability, ethical challenges surrounding data integrity, and the challenges associated with using non-deterministic technology for empirical linguistic research.}
}
@article{DUIVENVOORDE2025106141,
title = {Generative AI and the future of marketing: A consumer protection perspective},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106141},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106141},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000148},
author = {Bram Duivenvoorde},
keywords = {Generative AI, Marketing, Synthetic advertising, Consumer protection, Unfair commercial practices, Artificial Intelligence Act, Digital Services Act},
abstract = {Generative AI has the potential to be the biggest disruption in marketing since the emergence of digital commerce in the early 2000s. This article will focus on three ways in which generative AI is expected to change marketing. First, generative AI enables companies to automatically create advertising copy and images, potentially leading to significant cost reductions. Secondly, generative AI offers possibilities to improve and automate personalised marketing, potentially enabling companies to send the right persuasive message at the right time to each potential customer. Thirdly, generative AI potentially offers possibilities to market products to consumers via generative AI chatbots. These developments offer potential advantages but also bear risks for consumers. For example, deepfakes in advertising can mislead consumers, AI-generated personalised marketing can exploit consumer vulnerabilities, and B2C chatbots can deceive consumers by providing biased advice. This article shows that EU law does in principle provide protection to consumers in relation to AI-generated marketing, but is also likely to fall short in effectively protecting consumers against the identified risks in several ways.}
}
@article{PRUSTY2024111714,
title = {Enhancing medical image classification with generative AI using latent denoising diffusion probabilistic model and wiener filtering approachImage 1},
journal = {Applied Soft Computing},
volume = {161},
pages = {111714},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111714},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624004885},
author = {Manas Ranjan Prusty and Rohit Madhavan Sudharsan and Philip Anand},
keywords = {Latent Diffusion, Generative Modelling, Deep Learning, Synthetic Data Generation, Medical Imaging},
abstract = {In the evolving landscape of medical diagnostics, a paradigm shift is being catalysed by the advent of generative artificial intelligence. Medical X-ray, CT and MRI images are essential diagnostic tools used by healthcare professionals to assess various musculoskeletal conditions. However, obtaining a sufficient number of medical images for training deep learning models can be challenging due to limited access to labelled data. Hence, the authors propose a novel Latent diffusion process for synthesizing medical images that closely resemble real patient images, aiming to address the challenge of limited access to labelled data in medical diagnostics. Leveraging deep learning and generative modelling techniques, this method synthesizes high-fidelity images that closely mimic real patient scans. By introducing noise and subsequently training the model to denoise, the approach captures intricate patterns inherent in authentic medical images. Among the four datasets utilized, the Diabetes Retinopathy dataset demonstrates superior performance, achieving the highest Mean Structural Similarity Index (MSSIM) score of 0.57 (compared to the dataset baseline of 0.62) and an accuracy of 93.75% when passed through the proposed pipeline. The Cataract dataset, registered a MSSIM score of 0.51 (versus the dataset baseline of 0.53) and an accuracy score of 97.52%, while the Knee OA dataset follows closely with MSSIM and accuracy scores of 0.65 (in contrast to the dataset baseline of 0.63) and 68.66% respectively. The results obtained are then compared with the results generated by the other state of the art models.}
}
@article{EBNALIHARARI2025105701,
title = {A randomized controlled trial on evaluating clinician-supervised generative AI for decision support},
journal = {International Journal of Medical Informatics},
volume = {195},
pages = {105701},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105701},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624003642},
author = {Rayan {Ebnali Harari} and Abdullah Altaweel and Tareq Ahram and Madeleine Keehner and Hamid Shokoohi},
keywords = {Telemedicine, AI, ChatGPT, Clinician supervision of AI, Trust, Technology acceptance},
abstract = {Background
The integration of generative artificial intelligence (AI) as clinical decision support systems (CDSS) into telemedicine presents a significant opportunity to enhance clinical outcomes, yet its application remains underexplored.
Objective
This study investigates the efficacy of one of the most common generative AI tools, ChatGPT, for providing clinical guidance during cardiac arrest scenarios.
Methods
We examined the performance, cognitive load, and trust associated with traditional methods (paper guide), autonomous ChatGPT, and clinician-supervised ChatGPT, where a clinician supervised the AI recommendations. Fifty-four subjects without medical backgrounds participated in randomized controlled trials, each assigned to one of three intervention groups: paper guide, ChatGPT, or supervised ChatGPT. Participants completed a standardized CPR scenario using an Augmented Reality (AR) headset, and performance, physiological, and self-reported metrics were recorded.
Main Findings
Results indicate that the Supervised-ChatGPT group showed significantly higher decision accuracy compared to the paper guide and ChatGPT groups, although the scenario completion time was longer. Physiological data showed a reduced LF/HF ratio in the Supervised-ChatGPT group, suggesting potentially lower cognitive load. Trust in AI was also highest in the supervised condition. In one instance, ChatGPT suggested a risky option, highlighting the need for clinician supervision.
Conclusion
Our findings highlight the potential of supervised generative AI to enhance decision-making accuracy and user trust in emergency healthcare settings, despite trade-offs with response time. The study underscores the importance of clinician oversight and the need for further refinement of AI systems to improve safety. Future research should explore strategies to optimize AI supervision and assess the implementation of these systems in real-world clinical settings.}
}
@article{HUY2024100295,
title = {Appraisal model on how accounting data analytics impacts public sector sustainability reporting},
journal = {Sustainable Futures},
volume = {8},
pages = {100295},
year = {2024},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2024.100295},
url = {https://www.sciencedirect.com/science/article/pii/S2666188824001448},
author = {Pham Quang Huy and Vu Kien Phuc},
keywords = {Accounting information system, Artificial intelligence, Large language model, Internal control, Sustainability reporting},
abstract = {The current manuscript establishes and validates a conceptual framework that focuses on the correlation between accounting data analytics (ADA) and the quality of digital sustainability reporting (QDSR). Moreover, it aims to examine how the sustainable green internal control system (SGICS) facilitates the relationship between ADA and QDSR. The current manuscript employed a three-pronged methodology comprising of expert interviews, a literature review, and a self-administered survey, in sequential sequence. To determine the measuring scales and relevant concerns, the qualitative methodology originally involved conducting several semi-structured interviews with specialists and doing a thorough examination of the relevant literature. In the quantitative phase, statistical data were collected by two-wave paper-and-pencil surveys given to respondents in Vietnamese public sector organizations. The survey was conducted using a snowball and convenience sampling method. The data analysis was conducted utilizing the Partial Least Squares Structural Equation Modeling (PLS-SEM) technique with the assistance of SmartPLS 4.1.0.3. The statistical results validated the significantly positive connection between ADA and QDSR. This link was partially mediated by SGICS.}
}
@article{GORMAN2025A19,
title = {Generative AI Case Studies in Undergraduate Clinical Nutrition Education},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {125},
number = {10, Supplement },
pages = {A19},
year = {2025},
note = {2025 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2025.06.284},
url = {https://www.sciencedirect.com/science/article/pii/S2212267225006215},
author = {A. Gorman}
}
@article{YANG2024,
title = {Ascle—A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60601},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124006289},
author = {Rui Yang and Qingcheng Zeng and Keen You and Yujie Qiao and Lucas Huang and Chia-Chun Hsieh and Benjamin Rosand and Jeremy Goldwasser and Amisha Dave and Tiarnan Keenan and Yuhe Ke and Chuan Hong and Nan Liu and Emily Chew and Dragomir Radev and Zhiyong Lu and Hua Xu and Qingyu Chen and Irene Li},
keywords = {natural language processing, machine learning, deep learning, generative artificial intelligence, large language models, retrieval-augmented generation, healthcare},
abstract = {Background
Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to automate text processing. In the biomedical field, various toolkits for text processing exist, which have greatly improved the efficiency of handling unstructured text. However, these existing toolkits tend to emphasize different perspectives, and none of them offer generation capabilities, leaving a significant gap in the current offerings.
Objective
This study aims to describe the development and preliminary evaluation of Ascle. Ascle is tailored for biomedical researchers and clinical staff with an easy-to-use, all-in-one solution that requires minimal programming expertise. For the first time, Ascle provides 4 advanced and challenging generative functions: question-answering, text summarization, text simplification, and machine translation. In addition, Ascle integrates 12 essential NLP functions, along with query and search capabilities for clinical databases.
Methods
We fine-tuned 32 domain-specific language models and evaluated them thoroughly on 27 established benchmarks. In addition, for the question-answering task, we developed a retrieval-augmented generation (RAG) framework for large language models that incorporated a medical knowledge graph with ranking techniques to enhance the reliability of generated answers. Additionally, we conducted a physician validation to assess the quality of generated content beyond automated metrics.
Results
The fine-tuned models and RAG framework consistently enhanced text generation tasks. For example, the fine-tuned models improved the machine translation task by 20.27 in terms of BLEU score. In the question-answering task, the RAG framework raised the ROUGE-L score by 18% over the vanilla models. Physician validation of generated answers showed high scores for readability (4.95/5) and relevancy (4.43/5), with a lower score for accuracy (3.90/5) and completeness (3.31/5).
Conclusions
This study introduces the development and evaluation of Ascle, a user-friendly NLP toolkit designed for medical text generation. All code is publicly available through the Ascle GitHub repository. All fine-tuned language models can be accessed through Hugging Face.}
}
@article{ZHANG2025270,
title = {Knowledge Understanding and Citation Ability Improvement Strategy Based on End-to-end GenIR Model},
journal = {Procedia Computer Science},
volume = {261},
pages = {270-278},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.203},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925013055},
author = {Wenyan Zhang},
keywords = {End-To-End Genir Model, Knowledge Understanding, Citation Capability, Information Retrieval},
abstract = {In order to improve the machine’s knowledge understanding and citation capabilities in complex and heterogeneous information environments and ensure accuracy and efficiency, this paper constructs and optimizes an end-to-end GenIR model. The model combines the advantages of generative AI technology and information retrieval technology, aiming to automatically extract, understand and cite relevant knowledge from large amounts of text data. The paper first collects a large amount of text data in related fields, then preprocesses the data, and then builds an end-to-end GenIR model. The model is then trained and the model parameters are optimized using the back propagation algorithm. During the training process, the attention mechanism is used to enhance the model’s ability to capture key information, and adversarial training is used to improve the robustness of the model. After training, the model is fine-tuned. Experimental results show that the GenIR model reaches a maximum MAP value of 99.9% and also has significant advantages in nDCG. The average inference time is about 29% faster than the BM25 model, demonstrating dual optimization in accuracy and efficiency. This study successfully improves the machine’s knowledge understanding and citation capabilities in complex and heterogeneous information environments by building and optimizing an end-to-end GenIR model. It not only achieves optimization in accuracy and efficiency, but also provides a new solution for the field of information retrieval.}
}
@article{ZHANG2025115116,
title = {Automatic building energy model development and debugging using large language models agentic workflow},
journal = {Energy and Buildings},
volume = {327},
pages = {115116},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115116},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824012325},
author = {Liang Zhang and Vitaly Ford and Zhelun Chen and Jianli Chen},
keywords = {Building energy modeling, Complex system modeling, Large language model, Generative artificial intelligence, Agentic workflow},
abstract = {Building energy modeling (BEM) is a complex process that demands significant time and expertise, limiting its broader application in building design and operations. While Large Language Models (LLMs) agentic workflow have facilitated complex engineering processes, their application in BEM has not been specifically explored. This paper investigates the feasibility of automating BEM using LLM agentic workflow. We developed a generic LLM-planning-based workflow that takes a building description as input and generates an error-free EnergyPlus building energy model. Our robust workflow includes four core agents: 1) Building Description Pre-Processing, 2) IDF Object Information Extraction, 3) Single IDF Object Generator Suite, and 4) IDF Debugging Agent. These agents divide the complex tasks into manageable sub-steps, enabling LLMs to generate accurate and reliable results at each stage. The case study demonstrates the successful translation of a building description into an error-free EnergyPlus model for the iUnit modular building at the National Renewable Energy Laboratory. The effectiveness of our workflow surpasses: 1) naive prompt engineering, 2) other LLM-based workflows, and 3) manual modeling, in terms of accuracy, reliability, and time efficiency. The paper concludes with a discussion on the interplay between foundational models and LLM agent planning design, advocating for the use of fine-tuned, specialized models to advance this field.}
}
@article{RADTKE2025100350,
title = {Generative AI in academic writing: Does information on authorship impact learners’ revision behavior?},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100350},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100350},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400153X},
author = {Anna Radtke and Nikol Rummel},
keywords = {AI-assisted writing, Text revision, Generative AI, Academic writing, Collaborative writing},
abstract = {The role of generative artificial intelligence (AI) in education has expanded significantly over recent years. AI-based text generators such as ChatGPT provide an accessible and effective tool for learners, particularly in academic writing. While revision is considered an essential part of both individual and collaborative writing, research on the revision of AI-generated texts remains limited. However, with the growing adoption of generative AI in education, learners’ ability to effectively revise AI-generated content is likely to become increasingly important in the future. The aim of this study was to investigate whether learners exhibit different revision behaviors when presented with different information about the author of a text (peer vs. AI). We further examined the impact of learners’ prior experiences, attitudes, and gender on text revision. Therefore, N = 303 learners revised two different texts: one labeled as peer-written and the other as AI-generated. The results revealed that while learners invested less time in revising a text labeled as AI-generated, information about the author did not affect the number of areas identified as requiring improvement or the number of revisions made. Moreover, learners who indicated greater prior exposure to media reports about AI-based text generators, a higher level of trust in AI, and a tendency toward ‘loafing’ in AI-assisted writing spent less time revising a text labeled as AI-generated. Conversely, learners with more experience in academic writing identified more areas for improvement and made more extensive revisions, regardless of the labeled authorship.}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@incollection{TAKEDA20242689,
title = {Prediction Method for Reaction Yield of Deuteration of Polyfluoroperylene using Generative AI Techniques},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {2689-2694},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50449-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328824150449X},
author = {Kazuhiro Takeda and Naoya Ohtsuka and Toshiyasu Suzuki and Norie Momiyama},
keywords = {generative artificial intelligence, small data, prediction of reaction conditions, in-silico data generation, digitalization of organic molecules},
abstract = {Deuterated organic electroluminescent materials are gaining interest due to their enhanced luminous efficiency and durability with applications spanning academia and industry (Saito et al., 1994). Perylene is a typical organic molecule for organic lightemitting devices. Deuterated polyfluoroperylene (PFDPR), in which the hydrogen of the polyfluoroperylene is replaced by a deuterium, has potential as a new luminescent material. However, synthesizing PFDPR is challenging due to the complexity and scale of the required deuteration processes. On the other hand, in machine learning, large amounts of data are required to improve the estimation accuracy. Takeda et al. (2023) has proposed the virtual variables-enabled generation of datasets for the prediction of the yield of the iodination reactions of the polyfluoronaphthalenes. Using this method, this study proposes a model to estimate the non-experimental yield of PFDPR with a high accuracy from a small amount of data. The experimental conditions investigated in this study were two variables; i.e., temperature and time, across 16 conditions. While comprehensive data for the polyfluoronaphthalenes were fully available, the polyfluoroperylene data were limited to only 8 conditions. the experimental data from polyfluoronaphthalenes determined the yield prediction of the polyfluoroperylene under untested conditions. This process involved optimization using virtual variables to maximize the coefficient of determination between the actual and predicted yields of PFDPR. The model's efficacy is highlighted by the close alignment of the predicted and actual yields, offering a promising tool for accelerating the PFDPR synthesis research.}
}
@article{MEAFA20252166,
title = {Metaverse and Generative AI’s Digital Capabilities For Supply Chain Resilience},
journal = {Procedia Computer Science},
volume = {253},
pages = {2166-2175},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.277},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002856},
author = {Azz-eddine Meafa and Abla Chaouni Benabdellah and Kamar Zekhnini},
keywords = {Metaverse, Generative AI, Digital Capabilities, Supply Chain Resilience},
abstract = {Supply chains (SCs) are facing disruptions and perturbations daily. As a result, building a resilient SC is crucial in such dynamics and conditions. To have the ability to navigate and recover from unexpected challenges has become a strategic imperative for organizations to ensure sustained operations, adaptability, and long-term continuity. Thus, emphasizing the adoption of new technologies to strengthen supply chain resilience (SCR) is not only a proactive way to respond to current turbulences. It is a forward-thinking strategy to prepare the SC networks for unexpected crises that may arise in the future. In this context, this article explores the integration of Metaverse and Generative AI (GenAI) to enhance this ability, focusing on their digital capabilities and fundamentals. To do so, a systematic literature review (SLR) approach was adopted to explore new insights about the subject, identify the digital capabilities of these technologies for SCR, and build on research ideas from the current literature. After reviewing 50 relevant papers from the literature, the study presents a framework that leverages a combination of Metaverse and Generative AI to ensure resilience. Also, it highlights the practical implications for managers about the potential of these technologies to build informed decisions to face uncertain situations and provides some future research perspectives for academics to push the boundaries of knowledge in this research area.}
}
@article{YU2025156006,
title = {Exploring multi-instance learning in whole slide imaging: Current and future perspectives},
journal = {Pathology - Research and Practice},
volume = {271},
pages = {156006},
year = {2025},
issn = {0344-0338},
doi = {https://doi.org/10.1016/j.prp.2025.156006},
url = {https://www.sciencedirect.com/science/article/pii/S0344033825001980},
author = {Jikai Yu and Hongda Chen and Lianxin Hu and Boyuan Wu and Shicheng Zhou and Jiayun Zhu and Yizhen Jiang and Shuwen Han and Zefeng Wang},
keywords = {Deep learning, Multi-instance learning(MIL), MIL applications, Whole slide image},
abstract = {Whole slide images (WSI), due to their gigabyte-scale size and ultra-high resolution, play a significant role in diagnostic pathology. However, the enormous data size makes it difficult to directly input these images into image processing units (GPU) for computation, limiting the development of automated screening and diagnostic algorithms. As an effective computational framework, multi-instance learning (MIL) has provided strong support in addressing this challenge. This review systematically summarizes the research progress and applications of MIL in WSI analysis, based on over 90 articles retrieved from Web of Science, IEEE Xplore and PubMed. It briefly outlines the unique advantages and specific improvements in handling whole slide images, with a focus on analyzing the core characteristics and performance of mainstream techniques in tasks such as cancer detection and subtype classification. The results indicate that methods like data preprocessing, multi-scale feature fusion, representative instance selection, and Transformer-based models significantly enhance the ability of MIL in WSI processing. Furthermore, this paper also summarizes the characteristics of different technologies and proposes future research directions to promote the widespread application of MIL in pathological diagnosis.}
}
@article{PILGRAM2025101320,
title = {A consensus privacy metrics framework for synthetic data},
journal = {Patterns},
pages = {101320},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101320},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925001680},
author = {Lisa Pilgram and Fida Kamal Dankar and Jörg Drechsler and Mark Elliot and Josep Domingo-Ferrer and Paul Francis and Murat Kantarcioglu and Linglong Kong and Bradley Malin and Krishnamurty Muralidhar and Puja Myles and Fabian Prasser and Jean Louis Raisaro and Chao Yan and Khaled {El Emam}},
keywords = {synthetic data, privacy, generative artificial intelligence, membership disclosure, attribute disclosure, identity disclosure, data sharing},
abstract = {Summary
Synthetic data generation is a promising approach for sharing data for secondary purposes in sensitive sectors. However, to meet ethical standards and legislative requirements, it is necessary to demonstrate that the privacy of the individuals upon which the synthetic records are based is adequately protected. Through an expert consensus process, we developed a framework for privacy evaluation in synthetic data. The most commonly used metrics measure similarity between real and synthetic data and are assumed to capture identity disclosure. Our findings indicate that they lack precise interpretation and should be avoided. There was consensus on the importance of membership and attribute disclosure, both of which involve inferring personal information. The framework provides recommendations to effectively measure these types of disclosures, which also apply to differentially private synthetic data if the privacy budget is not close to zero. We further present future research opportunities to support widespread adoption of synthetic data.}
}
@article{SUN2025105388,
title = {Real-world implementation of an AI learning tool-MetaGP-Edu in medical education: A multi-center cohort study},
journal = {Computers & Education},
volume = {237},
pages = {105388},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105388},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001563},
author = {Yili Sun and Fei Liu},
keywords = {Artificial intelligence in education (AIEd), Large language models (LLMs), Medical education, Improving classroom teaching, Evaluation methodologies},
abstract = {This study aimed to evaluate the real-world educational impact associated with the implementation of MetaGP-Edu, a bespoke generative artificial intelligence tool fine-tuned for medical learning, within the undergraduate Internal Medicine curriculum. We conducted a large-scale, multi-center retrospective cohort study utilizing historical academic records from six major medical schools in China (N = 1632). We evaluated student performance across multiple dimensions, including final scores that assessed both foundational knowledge recall and clinical reasoning—defined as the cognitive process of analyzing patient data to formulate a diagnosis and management plan. Formative in-tool skill metrics were also included. These outcomes were then compared between pre- and post-implementation cohorts (Pre-MetaGP-Edu vs. Post-MetaGP-Edu) using adjusted multivariable regression models. Analysis also included usage patterns and embedded competency test scores for the post-implementation cohort. Results indicated that students with access to MetaGP-Edu achieved significantly higher overall Internal Medicine scores (Adjusted Mean Difference: +8.2 points, P < 0.001). This improvement was primarily associated with significantly higher scores in clinical reasoning assessments (P < 0.001), with no significant difference observed in knowledge recall scores (P > 0.05). The positive association also varied across clinical topics, being more pronounced in complex system modules. Furthermore, within the post-implementation cohort, significant skill development was observed over time, and higher total usage time significantly predicted greater skill gains (Adjusted OR = 2.42, P < 0.001). In conclusion, supplementary integration of a domain-specific AI educational tool like MetaGP-Edu shows a positive association with enhanced medical student performance, particularly for higher-order reasoning skills, although student engagement appears critical to realizing these benefits.}
}
@article{MATLI2025718,
title = {Empowering communities through engaged scholarship to Shape AI Development for AI for Social Good},
journal = {Procedia Computer Science},
volume = {256},
pages = {718-722},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.171},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925005289},
author = {Walter Matli},
keywords = {Engaged Scholarship, AI, Social good, Community, Empowerment},
abstract = {The increasing development of Artificial Intelligence for social good brings immense potential to address pressing societal challenges. However, there is a growing recognition that realising this potential requires moving beyond a top-down approach and actively empowering communities to shape AI development. This paper argues that engaged scholarship is essential for facilitating this empowerment and ensuring that AI for social good benefits the communities it aims to serve. The purpose of this paper is to explore how engaged scholarship can bridge the gap between AI expertise and community needs. The findings indicate that engaged scholarship is the key to achieving this empowerment, emphasising collaboration, co-creation, and action-oriented research. The study analyses the challenges and opportunities within this domain; this paper provides a roadmap for researchers, practitioners, and policymakers to foster community empowerment in AI for social good. We argue that by focusing on community voices and priorities, the engaged scholarship can unlock the transformative potential of AI to create more equitable and just societies.}
}
@article{GONZALEZGARCIA2025e41559,
title = {Impact of ChatGPT usage on nursing students education: A cross-sectional study},
journal = {Heliyon},
volume = {11},
number = {1},
pages = {e41559},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41559},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024175901},
author = {Alberto Gonzalez-Garcia and David Bermejo-Martinez and Ana Isabel Lopez-Alonso and Bibiana Trevisson-Redondo and Cristian Martín-Vázquez and Silvia Perez-Gonzalez},
keywords = {ChatGPT, Nursing education, Artificial intelligence, Academic performance, Technological innovations, Student perceptions, Nurse},
abstract = {Background
The use of artificial intelligence tools, such as ChatGPT, is on the rise in nursing education. In the field of healthcare, ChatGPT can offer unique opportunities to enhance the learning and clinical practice of nursing students. However, it is still necessary to explore how this tool affects students' performance and perception in their nursing education.
Objective
The objective of this study was to evaluate the impact of ChatGPT on nursing students' education and determine how it influences their learning outcomes.
Design
This study employed a quantitative cross-sectional design.
Setting
The study was conducted in the Bachelor of Nursing program at the University of León, Spain.
Participants
Ninety-eight nursing students enrolled in the Nursing Care and Services Management course during the second semester of 2024 participated in the study.
Methods
Data were collected using three validated questionnaires that assessed sociodemographic characteristics, knowledge of artificial intelligence, and perceptions of using ChatGPT as an educational tool. The data were analyzed using IBM SPSS Statistics, version 29.1.
Results
Students who used ChatGPT showed a significant improvement in their academic grades (p < 0.05). Additionally, 89.5 % of the students reported significant improvements in their academic performance. Women perceived ChatGPT as especially useful for completing academic tasks (85.14 % versus 50.00 % in men, p = 0.003). A positive correlation was observed between prior use of ChatGPT and GPA (ρ = 0.240, p = 0.026).
Conclusions
ChatGPT is a valuable tool that enhances the learning and satisfaction of nursing students. Its integration into nursing education programs not only boosts academic performance but also promotes the adoption of technological innovations in professional training. Continuous incorporation of AI tools in education is recommended to improve academic outcomes and prepare students for evolving healthcare environments.}
}
@article{LI2024101916,
title = {A privacy risk identification framework of open government data: A mixed-method study in China},
journal = {Government Information Quarterly},
volume = {41},
number = {1},
pages = {101916},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101916},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X2400008X},
author = {Ying Li and Rui Yang and Yikun Lu},
keywords = {Privacy risks, Open government data, Privacy risk identification framework, Mixed methods},
abstract = {Open government data (OGD) has great potential to promote economic growth, stimulate innovation, and improve service efficiency. However, as more and more private information is collected by government information systems, private data become increasingly vulnerable. Thus, governments must monitor the privacy risks of OGD. The focus of this study is to identify privacy risk factors in the process of developing OGD. Using a mixed-method design, we developed a privacy risk identification framework based on evidence from China. According to the results of qualitative interviews, the privacy risk identification framework mainly includes five risk dimensions: data risk, institutional risk, technical risk, structural risk, and behavioral risk. We identified 17 risk factors under these five dimensions. We further developed the measurement items for each risk factor and verified the indicator framework through quantitative methods. Our research provides a theoretical basis for identifying the privacy risks in OGD, supporting governments in discovering and dealing with them accordingly. Future research can continuously explore potential privacy risks arising from merging technologies such as generative artificial intelligence when applied to OGD.}
}
@article{PILGRAM2025,
title = {Magnitude and Impact of Hallucinations in Tabular Synthetic Health Data on Prognostic Machine Learning Models: Validation Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/77893},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011215},
author = {Lisa Pilgram and Samer {El Kababji} and Dan Liu and Khaled {El Emam}},
keywords = {synthetic data, data utility, hallucinations, generative models, artificial intelligence, AI},
abstract = {Background
Generative artificial intelligence (AI) for tabular synthetic data generation (SDG) has significant potential to accelerate health care research and innovation. A critical limitation of generative AI, however, is hallucinations. Although this has been commonly observed in text-generating models, it may also occur in tabular SDG.
Objective
This study aims to investigate the magnitude of hallucinations in tabular synthetic data, whether their frequency increases with training data complexity, and the extent to which they impact the utility of synthetic data for downstream prognostic machine learning (ML) modeling tasks.
Methods
On the basis of 12 large and high-dimensional real-world health care datasets, 6354 training datasets of different complexity were created by varying the subset of variables included in each dataset. Synthetic data were generated using 7 different SDG models. Hallucinations were defined as synthetic records that did not exist in the population, and the hallucination rate (HR) was the proportion of hallucinations in a synthetic dataset. Classification was the downstream prognostic modeling task, conducted via an ML approach (light gradient boosted machine) and an artificial neural network (multilayer perceptron). Mixed-effects models were fitted to examine the relationship between training data complexity and the HR and the HR and the predictive performance of AI and ML models when trained on the synthetic data.
Results
The HR ranged from 0.3% to 100% (median 99.1%, IQR 98.5%-100.0%) and increased with training data complexity. However, in most SDG models, the HR did not affect AI and ML prognostic model performance. In the SDG models in which a significant association was detected, the estimated effect was very small, with a maximum decrease in the area under the receiver operating characteristic curve of –0.0002 (95% CI –0.0003 to –0.0002, P<.001) in light gradient boosting machine and –0.0001 (95% CI –0.0002 to –0.0001, P=.002) in multilayer perceptron.
Conclusions
These findings suggest that while hallucinations may be very common in synthetic tabular health data, they do not necessarily impair its utility for prognostic modeling.}
}
@article{SHEN2024,
title = {Empathy Toward Artificial Intelligence Versus Human Experiences and the Role of Transparency in Mental Health and Social Support Chatbot Design: Comparative Study},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/62679},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924001057},
author = {Jocelyn Shen and Daniella DiPaola and Safinah Ali and Maarten Sap and Hae Won Park and Cynthia Breazeal},
keywords = {empathy, large language models, ethics, transparency, crowdsourcing, human-computer interaction},
abstract = {Background
Empathy is a driving force in our connection to others, our mental well-being, and resilience to challenges. With the rise of generative artificial intelligence (AI) systems, mental health chatbots, and AI social support companions, it is important to understand how empathy unfolds toward stories from human versus AI narrators and how transparency plays a role in user emotions.
Objective
We aim to understand how empathy shifts across human-written versus AI-written stories, and how these findings inform ethical implications and human-centered design of using mental health chatbots as objects of empathy.
Methods
We conducted crowd-sourced studies with 985 participants who each wrote a personal story and then rated empathy toward 2 retrieved stories, where one was written by a language model, and another was written by a human. Our studies varied disclosing whether a story was written by a human or an AI system to see how transparent author information affects empathy toward the narrator. We conducted mixed methods analyses: through statistical tests, we compared user’s self-reported state empathy toward the stories across different conditions. In addition, we qualitatively coded open-ended feedback about reactions to the stories to understand how and why transparency affects empathy toward human versus AI storytellers.
Results
We found that participants significantly empathized with human-written over AI-written stories in almost all conditions, regardless of whether they are aware (t196=7.07, P<.001, Cohen d=0.60) or not aware (t298=3.46, P<.001, Cohen d=0.24) that an AI system wrote the story. We also found that participants reported greater willingness to empathize with AI-written stories when there was transparency about the story author (t494=–5.49, P<.001, Cohen d=0.36).
Conclusions
Our work sheds light on how empathy toward AI or human narrators is tied to the way the text is presented, thus informing ethical considerations of empathetic artificial social support or mental health chatbots.}
}
@article{STORNAIUOLO202483,
title = {Digital writing with AI platforms: the role of fun with/in generative AI},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {83-103},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-08-2023-0103},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000189},
author = {Amy Stornaiuolo and Jennifer Higgs and Opal Jawale and Rhianne Mae Martin},
keywords = {Creativity, Artificial intelligence, Literacy, AI, Platforms, Multiliteracies, Character.ai, Digital writing, Postdigital},
abstract = {Purpose
With the rapid advancement of generative artificial intelligence (AI), it is important to consider how young people are making sense of these tools in their everyday lives. Drawing on critical postdigital approaches to learning and literacy, this study aims to center the experiences and perspectives of young people who encounter and experiment with generative AI in their daily writing practices.
Design/methodology/approach
This critical case study of one digital platform – Character.ai – brings together an adolescent and adult authorship team to inquire about the intertwining of young people’s playful and critical perspectives when writing on/with digital platforms. Drawing on critical walkthrough methodology (Light et al., 2018), the authors engage digital methods to study how the creative and “fun” uses of AI in youths’ writing lives are situated in broader platform ecologies.
Findings
The findings suggest experimentation and pleasure are key aspects of young people’s engagement with generative AI. The authors demonstrate how one platform works to capitalize on these dimensions, even as youth users engage critically and artfully with the platform and develop their digital writing practices.
Practical implications
This study highlights how playful experimentation with generative AI can engage young people both in pleasurable digital writing and in exploration and contemplation of platforms dynamics and structures that shape their and others’ literate activities. Educators can consider young people’s creative uses of these evolving technologies as potential opportunities to develop a critical awareness of how commercial platforms seek to benefit from their users.
Originality/value
This study contributes to the development of a critical and humanist research agenda around generative AI by centering the experiences, perspectives and practices of young people who are underrepresented in the burgeoning research devoted to AI and literacies.}
}