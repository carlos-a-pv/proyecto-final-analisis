@inbook{10880588,
    author = {},
    booktitle = {Generative Artificial Intelligence for Biomedical and Smart Health Informatics},
    doi = {10.1002/9781394280735.fmatter},
    keywords = {},
    number = {},
    pages = {i-xli},
    title = {Front Matter},
    volume = {},
    year = {2025}
}

@inbook{10880604,
    author = {},
    booktitle = {Generative Artificial Intelligence for Biomedical and Smart Health Informatics},
    doi = {10.1002/9781394280735.index},
    keywords = {},
    number = {},
    pages = {623-655},
    title = {Index},
    volume = {},
    year = {2025}
}

@article{BAUCON2024112027,
    abstract = {Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment.},
    author = {Andrea Baucon and Corrado Morelli and Carlos {Neto de Carvalho} and Evelyn Kustascher},
    doi = {https://doi.org/10.1016/j.palaeo.2024.112027},
    issn = {0031-0182},
    journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
    keywords = {Supervolcano, Freshwater, Trace fossils, Caldera, Planolites, Artificial intelligence},
    pages = {112027},
    title = {Life in an Artinskian (Cisuralian) Permian megacaldera: Benthic palaeoecology in the shadow of the Bolzano Supervolcano (Athesian Volcanic District, Italy)},
    url = {https://www.sciencedirect.com/science/article/pii/S0031018224000166},
    volume = {638},
    year = {2024}
}

@article{DERAKHSHAN2025102114,
    abstract = {Research on the contributions of generative artificial intelligence (GAI) technologies to second language (L2) education has soared in the past couple of years. However, there is limited evidence pertaining to the impact of AI-mediated instruction on postgraduate students’ psycho-affective factors and the overall learning climate in English as a foreign language (EFL) context. To address this gap, the present study drew on motivational climate theory (MCT) to explore postgraduate EFL students’ perceptions of the role of GAI technologies in their emotional engagement and goal orientation. To do so, an interview was conducted with 30 postgraduate students using maximum variation sampling. The results of the inductive thematic analysis revealed that AI-mediated instruction had affected both the emotional engagement and goal orientation of the students. In particular, it was found that GAI tools fostered emotional engagement by ‘enlightening teacher-student classroom relationships’, ‘making the overall classroom culture/climate engaging, motivating, and updated’, ‘improving teachers’ action, instruction, and feedback quality’, ‘providing a personalized, interactive, and autonomy supporting education’, and ‘taping into learner-specific idiosyncrasies and individual differences’. Furthermore, GAI tools affected the students’ goal orientation by ‘facilitating the mastery of course content’, ‘setting personalized and achievable goals’, ‘fostering students’ performance comparison in the classroom’, and ‘providing a reflective and adaptive learning environment’. The findings are discussed and implications are provided for EFL teachers, students, teacher educators, and policymakers concerning the interplay of GAI, emotions, goal orientation, and motivational climate.},
    author = {Ali Derakhshan},
    doi = {https://doi.org/10.1016/j.lmot.2025.102114},
    issn = {0023-9690},
    journal = {Learning and Motivation},
    keywords = {Achievement goal theory, Emotional engagement, Generative artificial intelligence (GAI), Goal orientation, L2 education, Motivational climate theory (MCT), Self-determination theory (SDT)},
    pages = {102114},
    title = {EFL students’ perceptions about the role of generative artificial intelligence (GAI)-mediated instruction in their emotional engagement and goal orientation: A motivational climate theory (MCT) perspective in focus},
    url = {https://www.sciencedirect.com/science/article/pii/S0023969025000219},
    volume = {90},
    year = {2025}
}

@article{HAMED2024108782,
    abstract = {Summary
As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society.},
    author = {Ahmed Abdeen Hamed and Malgorzata Zachara-Szymanska and Xindong Wu},
    doi = {https://doi.org/10.1016/j.isci.2024.108782},
    issn = {2589-0042},
    journal = {iScience},
    keywords = {Biocomputational method, Bioinformatics, Biological sciences, Computational bioinformatics, Natural sciences, Neural networks, Artificial intelligence, Artificial intelligence applications},
    number = {2},
    pages = {108782},
    title = {Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI},
    url = {https://www.sciencedirect.com/science/article/pii/S2589004224000038},
    volume = {27},
    year = {2024}
}

@article{HARRER2023104512,
    abstract = {Summary
Large Language Models (LLMs) are a key component of generative artificial intelligence (AI) applications for creating new content including text, imagery, audio, code, and videos in response to textual instructions. Without human oversight, guidance and responsible design and operation, such generative AI applications will remain a party trick with substantial potential for creating and spreading misinformation or harmful and inaccurate content at unprecedented scale. However, if positioned and developed responsibly as companions to humans augmenting but not replacing their role in decision making, knowledge retrieval and other cognitive processes, they could evolve into highly efficient, trustworthy, assistive tools for information management. This perspective describes how such tools could transform data management workflows in healthcare and medicine, explains how the underlying technology works, provides an assessment of risks and limitations, and proposes an ethical, technical, and cultural framework for responsible design, development, and deployment. It seeks to incentivise users, developers, providers, and regulators of generative AI that utilises LLMs to collectively prepare for the transformational role this technology could play in evidence-based sectors.},
    author = {Stefan Harrer},
    doi = {https://doi.org/10.1016/j.ebiom.2023.104512},
    issn = {2352-3964},
    journal = {eBioMedicine},
    keywords = {Generative artificial intelligence, Large language models, Foundation models, AI ethics, Augmented human intelligence, Information management, AI trustworthiness},
    pages = {104512},
    title = {Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine},
    url = {https://www.sciencedirect.com/science/article/pii/S2352396423000774},
    volume = {90},
    year = {2023}
}

@article{KENOPURUM2025S301,
    author = {Jennifer Ken-Opurum and Sidharth Singh and P. Pranav and Rahul Bhonsle and Shekhar Thumake and Heather Marino and Luke Dunlap},
    doi = {https://doi.org/10.1016/j.jval.2025.04.1290},
    issn = {1098-3015},
    journal = {Value in Health},
    number = {6, Supplement 1},
    pages = {S301},
    title = {MSR139 Application of Generative Artificial Intelligence for Extracting Structured Data from Unstructured Bladder Cancer Pathology Reports},
    url = {https://www.sciencedirect.com/science/article/pii/S1098301525014159},
    volume = {28},
    year = {2025}
}

@article{LEE20241318,
    author = {Christoph I. Lee and Jonathan H. Chen and Marc D. Kohli and Andrew D. Smith and Joshua M. Liao},
    doi = {https://doi.org/10.1016/j.jacr.2024.01.020},
    issn = {1546-1440},
    journal = {Journal of the American College of Radiology},
    note = {Focus on Global Radiology},
    number = {8},
    pages = {1318-1320},
    title = {Generative Artificial Intelligence},
    url = {https://www.sciencedirect.com/science/article/pii/S1546144024001303},
    volume = {21},
    year = {2024}
}

@article{OWENS2025,
    abstract = {Background
Generative artificial intelligence (AI) chatbots may be useful tools for supporting shared prostate cancer (PrCA) screening decisions, but the information produced by these tools sometimes lack quality or credibility. “Prostate Cancer Info” is a custom GPT chatbot developed to provide plain-language PrCA information only from websites of key authorities on cancer and peer-reviewed literature.
Objective
The objective of this paper was to evaluate the accuracy, completeness, and readability of Prostate Cancer Info’s responses to frequently asked PrCA screening questions.
Methods
A total of 23 frequently asked PrCA questions were individually input into Prostate Cancer Info. Responses were recorded in Microsoft Word and reviewed by 2 raters for their accuracy and completeness. Readability of content was determined by pasting responses into a web-based Flesch Kincaid Reading Ease Scores calculator.
Results
Responses to all questions were accurate and culturally appropriate. In total, 17 of the 23 questions (74%) had complete responses. The average readability of responses was 64.5 (SD 8.7; written at an 8th-grade level).
Conclusions
Generative AI chatbots, such as Prostate Cancer Info, are great starting places for learning about PrCA screening and preparing men to engage in shared decision-making but should not be used as independent sources of PrCA information because key information may be omitted. Men are encouraged to use these tools to complement information received from a health care provider.},
    author = {Otis L Owens and Michael S Leonard},
    doi = {https://doi.org/10.2196/72522},
    issn = {2369-1999},
    journal = {JMIR Cancer},
    keywords = {generative artificial intelligence, chatbot, chatGPT, prostate cancer, cancer screening, shared decision making, artificial intelligence},
    title = {Evaluating an AI Chatbot “Prostate Cancer Info” for Providing Quality Prostate Cancer Screening Information: Cross-Sectional Study},
    url = {https://www.sciencedirect.com/science/article/pii/S2369199925000606},
    volume = {11},
    year = {2025}
}

@article{SEYFI2025104105,
    abstract = {As generative artificial intelligence (GAI) technologies become increasingly integrated into the travel industry, understanding the barriers tourists face in adopting these innovative technologies for their travel planning and decision-making has growingly become a critical area of focus. Drawing on the theoretical frameworks of innovation resistance and Big Five personality traits, this study surveyed potential travelers in Korea and the US to assess their personality characteristics, innovation resistance, and perceptions of AI-generated travel recommendations. The findings, derived from structural equation modeling, multi-group analysis, and fuzzy-set qualitative comparative analysis, reveal that variations in personality traits significantly affect tourists’ reluctance to adopting these technologies. Overall, the results of this study contribute to the theoretical understanding of acceptance of GAI and offer practical insights for tourism industry stakeholders, enabling them to tailor their offerings to different personality types and enhance the travel experience for a wide range of travelers.},
    author = {Siamak Seyfi and Myung Ja Kim and Amin Nazifi and Samantha Murdy and Tan Vo-Thanh},
    doi = {https://doi.org/10.1016/j.ijhm.2025.104105},
    issn = {0278-4319},
    journal = {International Journal of Hospitality Management},
    keywords = {Generative AI, ChatGPT, Innovation resistance, Personality traits, Tourist decision-making},
    pages = {104105},
    title = {Understanding tourist barriers and personality influences in embracing generative AI for travel planning and decision-making},
    url = {https://www.sciencedirect.com/science/article/pii/S0278431925000283},
    volume = {126},
    year = {2025}
}

@article{SUFFOLETTO2024,
    abstract = {This paper examines the use of text message (SMS) interventions for health-related behavioral support. It first outlines the historical progress in SMS intervention research publications and the variety of funds from US government agencies. A narrative review follows, highlighting the effectiveness of SMS interventions in key health areas, such as physical activity, diet and weight loss, mental health, and substance use, based on published meta-analyses. It then outlines advantages of text messaging compared to other digital modalities, including the real-time capability to collect information and deliver microdoses of intervention support. Crucial design elements are proposed to optimize effectiveness and longitudinal engagement across communication strategies, psychological foundations, and behavior change tactics. We then discuss advanced functionalities, such as the potential for generative artificial intelligence to improve user interaction. Finally, major challenges to implementation are highlighted, including the absence of a dedicated commercial platform, privacy and security concerns with SMS technology, difficulties integrating SMS interventions with medical informatics systems, and concerns about user engagement. Proposed solutions aim to facilitate the broader application and effectiveness of SMS interventions. Our hope is that these insights can assist researchers and practitioners in using SMS interventions to improve health outcomes and reducing disparities.},
    author = {Brian Suffoletto},
    doi = {https://doi.org/10.2196/58726},
    issn = {1438-8871},
    journal = {Journal of Medical Internet Research},
    keywords = {SMS intervention, behavior, intervention, review, text messaging, SMS, interventions, behaviors, behaviour, behaviours, effectiveness, development, impact, narrative review, physical activity, diet, weight loss, mental health, substance use, meta-analysis, chatbot, chatbots, large language model, LLM, large language models, mobile phone},
    title = {Deceptively Simple yet Profoundly Impactful: Text Messaging Interventions to Support Health},
    url = {https://www.sciencedirect.com/science/article/pii/S1438887124005235},
    volume = {26},
    year = {2024}
}
